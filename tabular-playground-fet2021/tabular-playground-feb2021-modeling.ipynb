{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n!pip install optuna \n\n# category variable\ncategory = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\n\n# continuous variable\ncontinuous = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', \n              'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']","execution_count":1,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: optuna in /opt/conda/lib/python3.7/site-packages (2.4.0)\nRequirement already satisfied: sqlalchemy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (1.3.22)\nRequirement already satisfied: cliff in /opt/conda/lib/python3.7/site-packages (from optuna) (3.6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (20.8)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from optuna) (1.19.5)\nRequirement already satisfied: cmaes>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (0.7.0)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from optuna) (4.7.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from optuna) (4.55.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from optuna) (1.0.0)\nRequirement already satisfied: scipy!=1.4.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (1.4.1)\nRequirement already satisfied: alembic in /opt/conda/lib/python3.7/site-packages (from optuna) (1.5.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->optuna) (2.4.7)\nRequirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->optuna) (1.0.4)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->optuna) (1.1.4)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from alembic->optuna) (2.8.1)\nRequirement already satisfied: stevedore>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (3.3.0)\nRequirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (5.5.1)\nRequirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (5.3.1)\nRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (0.7.2)\nRequirement already satisfied: cmd2!=0.8.3,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (1.4.0)\nRequirement already satisfied: attrs>=16.3.0 in /opt/conda/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.3.0)\nRequirement already satisfied: importlib-metadata>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.3.0)\nRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\nRequirement already satisfied: pyperclip>=1.6 in /opt/conda/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.8.1)\nRequirement already satisfied: colorama>=0.3.7 in /opt/conda/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.4.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.6.0->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.4.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.6.0->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.7.4.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic->optuna) (1.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil->alembic->optuna) (1.15.0)\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: category_encoders in /opt/conda/lib/python3.7/site-packages (2.2.2)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.4.1)\nRequirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.12.1)\nRequirement already satisfied: pandas>=0.21.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.2.0)\nRequirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.5.1)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.19.5)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.23.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2019.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"train_dataset = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\ntest_data = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')\ndataset = pd.concat([train_dataset, test_data])\n#print(dataset.info())\n\n# あきらかな外れ値は削除\n# [166042]はあきらかな外れ値\noutlier=[166042]\nfor x in outlier:\n    dataset = dataset.loc[dataset['id'] != x, :] \n\n# idとtargetは避難させておく\nid = dataset['id']\ntarget = dataset['target']\n# 相関が高いものだけを使用。この手法は有効だったと思うが、Catboostでのスコアは一定以上伸びなかった。\n   \n## ***** Encoding ***** ##\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\nscaler = RobustScaler()\nencoder = LabelEncoder()\n\ncat_index = []\nfor col in dataset.columns:\n#    # カテゴリ変数はエンコーディングを適用\n    if dataset[col].dtype == object:\n        cat_index.append(dataset.columns.get_loc(col))\n        #dataset[col] = encoder.fit_transform(dataset[col])\n\n#dataset[continuous] = scaler.fit_transform(dataset.loc[:,continuous].values)\n\n# targetのあるなしでtrainとtestを分割\ntrain = dataset.loc[dataset['target'].notnull(), :]\ntest  = dataset.loc[dataset['target'].isnull(), :]\n\nX = train.drop(columns=['id', 'target'])\ny = train['target']\nX_prediction = test.drop(columns=['id', 'target'])\nprediction_id = test.loc[:,'id']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport statistics as stat\nimport lightgbm as lgb\n\ndef kfold_processing(models, X, y):\n    kf = KFold(n_splits=5,random_state=48,shuffle=True)\n    rmse=[]  # list contains rmse for each fold\n    n=0\n    preds=0\n    \n    for model in models:\n        # kf.splitはindexを返すことに注意。データ自体じゃないよ!\n        for train, test in kf.split(X, y):\n            x_tr = X.iloc[train, :]\n            x_te = X.iloc[test,  :]\n            y_tr = y.iloc[train]\n            y_te = y.iloc[test]\n            model.fit(x_tr,y_tr,eval_set=[(x_te,y_te)],early_stopping_rounds=100,verbose=False)\n            rmse.append(mean_squared_error(y_te, model.predict(x_te), squared=False))\n            preds+=model.predict(X_prediction)\n            print(n+1,rmse[n])\n            n+=1\n\n        print(f'RMSE mean = {stat.mean(rmse)}')\n        print(f'RMSE = {rmse}')\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sklearn.ensemble.StackingRegressor — scikit-learn 0.24.1 documentation \n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import StackingRegressor\nbest_lgb_params = {'objective': 'regression', 'num_leaves': 87, 'max_depth': 9, 'learning_rate': 0.009582240516938432, 'n_estimators': 2553, \n                   'reg_alpha': 0.037580598353005736, 'reg_lambda': 0.02686007922451687, 'colsample_bytree': 0.5534542046480458}\n\nbest_xgb_params = {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'tree_method': 'gpu_hist','eta': 0.6967322281466614, \n                   'gamma': 0.0036942646535044962, 'max_depth': 6, 'sub_sample': 0.553569633282626, \n                   'colsample_bytree': 0.554663669927102, 'lambda': 0.001701369247469206, 'alpha': 0.009630419498745284, \n                   'learning_rate': 0.03446986865236482, 'n_estimators': 603}\n\n\n        \n\nlgb_model = lgb.LGBMRegressor(**best_lgb_params)\nxgb_model = xgb.XGBRegressor(**best_xgb_params)\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\n\nmodels = [lgb_model, xgb_model]\n\ny_pred = kfold_processing(models=models, X=X, y=y)\n\n'''\nestimators = [\n    ('lgb', lgb_model),\n    ('xgb_model', xgb_model)\n]\n\nstreg = StackingRegressor(estimators=estimators, cv=kf)\nstreg.fit(X,y)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optuna Tuning\n[lightgbm.LGBMRegressor — LightGBM 3.1.1.99 documentation](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html)  \n[XGBoostパラメータのまとめとランダムサーチ実装 - Qiita](https://qiita.com/FJyusk56/items/0649f4362587261bd57a)  \n[XGBoost Parameters — xgboost 1.4.0-SNAPSHOT documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)  \n[CatBoostRegressor - CatBoost. Documentation](https://catboost.ai/docs/concepts/python-reference_catboostregressor.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport optuna\n\ntrains = lgb.Dataset(X_train, y_train)\ntests = lgb.Dataset(X_test, y_test)\n\ndef objective(trial):\n    params = {\n        'objective': 'regression',\n        'num_leaves': trial.suggest_int('num_leaves', 5, 200),\n        'max_depth': trial.suggest_int('max_depth', 4, 10),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 0.1),\n        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.5, 1),\n        'random_state': 42\n    }  \n    \n    \n    lgb_model = lgb.LGBMRegressor(**params)\n    lgb_model.fit(X=X_train, y=y_train, eval_set = [(X_test, y_test)], eval_metric='rmse',  early_stopping_rounds=10)\n    y_pred = lgb_model.predict(X_test)\n    \n    return np.sqrt(mean_squared_error(y_test, y_pred))\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=50, n_jobs=-1)\nlgb_best = study.best_params\nprint(lgb_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport optuna\n\n# XGBoost Parameters — xgboost 1.4.0-SNAPSHOT documentation https://xgboost.readthedocs.io/en/latest/parameter.html\n\ndef objective(trial):\n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'tree_method': 'gpu_hist',\n        'eta': trial.suggest_loguniform('eta', 0.1, 1.0),\n        'gamma': trial.suggest_loguniform('gamma', 0.001, 5.),\n        'max_depth': trial.suggest_int('max_depth', 4, 10),\n        'sub_sample': trial.suggest_loguniform('sub_sample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.5, 1.0),\n        'lambda': trial.suggest_loguniform('lambda', 0.001, 0.01),\n        'alpha': trial.suggest_loguniform('alpha', 0.001, 0.01),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 0.1),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n    }  \n    \n    xgb_model = xgb.XGBRegressor(**params)\n    xgb_model.fit(X_train, y_train, eval_set = [(X_test, y_test)],  early_stopping_rounds=10)\n    y_pred = xgb_model.predict(X_test)\n    \n    return np.sqrt(mean_squared_error(y_test, y_pred))\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=50, n_jobs=-1)\nxgb_best = study.best_params\nprint(xgb_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## CatBoost Optuna\nfrom catboost import CatBoostRegressor\nfrom catboost import Pool\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport optuna\n\ncat_train = Pool(X_train, y_train, cat_features=category)\ncat_test = Pool(X_test, y_test, cat_features=category)\n\ndef objective(trial):\n    params = {\n        'iterations': trial.suggest_int('iterations', 100, 3000),\n        'depth': trial.suggest_int('depth', 4, 10),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n        'l2_leaf_reg': trial.suggest_int('l2_leaf', 1,10),\n        'eval_metric': 'RMSE',\n        'random_strength': trial.suggest_int('random_strength', 0, 100),\n        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n        'od_wait': trial.suggest_int('od_wait', 10, 50),\n        'use_best_model': True\n    }  \n    \n    model = CatBoostRegressor(**params)\n    model.fit(cat_train, eval_set=cat_test, early_stopping_rounds=10, verbose=0)\n    y_pred = model.predict(cat_test)\n    \n    return np.sqrt(mean_squared_error(y_test, y_pred))\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=100, n_jobs=-1)\ncat_best = study.best_params\nprint(cat_best)\nprint(f'Best Value: {study.best_value}')","execution_count":15,"outputs":[{"output_type":"stream","text":"\u001b[32m[I 2021-02-08 23:56:08,039]\u001b[0m A new study created in memory with name: no-name-0c8cdbe1-4b65-4dfd-b410-de882789d2ee\u001b[0m\n\u001b[32m[I 2021-02-09 00:00:43,424]\u001b[0m Trial 3 finished with value: 0.8721303443712503 and parameters: {'iterations': 467, 'depth': 5, 'learning_rate': 0.013103925677769053, 'l2_leaf': 3, 'random_strength': 93, 'bagging_temperature': 14.735305943508498, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 3 with value: 0.8721303443712503.\u001b[0m\n\u001b[32m[I 2021-02-09 00:23:23,170]\u001b[0m Trial 2 finished with value: 0.8426832060325465 and parameters: {'iterations': 2585, 'depth': 7, 'learning_rate': 0.07148267295307521, 'l2_leaf': 3, 'random_strength': 80, 'bagging_temperature': 19.696303321327303, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 2 with value: 0.8426832060325465.\u001b[0m\n\u001b[32m[I 2021-02-09 00:29:04,143]\u001b[0m Trial 4 finished with value: 0.8811541008757278 and parameters: {'iterations': 2750, 'depth': 5, 'learning_rate': 0.0002781743242777458, 'l2_leaf': 5, 'random_strength': 35, 'bagging_temperature': 2.8780298749951143, 'od_type': 'IncToDec', 'od_wait': 12}. Best is trial 2 with value: 0.8426832060325465.\u001b[0m\n\u001b[32m[I 2021-02-09 00:29:34,185]\u001b[0m Trial 5 finished with value: 0.8840391049200904 and parameters: {'iterations': 745, 'depth': 4, 'learning_rate': 0.00021083314191440853, 'l2_leaf': 10, 'random_strength': 7, 'bagging_temperature': 0.050365209387185556, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 2 with value: 0.8426832060325465.\u001b[0m\n\u001b[32m[I 2021-02-09 00:35:52,264]\u001b[0m Trial 6 finished with value: 0.8645834440457545 and parameters: {'iterations': 653, 'depth': 5, 'learning_rate': 0.013111444803931949, 'l2_leaf': 4, 'random_strength': 34, 'bagging_temperature': 71.69961766857688, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 2 with value: 0.8426832060325465.\u001b[0m\n","name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7e88ce27e4e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mcat_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         )\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    117\u001b[0m                         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     )\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 )\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred=regressor.predict(X_prediction)\nprint(y_pred/10)\noutput = pd.DataFrame({'id': prediction_id, 'target': y_pred/10})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lightgbm Optuna\n\nimport optuna.integration.lightgbm as lgb\n\ntrains = lgb.Dataset(X_train, y_train)\ntests = lgb.Dataset(X_test, y_test)\n\nparams = {'objective': 'mean_squared_error',\n         'metric': 'rmse'}\n\nlgb_model = lgb.train(params, trains, valid_sets=tests, early_stopping_rounds=10)\nbest_params = lgb_model.params\n\n\nimport lightgbm as lgb\n\nlgb_model = lgb.train(best_params, trains, valid_sets=tests)\ny_pred = lgb_model.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\nprint(mean_squared_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\ndef rmse(y_true, y_pred):\n    return tf.sqrt(tf.losses.mean_squared_error(y_true, y_pred))\n\n### ***********************************************************###\nmodel = tf.keras.Sequential()\n\n#model.add(tf.keras.layers.Dense(1024, activation='relu', input_shape=(X.shape[1],)))\n#model.add(tf.keras.layers.LeakyReLU())\n#model.add(tf.keras.layers.BatchNormalization())\n#model.add(tf.keras.layers.Dropout(0.5))\n\n#model.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu',input_shape=(X.shape[1],)))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.4))\n\n#model.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.4))\n\n#model.add(tf.keras.layers.Dense(units=256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#model.add(tf.keras.layers.Dense(units=256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#model.add(tf.keras.layers.Dense(units=128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\n\nmodel.add(tf.keras.layers.Dense(units=1, activation='linear'))\n### ***********************************************************###\n\noptimizer = tf.keras.optimizers.Adam(lr=0.005, decay=5e-4)\nmodel.compile(optimizer = optimizer, loss = 'mae', metrics = ['mse', 'mae'])\n\n#checkpoint_name = 'Model/{epoch:03d}-{val_loss:.5f}.hdf5'\ncheckpoint_name = 'DNN_BestModel.hdf5'\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\ncallback_list = [checkpoint]\n\nhistory = model.fit(X_train, y_train, validation_split=0.2, epochs = 500, batch_size = 1024,\n                    validation_data=(X_test, y_test), callbacks=callback_list)\ny_pred = model.predict(X_test).reshape(-1)\nRMSE = rmse(y_test, y_pred)\nprint(f'RMSE = {RMSE}')\n\nfig = plt.figure(figsize=(8,5))\nax = fig.add_subplot(111)\nax.set_ylim(0.6, 0.75)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.savefig(fname='1024 neurons enable LearningRate.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# CatBoosting\n'''\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfrom sklearn.model_selection import GridSearchCV\nparam_cat = {'depth':[6,8,10],\n            'learning_rate':[0.005, 0.001],\n            'l2_leaf_reg':[1,4,9],\n            'iterations':[100],\n            'cat_features':[feature_cat],\n            'eval_metric':['RMSE']\n            }\n\ngrid_result = GridSearchCV(estimator=CatBoostRegressor(),param_grid=param_cat, cv=kfold, scoring='neg_mean_squared_error', n_jobs = -1, verbose=2)\ngrid_result.fit(X_train, y_train)\ngrid_param = grid_result.best_params_\nprint(grid_param)\n\n\ncat = CatBoostRegressor(task_type='GPU', iterations=8000, use_best_model=True, depth=10, eval_metric='RMSE', l2_leaf_reg=1, learning_rate=0.001, early_stopping_rounds=10)\ncat.fit(X_train, y_train, cat_features=feature_cat, eval_set = (X_test, y_test))\ny_pred = cat.predict(X_test)\nprint(f'RMSE: {mean_squared_error(y_test, y_pred)}')\n\n\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}