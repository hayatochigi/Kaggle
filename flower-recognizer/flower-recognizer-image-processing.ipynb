{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('digit-reg': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5d329b79b66bb5f10ef54625f055718c749a87f375ca3776438035528903fee5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetの取得 https://www.tensorflow.org/tutorials/load_data/images?hl=ja\n",
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import pathlib\n",
    "data_root_orig = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "print(data_root)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[WindowsPath('data/daisy'), WindowsPath('data/dandelion'), WindowsPath('data/roses'), WindowsPath('data/sunflowers'), WindowsPath('data/tulips')]\n['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "# dataフォルダ内の各花の写真が保存されたフォルダリストと、フォルダ名からラベルを取得\n",
    "\n",
    "import pathlib\n",
    "data_folder = pathlib.Path('../input/flowers-recognition/flowers')\n",
    "flower_folders = []\n",
    "Labels = []\n",
    "for item in data_folder.iterdir():\n",
    "    flower_folders.append(item)\n",
    "    # フォルダ名からラベルを取得\n",
    "    Labels.append(str(item).split('/')[-1])\n",
    "\n",
    "print(flower_folders)\n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max Width: 1024\nMax Height: 442\nNumber of Images: 3670\n"
     ]
    }
   ],
   "source": [
    "# 異なる画像サイズはcrop and padしたいので、最大サイズを確認\n",
    "\n",
    "from PIL import Image\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "image_count = 0\n",
    "\n",
    "for folder_path in flower_folders:\n",
    "    for file_path in folder_path.iterdir():\n",
    "        if os.path.splitext(file_path)[-1] == '.jpg':\n",
    "            image = Image.open(file_path)\n",
    "            size = image.size\n",
    "            image.close()\n",
    "\n",
    "            # 画像リストの中から最大幅、高さを取得\n",
    "            if size[0] > max_width:\n",
    "                max_width = size[0]\n",
    "            if size[1] > max_height:\n",
    "                max_height = size[1]\n",
    "            image_count += 1\n",
    "print(f'Max Width: {max_width}\\nMax Height: {max_height}')\n",
    "print(f'Number of Images: {image_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacked_array:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def update(self, row):\n",
    "        for r in row:\n",
    "            self.data.append(r)\n",
    "            \n",
    "    def shape(self)\n",
    "        return self.data.shape\n",
    "\n",
    "    def finalize(self):\n",
    "        return np.reshape(self.data, newshape=(len(self.data)/5, 5))\n",
    "\n",
    "X_data = Stack_array()\n",
    "\n",
    "for folder_path in flower_folders:\n",
    "    for file_path in folder_path.iterdir():\n",
    "        if os.path.splitext(file_path)[-1] == '.jpg':\n",
    "            image = Image.open(file_path)\n",
    "            size = image.size\n",
    "            data = np.asarray(image)\n",
    "            X_data.update(data)\n",
    "            image.close()\n",
    "            print('*', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 100, 100, 3)\n(3, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Features datasetを作成\n",
    "dataset = np.empty([0,max_width, max_height, 3])\n",
    "for folder_path in flower_folders:\n",
    "    for file_path in folder_path.iterdir():\n",
    "        # jpg拡張子の画像ファイルのみを保存\n",
    "        if os.path.splitext(file_path)[-1] == '.jpg':\n",
    "            img_raw = tf.io.read_file(str(file_path))\n",
    "            img_tensor = tf.image.decode_image(img_raw)\n",
    "            # 画像をpadし、255.で正規化\n",
    "            img_tensor = tf.image.resize_with_crop_or_pad(img_tensor, max_width, max_height).numpy()\n",
    "            dataset = np.append(dataset, img_tensor.reshape([1,max_width, max_height,3]), axis=0)\n",
    "            print('*', end='')\n",
    "            # Tensorをlist化し、3-dimensionを4-dimensionへ変更\n",
    "            # DON'T USE tf.concat, why? \n",
    "            # https://stackoverflow.com/questions/55929960/what-is-the-best-way-to-handle-large-data-with-tensorflow-js-and-tf-tensor \n",
    "            #X = tf.concat([X, tf.reshape(img_tensor,[1,max_width,max_height,3])],axis=0)\n",
    "            #print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 3 samples\n",
      "3/3 [==============================] - 0s 160ms/sample - loss: 48.1106 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "''' 入力の確認用に使用\n",
    "\n",
    "# CNNの初期化。単純なSequentialモデルで作成。\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# 畳み込み https://keras.io/ja/layers/convolutional/\n",
    "# 128x128 RGB画像ではinput_shape=(128, 128, 3)となります．\n",
    "# 最初のレイヤーだけは、入り口となる入力シェイプが必要\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[100, 100, 3], data_format='channels_last'))\n",
    "\n",
    "# Poolingにより、ダウンサンプリング\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "\n",
    "# 2層目の中間層を追加\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "\n",
    "# Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# 接続\n",
    "# unitsは   レイヤーの出力形状\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# 出力層\n",
    "#cnn.add(tf.keras.layers.Dense(units=10, activation='sigmoid'))\n",
    "cnn.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "# 評価関数の選定 -> https://keras.io/ja/metrics/\n",
    "cnn.compile(optimizer = 'adam', loss = tf.keras.losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "y_train = np.array([1,1,1])\n",
    "answer = cnn.fit(z, y_train, epochs = 1, batch_size = 20)\n",
    "'''\n"
   ]
  }
 ]
}