{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\nds_test = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\ndataset = pd.concat([ds_train, ds_test], axis=0)\n\nPassengerId = ds_test['PassengerId'].values\n\ndataset = dataset.drop(['PassengerId', 'Name'], axis=1)\n\nprint(dataset.info())\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engginering","metadata":{}},{"cell_type":"code","source":"## Cabin\n# NaN means they didn't have a private cabin\ndataset['Cabin'] = dataset['Cabin'].fillna('N')\n\n# Retrive top alphabet\ndataset['Cabin'] = dataset['Cabin'].map(lambda x: x[0])\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ticket\nimport re\n\ndef strip_key_word(target=''):    \n    return target.replace('.', '').replace(' ', '').replace('/', '')\n\ndataset['Ticket'] = dataset['Ticket'].fillna('X').apply(lambda x: str(x).split()[0] if len(str(x).split()) > 1 else 'X')\ndataset['Ticket'] = dataset['Ticket'].apply(lambda x: strip_key_word(x))\n\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## SibSp and Parch\ndataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 #Add one, it's ownself\n#dataset['Alone'] = dataset['Family'].apply(lambda x: 0 if x >= 1 else 0)\n\n#dataset = dataset.drop(['SibSp', 'Parch'], axis=1)\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Value Engineering\n\n### Original dataset info()\n 0   Survived  100000 non-null  float64  \n 1   Pclass    200000 non-null  int64    \n 2   Sex       200000 non-null  object   \n 3   Age       193221 non-null  float64  \n 4   SibSp     200000 non-null  int64    \n 5   Parch     200000 non-null  int64    \n 6   Ticket    190196 non-null  object   \n 7   Fare      199733 non-null  float64  \n 8   Cabin     61303 non-null   object   \n 9   Embarked  199473 non-null  object   ","metadata":{}},{"cell_type":"code","source":"## Show missing value information\nprint(dataset.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Don't use MICE for numerical columns\n#  MICE uses linear-regression model, there might not be a linear relation between Age and Fare\n\npclass_age = dataset[['Age', 'Pclass']].dropna().groupby('Pclass').mean().to_dict()\ndataset.fillna({'Age': dataset['Pclass'].apply(lambda x: pclass_age['Age'][x])}, inplace=True)\n\n## Fare has a large skew\ndataset.fillna({'Fare': dataset['Fare'].mean()}, inplace=True)\ndataset['Fare'] = np.log(np.clip(dataset['Fare'], 1e-100, 1e+100))\n\n## Fillna with mode in Embarked\ndataset.fillna({'Embarked': dataset['Embarked'].mode().values[0]}, inplace=True)\n\nprint(dataset.info())\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding","metadata":{}},{"cell_type":"code","source":"dataset = pd.get_dummies(data=dataset, columns=['Pclass', 'Sex', 'Cabin', 'Embarked'], drop_first=True)\n\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfor col in ['Ticket']:\n    dataset[col] = encoder.fit_transform(dataset[col])\n\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"ds_train = dataset[dataset['Survived'].notnull()]\nds_test = dataset[dataset['Survived'].isnull()]\nds_test = ds_test.drop(columns=['Survived'], axis=1)\n\ny = ds_train['Survived']\nX = ds_train.drop(columns=['Survived'], axis=1)\n\nprint(ds_train.shape)\nprint(ds_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\ndef stratified_lgb(X,y, params):\n    kf = StratifiedKFold(n_splits=5,random_state=42,shuffle=True)                  \n    accuracy=[]   # list contains AUC for each fold  \n    for tr_idx, te_idx in kf.split(X, y):\n        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n        lgb_classifier = lgb.LGBMClassifier(**params)\n        lgb_classifier.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False, early_stopping_rounds=200, eval_metric='auc')\n        \n        accuracy.append(accuracy_score(y_te, lgb_classifier.predict(X_te))) \n    return np.mean(accuracy)\n\n## LightGBM Classification\n\ndef objective(trial):\n    params = {\n            'objective': 'binary',\n            'metric': 'auc',\n            'n_estimators': 500,\n            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n            'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n            'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n            'learning_rate': trial.suggest_loguniform('learning_rate', 1e-7, 1e-2)\n        }\n\n    return stratified_lgb(X, y, params)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100, n_jobs=-1)\nlgb_best = study.best_params\nprint(lgb_best)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Predict\nlgb_best['n_estimators'] = 10000\nlgb_best['objective'] = 'binary'\nlgb_best['metric'] = 'auc'\n\nkf = StratifiedKFold(n_splits=5,random_state=42,shuffle=True)                  \npredict = pd.DataFrame()\nn=0   \nfor tr_idx, te_idx in kf.split(X, y):\n    X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n    y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n    lgb_classifier = lgb.LGBMClassifier(**lgb_best)\n    lgb_classifier.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False, early_stopping_rounds=2000, eval_metric='auc')\n    y_pred = lgb_classifier.predict(ds_test)\n    predict[n] = y_pred\n    n+=1\n\nresult = np.round(predict.mode(axis=1).loc[:,0].values).astype(int)\n\noutput = pd.DataFrame({'PassengerId': PassengerId, 'Survived': result})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}