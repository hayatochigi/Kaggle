{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Very very basic data ingest\n\nds_tr = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\n#print(ds_tr.info())\nds_pr = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')\n#print(ds_pr.info())\ndataset = pd.concat([ds_tr, ds_pr], axis=0)\n#print(dataset.info())\n\ncat_col = []\nnum_col = []\nfor col in ds_tr.columns:\n    if np.dtype(ds_tr[col]) == 'object':\n        cat_col.append(col)\n    else:\n        if col not in ['id', 'target']:\n            num_col.append(col)\n\nprint(f'Categorical is {cat_col}')\nprint(f'Numerical is {num_col}')\n\n# Label Encoding *****************\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfor cat in cat_col:\n    dataset[cat] = encoder.fit_transform(dataset[cat])\n# ********************************\n\n# Scaling ************************\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndataset[num_col] = scaler.fit_transform(dataset[num_col])\n\nds_train = dataset.loc[dataset['target'].notnull(),:]\nds_predict = dataset.loc[dataset['target'].isnull(),:]\n\ny_train = ds_train['target']\nX_train = ds_train.drop(['id','target'], axis=1)\n\nid = ds_predict['id']\nds_predict = ds_predict.drop(['id','target'], axis=1)","execution_count":2,"outputs":[{"output_type":"stream","text":"Categorical is ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']\nNumerical is ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Visualize dataset\n# In categorical, use histogram\n'''\nfig, axes = plt.subplots(5,4, figsize=(20,10))\nfor i, cat in enumerate(cat_col):\n    row = int(i/4)\n    col = int(i%4)\n    axes[row, col].set_title(cat)\n    plt.tight_layout()\n    ds_tr[cat].hist(ax=axes[row, col])\n\n# In numerical, use scatter\nfig, axes = plt.subplots(3,4, figsize=(20,10))\nfor i, num in enumerate(num_col):\n    row = int(i/4)\n    col = int(i%4)\n    axes[row, col].set_title(num)\n    plt.tight_layout()\n    ds_tr[num].plot(ax=axes[row, col])\n'''","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"'\\nfig, axes = plt.subplots(5,4, figsize=(20,10))\\nfor i, cat in enumerate(cat_col):\\n    row = int(i/4)\\n    col = int(i%4)\\n    axes[row, col].set_title(cat)\\n    plt.tight_layout()\\n    ds_tr[cat].hist(ax=axes[row, col])\\n\\n# In numerical, use scatter\\nfig, axes = plt.subplots(3,4, figsize=(20,10))\\nfor i, num in enumerate(num_col):\\n    row = int(i/4)\\n    col = int(i%4)\\n    axes[row, col].set_title(num)\\n    plt.tight_layout()\\n    ds_tr[num].plot(ax=axes[row, col])\\n'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# SMOTE \nTo resolve imbalanced data, try [SMOTENC](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(f'Orignal X shape = {X_train.shape}')\n#sm = SMOTE()\n#X_train, y_train = sm.fit_resample(X_train,y_train)\n#print(f'SMOTED X shape = {X_train.shape}')\n\n#from sklearn.model_selection import train_test_split\n#X_tr, X_te, y_tr, y_te = train_test_split(X_train,y_train,test_size=0.2,random_state=42)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lightgbm Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"def stratified_lgb(X,y, params):\n    kf = StratifiedKFold(n_splits=5,random_state=48,shuffle=True)                  \n    auc=[]   # list contains AUC for each fold  \n    n=0   \n    for tr_idx, te_idx in kf.split(X, y):\n        X_tr, X_te = X_train.iloc[tr_idx], X_train.iloc[te_idx]\n        y_tr, y_te = y_train.iloc[tr_idx], y_train.iloc[te_idx]\n        lgb_classifier = lgb.LGBMClassifier(**params)\n        lgb_classifier.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False, early_stopping_rounds=50)\n        \n        auc.append(roc_auc_score(y_te, lgb_classifier.predict_proba(X_te)[:, 1]))                               \n        n+=1\n    return np.mean(auc)\n\n\n## LightGBM Classification\n\nimport optuna\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, recall_score\n\ndef objective(trial):\n    params = {\n            'objective': 'binary',\n            'metric': 'binary_logloss',\n            'n_estimators': 50,\n            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n            'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n            'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n            'learning_rate': trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n        }\n\n    return stratified_lgb(X_train, y_train, params)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50, n_jobs=-1)\nlgb_best = study.best_params\nprint(lgb_best)","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"output_type":"stream","text":"\u001b[32m[I 2021-03-26 07:39:54,744]\u001b[0m A new study created in memory with name: no-name-5b1270e6-e7b9-4d62-8c7d-79e3eec58f2b\u001b[0m\n\u001b[32m[I 2021-03-26 07:40:54,852]\u001b[0m Trial 3 finished with value: 0.88104367434755 and parameters: {'lambda_l1': 0.17679212147643725, 'lambda_l2': 0.06011326497167807, 'num_leaves': 118, 'feature_fraction': 0.4745936990970153, 'bagging_fraction': 0.4020585792940372, 'bagging_freq': 6, 'min_child_samples': 93, 'learning_rate': 0.002200355986871634}. Best is trial 3 with value: 0.88104367434755.\u001b[0m\n\u001b[32m[I 2021-03-26 07:41:04,723]\u001b[0m Trial 2 finished with value: 0.8716613657646624 and parameters: {'lambda_l1': 0.00016767630546039302, 'lambda_l2': 0.054977729230618035, 'num_leaves': 99, 'feature_fraction': 0.9242526287338781, 'bagging_fraction': 0.7350678834162303, 'bagging_freq': 2, 'min_child_samples': 69, 'learning_rate': 9.21777917550574e-06}. Best is trial 3 with value: 0.88104367434755.\u001b[0m\n\u001b[32m[I 2021-03-26 07:41:08,747]\u001b[0m Trial 1 finished with value: 0.8745257848162208 and parameters: {'lambda_l1': 6.158374638869857e-07, 'lambda_l2': 1.670105676865002e-05, 'num_leaves': 115, 'feature_fraction': 0.826994318081076, 'bagging_fraction': 0.858715759420158, 'bagging_freq': 6, 'min_child_samples': 59, 'learning_rate': 1.3330294696789387e-06}. Best is trial 3 with value: 0.88104367434755.\u001b[0m\n\u001b[32m[I 2021-03-26 07:41:31,274]\u001b[0m Trial 0 finished with value: 0.882348035681771 and parameters: {'lambda_l1': 1.1575742530154535e-05, 'lambda_l2': 3.701161899141912e-08, 'num_leaves': 239, 'feature_fraction': 0.5869868997431732, 'bagging_fraction': 0.7346613964661326, 'bagging_freq': 6, 'min_child_samples': 30, 'learning_rate': 7.06370908675415e-05}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:42:19,357]\u001b[0m Trial 4 finished with value: 0.8758540010776997 and parameters: {'lambda_l1': 4.563453123517463e-08, 'lambda_l2': 0.0003214604222338589, 'num_leaves': 176, 'feature_fraction': 0.9091266200587532, 'bagging_fraction': 0.727486229006248, 'bagging_freq': 4, 'min_child_samples': 39, 'learning_rate': 0.0010401800513136995}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:42:24,559]\u001b[0m Trial 5 finished with value: 0.8743324392567828 and parameters: {'lambda_l1': 2.063234169435967e-06, 'lambda_l2': 2.5084558337612962e-05, 'num_leaves': 165, 'feature_fraction': 0.9184620216838512, 'bagging_fraction': 0.716846120423271, 'bagging_freq': 3, 'min_child_samples': 35, 'learning_rate': 1.1991432042260937e-06}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:42:41,521]\u001b[0m Trial 6 finished with value: 0.8732016677731724 and parameters: {'lambda_l1': 0.0436310411210228, 'lambda_l2': 8.754545715098418, 'num_leaves': 247, 'feature_fraction': 0.9980399408466684, 'bagging_fraction': 0.6408596199780768, 'bagging_freq': 3, 'min_child_samples': 40, 'learning_rate': 1.0454177083034495e-05}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:42:50,652]\u001b[0m Trial 7 finished with value: 0.8705340927237737 and parameters: {'lambda_l1': 5.763338233201963e-07, 'lambda_l2': 6.615342747105278e-07, 'num_leaves': 141, 'feature_fraction': 0.9944337587437243, 'bagging_fraction': 0.74398782113298, 'bagging_freq': 4, 'min_child_samples': 24, 'learning_rate': 4.970618339229857e-06}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:43:32,297]\u001b[0m Trial 11 finished with value: 0.8654392284694715 and parameters: {'lambda_l1': 5.719552766884269e-08, 'lambda_l2': 0.013415615925132829, 'num_leaves': 33, 'feature_fraction': 0.8945225989392829, 'bagging_fraction': 0.9142676235364385, 'bagging_freq': 1, 'min_child_samples': 92, 'learning_rate': 0.0006022286976638628}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:43:58,418]\u001b[0m Trial 8 finished with value: 0.8807440929214498 and parameters: {'lambda_l1': 3.291407862736628e-08, 'lambda_l2': 0.00047560794278916327, 'num_leaves': 242, 'feature_fraction': 0.7479858076127983, 'bagging_fraction': 0.6490617066435966, 'bagging_freq': 6, 'min_child_samples': 29, 'learning_rate': 8.909068789451822e-06}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:44:04,143]\u001b[0m Trial 9 finished with value: 0.8767113989838414 and parameters: {'lambda_l1': 0.06739838278500083, 'lambda_l2': 0.2622866649805222, 'num_leaves': 239, 'feature_fraction': 0.900374186722649, 'bagging_fraction': 0.7917836196254893, 'bagging_freq': 6, 'min_child_samples': 18, 'learning_rate': 2.020588892165115e-06}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:44:21,355]\u001b[0m Trial 10 finished with value: 0.8770647174496483 and parameters: {'lambda_l1': 0.00016986258023421122, 'lambda_l2': 1.0402114557925044, 'num_leaves': 238, 'feature_fraction': 0.9103957300029298, 'bagging_fraction': 0.728449012316785, 'bagging_freq': 3, 'min_child_samples': 36, 'learning_rate': 1.6542305068975885e-05}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:44:53,697]\u001b[0m Trial 14 finished with value: 0.8789244148951297 and parameters: {'lambda_l1': 7.365730947418778, 'lambda_l2': 1.2720127904628274e-08, 'num_leaves': 67, 'feature_fraction': 0.47815501000718075, 'bagging_fraction': 0.41660115073183146, 'bagging_freq': 7, 'min_child_samples': 6, 'learning_rate': 0.007302816721999737}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:45:04,268]\u001b[0m Trial 12 finished with value: 0.8803432332577208 and parameters: {'lambda_l1': 1.4491063394484753e-05, 'lambda_l2': 9.498422776053267e-08, 'num_leaves': 196, 'feature_fraction': 0.6953854226751048, 'bagging_fraction': 0.899392220646615, 'bagging_freq': 7, 'min_child_samples': 64, 'learning_rate': 3.6919228172441814e-05}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:45:07,991]\u001b[0m Trial 15 finished with value: 0.8780574844393867 and parameters: {'lambda_l1': 7.078907050860308, 'lambda_l2': 1.1980018082830134e-08, 'num_leaves': 54, 'feature_fraction': 0.4789972192641075, 'bagging_fraction': 0.4555816504424778, 'bagging_freq': 7, 'min_child_samples': 6, 'learning_rate': 0.006126483323505173}. Best is trial 0 with value: 0.882348035681771.\u001b[0m\n\u001b[32m[I 2021-03-26 07:45:24,628]\u001b[0m Trial 13 finished with value: 0.8824073851333667 and parameters: {'lambda_l1': 0.0005385974926439476, 'lambda_l2': 2.6764463367697197e-08, 'num_leaves': 223, 'feature_fraction': 0.5419798850762311, 'bagging_fraction': 0.4921759178201235, 'bagging_freq': 7, 'min_child_samples': 9, 'learning_rate': 0.0001439222121665655}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:45:55,642]\u001b[0m Trial 17 finished with value: 0.8784808347433455 and parameters: {'lambda_l1': 0.008276430949917235, 'lambda_l2': 0.0022978400932672444, 'num_leaves': 71, 'feature_fraction': 0.460720014713134, 'bagging_fraction': 0.5094300173551062, 'bagging_freq': 5, 'min_child_samples': 98, 'learning_rate': 0.00020459480614340293}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:46:06,595]\u001b[0m Trial 16 finished with value: 0.8823137858023508 and parameters: {'lambda_l1': 0.010614898681052976, 'lambda_l2': 7.254760480993674e-08, 'num_leaves': 190, 'feature_fraction': 0.5136663763437648, 'bagging_fraction': 0.4682723005886217, 'bagging_freq': 7, 'min_child_samples': 97, 'learning_rate': 9.426678580437977e-05}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:46:29,285]\u001b[0m Trial 18 finished with value: 0.8819789251468186 and parameters: {'lambda_l1': 0.015563143679423923, 'lambda_l2': 0.0037253431381304223, 'num_leaves': 201, 'feature_fraction': 0.5795181271058105, 'bagging_fraction': 0.5324963478938168, 'bagging_freq': 5, 'min_child_samples': 99, 'learning_rate': 0.00017226885840766507}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:46:45,830]\u001b[0m Trial 19 finished with value: 0.881551047267435 and parameters: {'lambda_l1': 0.004033845682903874, 'lambda_l2': 5.64559884136313e-07, 'num_leaves': 200, 'feature_fraction': 0.5893065160042945, 'bagging_fraction': 0.5455304786397871, 'bagging_freq': 5, 'min_child_samples': 16, 'learning_rate': 0.0001688885244060163}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n","name":"stderr"},{"output_type":"stream","text":"\u001b[32m[I 2021-03-26 07:47:17,546]\u001b[0m Trial 20 finished with value: 0.8819425652562412 and parameters: {'lambda_l1': 0.0014540397223706122, 'lambda_l2': 7.284091516389663e-07, 'num_leaves': 202, 'feature_fraction': 0.5779495377971744, 'bagging_fraction': 0.5625433046531221, 'bagging_freq': 7, 'min_child_samples': 12, 'learning_rate': 0.00012097287205047531}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:47:28,540]\u001b[0m Trial 21 finished with value: 0.8817686821352939 and parameters: {'lambda_l1': 0.0014392601804402569, 'lambda_l2': 2.3387328174926904e-06, 'num_leaves': 211, 'feature_fraction': 0.5884187091697821, 'bagging_fraction': 0.5524209366621688, 'bagging_freq': 5, 'min_child_samples': 15, 'learning_rate': 0.000160571688758693}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:47:53,617]\u001b[0m Trial 22 finished with value: 0.881850375322444 and parameters: {'lambda_l1': 0.0011338427599704632, 'lambda_l2': 2.0125571363422284e-06, 'num_leaves': 216, 'feature_fraction': 0.6160268365773812, 'bagging_fraction': 0.5912510586391541, 'bagging_freq': 5, 'min_child_samples': 13, 'learning_rate': 5.804020857247595e-05}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:48:00,239]\u001b[0m Trial 23 finished with value: 0.8803392221215169 and parameters: {'lambda_l1': 2.2934990726361502e-05, 'lambda_l2': 1.139008701645594e-05, 'num_leaves': 152, 'feature_fraction': 0.6297963688091288, 'bagging_fraction': 0.6164465337057105, 'bagging_freq': 5, 'min_child_samples': 51, 'learning_rate': 4.313604563351164e-05}. Best is trial 13 with value: 0.8824073851333667.\u001b[0m\n\u001b[32m[I 2021-03-26 07:48:37,701]\u001b[0m Trial 24 finished with value: 0.8834763011558693 and parameters: {'lambda_l1': 2.425787301631851e-05, 'lambda_l2': 6.07917616829183e-08, 'num_leaves': 222, 'feature_fraction': 0.40474747079141093, 'bagging_fraction': 0.622884947971879, 'bagging_freq': 7, 'min_child_samples': 81, 'learning_rate': 3.745825638600024e-05}. Best is trial 24 with value: 0.8834763011558693.\u001b[0m\n\u001b[32m[I 2021-03-26 07:48:50,476]\u001b[0m Trial 25 finished with value: 0.8835057054143484 and parameters: {'lambda_l1': 3.4210957013926886e-05, 'lambda_l2': 6.273626223829951e-08, 'num_leaves': 222, 'feature_fraction': 0.40061554826693435, 'bagging_fraction': 0.6410027268120786, 'bagging_freq': 7, 'min_child_samples': 79, 'learning_rate': 3.7017781632885974e-05}. Best is trial 25 with value: 0.8835057054143484.\u001b[0m\n\u001b[32m[I 2021-03-26 07:49:04,176]\u001b[0m Trial 26 finished with value: 0.8816672194257265 and parameters: {'lambda_l1': 2.3696326809271974e-05, 'lambda_l2': 5.512547109410044e-08, 'num_leaves': 171, 'feature_fraction': 0.5208039357750767, 'bagging_fraction': 0.46175922138383174, 'bagging_freq': 7, 'min_child_samples': 52, 'learning_rate': 0.000449752362606988}. Best is trial 25 with value: 0.8835057054143484.\u001b[0m\n\u001b[32m[I 2021-03-26 07:49:21,054]\u001b[0m Trial 27 finished with value: 0.8839002258451357 and parameters: {'lambda_l1': 1.3718247373771938e-05, 'lambda_l2': 6.819835956323443e-08, 'num_leaves': 254, 'feature_fraction': 0.40512626672535246, 'bagging_fraction': 0.454040531550707, 'bagging_freq': 7, 'min_child_samples': 81, 'learning_rate': 0.0007882016873817455}. Best is trial 27 with value: 0.8839002258451357.\u001b[0m\n\u001b[32m[I 2021-03-26 07:50:06,971]\u001b[0m Trial 28 finished with value: 0.8840637055447129 and parameters: {'lambda_l1': 2.667781840563479e-05, 'lambda_l2': 3.2546687996623065e-08, 'num_leaves': 254, 'feature_fraction': 0.40034023915427863, 'bagging_fraction': 0.8101008447155003, 'bagging_freq': 6, 'min_child_samples': 79, 'learning_rate': 0.0004122823377289655}. Best is trial 28 with value: 0.8840637055447129.\u001b[0m\n\u001b[32m[I 2021-03-26 07:50:16,619]\u001b[0m Trial 29 finished with value: 0.8840764958753324 and parameters: {'lambda_l1': 5.1257660311736815e-05, 'lambda_l2': 1.3263410496291926e-07, 'num_leaves': 256, 'feature_fraction': 0.408135824104198, 'bagging_fraction': 0.6513920734058962, 'bagging_freq': 7, 'min_child_samples': 77, 'learning_rate': 0.00046685378510359567}. Best is trial 29 with value: 0.8840764958753324.\u001b[0m\n\u001b[32m[I 2021-03-26 07:50:26,199]\u001b[0m Trial 30 finished with value: 0.8833571284491379 and parameters: {'lambda_l1': 9.813816187339804e-05, 'lambda_l2': 1.9407160862040695e-07, 'num_leaves': 217, 'feature_fraction': 0.40068647314896794, 'bagging_fraction': 0.668666196360852, 'bagging_freq': 6, 'min_child_samples': 77, 'learning_rate': 2.1673777682529492e-05}. Best is trial 29 with value: 0.8840764958753324.\u001b[0m\n\u001b[32m[I 2021-03-26 07:50:43,639]\u001b[0m Trial 31 finished with value: 0.8835235161159355 and parameters: {'lambda_l1': 4.2755260874114414e-06, 'lambda_l2': 2.1054136710858813e-07, 'num_leaves': 224, 'feature_fraction': 0.40032784541852634, 'bagging_fraction': 0.6594834848717833, 'bagging_freq': 6, 'min_child_samples': 81, 'learning_rate': 1.8239573178346646e-05}. Best is trial 29 with value: 0.8840764958753324.\u001b[0m\n\u001b[32m[I 2021-03-26 07:51:43,448]\u001b[0m Trial 32 finished with value: 0.8845157435741813 and parameters: {'lambda_l1': 4.313101019888192e-06, 'lambda_l2': 2.555668920414397e-07, 'num_leaves': 256, 'feature_fraction': 0.40942503350330045, 'bagging_fraction': 0.9983993336081348, 'bagging_freq': 6, 'min_child_samples': 80, 'learning_rate': 0.00222170822986667}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:51:53,440]\u001b[0m Trial 33 finished with value: 0.8842981351336109 and parameters: {'lambda_l1': 3.3247987777179676e-06, 'lambda_l2': 2.638006933322242e-07, 'num_leaves': 256, 'feature_fraction': 0.4258886167856878, 'bagging_fraction': 0.9691187925653901, 'bagging_freq': 6, 'min_child_samples': 82, 'learning_rate': 0.003037127682794744}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:51:59,741]\u001b[0m Trial 34 finished with value: 0.884113711595418 and parameters: {'lambda_l1': 1.1899467371229139e-06, 'lambda_l2': 1.1519449211795288e-08, 'num_leaves': 256, 'feature_fraction': 0.432895895653352, 'bagging_fraction': 0.8159500789773628, 'bagging_freq': 6, 'min_child_samples': 84, 'learning_rate': 0.0019380082729921547}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:52:22,329]\u001b[0m Trial 35 finished with value: 0.8842013243614867 and parameters: {'lambda_l1': 3.287510586028456e-06, 'lambda_l2': 1.0855548861754777e-08, 'num_leaves': 256, 'feature_fraction': 0.44201572103842846, 'bagging_fraction': 0.9961302102136227, 'bagging_freq': 6, 'min_child_samples': 86, 'learning_rate': 0.0021475631921174325}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:53:18,260]\u001b[0m Trial 36 finished with value: 0.8842971480306158 and parameters: {'lambda_l1': 3.0478031702711166e-07, 'lambda_l2': 1.2610478363500485e-08, 'num_leaves': 256, 'feature_fraction': 0.4334221962150376, 'bagging_fraction': 0.8181242175291075, 'bagging_freq': 6, 'min_child_samples': 71, 'learning_rate': 0.0030796185404125213}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:53:30,588]\u001b[0m Trial 37 finished with value: 0.8843071759867623 and parameters: {'lambda_l1': 2.736712151552435e-07, 'lambda_l2': 4.9973785154545754e-05, 'num_leaves': 255, 'feature_fraction': 0.4350794082238826, 'bagging_fraction': 0.9955976604932391, 'bagging_freq': 6, 'min_child_samples': 88, 'learning_rate': 0.002897615439836859}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:53:38,431]\u001b[0m Trial 38 finished with value: 0.8841844209292132 and parameters: {'lambda_l1': 2.8498024217321615e-07, 'lambda_l2': 6.266108382470705e-06, 'num_leaves': 252, 'feature_fraction': 0.44286428878444317, 'bagging_fraction': 0.9809585941429163, 'bagging_freq': 6, 'min_child_samples': 89, 'learning_rate': 0.0023869452925501947}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:53:59,585]\u001b[0m Trial 39 finished with value: 0.8840005778921066 and parameters: {'lambda_l1': 1.6551688484730123e-07, 'lambda_l2': 5.812028658691904e-05, 'num_leaves': 233, 'feature_fraction': 0.4443031694896054, 'bagging_fraction': 0.9996220623392709, 'bagging_freq': 6, 'min_child_samples': 89, 'learning_rate': 0.002835941949980426}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n","name":"stderr"},{"output_type":"stream","text":"\u001b[32m[I 2021-03-26 07:54:57,894]\u001b[0m Trial 40 finished with value: 0.8840566273033597 and parameters: {'lambda_l1': 2.2655468467126363e-07, 'lambda_l2': 3.713466559754379e-05, 'num_leaves': 234, 'feature_fraction': 0.44535693689298406, 'bagging_fraction': 0.9852768378384139, 'bagging_freq': 4, 'min_child_samples': 68, 'learning_rate': 0.0032424758142770528}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:55:11,133]\u001b[0m Trial 41 finished with value: 0.8838540744209624 and parameters: {'lambda_l1': 1.6937691243280752e-07, 'lambda_l2': 1.0798626215152728e-05, 'num_leaves': 236, 'feature_fraction': 0.5045045322535331, 'bagging_fraction': 0.9904756719545027, 'bagging_freq': 4, 'min_child_samples': 73, 'learning_rate': 0.003468029616374865}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:55:19,810]\u001b[0m Trial 42 finished with value: 0.8839874323136077 and parameters: {'lambda_l1': 1.5666612318523767e-07, 'lambda_l2': 2.7931142865636927e-05, 'num_leaves': 234, 'feature_fraction': 0.48995592382816494, 'bagging_fraction': 0.956998943933691, 'bagging_freq': 5, 'min_child_samples': 67, 'learning_rate': 0.004805571833048396}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:55:29,342]\u001b[0m Trial 43 finished with value: 0.8829629477599278 and parameters: {'lambda_l1': 1.4854737729739471e-08, 'lambda_l2': 7.35162929182889e-05, 'num_leaves': 182, 'feature_fraction': 0.5068952480551487, 'bagging_fraction': 0.9540289281205964, 'bagging_freq': 4, 'min_child_samples': 69, 'learning_rate': 0.004260324894208313}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:56:38,398]\u001b[0m Trial 44 finished with value: 0.883597526856347 and parameters: {'lambda_l1': 1.363986674811845e-08, 'lambda_l2': 1.8145622361044931e-06, 'num_leaves': 246, 'feature_fraction': 0.49583901832346683, 'bagging_fraction': 0.9479350586830375, 'bagging_freq': 5, 'min_child_samples': 71, 'learning_rate': 0.0013745987882029635}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:56:40,270]\u001b[0m Trial 47 finished with value: 0.8798513131441382 and parameters: {'lambda_l1': 2.484855403200382e-06, 'lambda_l2': 4.295737689698956e-07, 'num_leaves': 107, 'feature_fraction': 0.5515368731197484, 'bagging_fraction': 0.8923161433122189, 'bagging_freq': 6, 'min_child_samples': 87, 'learning_rate': 0.0013020633499319742}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:56:50,043]\u001b[0m Trial 45 finished with value: 0.8835828381353311 and parameters: {'lambda_l1': 2.6052405237876722e-06, 'lambda_l2': 4.289820654031738e-07, 'num_leaves': 246, 'feature_fraction': 0.4885526696269608, 'bagging_fraction': 0.9366103063336229, 'bagging_freq': 5, 'min_child_samples': 87, 'learning_rate': 0.0014671841235974995}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:56:59,516]\u001b[0m Trial 46 finished with value: 0.8833244504864736 and parameters: {'lambda_l1': 3.975444561392835e-06, 'lambda_l2': 3.651182858636437e-07, 'num_leaves': 246, 'feature_fraction': 0.5387781192329103, 'bagging_fraction': 0.9384197623598896, 'bagging_freq': 6, 'min_child_samples': 88, 'learning_rate': 0.0015504464830611753}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:57:27,963]\u001b[0m Trial 48 finished with value: 0.8815549092930107 and parameters: {'lambda_l1': 4.0871231564538495e-06, 'lambda_l2': 0.00012716349679397343, 'num_leaves': 117, 'feature_fraction': 0.5396362076385094, 'bagging_fraction': 0.8916491211772536, 'bagging_freq': 6, 'min_child_samples': 57, 'learning_rate': 0.008706683648618499}. Best is trial 32 with value: 0.8845157435741813.\u001b[0m\n\u001b[32m[I 2021-03-26 07:57:40,021]\u001b[0m Trial 49 finished with value: 0.8848710132155315 and parameters: {'lambda_l1': 4.302940448383378e-06, 'lambda_l2': 1.077771617437953e-08, 'num_leaves': 246, 'feature_fraction': 0.42965919004382874, 'bagging_fraction': 0.9224775786038552, 'bagging_freq': 6, 'min_child_samples': 59, 'learning_rate': 0.007573090063045077}. Best is trial 49 with value: 0.8848710132155315.\u001b[0m\n","name":"stderr"},{"output_type":"stream","text":"{'lambda_l1': 4.302940448383378e-06, 'lambda_l2': 1.077771617437953e-08, 'num_leaves': 246, 'feature_fraction': 0.42965919004382874, 'bagging_fraction': 0.9224775786038552, 'bagging_freq': 6, 'min_child_samples': 59, 'learning_rate': 0.007573090063045077}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2021/03/25\n# lgb_best = {'lambda_l1': 1.1669869035375718e-08, 'lambda_l2': 7.3221393789428e-07, 'num_leaves': 240, 'feature_fraction': 0.4510517074106803, 'bagging_fraction': 0.6612420891081325, 'bagging_freq': 1, 'min_child_samples': 28, 'learning_rate': 0.00992481068796537}\n\n# 2021/3/26 // n_estimators = 50\n# lgb_best = {'lambda_l1': 4.302940448383378e-06, 'lambda_l2': 1.077771617437953e-08, 'num_leaves': 246, 'feature_fraction': 0.42965919004382874, 'bagging_fraction': 0.9224775786038552, 'bagging_freq': 6, 'min_child_samples': 59, 'learning_rate': 0.007573090063045077}\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Estimators=[80,100,120,150,180,200,210,220,250,280,300,350,400,500,800,1000,1200,1500,2000,2500, 3000, 4000, 5000]\noptimized_est = 0\nauc_status = 0\nfor i in Estimators:\n    lgb_best['n_estimators']=i\n    auc = stratified_lgb(X_train, y_train, lgb_best)\n    if auc > auc_status:\n        auc_status = auc\n        optimized_est = i\n    print(\"\\n\\n For Estimators = {} \\t  AUC Score : {} \\n\\n\".format(i,auc))\n\nprint(f'Best estimator = {optimized_est}, auc = {auc_status}')\nlgb_best['n_estimators'] = optimized_est","execution_count":7,"outputs":[{"output_type":"stream","text":"[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n\n\n For Estimators = 80 \t  AUC Score : 0.8858311241691161 \n\n\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n\n\n For Estimators = 100 \t  AUC Score : 0.8861844593739638 \n\n\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n","name":"stdout"},{"output_type":"stream","text":"[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n\n\n For Estimators = 120 \t  AUC Score : 0.8866119620301351 \n\n\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n\n\n For Estimators = 150 \t  AUC Score : 0.8871349033761028 \n\n\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n","name":"stdout"},{"output_type":"stream","text":"[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n\n\n For Estimators = 180 \t  AUC Score : 0.8876797927695655 \n\n\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n\n\n For Estimators = 200 \t  AUC Score : 0.8879148212180686 \n\n\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n\n\n For Estimators = 210 \t  AUC Score : 0.888129413440694 \n\n\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n","name":"stdout"},{"output_type":"stream","text":"[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l1 is set=4.302940448383378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.302940448383378e-06\n[LightGBM] [Warning] bagging_fraction is set=0.9224775786038552, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224775786038552\n[LightGBM] [Warning] lambda_l2 is set=1.077771617437953e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.077771617437953e-08\n[LightGBM] [Warning] feature_fraction is set=0.42965919004382874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42965919004382874\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-07eb59f0cecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEstimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlgb_best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstratified_lgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mauc_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mauc_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-6d82f1ac7893>\u001b[0m in \u001b[0;36mstratified_lgb\u001b[0;34m(X, y, params)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlgb_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mauc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    855\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m                                         callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    615\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2458\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2460\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"# CatBoost Classification\n* category columnsfit\n* SMOTENC + CatBoost \"Best is trial 45 with value: 0.13424544780540504.\" "},{"metadata":{"trusted":true},"cell_type":"code","source":"## CatBoost Classification\n'''\nimport optuna\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import roc_auc_score\n\ndef objective(trial):\n    params = {\n        #'iterations' : trial.suggest_int('iterations', 50, 3000),\n        'iterations' : 1000,\n        'loss_function': 'CrossEntropy',\n        'depth' : trial.suggest_int('depth', 4, 10),                                       \n        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-6, 0.1),               \n        'random_strength' :trial.suggest_int('random_strength', 0, 100),                       \n        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00), \n        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n        'od_wait' :trial.suggest_int('od_wait', 10, 50)\n    }\n\n    # \n    model = CatBoostClassifier(**params)\n    \n    model.fit(X=X_tr, y=y_tr, eval_set=[(X_te, y_te)], use_best_model=True, early_stopping_rounds=50, verbose=False)\n    y_pred = model.predict(X_te)\n    \n    return 1 - roc_auc_score(y_te, y_pred)\n    \nfrom sklearn.model_selection import train_test_split\nX_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3)\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=100, n_jobs=-1)\ncat_best = study.best_params\nprint(cat_best)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Predict\nlgb_best['n_estimators'] = 2000\nkf = StratifiedKFold(n_splits=5,random_state=48,shuffle=True)                  \npreds = 0\nn=0   \nfor tr_idx, te_idx in kf.split(X_train, y_train):\n    X_tr, X_te = X_train.iloc[tr_idx], X_train.iloc[te_idx]\n    y_tr, y_te = y_train.iloc[tr_idx], y_train.iloc[te_idx]\n    lgb_classifier = lgb.LGBMClassifier(**lgb_best)\n    lgb_classifier.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False, early_stopping_rounds=50)\n    preds += lgb_classifier.predict_proba(ds_predict)[:, 1]/kf.n_splits \n\n\n'''\npredictor = CatBoostClassifier(**cat_best)\npredictor.fit(X=X_tr, y=y_tr, eval_set=[(X_te, y_te)],cat_features=cat_col, \n               use_best_model=True, early_stopping_rounds=50, verbose=False)\n    \ny_pred = predictor(predict_ds)\n'''\n\n\noutput = pd.DataFrame({'id': id, 'target': preds})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":8,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-8-aa23e1b41e54>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-aa23e1b41e54>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    lgb_best['n_estimators'] = 2---\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}