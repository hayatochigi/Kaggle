{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# category variable\ncategory = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\n\n# continuous variable\ncontinuous = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', \n              'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#features = ['cat1', 'cont0', 'cat2', 'cont11', 'cont13', 'cat8', 'cont8', 'cont1', 'cat9',\n#            'cont9', 'cont5', 'cat3', 'cat0', 'cat6', 'cont3', 'cat5', 'cont4', 'cont2', 'cont12']\n\ntrain_dataset = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\ntest_data = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')\ndataset = pd.concat([train_dataset, test_data])\n\n# あきらかな外れ値は削除\n# [166042]はあきらかな外れ値\noutlier=[166042]\nfor x in outlier:\n    dataset = dataset.loc[dataset['id'] != x, :]\n\n# idとtargetは避難させておく\nid = dataset['id']\ntarget = dataset['target']\n# 避難させたので遠慮なく削除\ndataset = dataset.drop(columns=['id', 'target'])\n# 相関が高いものだけを使用\n# この手法は有効だったと思うが、Catboostでのスコアは一定以上伸びなかった。\n\n# 重要度を確認するためにはLabelEncodingが有効\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\nencoder = LabelEncoder()\nscaler = RobustScaler()\n\nfor x in dataset.columns:\n    # notebookみると、みんなLabelEncoder使っているなぁ\n    if dataset[x].dtype == object:\n        dataset[x] = encoder.fit_transform(dataset[x])\n        #dataset = pd.get_dummies(dataset, columns=[x], drop_first=True)\n        \ndataset[continuous] = scaler.fit_transform(dataset.loc[:,continuous].values)\n\n# データセットにidとtargetを元に戻して\ndataset = pd.concat([id,dataset,target], axis=1)\n# targetのあるなしでtrainとtestを分割\ntrain = dataset.loc[dataset['target'].notnull(), :]\ntest  = dataset.loc[dataset['target'].isnull(), :]\n\nX = train.drop(columns=['id', 'target'])\ny = train['target']\nX_prediction = test.drop(columns=['id', 'target'])\nprediction_id = test.loc[:,'id']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler, StandardScaler\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet, BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.model_selection import cross_val_score\nfrom catboost import CatBoostRegressor\n\nfrom sklearn.ensemble import StackingRegressor\n\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\ndef cross_val(model):\n    score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=kfold)\n    print(f'{type(model).__name__} score = : {score.mean():.8f}')\n\n\nregressors = [LinearRegression(), Lasso(alpha=0.005),\n              #RandomForestRegressor(n_estimators = 100, criterion='mae', random_state=0, bootstrap=True),\n              lgb.LGBMRegressor(objective='regression', num_leaves=5, learning_rate=0.05, n_estimators=720, bagging_fraction=0.8, verbose=10),\n              GradientBoostingRegressor(n_estimators = 3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='RMSE', random_state=0),\n              xgb.XGBRegressor(colsample_bytree=0.463, gamma=0.0468, learning_rate=0.05, max_depth=3, min_child_weight=1.7817, n_estimators=2200, reg_alpha=0.4640, reg_lambda=0.8571, subsample=0.5213, silent=1, random_state=0, nthread=-1)\n             ]\n\n#for x in regressors:\n#    cross_val(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\nlight_grid = {'max_depth': [3, 5, 8],\n             'learning_rate': [0.001, 0.0001, 0.0001],\n             'n_estimators': [10, 100, 200, 500],\n              'num_leaves': [100, 300, 500]\n             }\nlgb_grid_search = GridSearchCV(lgb.LGBMRegressor(), light_grid, cv=kfold, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\nlgb_grid_search.fit(X,y)\nlgb_param = lgb_grid_search.best_params_\nprint(lgb_param)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n    \n    def fit(self, X, y, X_test, y_test):\n        self.models_ = [clone(x) for x in self.models]\n\n        for model in self.models_:\n            # CatBoostに関しては、eval_setが必須のためここでエラーが発生する。\n            # その場合はexceptでfit処理を行う\n            print(f'************ RUNNING : {model} ************')\n            try:\n                model.fit(X, y)\n            except:\n                model.fit(X, y, eval_set=(X_test, y_test))\n                \n            y_pred = model.predict(X_test)\n            print(f'{model} RMSE: {mean_squared_error(y_test, y_pred)}')\n            \n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack(\n            [model.predict(X) for model in self.models_]\n            )\n        return np.mean(predictions, axis=1)\n\n    \naveraged_models = AveragingModels(models = (cat, lasso, lgb_tuned))\naveraged_models.fit(X_train, y_train, X_test, y_test)\n\n# 予想してみる\nfrom sklearn.metrics import mean_squared_error\ny_pred = averaged_models.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\ndef rmse(y_true, y_pred):\n    return tf.sqrt(tf.losses.mean_squared_error(y_true, y_pred))\n\n### ***********************************************************###\nmodel = tf.keras.Sequential()\n\n#model.add(tf.keras.layers.Dense(1024, activation='relu', input_shape=(X.shape[1],)))\n#model.add(tf.keras.layers.LeakyReLU())\n#model.add(tf.keras.layers.BatchNormalization())\n#model.add(tf.keras.layers.Dropout(0.5))\n\n#model.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu',input_shape=(X.shape[1],)))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.4))\n\n#model.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.4))\n\n#model.add(tf.keras.layers.Dense(units=256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#model.add(tf.keras.layers.Dense(units=256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#model.add(tf.keras.layers.Dense(units=128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\n\nmodel.add(tf.keras.layers.Dense(units=1, activation='linear'))\n### ***********************************************************###\n\noptimizer = tf.keras.optimizers.Adam(lr=0.005, decay=5e-4)\nmodel.compile(optimizer = optimizer, loss = 'mae', metrics = ['mse', 'mae'])\n\n#checkpoint_name = 'Model/{epoch:03d}-{val_loss:.5f}.hdf5'\ncheckpoint_name = 'DNN_BestModel.hdf5'\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\ncallback_list = [checkpoint]\n\nhistory = model.fit(X_train, y_train, validation_split=0.2, epochs = 500, batch_size = 1024,\n                    validation_data=(X_test, y_test), callbacks=callback_list)\ny_pred = model.predict(X_test).reshape(-1)\nRMSE = rmse(y_test, y_pred)\nprint(f'RMSE = {RMSE}')\n\nfig = plt.figure(figsize=(8,5))\nax = fig.add_subplot(111)\nax.set_ylim(0.6, 0.75)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.savefig(fname='1024 neurons enable LearningRate.png')","execution_count":91,"outputs":[{"output_type":"stream","text":"Epoch 1/1000\n188/188 [==============================] - 3s 7ms/step - loss: 2.6093 - mse: 10.9217 - mae: 2.4182 - val_loss: 1.1590 - val_mse: 1.5188 - val_mae: 1.0212\n\nEpoch 00001: val_loss improved from inf to 1.15903, saving model to DNN_BestModel.hdf5\nEpoch 2/1000\n188/188 [==============================] - 1s 7ms/step - loss: 1.0651 - mse: 1.3750 - mae: 0.9448 - val_loss: 0.8273 - val_mse: 0.8061 - val_mae: 0.7495\n\nEpoch 00002: val_loss improved from 1.15903 to 0.82727, saving model to DNN_BestModel.hdf5\nEpoch 3/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.8652 - mse: 0.9475 - mae: 0.7969 - val_loss: 0.7949 - val_mse: 0.8181 - val_mae: 0.7481\n\nEpoch 00003: val_loss improved from 0.82727 to 0.79490, saving model to DNN_BestModel.hdf5\nEpoch 4/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7934 - mse: 0.8259 - mae: 0.7501 - val_loss: 0.7658 - val_mse: 0.7689 - val_mae: 0.7307\n\nEpoch 00004: val_loss improved from 0.79490 to 0.76577, saving model to DNN_BestModel.hdf5\nEpoch 5/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7711 - mse: 0.7977 - mae: 0.7383 - val_loss: 0.7545 - val_mse: 0.7677 - val_mae: 0.7279\n\nEpoch 00005: val_loss improved from 0.76577 to 0.75453, saving model to DNN_BestModel.hdf5\nEpoch 6/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7587 - mse: 0.7894 - mae: 0.7338 - val_loss: 0.7523 - val_mse: 0.8044 - val_mae: 0.7314\n\nEpoch 00006: val_loss improved from 0.75453 to 0.75232, saving model to DNN_BestModel.hdf5\nEpoch 7/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7535 - mse: 0.7916 - mae: 0.7337 - val_loss: 0.7429 - val_mse: 0.7617 - val_mae: 0.7260\n\nEpoch 00007: val_loss improved from 0.75232 to 0.74291, saving model to DNN_BestModel.hdf5\nEpoch 8/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7460 - mse: 0.7827 - mae: 0.7297 - val_loss: 0.7402 - val_mse: 0.7614 - val_mae: 0.7257\n\nEpoch 00008: val_loss improved from 0.74291 to 0.74025, saving model to DNN_BestModel.hdf5\nEpoch 9/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7434 - mse: 0.7801 - mae: 0.7292 - val_loss: 0.7379 - val_mse: 0.7617 - val_mae: 0.7245\n\nEpoch 00009: val_loss improved from 0.74025 to 0.73792, saving model to DNN_BestModel.hdf5\nEpoch 10/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7413 - mse: 0.7804 - mae: 0.7282 - val_loss: 0.7350 - val_mse: 0.7638 - val_mae: 0.7232\n\nEpoch 00010: val_loss improved from 0.73792 to 0.73505, saving model to DNN_BestModel.hdf5\nEpoch 11/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7397 - mse: 0.7782 - mae: 0.7281 - val_loss: 0.7361 - val_mse: 0.7714 - val_mae: 0.7253\n\nEpoch 00011: val_loss did not improve from 0.73505\nEpoch 12/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7388 - mse: 0.7787 - mae: 0.7283 - val_loss: 0.7355 - val_mse: 0.7696 - val_mae: 0.7259\n\nEpoch 00012: val_loss did not improve from 0.73505\nEpoch 13/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7340 - mse: 0.7710 - mae: 0.7247 - val_loss: 0.7303 - val_mse: 0.7640 - val_mae: 0.7219\n\nEpoch 00013: val_loss improved from 0.73505 to 0.73029, saving model to DNN_BestModel.hdf5\nEpoch 14/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7328 - mse: 0.7708 - mae: 0.7245 - val_loss: 0.7332 - val_mse: 0.7596 - val_mae: 0.7254\n\nEpoch 00014: val_loss did not improve from 0.73029\nEpoch 15/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7317 - mse: 0.7684 - mae: 0.7241 - val_loss: 0.7304 - val_mse: 0.7590 - val_mae: 0.7232\n\nEpoch 00015: val_loss did not improve from 0.73029\nEpoch 16/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7333 - mse: 0.7725 - mae: 0.7262 - val_loss: 0.7300 - val_mse: 0.7664 - val_mae: 0.7235\n\nEpoch 00016: val_loss improved from 0.73029 to 0.73004, saving model to DNN_BestModel.hdf5\nEpoch 17/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7296 - mse: 0.7675 - mae: 0.7232 - val_loss: 0.7264 - val_mse: 0.7641 - val_mae: 0.7204\n\nEpoch 00017: val_loss improved from 0.73004 to 0.72644, saving model to DNN_BestModel.hdf5\nEpoch 18/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7312 - mse: 0.7725 - mae: 0.7252 - val_loss: 0.7322 - val_mse: 0.7727 - val_mae: 0.7266\n\nEpoch 00018: val_loss did not improve from 0.72644\nEpoch 19/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7318 - mse: 0.7748 - mae: 0.7262 - val_loss: 0.7286 - val_mse: 0.7755 - val_mae: 0.7233\n\nEpoch 00019: val_loss did not improve from 0.72644\nEpoch 20/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7299 - mse: 0.7707 - mae: 0.7247 - val_loss: 0.7268 - val_mse: 0.7729 - val_mae: 0.7217\n\nEpoch 00020: val_loss did not improve from 0.72644\nEpoch 21/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7281 - mse: 0.7677 - mae: 0.7230 - val_loss: 0.7270 - val_mse: 0.7582 - val_mae: 0.7223\n\nEpoch 00021: val_loss did not improve from 0.72644\nEpoch 22/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7283 - mse: 0.7690 - mae: 0.7236 - val_loss: 0.7244 - val_mse: 0.7722 - val_mae: 0.7198\n\nEpoch 00022: val_loss improved from 0.72644 to 0.72435, saving model to DNN_BestModel.hdf5\nEpoch 23/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7286 - mse: 0.7716 - mae: 0.7241 - val_loss: 0.7251 - val_mse: 0.7564 - val_mae: 0.7208\n\nEpoch 00023: val_loss did not improve from 0.72435\nEpoch 24/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7280 - mse: 0.7695 - mae: 0.7237 - val_loss: 0.7233 - val_mse: 0.7605 - val_mae: 0.7191\n\nEpoch 00024: val_loss improved from 0.72435 to 0.72335, saving model to DNN_BestModel.hdf5\nEpoch 25/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7255 - mse: 0.7676 - mae: 0.7214 - val_loss: 0.7227 - val_mse: 0.7617 - val_mae: 0.7188\n\nEpoch 00025: val_loss improved from 0.72335 to 0.72274, saving model to DNN_BestModel.hdf5\nEpoch 26/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7266 - mse: 0.7677 - mae: 0.7227 - val_loss: 0.7240 - val_mse: 0.7570 - val_mae: 0.7202\n\nEpoch 00026: val_loss did not improve from 0.72274\nEpoch 27/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7272 - mse: 0.7684 - mae: 0.7235 - val_loss: 0.7241 - val_mse: 0.7704 - val_mae: 0.7204\n\nEpoch 00027: val_loss did not improve from 0.72274\nEpoch 28/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7264 - mse: 0.7683 - mae: 0.7228 - val_loss: 0.7233 - val_mse: 0.7684 - val_mae: 0.7198\n\nEpoch 00028: val_loss did not improve from 0.72274\nEpoch 29/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7265 - mse: 0.7691 - mae: 0.7230 - val_loss: 0.7233 - val_mse: 0.7604 - val_mae: 0.7199\n\nEpoch 00029: val_loss did not improve from 0.72274\nEpoch 30/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7264 - mse: 0.7680 - mae: 0.7231 - val_loss: 0.7277 - val_mse: 0.7765 - val_mae: 0.7245\n\nEpoch 00030: val_loss did not improve from 0.72274\nEpoch 31/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7259 - mse: 0.7666 - mae: 0.7227 - val_loss: 0.7237 - val_mse: 0.7560 - val_mae: 0.7206\n\nEpoch 00031: val_loss did not improve from 0.72274\nEpoch 32/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7279 - mse: 0.7725 - mae: 0.7249 - val_loss: 0.7221 - val_mse: 0.7574 - val_mae: 0.7192\n\nEpoch 00032: val_loss improved from 0.72274 to 0.72214, saving model to DNN_BestModel.hdf5\nEpoch 33/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7266 - mse: 0.7692 - mae: 0.7236 - val_loss: 0.7229 - val_mse: 0.7586 - val_mae: 0.7199\n\nEpoch 00033: val_loss did not improve from 0.72214\nEpoch 34/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7243 - mse: 0.7649 - mae: 0.7213 - val_loss: 0.7215 - val_mse: 0.7584 - val_mae: 0.7186\n\nEpoch 00034: val_loss improved from 0.72214 to 0.72148, saving model to DNN_BestModel.hdf5\nEpoch 35/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7271 - mse: 0.7711 - mae: 0.7242 - val_loss: 0.7235 - val_mse: 0.7613 - val_mae: 0.7206\n\nEpoch 00035: val_loss did not improve from 0.72148\nEpoch 36/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7247 - mse: 0.7647 - mae: 0.7219 - val_loss: 0.7209 - val_mse: 0.7629 - val_mae: 0.7182\n\nEpoch 00036: val_loss improved from 0.72148 to 0.72090, saving model to DNN_BestModel.hdf5\nEpoch 37/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7264 - mse: 0.7663 - mae: 0.7236 - val_loss: 0.7217 - val_mse: 0.7616 - val_mae: 0.7190\n\nEpoch 00037: val_loss did not improve from 0.72090\nEpoch 38/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7252 - mse: 0.7668 - mae: 0.7225 - val_loss: 0.7255 - val_mse: 0.7590 - val_mae: 0.7228\n\nEpoch 00038: val_loss did not improve from 0.72090\nEpoch 39/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7245 - mse: 0.7659 - mae: 0.7218 - val_loss: 0.7212 - val_mse: 0.7629 - val_mae: 0.7186\n\nEpoch 00039: val_loss did not improve from 0.72090\nEpoch 40/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7247 - mse: 0.7664 - mae: 0.7221 - val_loss: 0.7225 - val_mse: 0.7614 - val_mae: 0.7200\n\nEpoch 00040: val_loss did not improve from 0.72090\nEpoch 41/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7257 - mse: 0.7678 - mae: 0.7232 - val_loss: 0.7213 - val_mse: 0.7630 - val_mae: 0.7189\n\nEpoch 00041: val_loss did not improve from 0.72090\nEpoch 42/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7246 - mse: 0.7678 - mae: 0.7221 - val_loss: 0.7210 - val_mse: 0.7596 - val_mae: 0.7186\n\nEpoch 00042: val_loss did not improve from 0.72090\nEpoch 43/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7269 - mse: 0.7708 - mae: 0.7245 - val_loss: 0.7204 - val_mse: 0.7606 - val_mae: 0.7181\n\nEpoch 00043: val_loss improved from 0.72090 to 0.72044, saving model to DNN_BestModel.hdf5\nEpoch 44/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7235 - mse: 0.7661 - mae: 0.7211 - val_loss: 0.7226 - val_mse: 0.7666 - val_mae: 0.7203\n\nEpoch 00044: val_loss did not improve from 0.72044\nEpoch 45/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7246 - mse: 0.7671 - mae: 0.7223 - val_loss: 0.7228 - val_mse: 0.7564 - val_mae: 0.7205\n\nEpoch 00045: val_loss did not improve from 0.72044\nEpoch 46/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7272 - mse: 0.7698 - mae: 0.7249 - val_loss: 0.7217 - val_mse: 0.7553 - val_mae: 0.7195\n\nEpoch 00046: val_loss did not improve from 0.72044\nEpoch 47/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7231 - mse: 0.7651 - mae: 0.7209 - val_loss: 0.7202 - val_mse: 0.7596 - val_mae: 0.7180\n\nEpoch 00047: val_loss improved from 0.72044 to 0.72020, saving model to DNN_BestModel.hdf5\nEpoch 48/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7249 - mse: 0.7697 - mae: 0.7227 - val_loss: 0.7227 - val_mse: 0.7562 - val_mae: 0.7206\n\nEpoch 00048: val_loss did not improve from 0.72020\nEpoch 49/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7238 - mse: 0.7656 - mae: 0.7217 - val_loss: 0.7226 - val_mse: 0.7674 - val_mae: 0.7206\n\nEpoch 00049: val_loss did not improve from 0.72020\nEpoch 50/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7242 - mse: 0.7662 - mae: 0.7221 - val_loss: 0.7224 - val_mse: 0.7682 - val_mae: 0.7203\n\nEpoch 00050: val_loss did not improve from 0.72020\nEpoch 51/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7253 - mse: 0.7673 - mae: 0.7231 - val_loss: 0.7204 - val_mse: 0.7566 - val_mae: 0.7182\n\nEpoch 00051: val_loss did not improve from 0.72020\nEpoch 52/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7240 - mse: 0.7660 - mae: 0.7219 - val_loss: 0.7227 - val_mse: 0.7711 - val_mae: 0.7206\n\nEpoch 00052: val_loss did not improve from 0.72020\nEpoch 53/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7243 - mse: 0.7690 - mae: 0.7222 - val_loss: 0.7205 - val_mse: 0.7638 - val_mae: 0.7185\n\nEpoch 00053: val_loss did not improve from 0.72020\nEpoch 54/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7234 - mse: 0.7640 - mae: 0.7214 - val_loss: 0.7207 - val_mse: 0.7584 - val_mae: 0.7187\n\nEpoch 00054: val_loss did not improve from 0.72020\nEpoch 55/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7230 - mse: 0.7658 - mae: 0.7210 - val_loss: 0.7219 - val_mse: 0.7560 - val_mae: 0.7199\n\nEpoch 00055: val_loss did not improve from 0.72020\nEpoch 56/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7230 - mse: 0.7649 - mae: 0.7211 - val_loss: 0.7236 - val_mse: 0.7588 - val_mae: 0.7216\n\nEpoch 00056: val_loss did not improve from 0.72020\nEpoch 57/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7240 - mse: 0.7668 - mae: 0.7220 - val_loss: 0.7204 - val_mse: 0.7592 - val_mae: 0.7185\n\nEpoch 00057: val_loss did not improve from 0.72020\nEpoch 58/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7229 - mse: 0.7659 - mae: 0.7209 - val_loss: 0.7220 - val_mse: 0.7685 - val_mae: 0.7200\n\nEpoch 00058: val_loss did not improve from 0.72020\nEpoch 59/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7242 - mse: 0.7652 - mae: 0.7222 - val_loss: 0.7197 - val_mse: 0.7587 - val_mae: 0.7178\n\nEpoch 00059: val_loss improved from 0.72020 to 0.71975, saving model to DNN_BestModel.hdf5\nEpoch 60/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7241 - mse: 0.7674 - mae: 0.7221 - val_loss: 0.7201 - val_mse: 0.7589 - val_mae: 0.7181\n\nEpoch 00060: val_loss did not improve from 0.71975\nEpoch 61/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7242 - mse: 0.7677 - mae: 0.7222 - val_loss: 0.7219 - val_mse: 0.7544 - val_mae: 0.7200\n\nEpoch 00061: val_loss did not improve from 0.71975\nEpoch 62/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7220 - mse: 0.7616 - mae: 0.7200 - val_loss: 0.7217 - val_mse: 0.7620 - val_mae: 0.7198\n\nEpoch 00062: val_loss did not improve from 0.71975\nEpoch 63/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7230 - mse: 0.7640 - mae: 0.7211 - val_loss: 0.7211 - val_mse: 0.7575 - val_mae: 0.7192\n\nEpoch 00063: val_loss did not improve from 0.71975\nEpoch 64/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7221 - mse: 0.7650 - mae: 0.7202 - val_loss: 0.7209 - val_mse: 0.7596 - val_mae: 0.7190\n\nEpoch 00064: val_loss did not improve from 0.71975\nEpoch 65/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7244 - mse: 0.7652 - mae: 0.7226 - val_loss: 0.7195 - val_mse: 0.7588 - val_mae: 0.7177\n\nEpoch 00065: val_loss improved from 0.71975 to 0.71954, saving model to DNN_BestModel.hdf5\nEpoch 66/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7220 - mse: 0.7624 - mae: 0.7202 - val_loss: 0.7196 - val_mse: 0.7591 - val_mae: 0.7178\n\nEpoch 00066: val_loss did not improve from 0.71954\nEpoch 67/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7239 - mse: 0.7686 - mae: 0.7221 - val_loss: 0.7200 - val_mse: 0.7564 - val_mae: 0.7182\n\nEpoch 00067: val_loss did not improve from 0.71954\nEpoch 68/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7221 - mse: 0.7640 - mae: 0.7204 - val_loss: 0.7189 - val_mse: 0.7591 - val_mae: 0.7171\n\nEpoch 00068: val_loss improved from 0.71954 to 0.71888, saving model to DNN_BestModel.hdf5\nEpoch 69/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7221 - mse: 0.7638 - mae: 0.7203 - val_loss: 0.7196 - val_mse: 0.7548 - val_mae: 0.7178\n\nEpoch 00069: val_loss did not improve from 0.71888\nEpoch 70/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7235 - mse: 0.7663 - mae: 0.7218 - val_loss: 0.7198 - val_mse: 0.7624 - val_mae: 0.7180\n\nEpoch 00070: val_loss did not improve from 0.71888\nEpoch 71/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7229 - mse: 0.7655 - mae: 0.7211 - val_loss: 0.7198 - val_mse: 0.7518 - val_mae: 0.7181\n\nEpoch 00071: val_loss did not improve from 0.71888\nEpoch 72/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7233 - mse: 0.7644 - mae: 0.7216 - val_loss: 0.7188 - val_mse: 0.7583 - val_mae: 0.7170\n\nEpoch 00072: val_loss improved from 0.71888 to 0.71881, saving model to DNN_BestModel.hdf5\nEpoch 73/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7238 - mse: 0.7671 - mae: 0.7221 - val_loss: 0.7187 - val_mse: 0.7571 - val_mae: 0.7170\n\nEpoch 00073: val_loss improved from 0.71881 to 0.71873, saving model to DNN_BestModel.hdf5\nEpoch 74/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7219 - mse: 0.7627 - mae: 0.7202 - val_loss: 0.7194 - val_mse: 0.7574 - val_mae: 0.7176\n\nEpoch 00074: val_loss did not improve from 0.71873\nEpoch 75/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7221 - mse: 0.7660 - mae: 0.7204 - val_loss: 0.7189 - val_mse: 0.7573 - val_mae: 0.7171\n\nEpoch 00075: val_loss did not improve from 0.71873\nEpoch 76/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7227 - mse: 0.7640 - mae: 0.7210 - val_loss: 0.7207 - val_mse: 0.7542 - val_mae: 0.7189\n\nEpoch 00076: val_loss did not improve from 0.71873\nEpoch 77/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7232 - mse: 0.7647 - mae: 0.7215 - val_loss: 0.7190 - val_mse: 0.7574 - val_mae: 0.7173\n\nEpoch 00077: val_loss did not improve from 0.71873\nEpoch 78/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7208 - mse: 0.7609 - mae: 0.7191 - val_loss: 0.7194 - val_mse: 0.7551 - val_mae: 0.7177\n\nEpoch 00078: val_loss did not improve from 0.71873\nEpoch 79/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7211 - mse: 0.7620 - mae: 0.7194 - val_loss: 0.7197 - val_mse: 0.7537 - val_mae: 0.7180\n\nEpoch 00079: val_loss did not improve from 0.71873\nEpoch 80/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7225 - mse: 0.7625 - mae: 0.7208 - val_loss: 0.7195 - val_mse: 0.7613 - val_mae: 0.7178\n\nEpoch 00080: val_loss did not improve from 0.71873\nEpoch 81/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7233 - mse: 0.7653 - mae: 0.7216 - val_loss: 0.7189 - val_mse: 0.7591 - val_mae: 0.7173\n\nEpoch 00081: val_loss did not improve from 0.71873\nEpoch 82/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7220 - mse: 0.7655 - mae: 0.7203 - val_loss: 0.7188 - val_mse: 0.7582 - val_mae: 0.7171\n\nEpoch 00082: val_loss did not improve from 0.71873\nEpoch 83/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7623 - mae: 0.7196 - val_loss: 0.7198 - val_mse: 0.7617 - val_mae: 0.7182\n\nEpoch 00083: val_loss did not improve from 0.71873\nEpoch 84/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7637 - mae: 0.7196 - val_loss: 0.7194 - val_mse: 0.7632 - val_mae: 0.7178\n\nEpoch 00084: val_loss did not improve from 0.71873\nEpoch 85/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7614 - mae: 0.7186 - val_loss: 0.7200 - val_mse: 0.7525 - val_mae: 0.7183\n\nEpoch 00085: val_loss did not improve from 0.71873\nEpoch 86/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7216 - mse: 0.7624 - mae: 0.7200 - val_loss: 0.7219 - val_mse: 0.7534 - val_mae: 0.7203\n\nEpoch 00086: val_loss did not improve from 0.71873\nEpoch 87/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7235 - mse: 0.7662 - mae: 0.7219 - val_loss: 0.7189 - val_mse: 0.7580 - val_mae: 0.7173\n\nEpoch 00087: val_loss did not improve from 0.71873\nEpoch 88/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7233 - mse: 0.7649 - mae: 0.7217 - val_loss: 0.7196 - val_mse: 0.7545 - val_mae: 0.7180\n\nEpoch 00088: val_loss did not improve from 0.71873\nEpoch 89/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7608 - mae: 0.7195 - val_loss: 0.7195 - val_mse: 0.7584 - val_mae: 0.7179\n\nEpoch 00089: val_loss did not improve from 0.71873\nEpoch 90/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7216 - mse: 0.7632 - mae: 0.7200 - val_loss: 0.7191 - val_mse: 0.7563 - val_mae: 0.7175\n\nEpoch 00090: val_loss did not improve from 0.71873\nEpoch 91/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7217 - mse: 0.7629 - mae: 0.7201 - val_loss: 0.7197 - val_mse: 0.7547 - val_mae: 0.7182\n\nEpoch 00091: val_loss did not improve from 0.71873\nEpoch 92/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7216 - mse: 0.7612 - mae: 0.7200 - val_loss: 0.7190 - val_mse: 0.7555 - val_mae: 0.7174\n\nEpoch 00092: val_loss did not improve from 0.71873\nEpoch 93/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7219 - mse: 0.7626 - mae: 0.7203 - val_loss: 0.7189 - val_mse: 0.7601 - val_mae: 0.7173\n\nEpoch 00093: val_loss did not improve from 0.71873\nEpoch 94/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7208 - mse: 0.7610 - mae: 0.7192 - val_loss: 0.7196 - val_mse: 0.7572 - val_mae: 0.7180\n\nEpoch 00094: val_loss did not improve from 0.71873\nEpoch 95/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7227 - mse: 0.7644 - mae: 0.7211 - val_loss: 0.7196 - val_mse: 0.7571 - val_mae: 0.7181\n\nEpoch 00095: val_loss did not improve from 0.71873\nEpoch 96/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7226 - mse: 0.7647 - mae: 0.7211 - val_loss: 0.7194 - val_mse: 0.7583 - val_mae: 0.7178\n\nEpoch 00096: val_loss did not improve from 0.71873\nEpoch 97/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7593 - mae: 0.7191 - val_loss: 0.7193 - val_mse: 0.7610 - val_mae: 0.7177\n\nEpoch 00097: val_loss did not improve from 0.71873\nEpoch 98/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7230 - mse: 0.7644 - mae: 0.7214 - val_loss: 0.7186 - val_mse: 0.7618 - val_mae: 0.7170\n\nEpoch 00098: val_loss improved from 0.71873 to 0.71858, saving model to DNN_BestModel.hdf5\nEpoch 99/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7219 - mse: 0.7641 - mae: 0.7203 - val_loss: 0.7185 - val_mse: 0.7583 - val_mae: 0.7169\n\nEpoch 00099: val_loss improved from 0.71858 to 0.71847, saving model to DNN_BestModel.hdf5\nEpoch 100/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7230 - mse: 0.7670 - mae: 0.7215 - val_loss: 0.7205 - val_mse: 0.7537 - val_mae: 0.7190\n\nEpoch 00100: val_loss did not improve from 0.71847\nEpoch 101/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7240 - mse: 0.7676 - mae: 0.7225 - val_loss: 0.7202 - val_mse: 0.7609 - val_mae: 0.7187\n\nEpoch 00101: val_loss did not improve from 0.71847\nEpoch 102/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7629 - mae: 0.7195 - val_loss: 0.7193 - val_mse: 0.7560 - val_mae: 0.7177\n\nEpoch 00102: val_loss did not improve from 0.71847\nEpoch 103/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7222 - mse: 0.7652 - mae: 0.7207 - val_loss: 0.7199 - val_mse: 0.7600 - val_mae: 0.7184\n\nEpoch 00103: val_loss did not improve from 0.71847\nEpoch 104/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7611 - mae: 0.7198 - val_loss: 0.7194 - val_mse: 0.7572 - val_mae: 0.7179\n\nEpoch 00104: val_loss did not improve from 0.71847\nEpoch 105/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7212 - mse: 0.7640 - mae: 0.7197 - val_loss: 0.7212 - val_mse: 0.7539 - val_mae: 0.7197\n\nEpoch 00105: val_loss did not improve from 0.71847\nEpoch 106/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7227 - mse: 0.7647 - mae: 0.7212 - val_loss: 0.7193 - val_mse: 0.7612 - val_mae: 0.7178\n\nEpoch 00106: val_loss did not improve from 0.71847\nEpoch 107/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7219 - mse: 0.7649 - mae: 0.7205 - val_loss: 0.7192 - val_mse: 0.7614 - val_mae: 0.7177\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00107: val_loss did not improve from 0.71847\nEpoch 108/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7215 - mse: 0.7617 - mae: 0.7201 - val_loss: 0.7201 - val_mse: 0.7585 - val_mae: 0.7187\n\nEpoch 00108: val_loss did not improve from 0.71847\nEpoch 109/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7213 - mse: 0.7637 - mae: 0.7198 - val_loss: 0.7197 - val_mse: 0.7560 - val_mae: 0.7182\n\nEpoch 00109: val_loss did not improve from 0.71847\nEpoch 110/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7201 - mse: 0.7608 - mae: 0.7187 - val_loss: 0.7196 - val_mse: 0.7545 - val_mae: 0.7181\n\nEpoch 00110: val_loss did not improve from 0.71847\nEpoch 111/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7640 - mae: 0.7197 - val_loss: 0.7184 - val_mse: 0.7578 - val_mae: 0.7170\n\nEpoch 00111: val_loss improved from 0.71847 to 0.71844, saving model to DNN_BestModel.hdf5\nEpoch 112/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7219 - mse: 0.7642 - mae: 0.7204 - val_loss: 0.7189 - val_mse: 0.7603 - val_mae: 0.7175\n\nEpoch 00112: val_loss did not improve from 0.71844\nEpoch 113/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7218 - mse: 0.7630 - mae: 0.7204 - val_loss: 0.7193 - val_mse: 0.7561 - val_mae: 0.7178\n\nEpoch 00113: val_loss did not improve from 0.71844\nEpoch 114/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7211 - mse: 0.7623 - mae: 0.7196 - val_loss: 0.7186 - val_mse: 0.7578 - val_mae: 0.7172\n\nEpoch 00114: val_loss did not improve from 0.71844\nEpoch 115/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7209 - mse: 0.7631 - mae: 0.7194 - val_loss: 0.7186 - val_mse: 0.7569 - val_mae: 0.7171\n\nEpoch 00115: val_loss did not improve from 0.71844\nEpoch 116/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7214 - mse: 0.7626 - mae: 0.7200 - val_loss: 0.7189 - val_mse: 0.7575 - val_mae: 0.7175\n\nEpoch 00116: val_loss did not improve from 0.71844\nEpoch 117/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7226 - mse: 0.7645 - mae: 0.7211 - val_loss: 0.7190 - val_mse: 0.7545 - val_mae: 0.7176\n\nEpoch 00117: val_loss did not improve from 0.71844\nEpoch 118/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7606 - mae: 0.7184 - val_loss: 0.7189 - val_mse: 0.7566 - val_mae: 0.7175\n\nEpoch 00118: val_loss did not improve from 0.71844\nEpoch 119/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7216 - mse: 0.7641 - mae: 0.7201 - val_loss: 0.7187 - val_mse: 0.7603 - val_mae: 0.7173\n\nEpoch 00119: val_loss did not improve from 0.71844\nEpoch 120/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7208 - mse: 0.7633 - mae: 0.7193 - val_loss: 0.7187 - val_mse: 0.7576 - val_mae: 0.7173\n\nEpoch 00120: val_loss did not improve from 0.71844\nEpoch 121/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7182 - mse: 0.7586 - mae: 0.7168 - val_loss: 0.7188 - val_mse: 0.7582 - val_mae: 0.7174\n\nEpoch 00121: val_loss did not improve from 0.71844\nEpoch 122/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7218 - mse: 0.7646 - mae: 0.7204 - val_loss: 0.7195 - val_mse: 0.7655 - val_mae: 0.7180\n\nEpoch 00122: val_loss did not improve from 0.71844\nEpoch 123/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7220 - mse: 0.7634 - mae: 0.7206 - val_loss: 0.7189 - val_mse: 0.7574 - val_mae: 0.7175\n\nEpoch 00123: val_loss did not improve from 0.71844\nEpoch 124/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7220 - mse: 0.7654 - mae: 0.7206 - val_loss: 0.7191 - val_mse: 0.7560 - val_mae: 0.7177\n\nEpoch 00124: val_loss did not improve from 0.71844\nEpoch 125/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7622 - mae: 0.7193 - val_loss: 0.7187 - val_mse: 0.7617 - val_mae: 0.7173\n\nEpoch 00125: val_loss did not improve from 0.71844\nEpoch 126/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7638 - mae: 0.7199 - val_loss: 0.7186 - val_mse: 0.7606 - val_mae: 0.7172\n\nEpoch 00126: val_loss did not improve from 0.71844\nEpoch 127/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7224 - mse: 0.7661 - mae: 0.7210 - val_loss: 0.7197 - val_mse: 0.7628 - val_mae: 0.7183\n\nEpoch 00127: val_loss did not improve from 0.71844\nEpoch 128/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7229 - mse: 0.7669 - mae: 0.7216 - val_loss: 0.7209 - val_mse: 0.7643 - val_mae: 0.7195\n\nEpoch 00128: val_loss did not improve from 0.71844\nEpoch 129/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7220 - mse: 0.7633 - mae: 0.7206 - val_loss: 0.7188 - val_mse: 0.7549 - val_mae: 0.7174\n\nEpoch 00129: val_loss did not improve from 0.71844\nEpoch 130/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7219 - mse: 0.7644 - mae: 0.7205 - val_loss: 0.7185 - val_mse: 0.7558 - val_mae: 0.7171\n\nEpoch 00130: val_loss did not improve from 0.71844\nEpoch 131/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7222 - mse: 0.7649 - mae: 0.7208 - val_loss: 0.7187 - val_mse: 0.7558 - val_mae: 0.7173\n\nEpoch 00131: val_loss did not improve from 0.71844\nEpoch 132/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7210 - mse: 0.7615 - mae: 0.7196 - val_loss: 0.7189 - val_mse: 0.7592 - val_mae: 0.7176\n\nEpoch 00132: val_loss did not improve from 0.71844\nEpoch 133/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7614 - mae: 0.7189 - val_loss: 0.7189 - val_mse: 0.7602 - val_mae: 0.7176\n\nEpoch 00133: val_loss did not improve from 0.71844\nEpoch 134/1000\n188/188 [==============================] - 2s 10ms/step - loss: 0.7200 - mse: 0.7601 - mae: 0.7186 - val_loss: 0.7182 - val_mse: 0.7559 - val_mae: 0.7169\n\nEpoch 00134: val_loss improved from 0.71844 to 0.71823, saving model to DNN_BestModel.hdf5\nEpoch 135/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7208 - mse: 0.7607 - mae: 0.7194 - val_loss: 0.7184 - val_mse: 0.7579 - val_mae: 0.7171\n\nEpoch 00135: val_loss did not improve from 0.71823\nEpoch 136/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7223 - mse: 0.7662 - mae: 0.7209 - val_loss: 0.7182 - val_mse: 0.7578 - val_mae: 0.7168\n\nEpoch 00136: val_loss improved from 0.71823 to 0.71820, saving model to DNN_BestModel.hdf5\nEpoch 137/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7632 - mae: 0.7193 - val_loss: 0.7190 - val_mse: 0.7533 - val_mae: 0.7176\n\nEpoch 00137: val_loss did not improve from 0.71820\nEpoch 138/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7219 - mse: 0.7628 - mae: 0.7205 - val_loss: 0.7196 - val_mse: 0.7638 - val_mae: 0.7183\n\nEpoch 00138: val_loss did not improve from 0.71820\nEpoch 139/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7619 - mae: 0.7188 - val_loss: 0.7182 - val_mse: 0.7571 - val_mae: 0.7169\n\nEpoch 00139: val_loss improved from 0.71820 to 0.71820, saving model to DNN_BestModel.hdf5\nEpoch 140/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7226 - mse: 0.7670 - mae: 0.7212 - val_loss: 0.7185 - val_mse: 0.7559 - val_mae: 0.7172\n\nEpoch 00140: val_loss did not improve from 0.71820\nEpoch 141/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7222 - mse: 0.7638 - mae: 0.7208 - val_loss: 0.7183 - val_mse: 0.7588 - val_mae: 0.7170\n\nEpoch 00141: val_loss did not improve from 0.71820\nEpoch 142/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7631 - mae: 0.7193 - val_loss: 0.7196 - val_mse: 0.7543 - val_mae: 0.7183\n\nEpoch 00142: val_loss did not improve from 0.71820\nEpoch 143/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7214 - mse: 0.7638 - mae: 0.7200 - val_loss: 0.7188 - val_mse: 0.7578 - val_mae: 0.7175\n\nEpoch 00143: val_loss did not improve from 0.71820\nEpoch 144/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7632 - mae: 0.7194 - val_loss: 0.7194 - val_mse: 0.7591 - val_mae: 0.7181\n\nEpoch 00144: val_loss did not improve from 0.71820\nEpoch 145/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7594 - mae: 0.7180 - val_loss: 0.7200 - val_mse: 0.7577 - val_mae: 0.7187\n\nEpoch 00145: val_loss did not improve from 0.71820\nEpoch 146/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7216 - mse: 0.7653 - mae: 0.7203 - val_loss: 0.7187 - val_mse: 0.7545 - val_mae: 0.7174\n\nEpoch 00146: val_loss did not improve from 0.71820\nEpoch 147/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7220 - mse: 0.7647 - mae: 0.7206 - val_loss: 0.7187 - val_mse: 0.7542 - val_mae: 0.7174\n\nEpoch 00147: val_loss did not improve from 0.71820\nEpoch 148/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7235 - mse: 0.7667 - mae: 0.7222 - val_loss: 0.7188 - val_mse: 0.7547 - val_mae: 0.7175\n\nEpoch 00148: val_loss did not improve from 0.71820\nEpoch 149/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7237 - mse: 0.7680 - mae: 0.7224 - val_loss: 0.7188 - val_mse: 0.7619 - val_mae: 0.7175\n\nEpoch 00149: val_loss did not improve from 0.71820\nEpoch 150/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7628 - mae: 0.7190 - val_loss: 0.7181 - val_mse: 0.7556 - val_mae: 0.7167\n\nEpoch 00150: val_loss improved from 0.71820 to 0.71805, saving model to DNN_BestModel.hdf5\nEpoch 151/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7630 - mae: 0.7193 - val_loss: 0.7182 - val_mse: 0.7570 - val_mae: 0.7169\n\nEpoch 00151: val_loss did not improve from 0.71805\nEpoch 152/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7221 - mse: 0.7653 - mae: 0.7208 - val_loss: 0.7183 - val_mse: 0.7562 - val_mae: 0.7170\n\nEpoch 00152: val_loss did not improve from 0.71805\nEpoch 153/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7215 - mse: 0.7639 - mae: 0.7202 - val_loss: 0.7184 - val_mse: 0.7556 - val_mae: 0.7171\n\nEpoch 00153: val_loss did not improve from 0.71805\nEpoch 154/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7220 - mse: 0.7632 - mae: 0.7207 - val_loss: 0.7185 - val_mse: 0.7631 - val_mae: 0.7172\n\nEpoch 00154: val_loss did not improve from 0.71805\nEpoch 155/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7214 - mse: 0.7646 - mae: 0.7201 - val_loss: 0.7180 - val_mse: 0.7552 - val_mae: 0.7167\n\nEpoch 00155: val_loss improved from 0.71805 to 0.71804, saving model to DNN_BestModel.hdf5\nEpoch 156/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7231 - mse: 0.7669 - mae: 0.7219 - val_loss: 0.7185 - val_mse: 0.7578 - val_mae: 0.7172\n\nEpoch 00156: val_loss did not improve from 0.71804\nEpoch 157/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7210 - mse: 0.7643 - mae: 0.7197 - val_loss: 0.7181 - val_mse: 0.7561 - val_mae: 0.7169\n\nEpoch 00157: val_loss did not improve from 0.71804\nEpoch 158/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7199 - mse: 0.7592 - mae: 0.7186 - val_loss: 0.7182 - val_mse: 0.7589 - val_mae: 0.7169\n\nEpoch 00158: val_loss did not improve from 0.71804\nEpoch 159/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7175 - mse: 0.7569 - mae: 0.7162 - val_loss: 0.7190 - val_mse: 0.7535 - val_mae: 0.7178\n\nEpoch 00159: val_loss did not improve from 0.71804\nEpoch 160/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7575 - mae: 0.7176 - val_loss: 0.7177 - val_mse: 0.7560 - val_mae: 0.7165\n\nEpoch 00160: val_loss improved from 0.71804 to 0.71775, saving model to DNN_BestModel.hdf5\nEpoch 161/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7221 - mse: 0.7637 - mae: 0.7208 - val_loss: 0.7184 - val_mse: 0.7549 - val_mae: 0.7171\n\nEpoch 00161: val_loss did not improve from 0.71775\nEpoch 162/1000\n188/188 [==============================] - 2s 9ms/step - loss: 0.7213 - mse: 0.7640 - mae: 0.7200 - val_loss: 0.7176 - val_mse: 0.7567 - val_mae: 0.7163\n\nEpoch 00162: val_loss improved from 0.71775 to 0.71755, saving model to DNN_BestModel.hdf5\nEpoch 163/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7631 - mae: 0.7194 - val_loss: 0.7176 - val_mse: 0.7569 - val_mae: 0.7163\n\nEpoch 00163: val_loss did not improve from 0.71755\nEpoch 164/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7222 - mse: 0.7668 - mae: 0.7210 - val_loss: 0.7190 - val_mse: 0.7541 - val_mae: 0.7178\n\nEpoch 00164: val_loss did not improve from 0.71755\nEpoch 165/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7605 - mae: 0.7185 - val_loss: 0.7180 - val_mse: 0.7557 - val_mae: 0.7167\n\nEpoch 00165: val_loss did not improve from 0.71755\nEpoch 166/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7227 - mse: 0.7675 - mae: 0.7214 - val_loss: 0.7182 - val_mse: 0.7568 - val_mae: 0.7169\n\nEpoch 00166: val_loss did not improve from 0.71755\nEpoch 167/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7645 - mae: 0.7199 - val_loss: 0.7178 - val_mse: 0.7574 - val_mae: 0.7165\n\nEpoch 00167: val_loss did not improve from 0.71755\nEpoch 168/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7224 - mse: 0.7662 - mae: 0.7211 - val_loss: 0.7186 - val_mse: 0.7588 - val_mae: 0.7173\n\nEpoch 00168: val_loss did not improve from 0.71755\nEpoch 169/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7629 - mae: 0.7190 - val_loss: 0.7175 - val_mse: 0.7557 - val_mae: 0.7163\n\nEpoch 00169: val_loss improved from 0.71755 to 0.71751, saving model to DNN_BestModel.hdf5\nEpoch 170/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7620 - mae: 0.7194 - val_loss: 0.7182 - val_mse: 0.7605 - val_mae: 0.7169\n\nEpoch 00170: val_loss did not improve from 0.71751\nEpoch 171/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7238 - mse: 0.7687 - mae: 0.7225 - val_loss: 0.7186 - val_mse: 0.7549 - val_mae: 0.7174\n\nEpoch 00171: val_loss did not improve from 0.71751\nEpoch 172/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7638 - mae: 0.7198 - val_loss: 0.7183 - val_mse: 0.7609 - val_mae: 0.7170\n\nEpoch 00172: val_loss did not improve from 0.71751\nEpoch 173/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7627 - mae: 0.7190 - val_loss: 0.7184 - val_mse: 0.7554 - val_mae: 0.7171\n\nEpoch 00173: val_loss did not improve from 0.71751\nEpoch 174/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7603 - mae: 0.7188 - val_loss: 0.7180 - val_mse: 0.7590 - val_mae: 0.7167\n\nEpoch 00174: val_loss did not improve from 0.71751\nEpoch 175/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7610 - mae: 0.7179 - val_loss: 0.7183 - val_mse: 0.7554 - val_mae: 0.7171\n\nEpoch 00175: val_loss did not improve from 0.71751\nEpoch 176/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7610 - mae: 0.7192 - val_loss: 0.7187 - val_mse: 0.7553 - val_mae: 0.7175\n\nEpoch 00176: val_loss did not improve from 0.71751\nEpoch 177/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7625 - mae: 0.7190 - val_loss: 0.7179 - val_mse: 0.7567 - val_mae: 0.7167\n\nEpoch 00177: val_loss did not improve from 0.71751\nEpoch 178/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7619 - mae: 0.7180 - val_loss: 0.7182 - val_mse: 0.7599 - val_mae: 0.7170\n\nEpoch 00178: val_loss did not improve from 0.71751\nEpoch 179/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7221 - mse: 0.7656 - mae: 0.7209 - val_loss: 0.7177 - val_mse: 0.7562 - val_mae: 0.7165\n\nEpoch 00179: val_loss did not improve from 0.71751\nEpoch 180/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7214 - mse: 0.7641 - mae: 0.7202 - val_loss: 0.7185 - val_mse: 0.7551 - val_mae: 0.7173\n\nEpoch 00180: val_loss did not improve from 0.71751\nEpoch 181/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7195 - mse: 0.7601 - mae: 0.7182 - val_loss: 0.7179 - val_mse: 0.7574 - val_mae: 0.7167\n\nEpoch 00181: val_loss did not improve from 0.71751\nEpoch 182/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7226 - mse: 0.7653 - mae: 0.7214 - val_loss: 0.7178 - val_mse: 0.7537 - val_mae: 0.7166\n\nEpoch 00182: val_loss did not improve from 0.71751\nEpoch 183/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7211 - mse: 0.7637 - mae: 0.7199 - val_loss: 0.7185 - val_mse: 0.7564 - val_mae: 0.7173\n\nEpoch 00183: val_loss did not improve from 0.71751\nEpoch 184/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7209 - mse: 0.7620 - mae: 0.7196 - val_loss: 0.7181 - val_mse: 0.7576 - val_mae: 0.7169\n\nEpoch 00184: val_loss did not improve from 0.71751\nEpoch 185/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7214 - mse: 0.7649 - mae: 0.7202 - val_loss: 0.7181 - val_mse: 0.7553 - val_mae: 0.7169\n\nEpoch 00185: val_loss did not improve from 0.71751\nEpoch 186/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7216 - mse: 0.7644 - mae: 0.7204 - val_loss: 0.7179 - val_mse: 0.7554 - val_mae: 0.7167\n\nEpoch 00186: val_loss did not improve from 0.71751\nEpoch 187/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7609 - mae: 0.7188 - val_loss: 0.7182 - val_mse: 0.7596 - val_mae: 0.7170\n\nEpoch 00187: val_loss did not improve from 0.71751\nEpoch 188/1000\n188/188 [==============================] - 1s 5ms/step - loss: 0.7222 - mse: 0.7668 - mae: 0.7210 - val_loss: 0.7180 - val_mse: 0.7525 - val_mae: 0.7167\n\nEpoch 00188: val_loss did not improve from 0.71751\nEpoch 189/1000\n188/188 [==============================] - 2s 9ms/step - loss: 0.7207 - mse: 0.7616 - mae: 0.7194 - val_loss: 0.7198 - val_mse: 0.7613 - val_mae: 0.7186\n\nEpoch 00189: val_loss did not improve from 0.71751\nEpoch 190/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7216 - mse: 0.7639 - mae: 0.7204 - val_loss: 0.7180 - val_mse: 0.7569 - val_mae: 0.7168\n\nEpoch 00190: val_loss did not improve from 0.71751\nEpoch 191/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7630 - mae: 0.7199 - val_loss: 0.7180 - val_mse: 0.7553 - val_mae: 0.7167\n\nEpoch 00191: val_loss did not improve from 0.71751\nEpoch 192/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7640 - mae: 0.7200 - val_loss: 0.7179 - val_mse: 0.7589 - val_mae: 0.7167\n\nEpoch 00192: val_loss did not improve from 0.71751\nEpoch 193/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7605 - mae: 0.7185 - val_loss: 0.7179 - val_mse: 0.7586 - val_mae: 0.7167\n\nEpoch 00193: val_loss did not improve from 0.71751\nEpoch 194/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7199 - mse: 0.7609 - mae: 0.7186 - val_loss: 0.7178 - val_mse: 0.7555 - val_mae: 0.7166\n\nEpoch 00194: val_loss did not improve from 0.71751\nEpoch 195/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7199 - mse: 0.7626 - mae: 0.7187 - val_loss: 0.7178 - val_mse: 0.7536 - val_mae: 0.7166\n\nEpoch 00195: val_loss did not improve from 0.71751\nEpoch 196/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7216 - mse: 0.7633 - mae: 0.7204 - val_loss: 0.7180 - val_mse: 0.7574 - val_mae: 0.7168\n\nEpoch 00196: val_loss did not improve from 0.71751\nEpoch 197/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7215 - mse: 0.7640 - mae: 0.7203 - val_loss: 0.7184 - val_mse: 0.7562 - val_mae: 0.7171\n\nEpoch 00197: val_loss did not improve from 0.71751\nEpoch 198/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7589 - mae: 0.7173 - val_loss: 0.7180 - val_mse: 0.7541 - val_mae: 0.7168\n\nEpoch 00198: val_loss did not improve from 0.71751\nEpoch 199/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7213 - mse: 0.7648 - mae: 0.7200 - val_loss: 0.7176 - val_mse: 0.7529 - val_mae: 0.7164\n\nEpoch 00199: val_loss did not improve from 0.71751\nEpoch 200/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7209 - mse: 0.7630 - mae: 0.7197 - val_loss: 0.7180 - val_mse: 0.7596 - val_mae: 0.7168\n\nEpoch 00200: val_loss did not improve from 0.71751\nEpoch 201/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7640 - mae: 0.7199 - val_loss: 0.7177 - val_mse: 0.7536 - val_mae: 0.7165\n\nEpoch 00201: val_loss did not improve from 0.71751\nEpoch 202/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7228 - mse: 0.7661 - mae: 0.7216 - val_loss: 0.7179 - val_mse: 0.7565 - val_mae: 0.7167\n\nEpoch 00202: val_loss did not improve from 0.71751\nEpoch 203/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7227 - mse: 0.7668 - mae: 0.7215 - val_loss: 0.7180 - val_mse: 0.7542 - val_mae: 0.7168\n\nEpoch 00203: val_loss did not improve from 0.71751\nEpoch 204/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7601 - mae: 0.7185 - val_loss: 0.7184 - val_mse: 0.7534 - val_mae: 0.7172\n\nEpoch 00204: val_loss did not improve from 0.71751\nEpoch 205/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7616 - mae: 0.7189 - val_loss: 0.7181 - val_mse: 0.7587 - val_mae: 0.7169\n\nEpoch 00205: val_loss did not improve from 0.71751\nEpoch 206/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7621 - mae: 0.7188 - val_loss: 0.7185 - val_mse: 0.7573 - val_mae: 0.7173\n\nEpoch 00206: val_loss did not improve from 0.71751\nEpoch 207/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7214 - mse: 0.7641 - mae: 0.7202 - val_loss: 0.7179 - val_mse: 0.7548 - val_mae: 0.7167\n\nEpoch 00207: val_loss did not improve from 0.71751\nEpoch 208/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7230 - mse: 0.7676 - mae: 0.7218 - val_loss: 0.7183 - val_mse: 0.7554 - val_mae: 0.7171\n\nEpoch 00208: val_loss did not improve from 0.71751\nEpoch 209/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7189 - mse: 0.7605 - mae: 0.7177 - val_loss: 0.7175 - val_mse: 0.7588 - val_mae: 0.7163\n\nEpoch 00209: val_loss did not improve from 0.71751\nEpoch 210/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7638 - mae: 0.7192 - val_loss: 0.7174 - val_mse: 0.7541 - val_mae: 0.7162\n\nEpoch 00210: val_loss improved from 0.71751 to 0.71742, saving model to DNN_BestModel.hdf5\nEpoch 211/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7626 - mae: 0.7192 - val_loss: 0.7177 - val_mse: 0.7564 - val_mae: 0.7165\n\nEpoch 00211: val_loss did not improve from 0.71742\nEpoch 212/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7615 - mae: 0.7183 - val_loss: 0.7181 - val_mse: 0.7560 - val_mae: 0.7169\n\nEpoch 00212: val_loss did not improve from 0.71742\nEpoch 213/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7208 - mse: 0.7624 - mae: 0.7196 - val_loss: 0.7177 - val_mse: 0.7571 - val_mae: 0.7165\n\nEpoch 00213: val_loss did not improve from 0.71742\nEpoch 214/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7209 - mse: 0.7657 - mae: 0.7197 - val_loss: 0.7178 - val_mse: 0.7553 - val_mae: 0.7166\n\nEpoch 00214: val_loss did not improve from 0.71742\nEpoch 215/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7609 - mae: 0.7190 - val_loss: 0.7177 - val_mse: 0.7544 - val_mae: 0.7166\n\nEpoch 00215: val_loss did not improve from 0.71742\nEpoch 216/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7594 - mae: 0.7179 - val_loss: 0.7180 - val_mse: 0.7541 - val_mae: 0.7168\n\nEpoch 00216: val_loss did not improve from 0.71742\nEpoch 217/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 2s 8ms/step - loss: 0.7194 - mse: 0.7617 - mae: 0.7182 - val_loss: 0.7180 - val_mse: 0.7554 - val_mae: 0.7168\n\nEpoch 00217: val_loss did not improve from 0.71742\nEpoch 218/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7192 - mse: 0.7600 - mae: 0.7180 - val_loss: 0.7179 - val_mse: 0.7553 - val_mae: 0.7167\n\nEpoch 00218: val_loss did not improve from 0.71742\nEpoch 219/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7588 - mae: 0.7180 - val_loss: 0.7182 - val_mse: 0.7582 - val_mae: 0.7171\n\nEpoch 00219: val_loss did not improve from 0.71742\nEpoch 220/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7611 - mae: 0.7185 - val_loss: 0.7180 - val_mse: 0.7536 - val_mae: 0.7168\n\nEpoch 00220: val_loss did not improve from 0.71742\nEpoch 221/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7629 - mae: 0.7194 - val_loss: 0.7177 - val_mse: 0.7541 - val_mae: 0.7165\n\nEpoch 00221: val_loss did not improve from 0.71742\nEpoch 222/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7605 - mae: 0.7183 - val_loss: 0.7177 - val_mse: 0.7529 - val_mae: 0.7165\n\nEpoch 00222: val_loss did not improve from 0.71742\nEpoch 223/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7600 - mae: 0.7192 - val_loss: 0.7177 - val_mse: 0.7570 - val_mae: 0.7165\n\nEpoch 00223: val_loss did not improve from 0.71742\nEpoch 224/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7188 - mse: 0.7589 - mae: 0.7176 - val_loss: 0.7175 - val_mse: 0.7583 - val_mae: 0.7163\n\nEpoch 00224: val_loss did not improve from 0.71742\nEpoch 225/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7188 - mse: 0.7608 - mae: 0.7176 - val_loss: 0.7176 - val_mse: 0.7588 - val_mae: 0.7165\n\nEpoch 00225: val_loss did not improve from 0.71742\nEpoch 226/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7610 - mae: 0.7193 - val_loss: 0.7179 - val_mse: 0.7538 - val_mae: 0.7168\n\nEpoch 00226: val_loss did not improve from 0.71742\nEpoch 227/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7189 - mse: 0.7578 - mae: 0.7178 - val_loss: 0.7180 - val_mse: 0.7551 - val_mae: 0.7168\n\nEpoch 00227: val_loss did not improve from 0.71742\nEpoch 228/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7180 - mse: 0.7572 - mae: 0.7169 - val_loss: 0.7179 - val_mse: 0.7533 - val_mae: 0.7168\n\nEpoch 00228: val_loss did not improve from 0.71742\nEpoch 229/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7200 - mse: 0.7619 - mae: 0.7188 - val_loss: 0.7175 - val_mse: 0.7567 - val_mae: 0.7163\n\nEpoch 00229: val_loss did not improve from 0.71742\nEpoch 230/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7165 - mse: 0.7550 - mae: 0.7153 - val_loss: 0.7174 - val_mse: 0.7559 - val_mae: 0.7162\n\nEpoch 00230: val_loss improved from 0.71742 to 0.71738, saving model to DNN_BestModel.hdf5\nEpoch 231/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7210 - mse: 0.7625 - mae: 0.7198 - val_loss: 0.7177 - val_mse: 0.7570 - val_mae: 0.7165\n\nEpoch 00231: val_loss did not improve from 0.71738\nEpoch 232/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7205 - mse: 0.7638 - mae: 0.7193 - val_loss: 0.7169 - val_mse: 0.7603 - val_mae: 0.7157\n\nEpoch 00232: val_loss improved from 0.71738 to 0.71690, saving model to DNN_BestModel.hdf5\nEpoch 233/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7648 - mae: 0.7202 - val_loss: 0.7182 - val_mse: 0.7613 - val_mae: 0.7170\n\nEpoch 00233: val_loss did not improve from 0.71690\nEpoch 234/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7209 - mse: 0.7650 - mae: 0.7198 - val_loss: 0.7177 - val_mse: 0.7604 - val_mae: 0.7166\n\nEpoch 00234: val_loss did not improve from 0.71690\nEpoch 235/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7611 - mae: 0.7182 - val_loss: 0.7180 - val_mse: 0.7545 - val_mae: 0.7169\n\nEpoch 00235: val_loss did not improve from 0.71690\nEpoch 236/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7621 - mae: 0.7191 - val_loss: 0.7177 - val_mse: 0.7567 - val_mae: 0.7166\n\nEpoch 00236: val_loss did not improve from 0.71690\nEpoch 237/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7188 - mse: 0.7598 - mae: 0.7176 - val_loss: 0.7182 - val_mse: 0.7573 - val_mae: 0.7171\n\nEpoch 00237: val_loss did not improve from 0.71690\nEpoch 238/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7587 - mae: 0.7165 - val_loss: 0.7183 - val_mse: 0.7533 - val_mae: 0.7172\n\nEpoch 00238: val_loss did not improve from 0.71690\nEpoch 239/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7216 - mse: 0.7666 - mae: 0.7204 - val_loss: 0.7177 - val_mse: 0.7559 - val_mae: 0.7166\n\nEpoch 00239: val_loss did not improve from 0.71690\nEpoch 240/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7215 - mse: 0.7645 - mae: 0.7203 - val_loss: 0.7184 - val_mse: 0.7527 - val_mae: 0.7173\n\nEpoch 00240: val_loss did not improve from 0.71690\nEpoch 241/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7607 - mae: 0.7188 - val_loss: 0.7174 - val_mse: 0.7554 - val_mae: 0.7163\n\nEpoch 00241: val_loss did not improve from 0.71690\nEpoch 242/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7638 - mae: 0.7191 - val_loss: 0.7178 - val_mse: 0.7558 - val_mae: 0.7166\n\nEpoch 00242: val_loss did not improve from 0.71690\nEpoch 243/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7618 - mae: 0.7183 - val_loss: 0.7174 - val_mse: 0.7549 - val_mae: 0.7163\n\nEpoch 00243: val_loss did not improve from 0.71690\nEpoch 244/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7628 - mae: 0.7190 - val_loss: 0.7178 - val_mse: 0.7610 - val_mae: 0.7167\n\nEpoch 00244: val_loss did not improve from 0.71690\nEpoch 245/1000\n188/188 [==============================] - 2s 9ms/step - loss: 0.7209 - mse: 0.7638 - mae: 0.7198 - val_loss: 0.7175 - val_mse: 0.7562 - val_mae: 0.7164\n\nEpoch 00245: val_loss did not improve from 0.71690\nEpoch 246/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7200 - mse: 0.7630 - mae: 0.7189 - val_loss: 0.7177 - val_mse: 0.7564 - val_mae: 0.7166\n\nEpoch 00246: val_loss did not improve from 0.71690\nEpoch 247/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7640 - mae: 0.7196 - val_loss: 0.7179 - val_mse: 0.7565 - val_mae: 0.7168\n\nEpoch 00247: val_loss did not improve from 0.71690\nEpoch 248/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7620 - mae: 0.7195 - val_loss: 0.7184 - val_mse: 0.7614 - val_mae: 0.7172\n\nEpoch 00248: val_loss did not improve from 0.71690\nEpoch 249/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7182 - mse: 0.7601 - mae: 0.7171 - val_loss: 0.7178 - val_mse: 0.7566 - val_mae: 0.7166\n\nEpoch 00249: val_loss did not improve from 0.71690\nEpoch 250/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7614 - mae: 0.7190 - val_loss: 0.7189 - val_mse: 0.7603 - val_mae: 0.7178\n\nEpoch 00250: val_loss did not improve from 0.71690\nEpoch 251/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7626 - mae: 0.7196 - val_loss: 0.7173 - val_mse: 0.7562 - val_mae: 0.7162\n\nEpoch 00251: val_loss did not improve from 0.71690\nEpoch 252/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7228 - mse: 0.7662 - mae: 0.7217 - val_loss: 0.7181 - val_mse: 0.7568 - val_mae: 0.7170\n\nEpoch 00252: val_loss did not improve from 0.71690\nEpoch 253/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7655 - mae: 0.7200 - val_loss: 0.7172 - val_mse: 0.7549 - val_mae: 0.7161\n\nEpoch 00253: val_loss did not improve from 0.71690\nEpoch 254/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7185 - mse: 0.7575 - mae: 0.7174 - val_loss: 0.7175 - val_mse: 0.7557 - val_mae: 0.7164\n\nEpoch 00254: val_loss did not improve from 0.71690\nEpoch 255/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7199 - mse: 0.7613 - mae: 0.7188 - val_loss: 0.7174 - val_mse: 0.7556 - val_mae: 0.7163\n\nEpoch 00255: val_loss did not improve from 0.71690\nEpoch 256/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7189 - mse: 0.7616 - mae: 0.7178 - val_loss: 0.7176 - val_mse: 0.7553 - val_mae: 0.7165\n\nEpoch 00256: val_loss did not improve from 0.71690\nEpoch 257/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7633 - mae: 0.7190 - val_loss: 0.7180 - val_mse: 0.7540 - val_mae: 0.7169\n\nEpoch 00257: val_loss did not improve from 0.71690\nEpoch 258/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7624 - mae: 0.7184 - val_loss: 0.7173 - val_mse: 0.7587 - val_mae: 0.7162\n\nEpoch 00258: val_loss did not improve from 0.71690\nEpoch 259/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7624 - mae: 0.7195 - val_loss: 0.7181 - val_mse: 0.7582 - val_mae: 0.7170\n\nEpoch 00259: val_loss did not improve from 0.71690\nEpoch 260/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7618 - mae: 0.7196 - val_loss: 0.7177 - val_mse: 0.7571 - val_mae: 0.7166\n\nEpoch 00260: val_loss did not improve from 0.71690\nEpoch 261/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7215 - mse: 0.7642 - mae: 0.7204 - val_loss: 0.7181 - val_mse: 0.7562 - val_mae: 0.7170\n\nEpoch 00261: val_loss did not improve from 0.71690\nEpoch 262/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7634 - mae: 0.7200 - val_loss: 0.7176 - val_mse: 0.7551 - val_mae: 0.7165\n\nEpoch 00262: val_loss did not improve from 0.71690\nEpoch 263/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7591 - mae: 0.7172 - val_loss: 0.7180 - val_mse: 0.7580 - val_mae: 0.7169\n\nEpoch 00263: val_loss did not improve from 0.71690\nEpoch 264/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7650 - mae: 0.7201 - val_loss: 0.7175 - val_mse: 0.7569 - val_mae: 0.7164\n\nEpoch 00264: val_loss did not improve from 0.71690\nEpoch 265/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7187 - mse: 0.7595 - mae: 0.7176 - val_loss: 0.7171 - val_mse: 0.7574 - val_mae: 0.7160\n\nEpoch 00265: val_loss did not improve from 0.71690\nEpoch 266/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7217 - mse: 0.7642 - mae: 0.7206 - val_loss: 0.7177 - val_mse: 0.7549 - val_mae: 0.7166\n\nEpoch 00266: val_loss did not improve from 0.71690\nEpoch 267/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7217 - mse: 0.7636 - mae: 0.7206 - val_loss: 0.7180 - val_mse: 0.7553 - val_mae: 0.7169\n\nEpoch 00267: val_loss did not improve from 0.71690\nEpoch 268/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7624 - mae: 0.7186 - val_loss: 0.7180 - val_mse: 0.7556 - val_mae: 0.7170\n\nEpoch 00268: val_loss did not improve from 0.71690\nEpoch 269/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7592 - mae: 0.7182 - val_loss: 0.7179 - val_mse: 0.7583 - val_mae: 0.7168\n\nEpoch 00269: val_loss did not improve from 0.71690\nEpoch 270/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7222 - mse: 0.7660 - mae: 0.7211 - val_loss: 0.7174 - val_mse: 0.7555 - val_mae: 0.7163\n\nEpoch 00270: val_loss did not improve from 0.71690\nEpoch 271/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7599 - mae: 0.7180 - val_loss: 0.7177 - val_mse: 0.7585 - val_mae: 0.7166\n\nEpoch 00271: val_loss did not improve from 0.71690\nEpoch 272/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7182 - mse: 0.7576 - mae: 0.7171 - val_loss: 0.7180 - val_mse: 0.7564 - val_mae: 0.7170\n\nEpoch 00272: val_loss did not improve from 0.71690\nEpoch 273/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7625 - mae: 0.7184 - val_loss: 0.7176 - val_mse: 0.7533 - val_mae: 0.7165\n\nEpoch 00273: val_loss did not improve from 0.71690\nEpoch 274/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7205 - mse: 0.7608 - mae: 0.7194 - val_loss: 0.7176 - val_mse: 0.7556 - val_mae: 0.7165\n\nEpoch 00274: val_loss did not improve from 0.71690\nEpoch 275/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7217 - mse: 0.7657 - mae: 0.7206 - val_loss: 0.7180 - val_mse: 0.7595 - val_mae: 0.7169\n\nEpoch 00275: val_loss did not improve from 0.71690\nEpoch 276/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7214 - mse: 0.7652 - mae: 0.7203 - val_loss: 0.7176 - val_mse: 0.7547 - val_mae: 0.7165\n\nEpoch 00276: val_loss did not improve from 0.71690\nEpoch 277/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7622 - mae: 0.7190 - val_loss: 0.7180 - val_mse: 0.7542 - val_mae: 0.7169\n\nEpoch 00277: val_loss did not improve from 0.71690\nEpoch 278/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7205 - mse: 0.7639 - mae: 0.7194 - val_loss: 0.7180 - val_mse: 0.7561 - val_mae: 0.7169\n\nEpoch 00278: val_loss did not improve from 0.71690\nEpoch 279/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7618 - mae: 0.7188 - val_loss: 0.7169 - val_mse: 0.7565 - val_mae: 0.7159\n\nEpoch 00279: val_loss did not improve from 0.71690\nEpoch 280/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7572 - mae: 0.7166 - val_loss: 0.7172 - val_mse: 0.7549 - val_mae: 0.7161\n\nEpoch 00280: val_loss did not improve from 0.71690\nEpoch 281/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7585 - mae: 0.7175 - val_loss: 0.7174 - val_mse: 0.7555 - val_mae: 0.7163\n\nEpoch 00281: val_loss did not improve from 0.71690\nEpoch 282/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7622 - mae: 0.7190 - val_loss: 0.7169 - val_mse: 0.7584 - val_mae: 0.7158\n\nEpoch 00282: val_loss improved from 0.71690 to 0.71688, saving model to DNN_BestModel.hdf5\nEpoch 283/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7631 - mae: 0.7192 - val_loss: 0.7172 - val_mse: 0.7582 - val_mae: 0.7161\n\nEpoch 00283: val_loss did not improve from 0.71688\nEpoch 284/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7215 - mse: 0.7630 - mae: 0.7204 - val_loss: 0.7175 - val_mse: 0.7558 - val_mae: 0.7164\n\nEpoch 00284: val_loss did not improve from 0.71688\nEpoch 285/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7613 - mae: 0.7186 - val_loss: 0.7176 - val_mse: 0.7550 - val_mae: 0.7165\n\nEpoch 00285: val_loss did not improve from 0.71688\nEpoch 286/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7593 - mae: 0.7170 - val_loss: 0.7176 - val_mse: 0.7554 - val_mae: 0.7165\n\nEpoch 00286: val_loss did not improve from 0.71688\nEpoch 287/1000\n188/188 [==============================] - 1s 5ms/step - loss: 0.7189 - mse: 0.7604 - mae: 0.7178 - val_loss: 0.7174 - val_mse: 0.7571 - val_mae: 0.7163\n\nEpoch 00287: val_loss did not improve from 0.71688\nEpoch 288/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7210 - mse: 0.7640 - mae: 0.7199 - val_loss: 0.7169 - val_mse: 0.7556 - val_mae: 0.7158\n\nEpoch 00288: val_loss improved from 0.71688 to 0.71685, saving model to DNN_BestModel.hdf5\nEpoch 289/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7635 - mae: 0.7196 - val_loss: 0.7174 - val_mse: 0.7586 - val_mae: 0.7164\n\nEpoch 00289: val_loss did not improve from 0.71685\nEpoch 290/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7589 - mae: 0.7178 - val_loss: 0.7177 - val_mse: 0.7561 - val_mae: 0.7167\n\nEpoch 00290: val_loss did not improve from 0.71685\nEpoch 291/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7572 - mae: 0.7167 - val_loss: 0.7174 - val_mse: 0.7548 - val_mae: 0.7163\n\nEpoch 00291: val_loss did not improve from 0.71685\nEpoch 292/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7599 - mae: 0.7183 - val_loss: 0.7178 - val_mse: 0.7544 - val_mae: 0.7167\n\nEpoch 00292: val_loss did not improve from 0.71685\nEpoch 293/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7627 - mae: 0.7186 - val_loss: 0.7173 - val_mse: 0.7550 - val_mae: 0.7162\n\nEpoch 00293: val_loss did not improve from 0.71685\nEpoch 294/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7183 - mse: 0.7578 - mae: 0.7172 - val_loss: 0.7177 - val_mse: 0.7594 - val_mae: 0.7166\n\nEpoch 00294: val_loss did not improve from 0.71685\nEpoch 295/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7627 - mae: 0.7189 - val_loss: 0.7173 - val_mse: 0.7537 - val_mae: 0.7162\n\nEpoch 00295: val_loss did not improve from 0.71685\nEpoch 296/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7179 - mse: 0.7578 - mae: 0.7168 - val_loss: 0.7181 - val_mse: 0.7540 - val_mae: 0.7170\n\nEpoch 00296: val_loss did not improve from 0.71685\nEpoch 297/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7197 - mse: 0.7617 - mae: 0.7186 - val_loss: 0.7180 - val_mse: 0.7548 - val_mae: 0.7169\n\nEpoch 00297: val_loss did not improve from 0.71685\nEpoch 298/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7185 - mse: 0.7588 - mae: 0.7174 - val_loss: 0.7173 - val_mse: 0.7544 - val_mae: 0.7162\n\nEpoch 00298: val_loss did not improve from 0.71685\nEpoch 299/1000\n188/188 [==============================] - 2s 9ms/step - loss: 0.7197 - mse: 0.7616 - mae: 0.7186 - val_loss: 0.7172 - val_mse: 0.7568 - val_mae: 0.7162\n\nEpoch 00299: val_loss did not improve from 0.71685\nEpoch 300/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7633 - mae: 0.7193 - val_loss: 0.7173 - val_mse: 0.7548 - val_mae: 0.7162\n\nEpoch 00300: val_loss did not improve from 0.71685\nEpoch 301/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7188 - mse: 0.7609 - mae: 0.7178 - val_loss: 0.7177 - val_mse: 0.7566 - val_mae: 0.7166\n\nEpoch 00301: val_loss did not improve from 0.71685\nEpoch 302/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7168 - mse: 0.7571 - mae: 0.7158 - val_loss: 0.7171 - val_mse: 0.7557 - val_mae: 0.7160\n\nEpoch 00302: val_loss did not improve from 0.71685\nEpoch 303/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7196 - mse: 0.7612 - mae: 0.7185 - val_loss: 0.7174 - val_mse: 0.7555 - val_mae: 0.7163\n\nEpoch 00303: val_loss did not improve from 0.71685\nEpoch 304/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7623 - mae: 0.7188 - val_loss: 0.7171 - val_mse: 0.7552 - val_mae: 0.7161\n\nEpoch 00304: val_loss did not improve from 0.71685\nEpoch 305/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7583 - mae: 0.7168 - val_loss: 0.7168 - val_mse: 0.7570 - val_mae: 0.7157\n\nEpoch 00305: val_loss improved from 0.71685 to 0.71680, saving model to DNN_BestModel.hdf5\nEpoch 306/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7205 - mse: 0.7622 - mae: 0.7195 - val_loss: 0.7173 - val_mse: 0.7563 - val_mae: 0.7162\n\nEpoch 00306: val_loss did not improve from 0.71680\nEpoch 307/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7617 - mae: 0.7184 - val_loss: 0.7171 - val_mse: 0.7567 - val_mae: 0.7161\n\nEpoch 00307: val_loss did not improve from 0.71680\nEpoch 308/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7610 - mae: 0.7186 - val_loss: 0.7175 - val_mse: 0.7532 - val_mae: 0.7165\n\nEpoch 00308: val_loss did not improve from 0.71680\nEpoch 309/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7587 - mae: 0.7177 - val_loss: 0.7180 - val_mse: 0.7535 - val_mae: 0.7170\n\nEpoch 00309: val_loss did not improve from 0.71680\nEpoch 310/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7615 - mae: 0.7182 - val_loss: 0.7173 - val_mse: 0.7565 - val_mae: 0.7162\n\nEpoch 00310: val_loss did not improve from 0.71680\nEpoch 311/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7620 - mae: 0.7192 - val_loss: 0.7173 - val_mse: 0.7554 - val_mae: 0.7162\n\nEpoch 00311: val_loss did not improve from 0.71680\nEpoch 312/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7202 - mse: 0.7629 - mae: 0.7191 - val_loss: 0.7172 - val_mse: 0.7573 - val_mae: 0.7162\n\nEpoch 00312: val_loss did not improve from 0.71680\nEpoch 313/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7205 - mse: 0.7639 - mae: 0.7195 - val_loss: 0.7172 - val_mse: 0.7561 - val_mae: 0.7162\n\nEpoch 00313: val_loss did not improve from 0.71680\nEpoch 314/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7651 - mae: 0.7203 - val_loss: 0.7176 - val_mse: 0.7548 - val_mae: 0.7165\n\nEpoch 00314: val_loss did not improve from 0.71680\nEpoch 315/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7656 - mae: 0.7202 - val_loss: 0.7173 - val_mse: 0.7549 - val_mae: 0.7162\n\nEpoch 00315: val_loss did not improve from 0.71680\nEpoch 316/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7603 - mae: 0.7181 - val_loss: 0.7175 - val_mse: 0.7578 - val_mae: 0.7165\n\nEpoch 00316: val_loss did not improve from 0.71680\nEpoch 317/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7611 - mae: 0.7171 - val_loss: 0.7170 - val_mse: 0.7543 - val_mae: 0.7160\n\nEpoch 00317: val_loss did not improve from 0.71680\nEpoch 318/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7613 - mae: 0.7193 - val_loss: 0.7168 - val_mse: 0.7553 - val_mae: 0.7157\n\nEpoch 00318: val_loss improved from 0.71680 to 0.71675, saving model to DNN_BestModel.hdf5\nEpoch 319/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7191 - mse: 0.7618 - mae: 0.7181 - val_loss: 0.7173 - val_mse: 0.7543 - val_mae: 0.7163\n\nEpoch 00319: val_loss did not improve from 0.71675\nEpoch 320/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7642 - mae: 0.7202 - val_loss: 0.7173 - val_mse: 0.7558 - val_mae: 0.7163\n\nEpoch 00320: val_loss did not improve from 0.71675\nEpoch 321/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7195 - mse: 0.7630 - mae: 0.7185 - val_loss: 0.7177 - val_mse: 0.7535 - val_mae: 0.7167\n\nEpoch 00321: val_loss did not improve from 0.71675\nEpoch 322/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7179 - mse: 0.7583 - mae: 0.7168 - val_loss: 0.7173 - val_mse: 0.7533 - val_mae: 0.7163\n\nEpoch 00322: val_loss did not improve from 0.71675\nEpoch 323/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7612 - mae: 0.7181 - val_loss: 0.7171 - val_mse: 0.7562 - val_mae: 0.7161\n\nEpoch 00323: val_loss did not improve from 0.71675\nEpoch 324/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7632 - mae: 0.7197 - val_loss: 0.7170 - val_mse: 0.7556 - val_mae: 0.7160\n\nEpoch 00324: val_loss did not improve from 0.71675\nEpoch 325/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7191 - mse: 0.7594 - mae: 0.7180 - val_loss: 0.7178 - val_mse: 0.7582 - val_mae: 0.7168\n\nEpoch 00325: val_loss did not improve from 0.71675\nEpoch 326/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7629 - mae: 0.7192 - val_loss: 0.7174 - val_mse: 0.7557 - val_mae: 0.7163\n\nEpoch 00326: val_loss did not improve from 0.71675\nEpoch 327/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7171 - mse: 0.7564 - mae: 0.7161 - val_loss: 0.7181 - val_mse: 0.7533 - val_mae: 0.7171\n\nEpoch 00327: val_loss did not improve from 0.71675\nEpoch 328/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7606 - mae: 0.7187 - val_loss: 0.7174 - val_mse: 0.7571 - val_mae: 0.7163\n\nEpoch 00328: val_loss did not improve from 0.71675\nEpoch 329/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7618 - mae: 0.7184 - val_loss: 0.7174 - val_mse: 0.7558 - val_mae: 0.7164\n\nEpoch 00329: val_loss did not improve from 0.71675\nEpoch 330/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7604 - mae: 0.7180 - val_loss: 0.7172 - val_mse: 0.7558 - val_mae: 0.7162\n\nEpoch 00330: val_loss did not improve from 0.71675\nEpoch 331/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7189 - mse: 0.7596 - mae: 0.7179 - val_loss: 0.7172 - val_mse: 0.7545 - val_mae: 0.7162\n\nEpoch 00331: val_loss did not improve from 0.71675\nEpoch 332/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7632 - mae: 0.7196 - val_loss: 0.7175 - val_mse: 0.7553 - val_mae: 0.7165\n\nEpoch 00332: val_loss did not improve from 0.71675\nEpoch 333/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7208 - mse: 0.7625 - mae: 0.7198 - val_loss: 0.7178 - val_mse: 0.7595 - val_mae: 0.7168\n\nEpoch 00333: val_loss did not improve from 0.71675\nEpoch 334/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7596 - mae: 0.7168 - val_loss: 0.7172 - val_mse: 0.7551 - val_mae: 0.7161\n\nEpoch 00334: val_loss did not improve from 0.71675\nEpoch 335/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7205 - mse: 0.7643 - mae: 0.7195 - val_loss: 0.7176 - val_mse: 0.7563 - val_mae: 0.7165\n\nEpoch 00335: val_loss did not improve from 0.71675\nEpoch 336/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7565 - mae: 0.7171 - val_loss: 0.7170 - val_mse: 0.7567 - val_mae: 0.7160\n\nEpoch 00336: val_loss did not improve from 0.71675\nEpoch 337/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7608 - mae: 0.7177 - val_loss: 0.7178 - val_mse: 0.7543 - val_mae: 0.7168\n\nEpoch 00337: val_loss did not improve from 0.71675\nEpoch 338/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7188 - mse: 0.7606 - mae: 0.7178 - val_loss: 0.7172 - val_mse: 0.7585 - val_mae: 0.7162\n\nEpoch 00338: val_loss did not improve from 0.71675\nEpoch 339/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7616 - mae: 0.7173 - val_loss: 0.7174 - val_mse: 0.7575 - val_mae: 0.7164\n\nEpoch 00339: val_loss did not improve from 0.71675\nEpoch 340/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7185 - mse: 0.7600 - mae: 0.7175 - val_loss: 0.7178 - val_mse: 0.7563 - val_mae: 0.7168\n\nEpoch 00340: val_loss did not improve from 0.71675\nEpoch 341/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7588 - mae: 0.7170 - val_loss: 0.7168 - val_mse: 0.7556 - val_mae: 0.7158\n\nEpoch 00341: val_loss did not improve from 0.71675\nEpoch 342/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7621 - mae: 0.7194 - val_loss: 0.7175 - val_mse: 0.7553 - val_mae: 0.7165\n\nEpoch 00342: val_loss did not improve from 0.71675\nEpoch 343/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7621 - mae: 0.7191 - val_loss: 0.7171 - val_mse: 0.7546 - val_mae: 0.7161\n\nEpoch 00343: val_loss did not improve from 0.71675\nEpoch 344/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7174 - mse: 0.7568 - mae: 0.7164 - val_loss: 0.7169 - val_mse: 0.7559 - val_mae: 0.7159\n\nEpoch 00344: val_loss did not improve from 0.71675\nEpoch 345/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7635 - mae: 0.7186 - val_loss: 0.7173 - val_mse: 0.7555 - val_mae: 0.7163\n\nEpoch 00345: val_loss did not improve from 0.71675\nEpoch 346/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7200 - mse: 0.7626 - mae: 0.7190 - val_loss: 0.7180 - val_mse: 0.7592 - val_mae: 0.7170\n\nEpoch 00346: val_loss did not improve from 0.71675\nEpoch 347/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7176 - mse: 0.7578 - mae: 0.7166 - val_loss: 0.7169 - val_mse: 0.7561 - val_mae: 0.7159\n\nEpoch 00347: val_loss did not improve from 0.71675\nEpoch 348/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7612 - mae: 0.7179 - val_loss: 0.7176 - val_mse: 0.7546 - val_mae: 0.7166\n\nEpoch 00348: val_loss did not improve from 0.71675\nEpoch 349/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7184 - mse: 0.7594 - mae: 0.7174 - val_loss: 0.7173 - val_mse: 0.7529 - val_mae: 0.7163\n\nEpoch 00349: val_loss did not improve from 0.71675\nEpoch 350/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7556 - mae: 0.7168 - val_loss: 0.7171 - val_mse: 0.7554 - val_mae: 0.7161\n\nEpoch 00350: val_loss did not improve from 0.71675\nEpoch 351/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7653 - mae: 0.7203 - val_loss: 0.7169 - val_mse: 0.7561 - val_mae: 0.7159\n\nEpoch 00351: val_loss did not improve from 0.71675\nEpoch 352/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7182 - mse: 0.7590 - mae: 0.7172 - val_loss: 0.7168 - val_mse: 0.7571 - val_mae: 0.7159\n\nEpoch 00352: val_loss did not improve from 0.71675\nEpoch 353/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7192 - mse: 0.7618 - mae: 0.7182 - val_loss: 0.7170 - val_mse: 0.7560 - val_mae: 0.7160\n\nEpoch 00353: val_loss did not improve from 0.71675\nEpoch 354/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7205 - mse: 0.7633 - mae: 0.7195 - val_loss: 0.7168 - val_mse: 0.7576 - val_mae: 0.7158\n\nEpoch 00354: val_loss did not improve from 0.71675\nEpoch 355/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7615 - mae: 0.7190 - val_loss: 0.7175 - val_mse: 0.7520 - val_mae: 0.7165\n\nEpoch 00355: val_loss did not improve from 0.71675\nEpoch 356/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7604 - mae: 0.7181 - val_loss: 0.7178 - val_mse: 0.7562 - val_mae: 0.7168\n\nEpoch 00356: val_loss did not improve from 0.71675\nEpoch 357/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7593 - mae: 0.7174 - val_loss: 0.7172 - val_mse: 0.7581 - val_mae: 0.7162\n\nEpoch 00357: val_loss did not improve from 0.71675\nEpoch 358/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7610 - mae: 0.7183 - val_loss: 0.7171 - val_mse: 0.7563 - val_mae: 0.7162\n\nEpoch 00358: val_loss did not improve from 0.71675\nEpoch 359/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7181 - mse: 0.7598 - mae: 0.7171 - val_loss: 0.7179 - val_mse: 0.7551 - val_mae: 0.7169\n\nEpoch 00359: val_loss did not improve from 0.71675\nEpoch 360/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7570 - mae: 0.7167 - val_loss: 0.7170 - val_mse: 0.7566 - val_mae: 0.7160\n\nEpoch 00360: val_loss did not improve from 0.71675\nEpoch 361/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7645 - mae: 0.7191 - val_loss: 0.7172 - val_mse: 0.7566 - val_mae: 0.7163\n\nEpoch 00361: val_loss did not improve from 0.71675\nEpoch 362/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7604 - mae: 0.7181 - val_loss: 0.7176 - val_mse: 0.7552 - val_mae: 0.7166\n\nEpoch 00362: val_loss did not improve from 0.71675\nEpoch 363/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7574 - mae: 0.7168 - val_loss: 0.7177 - val_mse: 0.7545 - val_mae: 0.7167\n\nEpoch 00363: val_loss did not improve from 0.71675\nEpoch 364/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7208 - mse: 0.7632 - mae: 0.7198 - val_loss: 0.7173 - val_mse: 0.7579 - val_mae: 0.7163\n\nEpoch 00364: val_loss did not improve from 0.71675\nEpoch 365/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7602 - mae: 0.7176 - val_loss: 0.7171 - val_mse: 0.7567 - val_mae: 0.7162\n\nEpoch 00365: val_loss did not improve from 0.71675\nEpoch 366/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7188 - mse: 0.7615 - mae: 0.7178 - val_loss: 0.7176 - val_mse: 0.7545 - val_mae: 0.7166\n\nEpoch 00366: val_loss did not improve from 0.71675\nEpoch 367/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7185 - mse: 0.7599 - mae: 0.7175 - val_loss: 0.7178 - val_mse: 0.7558 - val_mae: 0.7169\n\nEpoch 00367: val_loss did not improve from 0.71675\nEpoch 368/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7180 - mse: 0.7574 - mae: 0.7170 - val_loss: 0.7172 - val_mse: 0.7566 - val_mae: 0.7163\n\nEpoch 00368: val_loss did not improve from 0.71675\nEpoch 369/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7167 - mse: 0.7584 - mae: 0.7158 - val_loss: 0.7168 - val_mse: 0.7539 - val_mae: 0.7158\n\nEpoch 00369: val_loss did not improve from 0.71675\nEpoch 370/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7205 - mse: 0.7631 - mae: 0.7195 - val_loss: 0.7179 - val_mse: 0.7543 - val_mae: 0.7169\n\nEpoch 00370: val_loss did not improve from 0.71675\nEpoch 371/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7612 - mae: 0.7189 - val_loss: 0.7174 - val_mse: 0.7559 - val_mae: 0.7164\n\nEpoch 00371: val_loss did not improve from 0.71675\nEpoch 372/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7194 - mse: 0.7607 - mae: 0.7184 - val_loss: 0.7168 - val_mse: 0.7548 - val_mae: 0.7158\n\nEpoch 00372: val_loss did not improve from 0.71675\nEpoch 373/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7625 - mae: 0.7187 - val_loss: 0.7170 - val_mse: 0.7552 - val_mae: 0.7161\n\nEpoch 00373: val_loss did not improve from 0.71675\nEpoch 374/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7171 - mse: 0.7582 - mae: 0.7162 - val_loss: 0.7176 - val_mse: 0.7553 - val_mae: 0.7166\n\nEpoch 00374: val_loss did not improve from 0.71675\nEpoch 375/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7182 - mse: 0.7603 - mae: 0.7173 - val_loss: 0.7172 - val_mse: 0.7560 - val_mae: 0.7162\n\nEpoch 00375: val_loss did not improve from 0.71675\nEpoch 376/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7614 - mae: 0.7185 - val_loss: 0.7170 - val_mse: 0.7564 - val_mae: 0.7160\n\nEpoch 00376: val_loss did not improve from 0.71675\nEpoch 377/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7212 - mse: 0.7652 - mae: 0.7202 - val_loss: 0.7179 - val_mse: 0.7529 - val_mae: 0.7169\n\nEpoch 00377: val_loss did not improve from 0.71675\nEpoch 378/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7586 - mae: 0.7171 - val_loss: 0.7170 - val_mse: 0.7562 - val_mae: 0.7160\n\nEpoch 00378: val_loss did not improve from 0.71675\nEpoch 379/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7612 - mae: 0.7184 - val_loss: 0.7176 - val_mse: 0.7541 - val_mae: 0.7167\n\nEpoch 00379: val_loss did not improve from 0.71675\nEpoch 380/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7168 - mse: 0.7591 - mae: 0.7159 - val_loss: 0.7175 - val_mse: 0.7563 - val_mae: 0.7166\n\nEpoch 00380: val_loss did not improve from 0.71675\nEpoch 381/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7184 - mse: 0.7601 - mae: 0.7175 - val_loss: 0.7173 - val_mse: 0.7566 - val_mae: 0.7164\n\nEpoch 00381: val_loss did not improve from 0.71675\nEpoch 382/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7596 - mae: 0.7181 - val_loss: 0.7171 - val_mse: 0.7542 - val_mae: 0.7161\n\nEpoch 00382: val_loss did not improve from 0.71675\nEpoch 383/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7652 - mae: 0.7201 - val_loss: 0.7174 - val_mse: 0.7548 - val_mae: 0.7164\n\nEpoch 00383: val_loss did not improve from 0.71675\nEpoch 384/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7630 - mae: 0.7198 - val_loss: 0.7170 - val_mse: 0.7534 - val_mae: 0.7161\n\nEpoch 00384: val_loss did not improve from 0.71675\nEpoch 385/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7607 - mae: 0.7187 - val_loss: 0.7172 - val_mse: 0.7541 - val_mae: 0.7163\n\nEpoch 00385: val_loss did not improve from 0.71675\nEpoch 386/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7617 - mae: 0.7194 - val_loss: 0.7171 - val_mse: 0.7540 - val_mae: 0.7162\n\nEpoch 00386: val_loss did not improve from 0.71675\nEpoch 387/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7191 - mse: 0.7610 - mae: 0.7182 - val_loss: 0.7172 - val_mse: 0.7538 - val_mae: 0.7163\n\nEpoch 00387: val_loss did not improve from 0.71675\nEpoch 388/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7192 - mse: 0.7597 - mae: 0.7182 - val_loss: 0.7169 - val_mse: 0.7537 - val_mae: 0.7159\n\nEpoch 00388: val_loss did not improve from 0.71675\nEpoch 389/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7589 - mae: 0.7168 - val_loss: 0.7181 - val_mse: 0.7537 - val_mae: 0.7171\n\nEpoch 00389: val_loss did not improve from 0.71675\nEpoch 390/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7211 - mse: 0.7645 - mae: 0.7202 - val_loss: 0.7170 - val_mse: 0.7542 - val_mae: 0.7160\n\nEpoch 00390: val_loss did not improve from 0.71675\nEpoch 391/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7627 - mae: 0.7197 - val_loss: 0.7168 - val_mse: 0.7551 - val_mae: 0.7159\n\nEpoch 00391: val_loss did not improve from 0.71675\nEpoch 392/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7205 - mse: 0.7630 - mae: 0.7196 - val_loss: 0.7169 - val_mse: 0.7554 - val_mae: 0.7159\n\nEpoch 00392: val_loss did not improve from 0.71675\nEpoch 393/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7175 - mse: 0.7576 - mae: 0.7166 - val_loss: 0.7172 - val_mse: 0.7549 - val_mae: 0.7162\n\nEpoch 00393: val_loss did not improve from 0.71675\nEpoch 394/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7214 - mse: 0.7652 - mae: 0.7204 - val_loss: 0.7170 - val_mse: 0.7552 - val_mae: 0.7161\n\nEpoch 00394: val_loss did not improve from 0.71675\nEpoch 395/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7584 - mae: 0.7175 - val_loss: 0.7169 - val_mse: 0.7555 - val_mae: 0.7160\n\nEpoch 00395: val_loss did not improve from 0.71675\nEpoch 396/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7190 - mse: 0.7596 - mae: 0.7180 - val_loss: 0.7171 - val_mse: 0.7557 - val_mae: 0.7161\n\nEpoch 00396: val_loss did not improve from 0.71675\nEpoch 397/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7600 - mae: 0.7173 - val_loss: 0.7171 - val_mse: 0.7574 - val_mae: 0.7162\n\nEpoch 00397: val_loss did not improve from 0.71675\nEpoch 398/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7614 - mae: 0.7183 - val_loss: 0.7172 - val_mse: 0.7583 - val_mae: 0.7162\n\nEpoch 00398: val_loss did not improve from 0.71675\nEpoch 399/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7193 - mse: 0.7625 - mae: 0.7184 - val_loss: 0.7170 - val_mse: 0.7573 - val_mae: 0.7161\n\nEpoch 00399: val_loss did not improve from 0.71675\nEpoch 400/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7600 - mae: 0.7168 - val_loss: 0.7169 - val_mse: 0.7547 - val_mae: 0.7160\n\nEpoch 00400: val_loss did not improve from 0.71675\nEpoch 401/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7626 - mae: 0.7188 - val_loss: 0.7176 - val_mse: 0.7553 - val_mae: 0.7167\n\nEpoch 00401: val_loss did not improve from 0.71675\nEpoch 402/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7602 - mae: 0.7185 - val_loss: 0.7168 - val_mse: 0.7570 - val_mae: 0.7158\n\nEpoch 00402: val_loss did not improve from 0.71675\nEpoch 403/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7608 - mae: 0.7175 - val_loss: 0.7171 - val_mse: 0.7563 - val_mae: 0.7162\n\nEpoch 00403: val_loss did not improve from 0.71675\nEpoch 404/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7606 - mae: 0.7183 - val_loss: 0.7178 - val_mse: 0.7612 - val_mae: 0.7168\n\nEpoch 00404: val_loss did not improve from 0.71675\nEpoch 405/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7203 - mse: 0.7639 - mae: 0.7194 - val_loss: 0.7170 - val_mse: 0.7547 - val_mae: 0.7160\n\nEpoch 00405: val_loss did not improve from 0.71675\nEpoch 406/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7584 - mae: 0.7168 - val_loss: 0.7174 - val_mse: 0.7541 - val_mae: 0.7165\n\nEpoch 00406: val_loss did not improve from 0.71675\nEpoch 407/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7213 - mse: 0.7656 - mae: 0.7204 - val_loss: 0.7167 - val_mse: 0.7568 - val_mae: 0.7158\n\nEpoch 00407: val_loss improved from 0.71675 to 0.71669, saving model to DNN_BestModel.hdf5\nEpoch 408/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7191 - mse: 0.7626 - mae: 0.7182 - val_loss: 0.7176 - val_mse: 0.7615 - val_mae: 0.7166\n\nEpoch 00408: val_loss did not improve from 0.71669\nEpoch 409/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7600 - mae: 0.7171 - val_loss: 0.7170 - val_mse: 0.7528 - val_mae: 0.7161\n\nEpoch 00409: val_loss did not improve from 0.71669\nEpoch 410/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7597 - mae: 0.7181 - val_loss: 0.7170 - val_mse: 0.7554 - val_mae: 0.7161\n\nEpoch 00410: val_loss did not improve from 0.71669\nEpoch 411/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7613 - mae: 0.7178 - val_loss: 0.7166 - val_mse: 0.7576 - val_mae: 0.7157\n\nEpoch 00411: val_loss improved from 0.71669 to 0.71663, saving model to DNN_BestModel.hdf5\nEpoch 412/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7641 - mae: 0.7198 - val_loss: 0.7173 - val_mse: 0.7553 - val_mae: 0.7164\n\nEpoch 00412: val_loss did not improve from 0.71663\nEpoch 413/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7626 - mae: 0.7184 - val_loss: 0.7176 - val_mse: 0.7526 - val_mae: 0.7167\n\nEpoch 00413: val_loss did not improve from 0.71663\nEpoch 414/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7196 - mse: 0.7622 - mae: 0.7187 - val_loss: 0.7168 - val_mse: 0.7543 - val_mae: 0.7159\n\nEpoch 00414: val_loss did not improve from 0.71663\nEpoch 415/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7600 - mae: 0.7180 - val_loss: 0.7171 - val_mse: 0.7552 - val_mae: 0.7162\n\nEpoch 00415: val_loss did not improve from 0.71663\nEpoch 416/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7179 - mse: 0.7575 - mae: 0.7169 - val_loss: 0.7178 - val_mse: 0.7582 - val_mae: 0.7169\n\nEpoch 00416: val_loss did not improve from 0.71663\nEpoch 417/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7179 - mse: 0.7564 - mae: 0.7170 - val_loss: 0.7172 - val_mse: 0.7544 - val_mae: 0.7163\n\nEpoch 00417: val_loss did not improve from 0.71663\nEpoch 418/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7596 - mae: 0.7182 - val_loss: 0.7171 - val_mse: 0.7556 - val_mae: 0.7162\n\nEpoch 00418: val_loss did not improve from 0.71663\nEpoch 419/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7175 - mse: 0.7574 - mae: 0.7166 - val_loss: 0.7180 - val_mse: 0.7550 - val_mae: 0.7171\n\nEpoch 00419: val_loss did not improve from 0.71663\nEpoch 420/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7171 - mse: 0.7576 - mae: 0.7162 - val_loss: 0.7169 - val_mse: 0.7552 - val_mae: 0.7160\n\nEpoch 00420: val_loss did not improve from 0.71663\nEpoch 421/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7607 - mae: 0.7186 - val_loss: 0.7169 - val_mse: 0.7568 - val_mae: 0.7160\n\nEpoch 00421: val_loss did not improve from 0.71663\nEpoch 422/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7627 - mae: 0.7189 - val_loss: 0.7175 - val_mse: 0.7547 - val_mae: 0.7166\n\nEpoch 00422: val_loss did not improve from 0.71663\nEpoch 423/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7182 - mse: 0.7592 - mae: 0.7173 - val_loss: 0.7170 - val_mse: 0.7559 - val_mae: 0.7161\n\nEpoch 00423: val_loss did not improve from 0.71663\nEpoch 424/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7182 - mse: 0.7592 - mae: 0.7173 - val_loss: 0.7170 - val_mse: 0.7557 - val_mae: 0.7160\n\nEpoch 00424: val_loss did not improve from 0.71663\nEpoch 425/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7638 - mae: 0.7195 - val_loss: 0.7168 - val_mse: 0.7557 - val_mae: 0.7159\n\nEpoch 00425: val_loss did not improve from 0.71663\nEpoch 426/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7626 - mae: 0.7181 - val_loss: 0.7170 - val_mse: 0.7537 - val_mae: 0.7161\n\nEpoch 00426: val_loss did not improve from 0.71663\nEpoch 427/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7624 - mae: 0.7188 - val_loss: 0.7169 - val_mse: 0.7559 - val_mae: 0.7160\n\nEpoch 00427: val_loss did not improve from 0.71663\nEpoch 428/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7593 - mae: 0.7169 - val_loss: 0.7170 - val_mse: 0.7573 - val_mae: 0.7161\n\nEpoch 00428: val_loss did not improve from 0.71663\nEpoch 429/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7592 - mae: 0.7169 - val_loss: 0.7167 - val_mse: 0.7551 - val_mae: 0.7158\n\nEpoch 00429: val_loss did not improve from 0.71663\nEpoch 430/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7183 - mse: 0.7602 - mae: 0.7174 - val_loss: 0.7169 - val_mse: 0.7561 - val_mae: 0.7160\n\nEpoch 00430: val_loss did not improve from 0.71663\nEpoch 431/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7621 - mae: 0.7186 - val_loss: 0.7170 - val_mse: 0.7571 - val_mae: 0.7161\n\nEpoch 00431: val_loss did not improve from 0.71663\nEpoch 432/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7601 - mae: 0.7175 - val_loss: 0.7169 - val_mse: 0.7554 - val_mae: 0.7160\n\nEpoch 00432: val_loss did not improve from 0.71663\nEpoch 433/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7197 - mse: 0.7642 - mae: 0.7188 - val_loss: 0.7165 - val_mse: 0.7579 - val_mae: 0.7156\n\nEpoch 00433: val_loss improved from 0.71663 to 0.71650, saving model to DNN_BestModel.hdf5\nEpoch 434/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7194 - mse: 0.7626 - mae: 0.7185 - val_loss: 0.7170 - val_mse: 0.7564 - val_mae: 0.7161\n\nEpoch 00434: val_loss did not improve from 0.71650\nEpoch 435/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7203 - mse: 0.7632 - mae: 0.7194 - val_loss: 0.7168 - val_mse: 0.7542 - val_mae: 0.7159\n\nEpoch 00435: val_loss did not improve from 0.71650\nEpoch 436/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7619 - mae: 0.7182 - val_loss: 0.7176 - val_mse: 0.7530 - val_mae: 0.7167\n\nEpoch 00436: val_loss did not improve from 0.71650\nEpoch 437/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7195 - mse: 0.7614 - mae: 0.7186 - val_loss: 0.7168 - val_mse: 0.7533 - val_mae: 0.7159\n\nEpoch 00437: val_loss did not improve from 0.71650\nEpoch 438/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7607 - mae: 0.7184 - val_loss: 0.7170 - val_mse: 0.7585 - val_mae: 0.7162\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00438: val_loss did not improve from 0.71650\nEpoch 439/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7169 - mse: 0.7588 - mae: 0.7160 - val_loss: 0.7168 - val_mse: 0.7550 - val_mae: 0.7159\n\nEpoch 00439: val_loss did not improve from 0.71650\nEpoch 440/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7601 - mae: 0.7174 - val_loss: 0.7171 - val_mse: 0.7563 - val_mae: 0.7162\n\nEpoch 00440: val_loss did not improve from 0.71650\nEpoch 441/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7649 - mae: 0.7197 - val_loss: 0.7170 - val_mse: 0.7560 - val_mae: 0.7161\n\nEpoch 00441: val_loss did not improve from 0.71650\nEpoch 442/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7196 - mse: 0.7626 - mae: 0.7187 - val_loss: 0.7172 - val_mse: 0.7540 - val_mae: 0.7163\n\nEpoch 00442: val_loss did not improve from 0.71650\nEpoch 443/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7619 - mae: 0.7189 - val_loss: 0.7170 - val_mse: 0.7547 - val_mae: 0.7161\n\nEpoch 00443: val_loss did not improve from 0.71650\nEpoch 444/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7632 - mae: 0.7193 - val_loss: 0.7172 - val_mse: 0.7601 - val_mae: 0.7163\n\nEpoch 00444: val_loss did not improve from 0.71650\nEpoch 445/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7618 - mae: 0.7183 - val_loss: 0.7171 - val_mse: 0.7553 - val_mae: 0.7162\n\nEpoch 00445: val_loss did not improve from 0.71650\nEpoch 446/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7583 - mae: 0.7171 - val_loss: 0.7171 - val_mse: 0.7558 - val_mae: 0.7162\n\nEpoch 00446: val_loss did not improve from 0.71650\nEpoch 447/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7179 - mse: 0.7584 - mae: 0.7170 - val_loss: 0.7167 - val_mse: 0.7545 - val_mae: 0.7158\n\nEpoch 00447: val_loss did not improve from 0.71650\nEpoch 448/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7627 - mae: 0.7182 - val_loss: 0.7167 - val_mse: 0.7549 - val_mae: 0.7158\n\nEpoch 00448: val_loss did not improve from 0.71650\nEpoch 449/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7619 - mae: 0.7184 - val_loss: 0.7165 - val_mse: 0.7559 - val_mae: 0.7156\n\nEpoch 00449: val_loss improved from 0.71650 to 0.71650, saving model to DNN_BestModel.hdf5\nEpoch 450/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7628 - mae: 0.7183 - val_loss: 0.7173 - val_mse: 0.7558 - val_mae: 0.7164\n\nEpoch 00450: val_loss did not improve from 0.71650\nEpoch 451/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7194 - mse: 0.7622 - mae: 0.7185 - val_loss: 0.7171 - val_mse: 0.7578 - val_mae: 0.7162\n\nEpoch 00451: val_loss did not improve from 0.71650\nEpoch 452/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7178 - mse: 0.7590 - mae: 0.7169 - val_loss: 0.7174 - val_mse: 0.7580 - val_mae: 0.7165\n\nEpoch 00452: val_loss did not improve from 0.71650\nEpoch 453/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7591 - mae: 0.7180 - val_loss: 0.7169 - val_mse: 0.7560 - val_mae: 0.7160\n\nEpoch 00453: val_loss did not improve from 0.71650\nEpoch 454/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7612 - mae: 0.7177 - val_loss: 0.7170 - val_mse: 0.7543 - val_mae: 0.7161\n\nEpoch 00454: val_loss did not improve from 0.71650\nEpoch 455/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7182 - mse: 0.7587 - mae: 0.7173 - val_loss: 0.7171 - val_mse: 0.7573 - val_mae: 0.7162\n\nEpoch 00455: val_loss did not improve from 0.71650\nEpoch 456/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7618 - mae: 0.7183 - val_loss: 0.7173 - val_mse: 0.7566 - val_mae: 0.7164\n\nEpoch 00456: val_loss did not improve from 0.71650\nEpoch 457/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7618 - mae: 0.7185 - val_loss: 0.7169 - val_mse: 0.7558 - val_mae: 0.7161\n\nEpoch 00457: val_loss did not improve from 0.71650\nEpoch 458/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7602 - mae: 0.7178 - val_loss: 0.7169 - val_mse: 0.7559 - val_mae: 0.7160\n\nEpoch 00458: val_loss did not improve from 0.71650\nEpoch 459/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7173 - mse: 0.7586 - mae: 0.7164 - val_loss: 0.7171 - val_mse: 0.7534 - val_mae: 0.7162\n\nEpoch 00459: val_loss did not improve from 0.71650\nEpoch 460/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7588 - mae: 0.7178 - val_loss: 0.7170 - val_mse: 0.7568 - val_mae: 0.7161\n\nEpoch 00460: val_loss did not improve from 0.71650\nEpoch 461/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7183 - mse: 0.7588 - mae: 0.7174 - val_loss: 0.7174 - val_mse: 0.7544 - val_mae: 0.7165\n\nEpoch 00461: val_loss did not improve from 0.71650\nEpoch 462/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7172 - mse: 0.7575 - mae: 0.7164 - val_loss: 0.7168 - val_mse: 0.7583 - val_mae: 0.7160\n\nEpoch 00462: val_loss did not improve from 0.71650\nEpoch 463/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7636 - mae: 0.7185 - val_loss: 0.7170 - val_mse: 0.7556 - val_mae: 0.7161\n\nEpoch 00463: val_loss did not improve from 0.71650\nEpoch 464/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7615 - mae: 0.7186 - val_loss: 0.7168 - val_mse: 0.7559 - val_mae: 0.7159\n\nEpoch 00464: val_loss did not improve from 0.71650\nEpoch 465/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7174 - mse: 0.7587 - mae: 0.7165 - val_loss: 0.7173 - val_mse: 0.7547 - val_mae: 0.7164\n\nEpoch 00465: val_loss did not improve from 0.71650\nEpoch 466/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7625 - mae: 0.7195 - val_loss: 0.7171 - val_mse: 0.7544 - val_mae: 0.7162\n\nEpoch 00466: val_loss did not improve from 0.71650\nEpoch 467/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7607 - mae: 0.7180 - val_loss: 0.7168 - val_mse: 0.7569 - val_mae: 0.7160\n\nEpoch 00467: val_loss did not improve from 0.71650\nEpoch 468/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7617 - mae: 0.7182 - val_loss: 0.7169 - val_mse: 0.7539 - val_mae: 0.7160\n\nEpoch 00468: val_loss did not improve from 0.71650\nEpoch 469/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7601 - mae: 0.7178 - val_loss: 0.7171 - val_mse: 0.7552 - val_mae: 0.7163\n\nEpoch 00469: val_loss did not improve from 0.71650\nEpoch 470/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7198 - mse: 0.7615 - mae: 0.7189 - val_loss: 0.7172 - val_mse: 0.7530 - val_mae: 0.7163\n\nEpoch 00470: val_loss did not improve from 0.71650\nEpoch 471/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7596 - mae: 0.7179 - val_loss: 0.7170 - val_mse: 0.7565 - val_mae: 0.7161\n\nEpoch 00471: val_loss did not improve from 0.71650\nEpoch 472/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7588 - mae: 0.7174 - val_loss: 0.7169 - val_mse: 0.7558 - val_mae: 0.7160\n\nEpoch 00472: val_loss did not improve from 0.71650\nEpoch 473/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7172 - mse: 0.7583 - mae: 0.7163 - val_loss: 0.7166 - val_mse: 0.7561 - val_mae: 0.7157\n\nEpoch 00473: val_loss did not improve from 0.71650\nEpoch 474/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7176 - mse: 0.7583 - mae: 0.7167 - val_loss: 0.7166 - val_mse: 0.7530 - val_mae: 0.7157\n\nEpoch 00474: val_loss did not improve from 0.71650\nEpoch 475/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7601 - mae: 0.7178 - val_loss: 0.7170 - val_mse: 0.7544 - val_mae: 0.7161\n\nEpoch 00475: val_loss did not improve from 0.71650\nEpoch 476/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 7ms/step - loss: 0.7192 - mse: 0.7615 - mae: 0.7184 - val_loss: 0.7173 - val_mse: 0.7546 - val_mae: 0.7164\n\nEpoch 00476: val_loss did not improve from 0.71650\nEpoch 477/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7189 - mse: 0.7622 - mae: 0.7181 - val_loss: 0.7169 - val_mse: 0.7569 - val_mae: 0.7160\n\nEpoch 00477: val_loss did not improve from 0.71650\nEpoch 478/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7196 - mse: 0.7632 - mae: 0.7188 - val_loss: 0.7172 - val_mse: 0.7575 - val_mae: 0.7163\n\nEpoch 00478: val_loss did not improve from 0.71650\nEpoch 479/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7183 - mse: 0.7586 - mae: 0.7175 - val_loss: 0.7168 - val_mse: 0.7538 - val_mae: 0.7160\n\nEpoch 00479: val_loss did not improve from 0.71650\nEpoch 480/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7591 - mae: 0.7172 - val_loss: 0.7169 - val_mse: 0.7539 - val_mae: 0.7160\n\nEpoch 00480: val_loss did not improve from 0.71650\nEpoch 481/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7179 - mse: 0.7579 - mae: 0.7171 - val_loss: 0.7172 - val_mse: 0.7557 - val_mae: 0.7163\n\nEpoch 00481: val_loss did not improve from 0.71650\nEpoch 482/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7577 - mae: 0.7173 - val_loss: 0.7168 - val_mse: 0.7529 - val_mae: 0.7159\n\nEpoch 00482: val_loss did not improve from 0.71650\nEpoch 483/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7173 - mse: 0.7584 - mae: 0.7165 - val_loss: 0.7169 - val_mse: 0.7556 - val_mae: 0.7160\n\nEpoch 00483: val_loss did not improve from 0.71650\nEpoch 484/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7606 - mae: 0.7184 - val_loss: 0.7168 - val_mse: 0.7564 - val_mae: 0.7159\n\nEpoch 00484: val_loss did not improve from 0.71650\nEpoch 485/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7584 - mae: 0.7171 - val_loss: 0.7168 - val_mse: 0.7547 - val_mae: 0.7159\n\nEpoch 00485: val_loss did not improve from 0.71650\nEpoch 486/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7598 - mae: 0.7178 - val_loss: 0.7166 - val_mse: 0.7558 - val_mae: 0.7158\n\nEpoch 00486: val_loss did not improve from 0.71650\nEpoch 487/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7185 - mse: 0.7589 - mae: 0.7177 - val_loss: 0.7175 - val_mse: 0.7555 - val_mae: 0.7167\n\nEpoch 00487: val_loss did not improve from 0.71650\nEpoch 488/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7202 - mse: 0.7636 - mae: 0.7194 - val_loss: 0.7172 - val_mse: 0.7541 - val_mae: 0.7163\n\nEpoch 00488: val_loss did not improve from 0.71650\nEpoch 489/1000\n188/188 [==============================] - 2s 9ms/step - loss: 0.7193 - mse: 0.7622 - mae: 0.7185 - val_loss: 0.7170 - val_mse: 0.7552 - val_mae: 0.7161\n\nEpoch 00489: val_loss did not improve from 0.71650\nEpoch 490/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7619 - mae: 0.7180 - val_loss: 0.7172 - val_mse: 0.7553 - val_mae: 0.7163\n\nEpoch 00490: val_loss did not improve from 0.71650\nEpoch 491/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7586 - mae: 0.7168 - val_loss: 0.7171 - val_mse: 0.7545 - val_mae: 0.7162\n\nEpoch 00491: val_loss did not improve from 0.71650\nEpoch 492/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7181 - mse: 0.7589 - mae: 0.7173 - val_loss: 0.7172 - val_mse: 0.7582 - val_mae: 0.7164\n\nEpoch 00492: val_loss did not improve from 0.71650\nEpoch 493/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7209 - mse: 0.7649 - mae: 0.7200 - val_loss: 0.7173 - val_mse: 0.7576 - val_mae: 0.7164\n\nEpoch 00493: val_loss did not improve from 0.71650\nEpoch 494/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7164 - mse: 0.7568 - mae: 0.7155 - val_loss: 0.7171 - val_mse: 0.7564 - val_mae: 0.7162\n\nEpoch 00494: val_loss did not improve from 0.71650\nEpoch 495/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7176 - mse: 0.7589 - mae: 0.7167 - val_loss: 0.7175 - val_mse: 0.7577 - val_mae: 0.7166\n\nEpoch 00495: val_loss did not improve from 0.71650\nEpoch 496/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7167 - mse: 0.7566 - mae: 0.7158 - val_loss: 0.7171 - val_mse: 0.7538 - val_mae: 0.7162\n\nEpoch 00496: val_loss did not improve from 0.71650\nEpoch 497/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7199 - mse: 0.7612 - mae: 0.7190 - val_loss: 0.7169 - val_mse: 0.7560 - val_mae: 0.7160\n\nEpoch 00497: val_loss did not improve from 0.71650\nEpoch 498/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7623 - mae: 0.7182 - val_loss: 0.7170 - val_mse: 0.7543 - val_mae: 0.7161\n\nEpoch 00498: val_loss did not improve from 0.71650\nEpoch 499/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7606 - mae: 0.7188 - val_loss: 0.7168 - val_mse: 0.7582 - val_mae: 0.7159\n\nEpoch 00499: val_loss did not improve from 0.71650\nEpoch 500/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7634 - mae: 0.7198 - val_loss: 0.7167 - val_mse: 0.7539 - val_mae: 0.7158\n\nEpoch 00500: val_loss did not improve from 0.71650\nEpoch 501/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7618 - mae: 0.7187 - val_loss: 0.7171 - val_mse: 0.7540 - val_mae: 0.7163\n\nEpoch 00501: val_loss did not improve from 0.71650\nEpoch 502/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7589 - mae: 0.7168 - val_loss: 0.7170 - val_mse: 0.7543 - val_mae: 0.7162\n\nEpoch 00502: val_loss did not improve from 0.71650\nEpoch 503/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7204 - mse: 0.7631 - mae: 0.7195 - val_loss: 0.7168 - val_mse: 0.7555 - val_mae: 0.7160\n\nEpoch 00503: val_loss did not improve from 0.71650\nEpoch 504/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7186 - mse: 0.7610 - mae: 0.7177 - val_loss: 0.7168 - val_mse: 0.7572 - val_mae: 0.7160\n\nEpoch 00504: val_loss did not improve from 0.71650\nEpoch 505/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7175 - mse: 0.7591 - mae: 0.7167 - val_loss: 0.7175 - val_mse: 0.7548 - val_mae: 0.7166\n\nEpoch 00505: val_loss did not improve from 0.71650\nEpoch 506/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7186 - mse: 0.7592 - mae: 0.7177 - val_loss: 0.7167 - val_mse: 0.7548 - val_mae: 0.7159\n\nEpoch 00506: val_loss did not improve from 0.71650\nEpoch 507/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7186 - mse: 0.7595 - mae: 0.7178 - val_loss: 0.7167 - val_mse: 0.7571 - val_mae: 0.7158\n\nEpoch 00507: val_loss did not improve from 0.71650\nEpoch 508/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7625 - mae: 0.7189 - val_loss: 0.7170 - val_mse: 0.7548 - val_mae: 0.7161\n\nEpoch 00508: val_loss did not improve from 0.71650\nEpoch 509/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7608 - mae: 0.7184 - val_loss: 0.7173 - val_mse: 0.7568 - val_mae: 0.7164\n\nEpoch 00509: val_loss did not improve from 0.71650\nEpoch 510/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7625 - mae: 0.7186 - val_loss: 0.7174 - val_mse: 0.7560 - val_mae: 0.7166\n\nEpoch 00510: val_loss did not improve from 0.71650\nEpoch 511/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7615 - mae: 0.7187 - val_loss: 0.7169 - val_mse: 0.7555 - val_mae: 0.7161\n\nEpoch 00511: val_loss did not improve from 0.71650\nEpoch 512/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7167 - mse: 0.7556 - mae: 0.7159 - val_loss: 0.7170 - val_mse: 0.7564 - val_mae: 0.7162\n\nEpoch 00512: val_loss did not improve from 0.71650\nEpoch 513/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7633 - mae: 0.7186 - val_loss: 0.7168 - val_mse: 0.7535 - val_mae: 0.7159\n\nEpoch 00513: val_loss did not improve from 0.71650\nEpoch 514/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7588 - mae: 0.7175 - val_loss: 0.7169 - val_mse: 0.7571 - val_mae: 0.7160\n\nEpoch 00514: val_loss did not improve from 0.71650\nEpoch 515/1000\n188/188 [==============================] - 2s 9ms/step - loss: 0.7190 - mse: 0.7616 - mae: 0.7181 - val_loss: 0.7170 - val_mse: 0.7602 - val_mae: 0.7162\n\nEpoch 00515: val_loss did not improve from 0.71650\nEpoch 516/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7176 - mse: 0.7594 - mae: 0.7168 - val_loss: 0.7174 - val_mse: 0.7551 - val_mae: 0.7166\n\nEpoch 00516: val_loss did not improve from 0.71650\nEpoch 517/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7597 - mae: 0.7179 - val_loss: 0.7172 - val_mse: 0.7576 - val_mae: 0.7163\n\nEpoch 00517: val_loss did not improve from 0.71650\nEpoch 518/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7166 - mse: 0.7571 - mae: 0.7157 - val_loss: 0.7167 - val_mse: 0.7555 - val_mae: 0.7159\n\nEpoch 00518: val_loss did not improve from 0.71650\nEpoch 519/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7179 - mse: 0.7590 - mae: 0.7170 - val_loss: 0.7174 - val_mse: 0.7550 - val_mae: 0.7166\n\nEpoch 00519: val_loss did not improve from 0.71650\nEpoch 520/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7169 - mse: 0.7582 - mae: 0.7161 - val_loss: 0.7171 - val_mse: 0.7562 - val_mae: 0.7162\n\nEpoch 00520: val_loss did not improve from 0.71650\nEpoch 521/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7182 - mse: 0.7603 - mae: 0.7173 - val_loss: 0.7171 - val_mse: 0.7547 - val_mae: 0.7162\n\nEpoch 00521: val_loss did not improve from 0.71650\nEpoch 522/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7584 - mae: 0.7168 - val_loss: 0.7169 - val_mse: 0.7548 - val_mae: 0.7161\n\nEpoch 00522: val_loss did not improve from 0.71650\nEpoch 523/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7604 - mae: 0.7178 - val_loss: 0.7166 - val_mse: 0.7559 - val_mae: 0.7158\n\nEpoch 00523: val_loss did not improve from 0.71650\nEpoch 524/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7613 - mae: 0.7176 - val_loss: 0.7169 - val_mse: 0.7557 - val_mae: 0.7161\n\nEpoch 00524: val_loss did not improve from 0.71650\nEpoch 525/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7186 - mse: 0.7605 - mae: 0.7178 - val_loss: 0.7171 - val_mse: 0.7538 - val_mae: 0.7162\n\nEpoch 00525: val_loss did not improve from 0.71650\nEpoch 526/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7177 - mse: 0.7574 - mae: 0.7169 - val_loss: 0.7168 - val_mse: 0.7587 - val_mae: 0.7160\n\nEpoch 00526: val_loss did not improve from 0.71650\nEpoch 527/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7603 - mae: 0.7183 - val_loss: 0.7168 - val_mse: 0.7555 - val_mae: 0.7160\n\nEpoch 00527: val_loss did not improve from 0.71650\nEpoch 528/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7648 - mae: 0.7191 - val_loss: 0.7174 - val_mse: 0.7576 - val_mae: 0.7166\n\nEpoch 00528: val_loss did not improve from 0.71650\nEpoch 529/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7589 - mae: 0.7171 - val_loss: 0.7174 - val_mse: 0.7550 - val_mae: 0.7166\n\nEpoch 00529: val_loss did not improve from 0.71650\nEpoch 530/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7212 - mse: 0.7642 - mae: 0.7204 - val_loss: 0.7171 - val_mse: 0.7541 - val_mae: 0.7162\n\nEpoch 00530: val_loss did not improve from 0.71650\nEpoch 531/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7632 - mae: 0.7192 - val_loss: 0.7171 - val_mse: 0.7577 - val_mae: 0.7163\n\nEpoch 00531: val_loss did not improve from 0.71650\nEpoch 532/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7199 - mse: 0.7626 - mae: 0.7191 - val_loss: 0.7171 - val_mse: 0.7564 - val_mae: 0.7163\n\nEpoch 00532: val_loss did not improve from 0.71650\nEpoch 533/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7633 - mae: 0.7184 - val_loss: 0.7169 - val_mse: 0.7547 - val_mae: 0.7161\n\nEpoch 00533: val_loss did not improve from 0.71650\nEpoch 534/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7600 - mae: 0.7173 - val_loss: 0.7170 - val_mse: 0.7530 - val_mae: 0.7162\n\nEpoch 00534: val_loss did not improve from 0.71650\nEpoch 535/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7188 - mse: 0.7579 - mae: 0.7179 - val_loss: 0.7169 - val_mse: 0.7544 - val_mae: 0.7161\n\nEpoch 00535: val_loss did not improve from 0.71650\nEpoch 536/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7175 - mse: 0.7568 - mae: 0.7167 - val_loss: 0.7174 - val_mse: 0.7541 - val_mae: 0.7166\n\nEpoch 00536: val_loss did not improve from 0.71650\nEpoch 537/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7623 - mae: 0.7188 - val_loss: 0.7170 - val_mse: 0.7574 - val_mae: 0.7161\n\nEpoch 00537: val_loss did not improve from 0.71650\nEpoch 538/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7181 - mse: 0.7607 - mae: 0.7173 - val_loss: 0.7171 - val_mse: 0.7546 - val_mae: 0.7163\n\nEpoch 00538: val_loss did not improve from 0.71650\nEpoch 539/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7609 - mae: 0.7184 - val_loss: 0.7172 - val_mse: 0.7545 - val_mae: 0.7163\n\nEpoch 00539: val_loss did not improve from 0.71650\nEpoch 540/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7167 - mse: 0.7566 - mae: 0.7158 - val_loss: 0.7168 - val_mse: 0.7555 - val_mae: 0.7160\n\nEpoch 00540: val_loss did not improve from 0.71650\nEpoch 541/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7605 - mae: 0.7184 - val_loss: 0.7169 - val_mse: 0.7550 - val_mae: 0.7161\n\nEpoch 00541: val_loss did not improve from 0.71650\nEpoch 542/1000\n188/188 [==============================] - 2s 9ms/step - loss: 0.7176 - mse: 0.7588 - mae: 0.7168 - val_loss: 0.7172 - val_mse: 0.7539 - val_mae: 0.7164\n\nEpoch 00542: val_loss did not improve from 0.71650\nEpoch 543/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7625 - mae: 0.7194 - val_loss: 0.7171 - val_mse: 0.7568 - val_mae: 0.7163\n\nEpoch 00543: val_loss did not improve from 0.71650\nEpoch 544/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7189 - mse: 0.7610 - mae: 0.7181 - val_loss: 0.7170 - val_mse: 0.7569 - val_mae: 0.7162\n\nEpoch 00544: val_loss did not improve from 0.71650\nEpoch 545/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7593 - mae: 0.7172 - val_loss: 0.7172 - val_mse: 0.7586 - val_mae: 0.7164\n\nEpoch 00545: val_loss did not improve from 0.71650\nEpoch 546/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7626 - mae: 0.7178 - val_loss: 0.7168 - val_mse: 0.7563 - val_mae: 0.7160\n\nEpoch 00546: val_loss did not improve from 0.71650\nEpoch 547/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7573 - mae: 0.7169 - val_loss: 0.7170 - val_mse: 0.7562 - val_mae: 0.7161\n\nEpoch 00547: val_loss did not improve from 0.71650\nEpoch 548/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7638 - mae: 0.7193 - val_loss: 0.7167 - val_mse: 0.7573 - val_mae: 0.7159\n\nEpoch 00548: val_loss did not improve from 0.71650\nEpoch 549/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7594 - mae: 0.7171 - val_loss: 0.7175 - val_mse: 0.7575 - val_mae: 0.7167\n\nEpoch 00549: val_loss did not improve from 0.71650\nEpoch 550/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7600 - mae: 0.7175 - val_loss: 0.7167 - val_mse: 0.7562 - val_mae: 0.7159\n\nEpoch 00550: val_loss did not improve from 0.71650\nEpoch 551/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7611 - mae: 0.7179 - val_loss: 0.7166 - val_mse: 0.7547 - val_mae: 0.7158\n\nEpoch 00551: val_loss did not improve from 0.71650\nEpoch 552/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7632 - mae: 0.7192 - val_loss: 0.7173 - val_mse: 0.7591 - val_mae: 0.7164\n\nEpoch 00552: val_loss did not improve from 0.71650\nEpoch 553/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7203 - mse: 0.7656 - mae: 0.7195 - val_loss: 0.7172 - val_mse: 0.7564 - val_mae: 0.7164\n\nEpoch 00553: val_loss did not improve from 0.71650\nEpoch 554/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7174 - mse: 0.7590 - mae: 0.7165 - val_loss: 0.7167 - val_mse: 0.7546 - val_mae: 0.7159\n\nEpoch 00554: val_loss did not improve from 0.71650\nEpoch 555/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7587 - mae: 0.7175 - val_loss: 0.7173 - val_mse: 0.7540 - val_mae: 0.7165\n\nEpoch 00555: val_loss did not improve from 0.71650\nEpoch 556/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7615 - mae: 0.7179 - val_loss: 0.7171 - val_mse: 0.7545 - val_mae: 0.7163\n\nEpoch 00556: val_loss did not improve from 0.71650\nEpoch 557/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7199 - mse: 0.7635 - mae: 0.7191 - val_loss: 0.7169 - val_mse: 0.7561 - val_mae: 0.7161\n\nEpoch 00557: val_loss did not improve from 0.71650\nEpoch 558/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7202 - mse: 0.7627 - mae: 0.7194 - val_loss: 0.7167 - val_mse: 0.7579 - val_mae: 0.7159\n\nEpoch 00558: val_loss did not improve from 0.71650\nEpoch 559/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7600 - mae: 0.7178 - val_loss: 0.7169 - val_mse: 0.7533 - val_mae: 0.7161\n\nEpoch 00559: val_loss did not improve from 0.71650\nEpoch 560/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7587 - mae: 0.7170 - val_loss: 0.7172 - val_mse: 0.7585 - val_mae: 0.7164\n\nEpoch 00560: val_loss did not improve from 0.71650\nEpoch 561/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7583 - mae: 0.7172 - val_loss: 0.7168 - val_mse: 0.7571 - val_mae: 0.7159\n\nEpoch 00561: val_loss did not improve from 0.71650\nEpoch 562/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7594 - mae: 0.7170 - val_loss: 0.7168 - val_mse: 0.7565 - val_mae: 0.7160\n\nEpoch 00562: val_loss did not improve from 0.71650\nEpoch 563/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7185 - mse: 0.7598 - mae: 0.7176 - val_loss: 0.7167 - val_mse: 0.7557 - val_mae: 0.7159\n\nEpoch 00563: val_loss did not improve from 0.71650\nEpoch 564/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7580 - mae: 0.7168 - val_loss: 0.7168 - val_mse: 0.7557 - val_mae: 0.7159\n\nEpoch 00564: val_loss did not improve from 0.71650\nEpoch 565/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7621 - mae: 0.7182 - val_loss: 0.7166 - val_mse: 0.7538 - val_mae: 0.7158\n\nEpoch 00565: val_loss did not improve from 0.71650\nEpoch 566/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7173 - mse: 0.7571 - mae: 0.7165 - val_loss: 0.7173 - val_mse: 0.7563 - val_mae: 0.7165\n\nEpoch 00566: val_loss did not improve from 0.71650\nEpoch 567/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7206 - mse: 0.7623 - mae: 0.7198 - val_loss: 0.7171 - val_mse: 0.7562 - val_mae: 0.7163\n\nEpoch 00567: val_loss did not improve from 0.71650\nEpoch 568/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7185 - mse: 0.7607 - mae: 0.7177 - val_loss: 0.7172 - val_mse: 0.7546 - val_mae: 0.7164\n\nEpoch 00568: val_loss did not improve from 0.71650\nEpoch 569/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7185 - mse: 0.7583 - mae: 0.7177 - val_loss: 0.7169 - val_mse: 0.7567 - val_mae: 0.7161\n\nEpoch 00569: val_loss did not improve from 0.71650\nEpoch 570/1000\n188/188 [==============================] - 2s 8ms/step - loss: 0.7173 - mse: 0.7567 - mae: 0.7165 - val_loss: 0.7167 - val_mse: 0.7555 - val_mae: 0.7159\n\nEpoch 00570: val_loss did not improve from 0.71650\nEpoch 571/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7619 - mae: 0.7173 - val_loss: 0.7170 - val_mse: 0.7561 - val_mae: 0.7162\n\nEpoch 00571: val_loss did not improve from 0.71650\nEpoch 572/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7174 - mse: 0.7589 - mae: 0.7166 - val_loss: 0.7168 - val_mse: 0.7572 - val_mae: 0.7160\n\nEpoch 00572: val_loss did not improve from 0.71650\nEpoch 573/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7173 - mse: 0.7586 - mae: 0.7165 - val_loss: 0.7171 - val_mse: 0.7562 - val_mae: 0.7163\n\nEpoch 00573: val_loss did not improve from 0.71650\nEpoch 574/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7205 - mse: 0.7644 - mae: 0.7197 - val_loss: 0.7171 - val_mse: 0.7546 - val_mae: 0.7162\n\nEpoch 00574: val_loss did not improve from 0.71650\nEpoch 575/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7596 - mae: 0.7182 - val_loss: 0.7169 - val_mse: 0.7568 - val_mae: 0.7161\n\nEpoch 00575: val_loss did not improve from 0.71650\nEpoch 576/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7620 - mae: 0.7181 - val_loss: 0.7171 - val_mse: 0.7568 - val_mae: 0.7163\n\nEpoch 00576: val_loss did not improve from 0.71650\nEpoch 577/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7194 - mse: 0.7628 - mae: 0.7186 - val_loss: 0.7169 - val_mse: 0.7552 - val_mae: 0.7161\n\nEpoch 00577: val_loss did not improve from 0.71650\nEpoch 578/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7217 - mse: 0.7666 - mae: 0.7209 - val_loss: 0.7168 - val_mse: 0.7563 - val_mae: 0.7159\n\nEpoch 00578: val_loss did not improve from 0.71650\nEpoch 579/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7628 - mae: 0.7175 - val_loss: 0.7168 - val_mse: 0.7570 - val_mae: 0.7160\n\nEpoch 00579: val_loss did not improve from 0.71650\nEpoch 580/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7176 - mse: 0.7584 - mae: 0.7168 - val_loss: 0.7169 - val_mse: 0.7562 - val_mae: 0.7161\n\nEpoch 00580: val_loss did not improve from 0.71650\nEpoch 581/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7171 - mse: 0.7577 - mae: 0.7163 - val_loss: 0.7174 - val_mse: 0.7583 - val_mae: 0.7166\n\nEpoch 00581: val_loss did not improve from 0.71650\nEpoch 582/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7180 - mse: 0.7594 - mae: 0.7172 - val_loss: 0.7170 - val_mse: 0.7560 - val_mae: 0.7162\n\nEpoch 00582: val_loss did not improve from 0.71650\nEpoch 583/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7615 - mae: 0.7187 - val_loss: 0.7165 - val_mse: 0.7562 - val_mae: 0.7157\n\nEpoch 00583: val_loss did not improve from 0.71650\nEpoch 584/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7168 - mse: 0.7566 - mae: 0.7160 - val_loss: 0.7171 - val_mse: 0.7565 - val_mae: 0.7163\n\nEpoch 00584: val_loss did not improve from 0.71650\nEpoch 585/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7585 - mae: 0.7169 - val_loss: 0.7168 - val_mse: 0.7560 - val_mae: 0.7160\n\nEpoch 00585: val_loss did not improve from 0.71650\nEpoch 586/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7174 - mse: 0.7579 - mae: 0.7166 - val_loss: 0.7168 - val_mse: 0.7542 - val_mae: 0.7160\n\nEpoch 00586: val_loss did not improve from 0.71650\nEpoch 587/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7589 - mae: 0.7179 - val_loss: 0.7172 - val_mse: 0.7541 - val_mae: 0.7164\n\nEpoch 00587: val_loss did not improve from 0.71650\nEpoch 588/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7191 - mse: 0.7621 - mae: 0.7183 - val_loss: 0.7170 - val_mse: 0.7565 - val_mae: 0.7162\n\nEpoch 00588: val_loss did not improve from 0.71650\nEpoch 589/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7586 - mae: 0.7172 - val_loss: 0.7168 - val_mse: 0.7565 - val_mae: 0.7160\n\nEpoch 00589: val_loss did not improve from 0.71650\nEpoch 590/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7616 - mae: 0.7182 - val_loss: 0.7166 - val_mse: 0.7565 - val_mae: 0.7158\n\nEpoch 00590: val_loss did not improve from 0.71650\nEpoch 591/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7172 - mse: 0.7588 - mae: 0.7164 - val_loss: 0.7166 - val_mse: 0.7557 - val_mae: 0.7158\n\nEpoch 00591: val_loss did not improve from 0.71650\nEpoch 592/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7190 - mse: 0.7592 - mae: 0.7182 - val_loss: 0.7168 - val_mse: 0.7541 - val_mae: 0.7160\n\nEpoch 00592: val_loss did not improve from 0.71650\nEpoch 593/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7187 - mse: 0.7610 - mae: 0.7179 - val_loss: 0.7170 - val_mse: 0.7546 - val_mae: 0.7162\n\nEpoch 00593: val_loss did not improve from 0.71650\nEpoch 594/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7620 - mae: 0.7185 - val_loss: 0.7169 - val_mse: 0.7570 - val_mae: 0.7161\n\nEpoch 00594: val_loss did not improve from 0.71650\nEpoch 595/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7197 - mse: 0.7627 - mae: 0.7190 - val_loss: 0.7167 - val_mse: 0.7555 - val_mae: 0.7159\n\nEpoch 00595: val_loss did not improve from 0.71650\nEpoch 596/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7180 - mse: 0.7600 - mae: 0.7172 - val_loss: 0.7174 - val_mse: 0.7560 - val_mae: 0.7166\n\nEpoch 00596: val_loss did not improve from 0.71650\nEpoch 597/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7605 - mae: 0.7176 - val_loss: 0.7173 - val_mse: 0.7565 - val_mae: 0.7165\n\nEpoch 00597: val_loss did not improve from 0.71650\nEpoch 598/1000\n188/188 [==============================] - 1s 8ms/step - loss: 0.7172 - mse: 0.7582 - mae: 0.7164 - val_loss: 0.7172 - val_mse: 0.7568 - val_mae: 0.7164\n\nEpoch 00598: val_loss did not improve from 0.71650\nEpoch 599/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7566 - mae: 0.7170 - val_loss: 0.7168 - val_mse: 0.7563 - val_mae: 0.7160\n\nEpoch 00599: val_loss did not improve from 0.71650\nEpoch 600/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7195 - mse: 0.7596 - mae: 0.7187 - val_loss: 0.7168 - val_mse: 0.7552 - val_mae: 0.7160\n\nEpoch 00600: val_loss did not improve from 0.71650\nEpoch 601/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7188 - mse: 0.7610 - mae: 0.7180 - val_loss: 0.7175 - val_mse: 0.7533 - val_mae: 0.7167\n\nEpoch 00601: val_loss did not improve from 0.71650\nEpoch 602/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7183 - mse: 0.7594 - mae: 0.7175 - val_loss: 0.7171 - val_mse: 0.7570 - val_mae: 0.7163\n\nEpoch 00602: val_loss did not improve from 0.71650\nEpoch 603/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7618 - mae: 0.7185 - val_loss: 0.7169 - val_mse: 0.7570 - val_mae: 0.7161\n\nEpoch 00603: val_loss did not improve from 0.71650\nEpoch 604/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7177 - mse: 0.7609 - mae: 0.7169 - val_loss: 0.7171 - val_mse: 0.7565 - val_mae: 0.7163\n\nEpoch 00604: val_loss did not improve from 0.71650\nEpoch 605/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7162 - mse: 0.7560 - mae: 0.7154 - val_loss: 0.7172 - val_mse: 0.7529 - val_mae: 0.7164\n\nEpoch 00605: val_loss did not improve from 0.71650\nEpoch 606/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7597 - mae: 0.7178 - val_loss: 0.7167 - val_mse: 0.7550 - val_mae: 0.7159\n\nEpoch 00606: val_loss did not improve from 0.71650\nEpoch 607/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7182 - mse: 0.7594 - mae: 0.7174 - val_loss: 0.7174 - val_mse: 0.7552 - val_mae: 0.7166\n\nEpoch 00607: val_loss did not improve from 0.71650\nEpoch 608/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7207 - mse: 0.7632 - mae: 0.7199 - val_loss: 0.7167 - val_mse: 0.7574 - val_mae: 0.7159\n\nEpoch 00608: val_loss did not improve from 0.71650\nEpoch 609/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7189 - mse: 0.7620 - mae: 0.7181 - val_loss: 0.7169 - val_mse: 0.7539 - val_mae: 0.7161\n\nEpoch 00609: val_loss did not improve from 0.71650\nEpoch 610/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7201 - mse: 0.7636 - mae: 0.7193 - val_loss: 0.7170 - val_mse: 0.7551 - val_mae: 0.7162\n\nEpoch 00610: val_loss did not improve from 0.71650\nEpoch 611/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7192 - mse: 0.7624 - mae: 0.7184 - val_loss: 0.7168 - val_mse: 0.7562 - val_mae: 0.7160\n\nEpoch 00611: val_loss did not improve from 0.71650\nEpoch 612/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7609 - mae: 0.7170 - val_loss: 0.7168 - val_mse: 0.7559 - val_mae: 0.7160\n\nEpoch 00612: val_loss did not improve from 0.71650\nEpoch 613/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7604 - mae: 0.7174 - val_loss: 0.7167 - val_mse: 0.7541 - val_mae: 0.7159\n\nEpoch 00613: val_loss did not improve from 0.71650\nEpoch 614/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7175 - mse: 0.7572 - mae: 0.7167 - val_loss: 0.7172 - val_mse: 0.7546 - val_mae: 0.7164\n\nEpoch 00614: val_loss did not improve from 0.71650\nEpoch 615/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7594 - mae: 0.7173 - val_loss: 0.7171 - val_mse: 0.7541 - val_mae: 0.7163\n\nEpoch 00615: val_loss did not improve from 0.71650\nEpoch 616/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7198 - mse: 0.7616 - mae: 0.7190 - val_loss: 0.7168 - val_mse: 0.7538 - val_mae: 0.7160\n\nEpoch 00616: val_loss did not improve from 0.71650\nEpoch 617/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7606 - mae: 0.7178 - val_loss: 0.7171 - val_mse: 0.7566 - val_mae: 0.7163\n\nEpoch 00617: val_loss did not improve from 0.71650\nEpoch 618/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7192 - mse: 0.7628 - mae: 0.7184 - val_loss: 0.7169 - val_mse: 0.7556 - val_mae: 0.7161\n\nEpoch 00618: val_loss did not improve from 0.71650\nEpoch 619/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7158 - mse: 0.7547 - mae: 0.7150 - val_loss: 0.7174 - val_mse: 0.7529 - val_mae: 0.7166\n\nEpoch 00619: val_loss did not improve from 0.71650\nEpoch 620/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7202 - mse: 0.7621 - mae: 0.7194 - val_loss: 0.7169 - val_mse: 0.7566 - val_mae: 0.7161\n\nEpoch 00620: val_loss did not improve from 0.71650\nEpoch 621/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7614 - mae: 0.7173 - val_loss: 0.7168 - val_mse: 0.7551 - val_mae: 0.7160\n\nEpoch 00621: val_loss did not improve from 0.71650\nEpoch 622/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7600 - mae: 0.7177 - val_loss: 0.7171 - val_mse: 0.7537 - val_mae: 0.7163\n\nEpoch 00622: val_loss did not improve from 0.71650\nEpoch 623/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7203 - mse: 0.7634 - mae: 0.7195 - val_loss: 0.7169 - val_mse: 0.7564 - val_mae: 0.7161\n\nEpoch 00623: val_loss did not improve from 0.71650\nEpoch 624/1000\n","name":"stdout"},{"output_type":"stream","text":"188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7589 - mae: 0.7176 - val_loss: 0.7171 - val_mse: 0.7570 - val_mae: 0.7163\n\nEpoch 00624: val_loss did not improve from 0.71650\nEpoch 625/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7183 - mse: 0.7588 - mae: 0.7175 - val_loss: 0.7169 - val_mse: 0.7560 - val_mae: 0.7161\n\nEpoch 00625: val_loss did not improve from 0.71650\nEpoch 626/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7185 - mse: 0.7605 - mae: 0.7177 - val_loss: 0.7172 - val_mse: 0.7552 - val_mae: 0.7165\n\nEpoch 00626: val_loss did not improve from 0.71650\nEpoch 627/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7184 - mse: 0.7619 - mae: 0.7177 - val_loss: 0.7170 - val_mse: 0.7550 - val_mae: 0.7162\n\nEpoch 00627: val_loss did not improve from 0.71650\nEpoch 628/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7167 - mse: 0.7568 - mae: 0.7159 - val_loss: 0.7169 - val_mse: 0.7537 - val_mae: 0.7161\n\nEpoch 00628: val_loss did not improve from 0.71650\nEpoch 629/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7195 - mse: 0.7622 - mae: 0.7187 - val_loss: 0.7168 - val_mse: 0.7573 - val_mae: 0.7160\n\nEpoch 00629: val_loss did not improve from 0.71650\nEpoch 630/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7592 - mae: 0.7170 - val_loss: 0.7167 - val_mse: 0.7573 - val_mae: 0.7159\n\nEpoch 00630: val_loss did not improve from 0.71650\nEpoch 631/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7171 - mse: 0.7579 - mae: 0.7163 - val_loss: 0.7170 - val_mse: 0.7548 - val_mae: 0.7162\n\nEpoch 00631: val_loss did not improve from 0.71650\nEpoch 632/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7196 - mse: 0.7620 - mae: 0.7188 - val_loss: 0.7170 - val_mse: 0.7555 - val_mae: 0.7163\n\nEpoch 00632: val_loss did not improve from 0.71650\nEpoch 633/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7182 - mse: 0.7602 - mae: 0.7174 - val_loss: 0.7167 - val_mse: 0.7549 - val_mae: 0.7159\n\nEpoch 00633: val_loss did not improve from 0.71650\nEpoch 634/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7171 - mse: 0.7579 - mae: 0.7163 - val_loss: 0.7168 - val_mse: 0.7557 - val_mae: 0.7160\n\nEpoch 00634: val_loss did not improve from 0.71650\nEpoch 635/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7594 - mae: 0.7173 - val_loss: 0.7170 - val_mse: 0.7551 - val_mae: 0.7162\n\nEpoch 00635: val_loss did not improve from 0.71650\nEpoch 636/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7178 - mse: 0.7579 - mae: 0.7170 - val_loss: 0.7172 - val_mse: 0.7568 - val_mae: 0.7164\n\nEpoch 00636: val_loss did not improve from 0.71650\nEpoch 637/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7180 - mse: 0.7608 - mae: 0.7172 - val_loss: 0.7168 - val_mse: 0.7549 - val_mae: 0.7160\n\nEpoch 00637: val_loss did not improve from 0.71650\nEpoch 638/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7174 - mse: 0.7581 - mae: 0.7166 - val_loss: 0.7169 - val_mse: 0.7567 - val_mae: 0.7162\n\nEpoch 00638: val_loss did not improve from 0.71650\nEpoch 639/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7176 - mse: 0.7588 - mae: 0.7168 - val_loss: 0.7169 - val_mse: 0.7547 - val_mae: 0.7161\n\nEpoch 00639: val_loss did not improve from 0.71650\nEpoch 640/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7200 - mse: 0.7631 - mae: 0.7192 - val_loss: 0.7171 - val_mse: 0.7563 - val_mae: 0.7163\n\nEpoch 00640: val_loss did not improve from 0.71650\nEpoch 641/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7176 - mse: 0.7593 - mae: 0.7168 - val_loss: 0.7172 - val_mse: 0.7540 - val_mae: 0.7164\n\nEpoch 00641: val_loss did not improve from 0.71650\nEpoch 642/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7168 - mse: 0.7570 - mae: 0.7160 - val_loss: 0.7173 - val_mse: 0.7567 - val_mae: 0.7165\n\nEpoch 00642: val_loss did not improve from 0.71650\nEpoch 643/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7190 - mse: 0.7602 - mae: 0.7182 - val_loss: 0.7169 - val_mse: 0.7577 - val_mae: 0.7161\n\nEpoch 00643: val_loss did not improve from 0.71650\nEpoch 644/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7179 - mse: 0.7610 - mae: 0.7171 - val_loss: 0.7172 - val_mse: 0.7537 - val_mae: 0.7165\n\nEpoch 00644: val_loss did not improve from 0.71650\nEpoch 645/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7186 - mse: 0.7607 - mae: 0.7178 - val_loss: 0.7169 - val_mse: 0.7560 - val_mae: 0.7161\n\nEpoch 00645: val_loss did not improve from 0.71650\nEpoch 646/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7616 - mae: 0.7170 - val_loss: 0.7168 - val_mse: 0.7569 - val_mae: 0.7160\n\nEpoch 00646: val_loss did not improve from 0.71650\nEpoch 647/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7625 - mae: 0.7185 - val_loss: 0.7169 - val_mse: 0.7563 - val_mae: 0.7161\n\nEpoch 00647: val_loss did not improve from 0.71650\nEpoch 648/1000\n188/188 [==============================] - 1s 7ms/step - loss: 0.7177 - mse: 0.7594 - mae: 0.7169 - val_loss: 0.7172 - val_mse: 0.7548 - val_mae: 0.7165\n\nEpoch 00648: val_loss did not improve from 0.71650\nEpoch 649/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7193 - mse: 0.7617 - mae: 0.7186 - val_loss: 0.7168 - val_mse: 0.7572 - val_mae: 0.7161\n\nEpoch 00649: val_loss did not improve from 0.71650\nEpoch 650/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7181 - mse: 0.7584 - mae: 0.7173 - val_loss: 0.7166 - val_mse: 0.7551 - val_mae: 0.7158\n\nEpoch 00650: val_loss did not improve from 0.71650\nEpoch 651/1000\n188/188 [==============================] - 1s 6ms/step - loss: 0.7178 - mse: 0.7590 - mae: 0.7170 - val_loss: 0.7165 - val_mse: 0.7549 - val_mae: 0.7158\n\nEpoch 00651: val_loss did not improve from 0.71650\nEpoch 652/1000\n 64/188 [=========>....................] - ETA: 0s - loss: 0.7193 - mse: 0.7633 - mae: 0.7186","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-46f9827e9b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m history = model.fit(X_train, y_train, validation_split=0.2, epochs = 1000, batch_size = 1024,\n\u001b[0;32m---> 55\u001b[0;31m                     validation_data=(X_test, y_test), callbacks=callback_list)\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mRMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# CatBoosting\n'''\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfrom sklearn.model_selection import GridSearchCV\nparam_cat = {'depth':[6,8,10],\n            'learning_rate':[0.005, 0.001],\n            'l2_leaf_reg':[1,4,9],\n            'iterations':[100],\n            'cat_features':[feature_cat],\n            'eval_metric':['RMSE']\n            }\n\ngrid_result = GridSearchCV(estimator=CatBoostRegressor(),param_grid=param_cat, cv=kfold, scoring='neg_mean_squared_error', n_jobs = -1, verbose=2)\ngrid_result.fit(X_train, y_train)\ngrid_param = grid_result.best_params_\nprint(grid_param)\n\n\ncat = CatBoostRegressor(task_type='GPU', iterations=8000, use_best_model=True, depth=10, eval_metric='RMSE', l2_leaf_reg=1, learning_rate=0.001, early_stopping_rounds=10)\ncat.fit(X_train, y_train, cat_features=feature_cat, eval_set = (X_test, y_test))\ny_pred = cat.predict(X_test)\nprint(f'RMSE: {mean_squared_error(y_test, y_pred)}')\n\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred=cat.predict(X_prediction)\noutput = pd.DataFrame({'id': prediction_id, 'target': y_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}