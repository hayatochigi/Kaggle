{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('digit-reg': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5d329b79b66bb5f10ef54625f055718c749a87f375ca3776438035528903fee5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetの取得 https://www.tensorflow.org/tutorials/load_data/images?hl=ja\n",
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import pathlib\n",
    "data_root_orig = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "print(data_root)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[WindowsPath('data/daisy'), WindowsPath('data/dandelion'), WindowsPath('data/roses'), WindowsPath('data/sunflowers'), WindowsPath('data/tulips')]\n['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Pathがkaggle上のパスになっているので注意\n",
    "data_folder = pathlib.Path('../input/flowers-recognition/flowers')\n",
    "flower_folders = []\n",
    "Labels = []\n",
    "for item in data_folder.iterdir():\n",
    "    flower_folders.append(item)\n",
    "    # フォルダ名からラベルを取得\n",
    "    Labels.append(str(item).split('/')[-1])\n",
    "\n",
    "label_dictionary = dict(zip(Labels, np.arange(0,len(Labels))))\n",
    "print(label_dictionary)\n",
    "\n",
    "# .jpgのファイル数をカウントして、ndarrayを初期化したい\n",
    "total_images_number = 0\n",
    "for folder_path in flower_folders:\n",
    "    for file_path in folder_path.iterdir():\n",
    "        if os.path.splitext(file_path)[-1] == '.jpg':\n",
    "            total_images_number += 1\n",
    "print(total_images_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max Width: 1024\nMax Height: 442\nNumber of Images: 3670\n"
     ]
    }
   ],
   "source": [
    "image_size=256\n",
    "X = np.empty([total_images_number,image_size, image_size, 3])\n",
    "y = np.empty([0])\n",
    "count = 0\n",
    "from PIL import Image\n",
    "for folder_path in flower_folders:\n",
    "    for file_path in folder_path.iterdir():\n",
    "        if os.path.splitext(file_path)[-1] == '.jpg':\n",
    "            image = Image.open(file_path)\n",
    "            # 画像データをリサイズし、ndarrayへ変換\n",
    "            image_array = np.asarray(image.resize((image_size, image_size), Image.NEAREST))\n",
    "            image.close()\n",
    "            X[count,:,:,:] = image_array\n",
    "            # 末尾に(label列に)ディクショナリからの値を追加\n",
    "            folder_name = os.path.basename(os.path.dirname(file_path))\n",
    "            y = np.append(y,label_dictionary[folder_name])\n",
    "            count += 1\n",
    "    print(str(folder_name) + ' Completed:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 3 samples\n",
      "3/3 [==============================] - 0s 160ms/sample - loss: 48.1106 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "''' 入力の確認用に使用\n",
    "\n",
    "# CNNの初期化。単純なSequentialモデルで作成。\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# 畳み込み https://keras.io/ja/layers/convolutional/\n",
    "# 128x128 RGB画像ではinput_shape=(128, 128, 3)となります．\n",
    "# 最初のレイヤーだけは、入り口となる入力シェイプが必要\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[100, 100, 3], data_format='channels_last'))\n",
    "\n",
    "# Poolingにより、ダウンサンプリング\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "\n",
    "# 2層目の中間層を追加\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "\n",
    "# Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# 接続\n",
    "# unitsは   レイヤーの出力形状\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# 出力層\n",
    "#cnn.add(tf.keras.layers.Dense(units=10, activation='sigmoid'))\n",
    "cnn.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "# 評価関数の選定 -> https://keras.io/ja/metrics/\n",
    "cnn.compile(optimizer = 'adam', loss = tf.keras.losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "y_train = np.array([1,1,1])\n",
    "answer = cnn.fit(z, y_train, epochs = 1, batch_size = 20)\n",
    "'''\n"
   ]
  }
 ]
}