{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# category variable\ncategory = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\n\n# continuous variable\ncontinuous = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', \n              'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#features = ['cat1', 'cont0', 'cat2', 'cont11', 'cont13', 'cat8', 'cont8', 'cont1', 'cat9',\n#            'cont9', 'cont5', 'cat3', 'cat0', 'cat6', 'cont3', 'cat5', 'cont4', 'cont2', 'cont12']\n\ntrain_dataset = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\ntest_data = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')\ndataset = pd.concat([train_dataset, test_data])\n\n# あきらかな外れ値は削除\n# [166042]はあきらかな外れ値\noutlier=[166042]\nfor x in outlier:\n    dataset = dataset.loc[dataset['id'] != x, :]\n\n# idとtargetは避難させておく\nid = dataset['id']\ntarget = dataset['target']\n# 避難させたので遠慮なく削除\ndataset = dataset.drop(columns=['id', 'target'])\n# 相関が高いものだけを使用\n# この手法は有効だったと思うが、Catboostでのスコアは一定以上伸びなかった。\n\n# 重要度を確認するためにはLabelEncodingが有効\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\nencoder = LabelEncoder()\nscaler = RobustScaler()\n#scaler = StandardScaler()\n\nfor x in dataset.columns:\n    # notebookみると、みんなLabelEncoder使っているなぁ\n    if dataset[x].dtype == object:\n        #dataset[x] = encoder.fit_transform(dataset[x])\n        dataset = pd.get_dummies(dataset, columns=[x], drop_first=True)\n        \n#dataset[continuous] = scaler.fit_transform(dataset.loc[:,continuous].values)\n\n# データセットにidとtargetを元に戻して\ndataset = pd.concat([id,dataset,target], axis=1)\n# targetのあるなしでtrainとtestを分割\ntrain = dataset.loc[dataset['target'].notnull(), :]\ntest  = dataset.loc[dataset['target'].isnull(), :]\n\nX = train.drop(columns=['id', 'target'])\ny = train['target']\nX_prediction = test.drop(columns=['id', 'target'])\nprediction_id = test.loc[:,'id']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lightgbm Optuna\n\n#!pip install optuna \nimport optuna.integration.lightgbm as lgb\n\ntrains = lgb.Dataset(X_train, y_train)\ntests = lgb.Dataset(X_test, y_test)\n\nparams = {'objective': 'mean_squared_error',\n         'metric': 'rmse'}\n\nmodel = lgb.train(params, trains, valid_sets=tests, early_stopping_rounds=10)\nbest_params = model.params\n\n\nimport lightgbm as lgb\n\nregressor = lgb.train(best_params, trains, valid_sets=tests)\ny_pred = regressor.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\nprint(mean_squared_error(y_test, y_pred))","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"output_type":"stream","text":"\u001b[32m[I 2021-02-05 22:50:58,696]\u001b[0m A new study created in memory with name: no-name-c38c9714-0ce2-41ed-8978-51eecaaadeb7\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022568 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888383\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885634\n[3]\tvalid_0's rmse: 0.883426\n[4]\tvalid_0's rmse: 0.881277\n[5]\tvalid_0's rmse: 0.879457\n[6]\tvalid_0's rmse: 0.877413\n[7]\tvalid_0's rmse: 0.875946\n[8]\tvalid_0's rmse: 0.874716\n[9]\tvalid_0's rmse: 0.873567\n[10]\tvalid_0's rmse: 0.87252\n[11]\tvalid_0's rmse: 0.87115\n[12]\tvalid_0's rmse: 0.869951\n[13]\tvalid_0's rmse: 0.868912\n[14]\tvalid_0's rmse: 0.867893\n[15]\tvalid_0's rmse: 0.867223\n[16]\tvalid_0's rmse: 0.866448\n[17]\tvalid_0's rmse: 0.865629\n[18]\tvalid_0's rmse: 0.864958\n[19]\tvalid_0's rmse: 0.864277\n[20]\tvalid_0's rmse: 0.863736\n[21]\tvalid_0's rmse: 0.863174\n[22]\tvalid_0's rmse: 0.86254\n[23]\tvalid_0's rmse: 0.86203\n[24]\tvalid_0's rmse: 0.861496\n[25]\tvalid_0's rmse: 0.861115\n[26]\tvalid_0's rmse: 0.860688\n[27]\tvalid_0's rmse: 0.860287\n[28]\tvalid_0's rmse: 0.859893\n[29]\tvalid_0's rmse: 0.859534\n[30]\tvalid_0's rmse: 0.859173\n[31]\tvalid_0's rmse: 0.858849\n[32]\tvalid_0's rmse: 0.858478\n[33]\tvalid_0's rmse: 0.8582\n[34]\tvalid_0's rmse: 0.857859\n[35]\tvalid_0's rmse: 0.857651\n[36]\tvalid_0's rmse: 0.857327\n[37]\tvalid_0's rmse: 0.857039\n[38]\tvalid_0's rmse: 0.856748\n[39]\tvalid_0's rmse: 0.856478\n[40]\tvalid_0's rmse: 0.856209\n[41]\tvalid_0's rmse: 0.85605\n[42]\tvalid_0's rmse: 0.855829\n[43]\tvalid_0's rmse: 0.855637\n[44]\tvalid_0's rmse: 0.85545\n[45]\tvalid_0's rmse: 0.855202\n[46]\tvalid_0's rmse: 0.855048\n[47]\tvalid_0's rmse: 0.854902\n[48]\tvalid_0's rmse: 0.854705\n[49]\tvalid_0's rmse: 0.854557\n[50]\tvalid_0's rmse: 0.854353\n[51]\tvalid_0's rmse: 0.854249\n[52]\tvalid_0's rmse: 0.854099\n[53]\tvalid_0's rmse: 0.853923\n[54]\tvalid_0's rmse: 0.853732\n[55]\tvalid_0's rmse: 0.853625\n[56]\tvalid_0's rmse: 0.853383\n[57]\tvalid_0's rmse: 0.853242\n[58]\tvalid_0's rmse: 0.853077\n[59]\tvalid_0's rmse: 0.852969\n[60]\tvalid_0's rmse: 0.852823\n[61]\tvalid_0's rmse: 0.852713\n[62]\tvalid_0's rmse: 0.852613\n[63]\tvalid_0's rmse: 0.852393\n[64]\tvalid_0's rmse: 0.852277\n[65]\tvalid_0's rmse: 0.852215\n[66]\tvalid_0's rmse: 0.852101\n[67]\tvalid_0's rmse: 0.852021\n[68]\tvalid_0's rmse: 0.851908\n[69]\tvalid_0's rmse: 0.851734\n[70]\tvalid_0's rmse: 0.851638\n[71]\tvalid_0's rmse: 0.851587\n[72]\tvalid_0's rmse: 0.851526\n[73]\tvalid_0's rmse: 0.851451\n[74]\tvalid_0's rmse: 0.85139\n[75]\tvalid_0's rmse: 0.851296\n[76]\tvalid_0's rmse: 0.851188\n[77]\tvalid_0's rmse: 0.851107\n[78]\tvalid_0's rmse: 0.851015\n[79]\tvalid_0's rmse: 0.850928\n[80]\tvalid_0's rmse: 0.850862\n[81]\tvalid_0's rmse: 0.850767\n[82]\tvalid_0's rmse: 0.85073\n[83]\tvalid_0's rmse: 0.850669\n[84]\tvalid_0's rmse: 0.850608\n[85]\tvalid_0's rmse: 0.850569\n[86]\tvalid_0's rmse: 0.85051\n[87]\tvalid_0's rmse: 0.850455\n[88]\tvalid_0's rmse: 0.850334\n[89]\tvalid_0's rmse: 0.8503\n[90]\tvalid_0's rmse: 0.850243\n[91]\tvalid_0's rmse: 0.850178\n[92]\tvalid_0's rmse: 0.850116\n[93]\tvalid_0's rmse: 0.850077\n[94]\tvalid_0's rmse: 0.850014\n[95]\tvalid_0's rmse: 0.849935\n[96]\tvalid_0's rmse: 0.849879\n[97]\tvalid_0's rmse: 0.849838\n[98]\tvalid_0's rmse: 0.849774\n[99]\tvalid_0's rmse: 0.849743\n[100]\tvalid_0's rmse: 0.849693\n[101]\tvalid_0's rmse: 0.849645\n[102]\tvalid_0's rmse: 0.84956\n[103]\tvalid_0's rmse: 0.849529\n[104]\tvalid_0's rmse: 0.8495\n[105]\tvalid_0's rmse: 0.849429\n[106]\tvalid_0's rmse: 0.84941\n[107]\tvalid_0's rmse: 0.849364\n[108]\tvalid_0's rmse: 0.849268\n[109]\tvalid_0's rmse: 0.849227\n[110]\tvalid_0's rmse: 0.849216\n[111]\tvalid_0's rmse: 0.849156\n[112]\tvalid_0's rmse: 0.849142\n[113]\tvalid_0's rmse: 0.849086\n[114]\tvalid_0's rmse: 0.849084\n[115]\tvalid_0's rmse: 0.849048\n[116]\tvalid_0's rmse: 0.849024\n[117]\tvalid_0's rmse: 0.848955\n[118]\tvalid_0's rmse: 0.848924\n[119]\tvalid_0's rmse: 0.848857\n[120]\tvalid_0's rmse: 0.848847\n[121]\tvalid_0's rmse: 0.848802\n[122]\tvalid_0's rmse: 0.848782\n[123]\tvalid_0's rmse: 0.848731\n[124]\tvalid_0's rmse: 0.848688\n[125]\tvalid_0's rmse: 0.848642\n[126]\tvalid_0's rmse: 0.848643\n[127]\tvalid_0's rmse: 0.848635\n[128]\tvalid_0's rmse: 0.848607\n[129]\tvalid_0's rmse: 0.848557\n[130]\tvalid_0's rmse: 0.848551\n[131]\tvalid_0's rmse: 0.848567\n[132]\tvalid_0's rmse: 0.848558\n[133]\tvalid_0's rmse: 0.848536\n[134]\tvalid_0's rmse: 0.848482\n[135]\tvalid_0's rmse: 0.848469\n[136]\tvalid_0's rmse: 0.848441\n[137]\tvalid_0's rmse: 0.848407\n[138]\tvalid_0's rmse: 0.84838\n[139]\tvalid_0's rmse: 0.848335\n[140]\tvalid_0's rmse: 0.848343\n[141]\tvalid_0's rmse: 0.848343\n[142]\tvalid_0's rmse: 0.848319\n[143]\tvalid_0's rmse: 0.848274\n[144]\tvalid_0's rmse: 0.848257\n[145]\tvalid_0's rmse: 0.848257\n[146]\tvalid_0's rmse: 0.848228\n[147]\tvalid_0's rmse: 0.848227\n[148]\tvalid_0's rmse: 0.848217\n[149]\tvalid_0's rmse: 0.84819\n[150]\tvalid_0's rmse: 0.848181\n[151]\tvalid_0's rmse: 0.848183\n[152]\tvalid_0's rmse: 0.848173\n[153]\tvalid_0's rmse: 0.848171\n[154]\tvalid_0's rmse: 0.848161\n[155]\tvalid_0's rmse: 0.848132\n[156]\tvalid_0's rmse: 0.848131\n[157]\tvalid_0's rmse: 0.848134\n[158]\tvalid_0's rmse: 0.848128\n[159]\tvalid_0's rmse: 0.848141\n[160]\tvalid_0's rmse: 0.848137\n[161]\tvalid_0's rmse: 0.848109\n[162]\tvalid_0's rmse: 0.848117\n[163]\tvalid_0's rmse: 0.848107\n[164]\tvalid_0's rmse: 0.848109\n[165]\tvalid_0's rmse: 0.848121\n[166]\tvalid_0's rmse: 0.848104\n[167]\tvalid_0's rmse: 0.848077\n[168]\tvalid_0's rmse: 0.848063\n[169]\tvalid_0's rmse: 0.848051\n[170]\tvalid_0's rmse: 0.848017\n[171]\tvalid_0's rmse: 0.848015\n[172]\tvalid_0's rmse: 0.848005\n[173]\tvalid_0's rmse: 0.847977\n[174]\tvalid_0's rmse: 0.847958\n[175]\tvalid_0's rmse: 0.847951\n[176]\tvalid_0's rmse: 0.847957\n[177]\tvalid_0's rmse: 0.847947\n[178]\tvalid_0's rmse: 0.847925\n[179]\tvalid_0's rmse: 0.847929\n[180]\tvalid_0's rmse: 0.847919\n[181]\tvalid_0's rmse: 0.847929\n[182]\tvalid_0's rmse: 0.847944\n[183]\tvalid_0's rmse: 0.847938\n[184]\tvalid_0's rmse: 0.847936\n[185]\tvalid_0's rmse: 0.847936\n[186]\tvalid_0's rmse: 0.847924\n[187]\tvalid_0's rmse: 0.847911\n[188]\tvalid_0's rmse: 0.847926\n[189]\tvalid_0's rmse: 0.847918\n[190]\tvalid_0's rmse: 0.847911\n[191]\tvalid_0's rmse: 0.847914\n[192]\tvalid_0's rmse: 0.847895\n[193]\tvalid_0's rmse: 0.847883\n[194]\tvalid_0's rmse: 0.847883\n[195]\tvalid_0's rmse: 0.847839\n[196]\tvalid_0's rmse: 0.847823\n[197]\tvalid_0's rmse: 0.847826\n[198]\tvalid_0's rmse: 0.847827\n[199]\tvalid_0's rmse: 0.847828\n[200]\tvalid_0's rmse: 0.847813\n[201]\tvalid_0's rmse: 0.847789\n[202]\tvalid_0's rmse: 0.84779\n[203]\tvalid_0's rmse: 0.847771\n[204]\tvalid_0's rmse: 0.847768\n[205]\tvalid_0's rmse: 0.847766\n[206]\tvalid_0's rmse: 0.84778\n[207]\tvalid_0's rmse: 0.847779\n[208]\tvalid_0's rmse: 0.847764\n[209]\tvalid_0's rmse: 0.847756\n[210]\tvalid_0's rmse: 0.847739\n[211]\tvalid_0's rmse: 0.847746\n[212]\tvalid_0's rmse: 0.847735\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction, val_score: 0.847706:  14%|#4        | 1/7 [00:05<00:31,  5.20s/it]\u001b[32m[I 2021-02-05 22:51:03,901]\u001b[0m Trial 0 finished with value: 0.8477055332224409 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.8477055332224409.\u001b[0m\nfeature_fraction, val_score: 0.847706:  14%|#4        | 1/7 [00:05<00:31,  5.20s/it]","name":"stderr"},{"output_type":"stream","text":"[213]\tvalid_0's rmse: 0.847709\n[214]\tvalid_0's rmse: 0.847708\n[215]\tvalid_0's rmse: 0.847707\n[216]\tvalid_0's rmse: 0.847706\n[217]\tvalid_0's rmse: 0.847718\n[218]\tvalid_0's rmse: 0.84771\n[219]\tvalid_0's rmse: 0.847723\n[220]\tvalid_0's rmse: 0.847737\n[221]\tvalid_0's rmse: 0.847732\n[222]\tvalid_0's rmse: 0.847748\n[223]\tvalid_0's rmse: 0.847759\n[224]\tvalid_0's rmse: 0.847768\n[225]\tvalid_0's rmse: 0.847771\n[226]\tvalid_0's rmse: 0.847769\nEarly stopping, best iteration is:\n[216]\tvalid_0's rmse: 0.847706\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068561 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887489\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884451\n[3]\tvalid_0's rmse: 0.881814\n[4]\tvalid_0's rmse: 0.879608\n[5]\tvalid_0's rmse: 0.877637\n[6]\tvalid_0's rmse: 0.875839\n[7]\tvalid_0's rmse: 0.87437\n[8]\tvalid_0's rmse: 0.872999\n[9]\tvalid_0's rmse: 0.871675\n[10]\tvalid_0's rmse: 0.870608\n[11]\tvalid_0's rmse: 0.869555\n[12]\tvalid_0's rmse: 0.868753\n[13]\tvalid_0's rmse: 0.867826\n[14]\tvalid_0's rmse: 0.867071\n[15]\tvalid_0's rmse: 0.866333\n[16]\tvalid_0's rmse: 0.865564\n[17]\tvalid_0's rmse: 0.864873\n[18]\tvalid_0's rmse: 0.86432\n[19]\tvalid_0's rmse: 0.863727\n[20]\tvalid_0's rmse: 0.863264\n[21]\tvalid_0's rmse: 0.862737\n[22]\tvalid_0's rmse: 0.862327\n[23]\tvalid_0's rmse: 0.861779\n[24]\tvalid_0's rmse: 0.861385\n[25]\tvalid_0's rmse: 0.860974\n[26]\tvalid_0's rmse: 0.860626\n[27]\tvalid_0's rmse: 0.860292\n[28]\tvalid_0's rmse: 0.859911\n[29]\tvalid_0's rmse: 0.859623\n[30]\tvalid_0's rmse: 0.859286\n[31]\tvalid_0's rmse: 0.859064\n[32]\tvalid_0's rmse: 0.858633\n[33]\tvalid_0's rmse: 0.858409\n[34]\tvalid_0's rmse: 0.858063\n[35]\tvalid_0's rmse: 0.857766\n[36]\tvalid_0's rmse: 0.857562\n[37]\tvalid_0's rmse: 0.857341\n[38]\tvalid_0's rmse: 0.857006\n[39]\tvalid_0's rmse: 0.856778\n[40]\tvalid_0's rmse: 0.856519\n[41]\tvalid_0's rmse: 0.856287\n[42]\tvalid_0's rmse: 0.856069\n[43]\tvalid_0's rmse: 0.855911\n[44]\tvalid_0's rmse: 0.855636\n[45]\tvalid_0's rmse: 0.855461\n[46]\tvalid_0's rmse: 0.855264\n[47]\tvalid_0's rmse: 0.8551\n[48]\tvalid_0's rmse: 0.854879\n[49]\tvalid_0's rmse: 0.854736\n[50]\tvalid_0's rmse: 0.854596\n[51]\tvalid_0's rmse: 0.854444\n[52]\tvalid_0's rmse: 0.85432\n[53]\tvalid_0's rmse: 0.854166\n[54]\tvalid_0's rmse: 0.854019\n[55]\tvalid_0's rmse: 0.853928\n[56]\tvalid_0's rmse: 0.853821\n[57]\tvalid_0's rmse: 0.853687\n[58]\tvalid_0's rmse: 0.853509\n[59]\tvalid_0's rmse: 0.853399\n[60]\tvalid_0's rmse: 0.853255\n[61]\tvalid_0's rmse: 0.853105\n[62]\tvalid_0's rmse: 0.852938\n[63]\tvalid_0's rmse: 0.852847\n[64]\tvalid_0's rmse: 0.852677\n[65]\tvalid_0's rmse: 0.852517\n[66]\tvalid_0's rmse: 0.852463\n[67]\tvalid_0's rmse: 0.852362\n[68]\tvalid_0's rmse: 0.852236\n[69]\tvalid_0's rmse: 0.852134\n[70]\tvalid_0's rmse: 0.852071\n[71]\tvalid_0's rmse: 0.852005\n[72]\tvalid_0's rmse: 0.851934\n[73]\tvalid_0's rmse: 0.851868\n[74]\tvalid_0's rmse: 0.851737\n[75]\tvalid_0's rmse: 0.851687\n[76]\tvalid_0's rmse: 0.851603\n[77]\tvalid_0's rmse: 0.851545\n[78]\tvalid_0's rmse: 0.851435\n[79]\tvalid_0's rmse: 0.851358\n[80]\tvalid_0's rmse: 0.851264\n[81]\tvalid_0's rmse: 0.851238\n[82]\tvalid_0's rmse: 0.851152\n[83]\tvalid_0's rmse: 0.851126\n[84]\tvalid_0's rmse: 0.851039\n[85]\tvalid_0's rmse: 0.850964\n[86]\tvalid_0's rmse: 0.850874\n[87]\tvalid_0's rmse: 0.850807\n[88]\tvalid_0's rmse: 0.850709\n[89]\tvalid_0's rmse: 0.85066\n[90]\tvalid_0's rmse: 0.850583\n[91]\tvalid_0's rmse: 0.850538\n[92]\tvalid_0's rmse: 0.850517\n[93]\tvalid_0's rmse: 0.85051\n[94]\tvalid_0's rmse: 0.850476\n[95]\tvalid_0's rmse: 0.850442\n[96]\tvalid_0's rmse: 0.850394\n[97]\tvalid_0's rmse: 0.850339\n[98]\tvalid_0's rmse: 0.85026\n[99]\tvalid_0's rmse: 0.85023\n[100]\tvalid_0's rmse: 0.850174\n[101]\tvalid_0's rmse: 0.850136\n[102]\tvalid_0's rmse: 0.850135\n[103]\tvalid_0's rmse: 0.850095\n[104]\tvalid_0's rmse: 0.850067\n[105]\tvalid_0's rmse: 0.850016\n[106]\tvalid_0's rmse: 0.850003\n[107]\tvalid_0's rmse: 0.849945\n[108]\tvalid_0's rmse: 0.849855\n[109]\tvalid_0's rmse: 0.849842\n[110]\tvalid_0's rmse: 0.849837\n[111]\tvalid_0's rmse: 0.849791\n[112]\tvalid_0's rmse: 0.849786\n[113]\tvalid_0's rmse: 0.849792\n[114]\tvalid_0's rmse: 0.849712\n[115]\tvalid_0's rmse: 0.849658\n[116]\tvalid_0's rmse: 0.849629\n[117]\tvalid_0's rmse: 0.849592\n[118]\tvalid_0's rmse: 0.849584\n[119]\tvalid_0's rmse: 0.849475\n[120]\tvalid_0's rmse: 0.849441\n[121]\tvalid_0's rmse: 0.849418\n[122]\tvalid_0's rmse: 0.849394\n[123]\tvalid_0's rmse: 0.849345\n[124]\tvalid_0's rmse: 0.849325\n[125]\tvalid_0's rmse: 0.849295\n[126]\tvalid_0's rmse: 0.849272\n[127]\tvalid_0's rmse: 0.84925\n[128]\tvalid_0's rmse: 0.849231\n[129]\tvalid_0's rmse: 0.849183\n[130]\tvalid_0's rmse: 0.849186\n[131]\tvalid_0's rmse: 0.849133\n[132]\tvalid_0's rmse: 0.84913\n[133]\tvalid_0's rmse: 0.849099\n[134]\tvalid_0's rmse: 0.849103\n[135]\tvalid_0's rmse: 0.849098\n[136]\tvalid_0's rmse: 0.849098\n[137]\tvalid_0's rmse: 0.849086\n[138]\tvalid_0's rmse: 0.849093\n[139]\tvalid_0's rmse: 0.849083\n[140]\tvalid_0's rmse: 0.849069\n[141]\tvalid_0's rmse: 0.849049\n[142]\tvalid_0's rmse: 0.849039\n[143]\tvalid_0's rmse: 0.849051\n[144]\tvalid_0's rmse: 0.849022\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction, val_score: 0.847706:  29%|##8       | 2/7 [00:09<00:22,  4.55s/it]\u001b[32m[I 2021-02-05 22:51:07,993]\u001b[0m Trial 1 finished with value: 0.8489921624405916 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.8477055332224409.\u001b[0m\nfeature_fraction, val_score: 0.847706:  29%|##8       | 2/7 [00:09<00:22,  4.55s/it]","name":"stderr"},{"output_type":"stream","text":"[145]\tvalid_0's rmse: 0.848992\n[146]\tvalid_0's rmse: 0.848993\n[147]\tvalid_0's rmse: 0.84902\n[148]\tvalid_0's rmse: 0.849027\n[149]\tvalid_0's rmse: 0.84905\n[150]\tvalid_0's rmse: 0.849045\n[151]\tvalid_0's rmse: 0.84904\n[152]\tvalid_0's rmse: 0.849021\n[153]\tvalid_0's rmse: 0.849034\n[154]\tvalid_0's rmse: 0.849027\n[155]\tvalid_0's rmse: 0.849026\nEarly stopping, best iteration is:\n[145]\tvalid_0's rmse: 0.848992\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019201 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887492\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884938\n[3]\tvalid_0's rmse: 0.882318\n[4]\tvalid_0's rmse: 0.880263\n[5]\tvalid_0's rmse: 0.878387\n[6]\tvalid_0's rmse: 0.876478\n[7]\tvalid_0's rmse: 0.874991\n[8]\tvalid_0's rmse: 0.873633\n[9]\tvalid_0's rmse: 0.872518\n[10]\tvalid_0's rmse: 0.871361\n[11]\tvalid_0's rmse: 0.870089\n[12]\tvalid_0's rmse: 0.869114\n[13]\tvalid_0's rmse: 0.868151\n[14]\tvalid_0's rmse: 0.867248\n[15]\tvalid_0's rmse: 0.866587\n[16]\tvalid_0's rmse: 0.865963\n[17]\tvalid_0's rmse: 0.865157\n[18]\tvalid_0's rmse: 0.864544\n[19]\tvalid_0's rmse: 0.863864\n[20]\tvalid_0's rmse: 0.863309\n[21]\tvalid_0's rmse: 0.862708\n[22]\tvalid_0's rmse: 0.862276\n[23]\tvalid_0's rmse: 0.861747\n[24]\tvalid_0's rmse: 0.861377\n[25]\tvalid_0's rmse: 0.86096\n[26]\tvalid_0's rmse: 0.860555\n[27]\tvalid_0's rmse: 0.860104\n[28]\tvalid_0's rmse: 0.859789\n[29]\tvalid_0's rmse: 0.859464\n[30]\tvalid_0's rmse: 0.859033\n[31]\tvalid_0's rmse: 0.858691\n[32]\tvalid_0's rmse: 0.858333\n[33]\tvalid_0's rmse: 0.858022\n[34]\tvalid_0's rmse: 0.857782\n[35]\tvalid_0's rmse: 0.857552\n[36]\tvalid_0's rmse: 0.857289\n[37]\tvalid_0's rmse: 0.857032\n[38]\tvalid_0's rmse: 0.856817\n[39]\tvalid_0's rmse: 0.856577\n[40]\tvalid_0's rmse: 0.856322\n[41]\tvalid_0's rmse: 0.856139\n[42]\tvalid_0's rmse: 0.855966\n[43]\tvalid_0's rmse: 0.855713\n[44]\tvalid_0's rmse: 0.855449\n[45]\tvalid_0's rmse: 0.855308\n[46]\tvalid_0's rmse: 0.855136\n[47]\tvalid_0's rmse: 0.85492\n[48]\tvalid_0's rmse: 0.854726\n[49]\tvalid_0's rmse: 0.854583\n[50]\tvalid_0's rmse: 0.854446\n[51]\tvalid_0's rmse: 0.854317\n[52]\tvalid_0's rmse: 0.854165\n[53]\tvalid_0's rmse: 0.853983\n[54]\tvalid_0's rmse: 0.853786\n[55]\tvalid_0's rmse: 0.853618\n[56]\tvalid_0's rmse: 0.853497\n[57]\tvalid_0's rmse: 0.853376\n[58]\tvalid_0's rmse: 0.853249\n[59]\tvalid_0's rmse: 0.853109\n[60]\tvalid_0's rmse: 0.852925\n[61]\tvalid_0's rmse: 0.852843\n[62]\tvalid_0's rmse: 0.852758\n[63]\tvalid_0's rmse: 0.852634\n[64]\tvalid_0's rmse: 0.852499\n[65]\tvalid_0's rmse: 0.852343\n[66]\tvalid_0's rmse: 0.852258\n[67]\tvalid_0's rmse: 0.852186\n[68]\tvalid_0's rmse: 0.852112\n[69]\tvalid_0's rmse: 0.852001\n[70]\tvalid_0's rmse: 0.851914\n[71]\tvalid_0's rmse: 0.851849\n[72]\tvalid_0's rmse: 0.851734\n[73]\tvalid_0's rmse: 0.85166\n[74]\tvalid_0's rmse: 0.851548\n[75]\tvalid_0's rmse: 0.851492\n[76]\tvalid_0's rmse: 0.851409\n[77]\tvalid_0's rmse: 0.851318\n[78]\tvalid_0's rmse: 0.851238\n[79]\tvalid_0's rmse: 0.851175\n[80]\tvalid_0's rmse: 0.851137\n[81]\tvalid_0's rmse: 0.851059\n[82]\tvalid_0's rmse: 0.85101\n[83]\tvalid_0's rmse: 0.850952\n[84]\tvalid_0's rmse: 0.850825\n[85]\tvalid_0's rmse: 0.850763\n[86]\tvalid_0's rmse: 0.85073\n[87]\tvalid_0's rmse: 0.850677\n[88]\tvalid_0's rmse: 0.85062\n[89]\tvalid_0's rmse: 0.850561\n[90]\tvalid_0's rmse: 0.850519\n[91]\tvalid_0's rmse: 0.850453\n[92]\tvalid_0's rmse: 0.850366\n[93]\tvalid_0's rmse: 0.850294\n[94]\tvalid_0's rmse: 0.850246\n[95]\tvalid_0's rmse: 0.850184\n[96]\tvalid_0's rmse: 0.850167\n[97]\tvalid_0's rmse: 0.850137\n[98]\tvalid_0's rmse: 0.850093\n[99]\tvalid_0's rmse: 0.850047\n[100]\tvalid_0's rmse: 0.849975\n[101]\tvalid_0's rmse: 0.849941\n[102]\tvalid_0's rmse: 0.849834\n[103]\tvalid_0's rmse: 0.849829\n[104]\tvalid_0's rmse: 0.84977\n[105]\tvalid_0's rmse: 0.849722\n[106]\tvalid_0's rmse: 0.84972\n[107]\tvalid_0's rmse: 0.849704\n[108]\tvalid_0's rmse: 0.849659\n[109]\tvalid_0's rmse: 0.849639\n[110]\tvalid_0's rmse: 0.849608\n[111]\tvalid_0's rmse: 0.849571\n[112]\tvalid_0's rmse: 0.849552\n[113]\tvalid_0's rmse: 0.84951\n[114]\tvalid_0's rmse: 0.849444\n[115]\tvalid_0's rmse: 0.849404\n[116]\tvalid_0's rmse: 0.849413\n[117]\tvalid_0's rmse: 0.84939\n[118]\tvalid_0's rmse: 0.849381\n[119]\tvalid_0's rmse: 0.849362\n[120]\tvalid_0's rmse: 0.849329\n[121]\tvalid_0's rmse: 0.849295\n[122]\tvalid_0's rmse: 0.849274\n[123]\tvalid_0's rmse: 0.849252\n[124]\tvalid_0's rmse: 0.849235\n[125]\tvalid_0's rmse: 0.849219\n[126]\tvalid_0's rmse: 0.849193\n[127]\tvalid_0's rmse: 0.8492\n[128]\tvalid_0's rmse: 0.849173\n[129]\tvalid_0's rmse: 0.849165\n[130]\tvalid_0's rmse: 0.849171\n[131]\tvalid_0's rmse: 0.849154\n[132]\tvalid_0's rmse: 0.849138\n[133]\tvalid_0's rmse: 0.849145\n[134]\tvalid_0's rmse: 0.849139\n[135]\tvalid_0's rmse: 0.849091\n[136]\tvalid_0's rmse: 0.849065\n[137]\tvalid_0's rmse: 0.849032\n[138]\tvalid_0's rmse: 0.849022\n[139]\tvalid_0's rmse: 0.848993\n[140]\tvalid_0's rmse: 0.848991\n[141]\tvalid_0's rmse: 0.848971\n[142]\tvalid_0's rmse: 0.848943\n[143]\tvalid_0's rmse: 0.848937\n[144]\tvalid_0's rmse: 0.848928\n[145]\tvalid_0's rmse: 0.848914\n[146]\tvalid_0's rmse: 0.848913\n[147]\tvalid_0's rmse: 0.848909\n[148]\tvalid_0's rmse: 0.848904\n[149]\tvalid_0's rmse: 0.848886\n[150]\tvalid_0's rmse: 0.848881\n[151]\tvalid_0's rmse: 0.848852\n[152]\tvalid_0's rmse: 0.848822\n[153]\tvalid_0's rmse: 0.848833\n[154]\tvalid_0's rmse: 0.848796\n[155]\tvalid_0's rmse: 0.848777\n[156]\tvalid_0's rmse: 0.848778\n[157]\tvalid_0's rmse: 0.848748\n[158]\tvalid_0's rmse: 0.848757\n[159]\tvalid_0's rmse: 0.848752\n[160]\tvalid_0's rmse: 0.848757\n[161]\tvalid_0's rmse: 0.848723\n[162]\tvalid_0's rmse: 0.848648\n[163]\tvalid_0's rmse: 0.848619\n[164]\tvalid_0's rmse: 0.848628\n[165]\tvalid_0's rmse: 0.848617\n[166]\tvalid_0's rmse: 0.848615\n[167]\tvalid_0's rmse: 0.848602\n[168]\tvalid_0's rmse: 0.848578\n[169]\tvalid_0's rmse: 0.848558\n[170]\tvalid_0's rmse: 0.848565\n[171]\tvalid_0's rmse: 0.848548\n[172]\tvalid_0's rmse: 0.848503\n[173]\tvalid_0's rmse: 0.848469\n[174]\tvalid_0's rmse: 0.848469\n[175]\tvalid_0's rmse: 0.848458\n[176]\tvalid_0's rmse: 0.848452\n[177]\tvalid_0's rmse: 0.848429\n[178]\tvalid_0's rmse: 0.848428\n[179]\tvalid_0's rmse: 0.84843\n[180]\tvalid_0's rmse: 0.848431\n[181]\tvalid_0's rmse: 0.84842\n[182]\tvalid_0's rmse: 0.84838\n[183]\tvalid_0's rmse: 0.848365\n[184]\tvalid_0's rmse: 0.848345\n[185]\tvalid_0's rmse: 0.848333\n[186]\tvalid_0's rmse: 0.848332\n[187]\tvalid_0's rmse: 0.848316\n[188]\tvalid_0's rmse: 0.848295\n[189]\tvalid_0's rmse: 0.848291\n[190]\tvalid_0's rmse: 0.848302\n[191]\tvalid_0's rmse: 0.848294\n[192]\tvalid_0's rmse: 0.848306\n[193]\tvalid_0's rmse: 0.848306\n[194]\tvalid_0's rmse: 0.848292\n[195]\tvalid_0's rmse: 0.848291\n[196]\tvalid_0's rmse: 0.848282\n[197]\tvalid_0's rmse: 0.848292\n[198]\tvalid_0's rmse: 0.848299\n[199]\tvalid_0's rmse: 0.84829\n[200]\tvalid_0's rmse: 0.848287\n[201]\tvalid_0's rmse: 0.848267\n[202]\tvalid_0's rmse: 0.848266\n[203]\tvalid_0's rmse: 0.848274\n[204]\tvalid_0's rmse: 0.848274\n[205]\tvalid_0's rmse: 0.848278\n[206]\tvalid_0's rmse: 0.848258\n[207]\tvalid_0's rmse: 0.848251\n[208]\tvalid_0's rmse: 0.848248\n[209]\tvalid_0's rmse: 0.84825\n[210]\tvalid_0's rmse: 0.848239\n[211]\tvalid_0's rmse: 0.848207\n[212]\tvalid_0's rmse: 0.848194\n[213]\tvalid_0's rmse: 0.848191\n[214]\tvalid_0's rmse: 0.848168\n[215]\tvalid_0's rmse: 0.848156\n[216]\tvalid_0's rmse: 0.848146\n[217]\tvalid_0's rmse: 0.84813\n[218]\tvalid_0's rmse: 0.848128\n[219]\tvalid_0's rmse: 0.848136\n[220]\tvalid_0's rmse: 0.848127\n[221]\tvalid_0's rmse: 0.848132\n[222]\tvalid_0's rmse: 0.848122\n[223]\tvalid_0's rmse: 0.84814\n[224]\tvalid_0's rmse: 0.848137\n[225]\tvalid_0's rmse: 0.848137\n[226]\tvalid_0's rmse: 0.848146\n[227]\tvalid_0's rmse: 0.848144\n[228]\tvalid_0's rmse: 0.848138\n[229]\tvalid_0's rmse: 0.848135\n[230]\tvalid_0's rmse: 0.848126\n[231]\tvalid_0's rmse: 0.848107\n[232]\tvalid_0's rmse: 0.8481\n[233]\tvalid_0's rmse: 0.848108\n[234]\tvalid_0's rmse: 0.848119\n[235]\tvalid_0's rmse: 0.848122\n[236]\tvalid_0's rmse: 0.848112\n[237]\tvalid_0's rmse: 0.848117\n[238]\tvalid_0's rmse: 0.84813\n[239]\tvalid_0's rmse: 0.848126\n[240]\tvalid_0's rmse: 0.848121\n[241]\tvalid_0's rmse: 0.848104\n[242]\tvalid_0's rmse: 0.848094\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction, val_score: 0.847706:  43%|####2     | 3/7 [00:14<00:19,  4.88s/it]","name":"stderr"},{"output_type":"stream","text":"[243]\tvalid_0's rmse: 0.848091\n[244]\tvalid_0's rmse: 0.84808\n[245]\tvalid_0's rmse: 0.848085\n[246]\tvalid_0's rmse: 0.848095\n[247]\tvalid_0's rmse: 0.848092\n[248]\tvalid_0's rmse: 0.848079\n[249]\tvalid_0's rmse: 0.848093\n[250]\tvalid_0's rmse: 0.848105\n[251]\tvalid_0's rmse: 0.848114\n[252]\tvalid_0's rmse: 0.848102\n[253]\tvalid_0's rmse: 0.848104\n[254]\tvalid_0's rmse: 0.848102\n[255]\tvalid_0's rmse: 0.848108\n[256]\tvalid_0's rmse: 0.848113\n[257]\tvalid_0's rmse: 0.848118\n[258]\tvalid_0's rmse: 0.848127\nEarly stopping, best iteration is:\n[248]\tvalid_0's rmse: 0.848079\n","name":"stdout"},{"output_type":"stream","text":"\u001b[32m[I 2021-02-05 22:51:13,275]\u001b[0m Trial 2 finished with value: 0.8480794408696262 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.8477055332224409.\u001b[0m\nfeature_fraction, val_score: 0.847706:  43%|####2     | 3/7 [00:14<00:19,  4.88s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022475 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887154\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884189\n[3]\tvalid_0's rmse: 0.881562\n[4]\tvalid_0's rmse: 0.879283\n[5]\tvalid_0's rmse: 0.877445\n[6]\tvalid_0's rmse: 0.875651\n[7]\tvalid_0's rmse: 0.874175\n[8]\tvalid_0's rmse: 0.872926\n[9]\tvalid_0's rmse: 0.871684\n[10]\tvalid_0's rmse: 0.870609\n[11]\tvalid_0's rmse: 0.86971\n[12]\tvalid_0's rmse: 0.86872\n[13]\tvalid_0's rmse: 0.867826\n[14]\tvalid_0's rmse: 0.86711\n[15]\tvalid_0's rmse: 0.866357\n[16]\tvalid_0's rmse: 0.865678\n[17]\tvalid_0's rmse: 0.865019\n[18]\tvalid_0's rmse: 0.864363\n[19]\tvalid_0's rmse: 0.863832\n[20]\tvalid_0's rmse: 0.863278\n[21]\tvalid_0's rmse: 0.862827\n[22]\tvalid_0's rmse: 0.86232\n[23]\tvalid_0's rmse: 0.861893\n[24]\tvalid_0's rmse: 0.861484\n[25]\tvalid_0's rmse: 0.861054\n[26]\tvalid_0's rmse: 0.860593\n[27]\tvalid_0's rmse: 0.860263\n[28]\tvalid_0's rmse: 0.859941\n[29]\tvalid_0's rmse: 0.859576\n[30]\tvalid_0's rmse: 0.859283\n[31]\tvalid_0's rmse: 0.858953\n[32]\tvalid_0's rmse: 0.858691\n[33]\tvalid_0's rmse: 0.858433\n[34]\tvalid_0's rmse: 0.858157\n[35]\tvalid_0's rmse: 0.8579\n[36]\tvalid_0's rmse: 0.857626\n[37]\tvalid_0's rmse: 0.857402\n[38]\tvalid_0's rmse: 0.857139\n[39]\tvalid_0's rmse: 0.856946\n[40]\tvalid_0's rmse: 0.856692\n[41]\tvalid_0's rmse: 0.856468\n[42]\tvalid_0's rmse: 0.856286\n[43]\tvalid_0's rmse: 0.856064\n[44]\tvalid_0's rmse: 0.855849\n[45]\tvalid_0's rmse: 0.855562\n[46]\tvalid_0's rmse: 0.855374\n[47]\tvalid_0's rmse: 0.855125\n[48]\tvalid_0's rmse: 0.854945\n[49]\tvalid_0's rmse: 0.854817\n[50]\tvalid_0's rmse: 0.854671\n[51]\tvalid_0's rmse: 0.854498\n[52]\tvalid_0's rmse: 0.854299\n[53]\tvalid_0's rmse: 0.854077\n[54]\tvalid_0's rmse: 0.85391\n[55]\tvalid_0's rmse: 0.853794\n[56]\tvalid_0's rmse: 0.853651\n[57]\tvalid_0's rmse: 0.853529\n[58]\tvalid_0's rmse: 0.853405\n[59]\tvalid_0's rmse: 0.853197\n[60]\tvalid_0's rmse: 0.853122\n[61]\tvalid_0's rmse: 0.853032\n[62]\tvalid_0's rmse: 0.852965\n[63]\tvalid_0's rmse: 0.852876\n[64]\tvalid_0's rmse: 0.852761\n[65]\tvalid_0's rmse: 0.852572\n[66]\tvalid_0's rmse: 0.852501\n[67]\tvalid_0's rmse: 0.852392\n[68]\tvalid_0's rmse: 0.852288\n[69]\tvalid_0's rmse: 0.852194\n[70]\tvalid_0's rmse: 0.852058\n[71]\tvalid_0's rmse: 0.85199\n[72]\tvalid_0's rmse: 0.851889\n[73]\tvalid_0's rmse: 0.851806\n[74]\tvalid_0's rmse: 0.851688\n[75]\tvalid_0's rmse: 0.85151\n[76]\tvalid_0's rmse: 0.851454\n[77]\tvalid_0's rmse: 0.851353\n[78]\tvalid_0's rmse: 0.851268\n[79]\tvalid_0's rmse: 0.851215\n[80]\tvalid_0's rmse: 0.85113\n[81]\tvalid_0's rmse: 0.851072\n[82]\tvalid_0's rmse: 0.851017\n[83]\tvalid_0's rmse: 0.850924\n[84]\tvalid_0's rmse: 0.850821\n[85]\tvalid_0's rmse: 0.850738\n[86]\tvalid_0's rmse: 0.850675\n[87]\tvalid_0's rmse: 0.850577\n[88]\tvalid_0's rmse: 0.850535\n[89]\tvalid_0's rmse: 0.850477\n[90]\tvalid_0's rmse: 0.850413\n[91]\tvalid_0's rmse: 0.850375\n[92]\tvalid_0's rmse: 0.850343\n[93]\tvalid_0's rmse: 0.850312\n[94]\tvalid_0's rmse: 0.850267\n[95]\tvalid_0's rmse: 0.850207\n[96]\tvalid_0's rmse: 0.850175\n[97]\tvalid_0's rmse: 0.850169\n[98]\tvalid_0's rmse: 0.850123\n[99]\tvalid_0's rmse: 0.850114\n[100]\tvalid_0's rmse: 0.850106\n[101]\tvalid_0's rmse: 0.850037\n[102]\tvalid_0's rmse: 0.850006\n[103]\tvalid_0's rmse: 0.849953\n[104]\tvalid_0's rmse: 0.849927\n[105]\tvalid_0's rmse: 0.849903\n[106]\tvalid_0's rmse: 0.849881\n[107]\tvalid_0's rmse: 0.84986\n[108]\tvalid_0's rmse: 0.849823\n[109]\tvalid_0's rmse: 0.849775\n[110]\tvalid_0's rmse: 0.849741\n[111]\tvalid_0's rmse: 0.849717\n[112]\tvalid_0's rmse: 0.849691\n[113]\tvalid_0's rmse: 0.84969\n[114]\tvalid_0's rmse: 0.849664\n[115]\tvalid_0's rmse: 0.849643\n[116]\tvalid_0's rmse: 0.84961\n[117]\tvalid_0's rmse: 0.84957\n[118]\tvalid_0's rmse: 0.849553\n[119]\tvalid_0's rmse: 0.849496\n[120]\tvalid_0's rmse: 0.849479\n[121]\tvalid_0's rmse: 0.849433\n[122]\tvalid_0's rmse: 0.849422\n[123]\tvalid_0's rmse: 0.849387\n[124]\tvalid_0's rmse: 0.849385\n[125]\tvalid_0's rmse: 0.849406\n[126]\tvalid_0's rmse: 0.849397\n[127]\tvalid_0's rmse: 0.849371\n[128]\tvalid_0's rmse: 0.849347\n[129]\tvalid_0's rmse: 0.849285\n[130]\tvalid_0's rmse: 0.849244\n[131]\tvalid_0's rmse: 0.849234\n[132]\tvalid_0's rmse: 0.849234\n[133]\tvalid_0's rmse: 0.849217\n[134]\tvalid_0's rmse: 0.849223\n[135]\tvalid_0's rmse: 0.84921\n[136]\tvalid_0's rmse: 0.84922\n[137]\tvalid_0's rmse: 0.849223\n[138]\tvalid_0's rmse: 0.849209\n[139]\tvalid_0's rmse: 0.849197\n[140]\tvalid_0's rmse: 0.849202\n[141]\tvalid_0's rmse: 0.849179\n[142]\tvalid_0's rmse: 0.849202\n[143]\tvalid_0's rmse: 0.849202\n[144]\tvalid_0's rmse: 0.849183\n[145]\tvalid_0's rmse: 0.849177\n[146]\tvalid_0's rmse: 0.84914\n[147]\tvalid_0's rmse: 0.849124\n[148]\tvalid_0's rmse: 0.849121\n[149]\tvalid_0's rmse: 0.849113\n[150]\tvalid_0's rmse: 0.849142\n[151]\tvalid_0's rmse: 0.849148\n[152]\tvalid_0's rmse: 0.849147\n[153]\tvalid_0's rmse: 0.849162\n[154]\tvalid_0's rmse: 0.849144\n[155]\tvalid_0's rmse: 0.849125\n[156]\tvalid_0's rmse: 0.849145\n[157]\tvalid_0's rmse: 0.849141\n[158]\tvalid_0's rmse: 0.849116\n[159]\tvalid_0's rmse: 0.849096\n[160]\tvalid_0's rmse: 0.849085\n[161]\tvalid_0's rmse: 0.849067\n[162]\tvalid_0's rmse: 0.849058\n[163]\tvalid_0's rmse: 0.849055\n[164]\tvalid_0's rmse: 0.849047\n[165]\tvalid_0's rmse: 0.849048\n[166]\tvalid_0's rmse: 0.849063\n[167]\tvalid_0's rmse: 0.849047\n[168]\tvalid_0's rmse: 0.84904\n[169]\tvalid_0's rmse: 0.849014\n[170]\tvalid_0's rmse: 0.849009\n[171]\tvalid_0's rmse: 0.849017\n[172]\tvalid_0's rmse: 0.849014\n[173]\tvalid_0's rmse: 0.848999\n[174]\tvalid_0's rmse: 0.848995\n[175]\tvalid_0's rmse: 0.848998\n[176]\tvalid_0's rmse: 0.849023\n[177]\tvalid_0's rmse: 0.849023\n[178]\tvalid_0's rmse: 0.849013\n[179]\tvalid_0's rmse: 0.848991\n[180]\tvalid_0's rmse: 0.848966\n[181]\tvalid_0's rmse: 0.848963\n[182]\tvalid_0's rmse: 0.84898\n[183]\tvalid_0's rmse: 0.848997\n[184]\tvalid_0's rmse: 0.849005\n[185]\tvalid_0's rmse: 0.849015\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction, val_score: 0.847706:  57%|#####7    | 4/7 [00:18<00:14,  4.69s/it]\u001b[32m[I 2021-02-05 22:51:17,659]\u001b[0m Trial 3 finished with value: 0.8489632261898453 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.8477055332224409.\u001b[0m\nfeature_fraction, val_score: 0.847706:  57%|#####7    | 4/7 [00:18<00:14,  4.69s/it]","name":"stderr"},{"output_type":"stream","text":"[186]\tvalid_0's rmse: 0.849012\n[187]\tvalid_0's rmse: 0.849001\n[188]\tvalid_0's rmse: 0.849009\n[189]\tvalid_0's rmse: 0.849027\n[190]\tvalid_0's rmse: 0.849026\n[191]\tvalid_0's rmse: 0.849008\nEarly stopping, best iteration is:\n[181]\tvalid_0's rmse: 0.848963\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062867 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887493\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884936\n[3]\tvalid_0's rmse: 0.882317\n[4]\tvalid_0's rmse: 0.880148\n[5]\tvalid_0's rmse: 0.878171\n[6]\tvalid_0's rmse: 0.876313\n[7]\tvalid_0's rmse: 0.874703\n[8]\tvalid_0's rmse: 0.873372\n[9]\tvalid_0's rmse: 0.872226\n[10]\tvalid_0's rmse: 0.871112\n[11]\tvalid_0's rmse: 0.86988\n[12]\tvalid_0's rmse: 0.868842\n[13]\tvalid_0's rmse: 0.867968\n[14]\tvalid_0's rmse: 0.86707\n[15]\tvalid_0's rmse: 0.86635\n[16]\tvalid_0's rmse: 0.865757\n[17]\tvalid_0's rmse: 0.865\n[18]\tvalid_0's rmse: 0.864294\n[19]\tvalid_0's rmse: 0.86364\n[20]\tvalid_0's rmse: 0.863118\n[21]\tvalid_0's rmse: 0.862554\n[22]\tvalid_0's rmse: 0.862116\n[23]\tvalid_0's rmse: 0.861633\n[24]\tvalid_0's rmse: 0.861233\n[25]\tvalid_0's rmse: 0.860792\n[26]\tvalid_0's rmse: 0.860371\n[27]\tvalid_0's rmse: 0.860008\n[28]\tvalid_0's rmse: 0.8597\n[29]\tvalid_0's rmse: 0.859358\n[30]\tvalid_0's rmse: 0.859053\n[31]\tvalid_0's rmse: 0.858782\n[32]\tvalid_0's rmse: 0.858369\n[33]\tvalid_0's rmse: 0.858096\n[34]\tvalid_0's rmse: 0.857822\n[35]\tvalid_0's rmse: 0.857519\n[36]\tvalid_0's rmse: 0.857293\n[37]\tvalid_0's rmse: 0.85706\n[38]\tvalid_0's rmse: 0.856844\n[39]\tvalid_0's rmse: 0.856596\n[40]\tvalid_0's rmse: 0.856334\n[41]\tvalid_0's rmse: 0.85613\n[42]\tvalid_0's rmse: 0.855963\n[43]\tvalid_0's rmse: 0.855573\n[44]\tvalid_0's rmse: 0.855316\n[45]\tvalid_0's rmse: 0.855146\n[46]\tvalid_0's rmse: 0.854952\n[47]\tvalid_0's rmse: 0.854762\n[48]\tvalid_0's rmse: 0.854544\n[49]\tvalid_0's rmse: 0.854398\n[50]\tvalid_0's rmse: 0.854228\n[51]\tvalid_0's rmse: 0.854115\n[52]\tvalid_0's rmse: 0.854011\n[53]\tvalid_0's rmse: 0.853862\n[54]\tvalid_0's rmse: 0.85378\n[55]\tvalid_0's rmse: 0.853666\n[56]\tvalid_0's rmse: 0.853439\n[57]\tvalid_0's rmse: 0.853335\n[58]\tvalid_0's rmse: 0.853214\n[59]\tvalid_0's rmse: 0.853109\n[60]\tvalid_0's rmse: 0.853017\n[61]\tvalid_0's rmse: 0.852905\n[62]\tvalid_0's rmse: 0.852826\n[63]\tvalid_0's rmse: 0.852712\n[64]\tvalid_0's rmse: 0.852617\n[65]\tvalid_0's rmse: 0.852476\n[66]\tvalid_0's rmse: 0.852388\n[67]\tvalid_0's rmse: 0.852292\n[68]\tvalid_0's rmse: 0.852143\n[69]\tvalid_0's rmse: 0.851998\n[70]\tvalid_0's rmse: 0.851896\n[71]\tvalid_0's rmse: 0.85173\n[72]\tvalid_0's rmse: 0.851685\n[73]\tvalid_0's rmse: 0.851633\n[74]\tvalid_0's rmse: 0.851585\n[75]\tvalid_0's rmse: 0.851456\n[76]\tvalid_0's rmse: 0.851324\n[77]\tvalid_0's rmse: 0.851248\n[78]\tvalid_0's rmse: 0.851154\n[79]\tvalid_0's rmse: 0.851107\n[80]\tvalid_0's rmse: 0.851014\n[81]\tvalid_0's rmse: 0.850945\n[82]\tvalid_0's rmse: 0.850878\n[83]\tvalid_0's rmse: 0.850826\n[84]\tvalid_0's rmse: 0.850708\n[85]\tvalid_0's rmse: 0.850678\n[86]\tvalid_0's rmse: 0.850596\n[87]\tvalid_0's rmse: 0.850586\n[88]\tvalid_0's rmse: 0.850518\n[89]\tvalid_0's rmse: 0.850511\n[90]\tvalid_0's rmse: 0.850461\n[91]\tvalid_0's rmse: 0.850431\n[92]\tvalid_0's rmse: 0.850408\n[93]\tvalid_0's rmse: 0.850343\n[94]\tvalid_0's rmse: 0.850297\n[95]\tvalid_0's rmse: 0.850223\n[96]\tvalid_0's rmse: 0.850173\n[97]\tvalid_0's rmse: 0.85012\n[98]\tvalid_0's rmse: 0.850087\n[99]\tvalid_0's rmse: 0.85009\n[100]\tvalid_0's rmse: 0.850035\n[101]\tvalid_0's rmse: 0.849999\n[102]\tvalid_0's rmse: 0.849934\n[103]\tvalid_0's rmse: 0.84989\n[104]\tvalid_0's rmse: 0.849834\n[105]\tvalid_0's rmse: 0.849799\n[106]\tvalid_0's rmse: 0.849777\n[107]\tvalid_0's rmse: 0.849716\n[108]\tvalid_0's rmse: 0.849673\n[109]\tvalid_0's rmse: 0.849632\n[110]\tvalid_0's rmse: 0.849597\n[111]\tvalid_0's rmse: 0.849551\n[112]\tvalid_0's rmse: 0.849548\n[113]\tvalid_0's rmse: 0.849526\n[114]\tvalid_0's rmse: 0.84951\n[115]\tvalid_0's rmse: 0.849485\n[116]\tvalid_0's rmse: 0.849464\n[117]\tvalid_0's rmse: 0.849418\n[118]\tvalid_0's rmse: 0.849407\n[119]\tvalid_0's rmse: 0.849321\n[120]\tvalid_0's rmse: 0.849291\n[121]\tvalid_0's rmse: 0.849265\n[122]\tvalid_0's rmse: 0.849241\n[123]\tvalid_0's rmse: 0.849217\n[124]\tvalid_0's rmse: 0.849193\n[125]\tvalid_0's rmse: 0.849209\n[126]\tvalid_0's rmse: 0.849205\n[127]\tvalid_0's rmse: 0.849148\n[128]\tvalid_0's rmse: 0.849115\n[129]\tvalid_0's rmse: 0.849089\n[130]\tvalid_0's rmse: 0.849062\n[131]\tvalid_0's rmse: 0.849056\n[132]\tvalid_0's rmse: 0.849052\n[133]\tvalid_0's rmse: 0.849048\n[134]\tvalid_0's rmse: 0.849025\n[135]\tvalid_0's rmse: 0.849023\n[136]\tvalid_0's rmse: 0.848979\n[137]\tvalid_0's rmse: 0.848964\n[138]\tvalid_0's rmse: 0.848946\n[139]\tvalid_0's rmse: 0.848935\n[140]\tvalid_0's rmse: 0.848939\n[141]\tvalid_0's rmse: 0.848928\n[142]\tvalid_0's rmse: 0.848896\n[143]\tvalid_0's rmse: 0.848884\n[144]\tvalid_0's rmse: 0.848884\n[145]\tvalid_0's rmse: 0.848878\n[146]\tvalid_0's rmse: 0.848856\n[147]\tvalid_0's rmse: 0.848864\n[148]\tvalid_0's rmse: 0.848856\n[149]\tvalid_0's rmse: 0.848847\n[150]\tvalid_0's rmse: 0.848835\n[151]\tvalid_0's rmse: 0.848802\n[152]\tvalid_0's rmse: 0.848779\n[153]\tvalid_0's rmse: 0.848757\n[154]\tvalid_0's rmse: 0.848731\n[155]\tvalid_0's rmse: 0.848736\n[156]\tvalid_0's rmse: 0.848726\n[157]\tvalid_0's rmse: 0.848733\n[158]\tvalid_0's rmse: 0.848725\n[159]\tvalid_0's rmse: 0.848698\n[160]\tvalid_0's rmse: 0.848677\n[161]\tvalid_0's rmse: 0.848682\n[162]\tvalid_0's rmse: 0.848696\n[163]\tvalid_0's rmse: 0.848706\n[164]\tvalid_0's rmse: 0.848673\n[165]\tvalid_0's rmse: 0.848646\n[166]\tvalid_0's rmse: 0.848663\n[167]\tvalid_0's rmse: 0.848649\n[168]\tvalid_0's rmse: 0.848612\n[169]\tvalid_0's rmse: 0.848618\n[170]\tvalid_0's rmse: 0.848577\n[171]\tvalid_0's rmse: 0.848569\n[172]\tvalid_0's rmse: 0.848569\n[173]\tvalid_0's rmse: 0.84858\n[174]\tvalid_0's rmse: 0.848556\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction, val_score: 0.847706:  71%|#######1  | 5/7 [00:22<00:08,  4.43s/it]\u001b[32m[I 2021-02-05 22:51:21,629]\u001b[0m Trial 4 finished with value: 0.8484701855462348 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8477055332224409.\u001b[0m\nfeature_fraction, val_score: 0.847706:  71%|#######1  | 5/7 [00:22<00:08,  4.43s/it]","name":"stderr"},{"output_type":"stream","text":"[175]\tvalid_0's rmse: 0.848538\n[176]\tvalid_0's rmse: 0.848535\n[177]\tvalid_0's rmse: 0.848526\n[178]\tvalid_0's rmse: 0.848514\n[179]\tvalid_0's rmse: 0.848508\n[180]\tvalid_0's rmse: 0.848502\n[181]\tvalid_0's rmse: 0.848474\n[182]\tvalid_0's rmse: 0.84847\n[183]\tvalid_0's rmse: 0.848481\n[184]\tvalid_0's rmse: 0.848495\n[185]\tvalid_0's rmse: 0.848498\n[186]\tvalid_0's rmse: 0.84851\n[187]\tvalid_0's rmse: 0.848516\n[188]\tvalid_0's rmse: 0.848534\n[189]\tvalid_0's rmse: 0.848501\n[190]\tvalid_0's rmse: 0.848498\n[191]\tvalid_0's rmse: 0.848498\n[192]\tvalid_0's rmse: 0.848507\nEarly stopping, best iteration is:\n[182]\tvalid_0's rmse: 0.84847\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022447 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887087\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884007\n[3]\tvalid_0's rmse: 0.881565\n[4]\tvalid_0's rmse: 0.879264\n[5]\tvalid_0's rmse: 0.877364\n[6]\tvalid_0's rmse: 0.875798\n[7]\tvalid_0's rmse: 0.874316\n[8]\tvalid_0's rmse: 0.873018\n[9]\tvalid_0's rmse: 0.871938\n[10]\tvalid_0's rmse: 0.870801\n[11]\tvalid_0's rmse: 0.869837\n[12]\tvalid_0's rmse: 0.868922\n[13]\tvalid_0's rmse: 0.867995\n[14]\tvalid_0's rmse: 0.86722\n[15]\tvalid_0's rmse: 0.86651\n[16]\tvalid_0's rmse: 0.865872\n[17]\tvalid_0's rmse: 0.865265\n[18]\tvalid_0's rmse: 0.864504\n[19]\tvalid_0's rmse: 0.863963\n[20]\tvalid_0's rmse: 0.863409\n[21]\tvalid_0's rmse: 0.862948\n[22]\tvalid_0's rmse: 0.862426\n[23]\tvalid_0's rmse: 0.862009\n[24]\tvalid_0's rmse: 0.861541\n[25]\tvalid_0's rmse: 0.861012\n[26]\tvalid_0's rmse: 0.86063\n[27]\tvalid_0's rmse: 0.860219\n[28]\tvalid_0's rmse: 0.859832\n[29]\tvalid_0's rmse: 0.859463\n[30]\tvalid_0's rmse: 0.859112\n[31]\tvalid_0's rmse: 0.858855\n[32]\tvalid_0's rmse: 0.858572\n[33]\tvalid_0's rmse: 0.85823\n[34]\tvalid_0's rmse: 0.858019\n[35]\tvalid_0's rmse: 0.857767\n[36]\tvalid_0's rmse: 0.857541\n[37]\tvalid_0's rmse: 0.857291\n[38]\tvalid_0's rmse: 0.857088\n[39]\tvalid_0's rmse: 0.856859\n[40]\tvalid_0's rmse: 0.856624\n[41]\tvalid_0's rmse: 0.856403\n[42]\tvalid_0's rmse: 0.856145\n[43]\tvalid_0's rmse: 0.85592\n[44]\tvalid_0's rmse: 0.855761\n[45]\tvalid_0's rmse: 0.855584\n[46]\tvalid_0's rmse: 0.855454\n[47]\tvalid_0's rmse: 0.855312\n[48]\tvalid_0's rmse: 0.855123\n[49]\tvalid_0's rmse: 0.854967\n[50]\tvalid_0's rmse: 0.85484\n[51]\tvalid_0's rmse: 0.854601\n[52]\tvalid_0's rmse: 0.854458\n[53]\tvalid_0's rmse: 0.85436\n[54]\tvalid_0's rmse: 0.854182\n[55]\tvalid_0's rmse: 0.854054\n[56]\tvalid_0's rmse: 0.853941\n[57]\tvalid_0's rmse: 0.853842\n[58]\tvalid_0's rmse: 0.853709\n[59]\tvalid_0's rmse: 0.853511\n[60]\tvalid_0's rmse: 0.853313\n[61]\tvalid_0's rmse: 0.85318\n[62]\tvalid_0's rmse: 0.853061\n[63]\tvalid_0's rmse: 0.852969\n[64]\tvalid_0's rmse: 0.852858\n[65]\tvalid_0's rmse: 0.85278\n[66]\tvalid_0's rmse: 0.852641\n[67]\tvalid_0's rmse: 0.852521\n[68]\tvalid_0's rmse: 0.852416\n[69]\tvalid_0's rmse: 0.852304\n[70]\tvalid_0's rmse: 0.852218\n[71]\tvalid_0's rmse: 0.852105\n[72]\tvalid_0's rmse: 0.85203\n[73]\tvalid_0's rmse: 0.851952\n[74]\tvalid_0's rmse: 0.851801\n[75]\tvalid_0's rmse: 0.851734\n[76]\tvalid_0's rmse: 0.851602\n[77]\tvalid_0's rmse: 0.851509\n[78]\tvalid_0's rmse: 0.851464\n[79]\tvalid_0's rmse: 0.851415\n[80]\tvalid_0's rmse: 0.851354\n[81]\tvalid_0's rmse: 0.851276\n[82]\tvalid_0's rmse: 0.85122\n[83]\tvalid_0's rmse: 0.85115\n[84]\tvalid_0's rmse: 0.851109\n[85]\tvalid_0's rmse: 0.850924\n[86]\tvalid_0's rmse: 0.850855\n[87]\tvalid_0's rmse: 0.850809\n[88]\tvalid_0's rmse: 0.850747\n[89]\tvalid_0's rmse: 0.850715\n[90]\tvalid_0's rmse: 0.850701\n[91]\tvalid_0's rmse: 0.850614\n[92]\tvalid_0's rmse: 0.850578\n[93]\tvalid_0's rmse: 0.850536\n[94]\tvalid_0's rmse: 0.850504\n[95]\tvalid_0's rmse: 0.850468\n[96]\tvalid_0's rmse: 0.850397\n[97]\tvalid_0's rmse: 0.85034\n[98]\tvalid_0's rmse: 0.850292\n[99]\tvalid_0's rmse: 0.850221\n[100]\tvalid_0's rmse: 0.850236\n[101]\tvalid_0's rmse: 0.85022\n[102]\tvalid_0's rmse: 0.850177\n[103]\tvalid_0's rmse: 0.850139\n[104]\tvalid_0's rmse: 0.850027\n[105]\tvalid_0's rmse: 0.849978\n[106]\tvalid_0's rmse: 0.849958\n[107]\tvalid_0's rmse: 0.849907\n[108]\tvalid_0's rmse: 0.849912\n[109]\tvalid_0's rmse: 0.849876\n[110]\tvalid_0's rmse: 0.849838\n[111]\tvalid_0's rmse: 0.849737\n[112]\tvalid_0's rmse: 0.849679\n[113]\tvalid_0's rmse: 0.849674\n[114]\tvalid_0's rmse: 0.849655\n[115]\tvalid_0's rmse: 0.84963\n[116]\tvalid_0's rmse: 0.849611\n[117]\tvalid_0's rmse: 0.849569\n[118]\tvalid_0's rmse: 0.849563\n[119]\tvalid_0's rmse: 0.849526\n[120]\tvalid_0's rmse: 0.849501\n[121]\tvalid_0's rmse: 0.849495\n[122]\tvalid_0's rmse: 0.849499\n[123]\tvalid_0's rmse: 0.849494\n[124]\tvalid_0's rmse: 0.849477\n[125]\tvalid_0's rmse: 0.849455\n[126]\tvalid_0's rmse: 0.849452\n[127]\tvalid_0's rmse: 0.849398\n[128]\tvalid_0's rmse: 0.849414\n[129]\tvalid_0's rmse: 0.849414\n[130]\tvalid_0's rmse: 0.849405\n[131]\tvalid_0's rmse: 0.849429\n[132]\tvalid_0's rmse: 0.849383\n[133]\tvalid_0's rmse: 0.849311\n[134]\tvalid_0's rmse: 0.849285\n[135]\tvalid_0's rmse: 0.849273\n[136]\tvalid_0's rmse: 0.849263\n[137]\tvalid_0's rmse: 0.849276\n[138]\tvalid_0's rmse: 0.849279\n[139]\tvalid_0's rmse: 0.849276\n[140]\tvalid_0's rmse: 0.849258\n[141]\tvalid_0's rmse: 0.849202\n[142]\tvalid_0's rmse: 0.849156\n[143]\tvalid_0's rmse: 0.849162\n[144]\tvalid_0's rmse: 0.849147\n[145]\tvalid_0's rmse: 0.849149\n[146]\tvalid_0's rmse: 0.849132\n[147]\tvalid_0's rmse: 0.849116\n[148]\tvalid_0's rmse: 0.849072\n[149]\tvalid_0's rmse: 0.849073\n[150]\tvalid_0's rmse: 0.849064\n[151]\tvalid_0's rmse: 0.849069\n[152]\tvalid_0's rmse: 0.849057\n[153]\tvalid_0's rmse: 0.849044\n[154]\tvalid_0's rmse: 0.84904\n[155]\tvalid_0's rmse: 0.849016\n[156]\tvalid_0's rmse: 0.84901\n[157]\tvalid_0's rmse: 0.848975\n[158]\tvalid_0's rmse: 0.848952\n[159]\tvalid_0's rmse: 0.848928\n[160]\tvalid_0's rmse: 0.848936\n[161]\tvalid_0's rmse: 0.848917\n[162]\tvalid_0's rmse: 0.848895\n[163]\tvalid_0's rmse: 0.848882\n[164]\tvalid_0's rmse: 0.848876\n[165]\tvalid_0's rmse: 0.848853\n[166]\tvalid_0's rmse: 0.84887\n[167]\tvalid_0's rmse: 0.848837\n[168]\tvalid_0's rmse: 0.848838\n[169]\tvalid_0's rmse: 0.848827\n[170]\tvalid_0's rmse: 0.848816\n[171]\tvalid_0's rmse: 0.848814\n[172]\tvalid_0's rmse: 0.848826\n[173]\tvalid_0's rmse: 0.848825\n[174]\tvalid_0's rmse: 0.848812\n[175]\tvalid_0's rmse: 0.848785\n[176]\tvalid_0's rmse: 0.84879\n[177]\tvalid_0's rmse: 0.848791\n[178]\tvalid_0's rmse: 0.848784\n[179]\tvalid_0's rmse: 0.848783\n[180]\tvalid_0's rmse: 0.8488\n[181]\tvalid_0's rmse: 0.848794\n[182]\tvalid_0's rmse: 0.84879\n[183]\tvalid_0's rmse: 0.848803\n[184]\tvalid_0's rmse: 0.848797\n[185]\tvalid_0's rmse: 0.848806\n[186]\tvalid_0's rmse: 0.848793\n[187]\tvalid_0's rmse: 0.848792\n[188]\tvalid_0's rmse: 0.848802\n[189]\tvalid_0's rmse: 0.848751\n[190]\tvalid_0's rmse: 0.848731\n[191]\tvalid_0's rmse: 0.848714\n[192]\tvalid_0's rmse: 0.848721\n[193]\tvalid_0's rmse: 0.848721\n[194]\tvalid_0's rmse: 0.848697\n[195]\tvalid_0's rmse: 0.848696\n[196]\tvalid_0's rmse: 0.848702\n[197]\tvalid_0's rmse: 0.848683\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction, val_score: 0.847706:  86%|########5 | 6/7 [00:27<00:04,  4.41s/it]\u001b[32m[I 2021-02-05 22:51:26,012]\u001b[0m Trial 5 finished with value: 0.8486625255092778 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.8477055332224409.\u001b[0m\nfeature_fraction, val_score: 0.847706:  86%|########5 | 6/7 [00:27<00:04,  4.41s/it]","name":"stderr"},{"output_type":"stream","text":"[198]\tvalid_0's rmse: 0.848677\n[199]\tvalid_0's rmse: 0.848663\n[200]\tvalid_0's rmse: 0.848666\n[201]\tvalid_0's rmse: 0.848675\n[202]\tvalid_0's rmse: 0.848668\n[203]\tvalid_0's rmse: 0.848669\n[204]\tvalid_0's rmse: 0.848676\n[205]\tvalid_0's rmse: 0.84867\n[206]\tvalid_0's rmse: 0.84868\n[207]\tvalid_0's rmse: 0.84867\n[208]\tvalid_0's rmse: 0.84869\n[209]\tvalid_0's rmse: 0.848686\nEarly stopping, best iteration is:\n[199]\tvalid_0's rmse: 0.848663\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062785 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887467\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.8848\n[3]\tvalid_0's rmse: 0.882075\n[4]\tvalid_0's rmse: 0.879731\n[5]\tvalid_0's rmse: 0.877792\n[6]\tvalid_0's rmse: 0.875992\n[7]\tvalid_0's rmse: 0.874278\n[8]\tvalid_0's rmse: 0.872854\n[9]\tvalid_0's rmse: 0.871657\n[10]\tvalid_0's rmse: 0.870473\n[11]\tvalid_0's rmse: 0.869378\n[12]\tvalid_0's rmse: 0.868434\n[13]\tvalid_0's rmse: 0.867589\n[14]\tvalid_0's rmse: 0.866762\n[15]\tvalid_0's rmse: 0.866078\n[16]\tvalid_0's rmse: 0.865445\n[17]\tvalid_0's rmse: 0.864856\n[18]\tvalid_0's rmse: 0.864229\n[19]\tvalid_0's rmse: 0.863569\n[20]\tvalid_0's rmse: 0.863042\n[21]\tvalid_0's rmse: 0.862519\n[22]\tvalid_0's rmse: 0.862113\n[23]\tvalid_0's rmse: 0.861691\n[24]\tvalid_0's rmse: 0.861268\n[25]\tvalid_0's rmse: 0.860734\n[26]\tvalid_0's rmse: 0.860376\n[27]\tvalid_0's rmse: 0.860049\n[28]\tvalid_0's rmse: 0.859685\n[29]\tvalid_0's rmse: 0.859382\n[30]\tvalid_0's rmse: 0.859085\n[31]\tvalid_0's rmse: 0.858787\n[32]\tvalid_0's rmse: 0.858344\n[33]\tvalid_0's rmse: 0.858065\n[34]\tvalid_0's rmse: 0.857787\n[35]\tvalid_0's rmse: 0.857493\n[36]\tvalid_0's rmse: 0.857209\n[37]\tvalid_0's rmse: 0.857028\n[38]\tvalid_0's rmse: 0.856815\n[39]\tvalid_0's rmse: 0.856559\n[40]\tvalid_0's rmse: 0.856359\n[41]\tvalid_0's rmse: 0.856133\n[42]\tvalid_0's rmse: 0.855952\n[43]\tvalid_0's rmse: 0.855738\n[44]\tvalid_0's rmse: 0.855478\n[45]\tvalid_0's rmse: 0.855316\n[46]\tvalid_0's rmse: 0.85515\n[47]\tvalid_0's rmse: 0.854943\n[48]\tvalid_0's rmse: 0.854739\n[49]\tvalid_0's rmse: 0.854579\n[50]\tvalid_0's rmse: 0.854432\n[51]\tvalid_0's rmse: 0.854282\n[52]\tvalid_0's rmse: 0.854026\n[53]\tvalid_0's rmse: 0.853882\n[54]\tvalid_0's rmse: 0.853752\n[55]\tvalid_0's rmse: 0.853636\n[56]\tvalid_0's rmse: 0.853489\n[57]\tvalid_0's rmse: 0.85337\n[58]\tvalid_0's rmse: 0.853275\n[59]\tvalid_0's rmse: 0.853151\n[60]\tvalid_0's rmse: 0.853066\n[61]\tvalid_0's rmse: 0.852917\n[62]\tvalid_0's rmse: 0.852838\n[63]\tvalid_0's rmse: 0.852715\n[64]\tvalid_0's rmse: 0.852581\n[65]\tvalid_0's rmse: 0.852406\n[66]\tvalid_0's rmse: 0.852287\n[67]\tvalid_0's rmse: 0.85222\n[68]\tvalid_0's rmse: 0.85212\n[69]\tvalid_0's rmse: 0.852059\n[70]\tvalid_0's rmse: 0.851952\n[71]\tvalid_0's rmse: 0.851799\n[72]\tvalid_0's rmse: 0.851736\n[73]\tvalid_0's rmse: 0.851662\n[74]\tvalid_0's rmse: 0.851589\n[75]\tvalid_0's rmse: 0.851482\n[76]\tvalid_0's rmse: 0.851425\n[77]\tvalid_0's rmse: 0.851375\n[78]\tvalid_0's rmse: 0.851303\n[79]\tvalid_0's rmse: 0.851211\n[80]\tvalid_0's rmse: 0.851148\n[81]\tvalid_0's rmse: 0.851077\n[82]\tvalid_0's rmse: 0.851013\n[83]\tvalid_0's rmse: 0.850942\n[84]\tvalid_0's rmse: 0.850898\n[85]\tvalid_0's rmse: 0.85076\n[86]\tvalid_0's rmse: 0.850751\n[87]\tvalid_0's rmse: 0.850714\n[88]\tvalid_0's rmse: 0.850679\n[89]\tvalid_0's rmse: 0.850616\n[90]\tvalid_0's rmse: 0.850573\n[91]\tvalid_0's rmse: 0.850509\n[92]\tvalid_0's rmse: 0.850405\n[93]\tvalid_0's rmse: 0.850292\n[94]\tvalid_0's rmse: 0.850267\n[95]\tvalid_0's rmse: 0.850188\n[96]\tvalid_0's rmse: 0.850147\n[97]\tvalid_0's rmse: 0.850103\n[98]\tvalid_0's rmse: 0.849994\n[99]\tvalid_0's rmse: 0.849919\n[100]\tvalid_0's rmse: 0.849871\n[101]\tvalid_0's rmse: 0.849822\n[102]\tvalid_0's rmse: 0.849778\n[103]\tvalid_0's rmse: 0.849744\n[104]\tvalid_0's rmse: 0.849714\n[105]\tvalid_0's rmse: 0.849679\n[106]\tvalid_0's rmse: 0.849635\n[107]\tvalid_0's rmse: 0.849602\n[108]\tvalid_0's rmse: 0.849576\n[109]\tvalid_0's rmse: 0.849487\n[110]\tvalid_0's rmse: 0.849454\n[111]\tvalid_0's rmse: 0.849375\n[112]\tvalid_0's rmse: 0.849346\n[113]\tvalid_0's rmse: 0.849315\n[114]\tvalid_0's rmse: 0.849271\n[115]\tvalid_0's rmse: 0.849262\n[116]\tvalid_0's rmse: 0.849235\n[117]\tvalid_0's rmse: 0.849212\n[118]\tvalid_0's rmse: 0.849191\n[119]\tvalid_0's rmse: 0.849148\n[120]\tvalid_0's rmse: 0.849158\n[121]\tvalid_0's rmse: 0.849099\n[122]\tvalid_0's rmse: 0.84906\n[123]\tvalid_0's rmse: 0.84906\n[124]\tvalid_0's rmse: 0.849062\n[125]\tvalid_0's rmse: 0.849046\n[126]\tvalid_0's rmse: 0.849005\n[127]\tvalid_0's rmse: 0.848986\n[128]\tvalid_0's rmse: 0.848981\n[129]\tvalid_0's rmse: 0.848967\n[130]\tvalid_0's rmse: 0.84897\n[131]\tvalid_0's rmse: 0.848979\n[132]\tvalid_0's rmse: 0.848967\n[133]\tvalid_0's rmse: 0.848972\n[134]\tvalid_0's rmse: 0.848979\n[135]\tvalid_0's rmse: 0.848992\n[136]\tvalid_0's rmse: 0.848948\n[137]\tvalid_0's rmse: 0.848951\n[138]\tvalid_0's rmse: 0.84895\n[139]\tvalid_0's rmse: 0.848923\n[140]\tvalid_0's rmse: 0.848899\n[141]\tvalid_0's rmse: 0.848884\n[142]\tvalid_0's rmse: 0.848865\n[143]\tvalid_0's rmse: 0.848885\n[144]\tvalid_0's rmse: 0.848875\n[145]\tvalid_0's rmse: 0.848885\n[146]\tvalid_0's rmse: 0.848875\n[147]\tvalid_0's rmse: 0.848891\n[148]\tvalid_0's rmse: 0.848881\n[149]\tvalid_0's rmse: 0.848867\n[150]\tvalid_0's rmse: 0.848816\n[151]\tvalid_0's rmse: 0.848817\n[152]\tvalid_0's rmse: 0.848818\n[153]\tvalid_0's rmse: 0.848821\n[154]\tvalid_0's rmse: 0.848828\n[155]\tvalid_0's rmse: 0.848832\n[156]\tvalid_0's rmse: 0.848789\n[157]\tvalid_0's rmse: 0.848763\n[158]\tvalid_0's rmse: 0.848764\n[159]\tvalid_0's rmse: 0.84875\n[160]\tvalid_0's rmse: 0.848769\n[161]\tvalid_0's rmse: 0.848741\n[162]\tvalid_0's rmse: 0.84873\n[163]\tvalid_0's rmse: 0.848706\n[164]\tvalid_0's rmse: 0.848678\n[165]\tvalid_0's rmse: 0.848686\n[166]\tvalid_0's rmse: 0.848691\n[167]\tvalid_0's rmse: 0.84869\n[168]\tvalid_0's rmse: 0.84868\n[169]\tvalid_0's rmse: 0.848669\n[170]\tvalid_0's rmse: 0.848658\n[171]\tvalid_0's rmse: 0.848655\n[172]\tvalid_0's rmse: 0.848647\n[173]\tvalid_0's rmse: 0.848641\n[174]\tvalid_0's rmse: 0.848638\n[175]\tvalid_0's rmse: 0.848587\n[176]\tvalid_0's rmse: 0.848585\n[177]\tvalid_0's rmse: 0.848595\n[178]\tvalid_0's rmse: 0.848598\n[179]\tvalid_0's rmse: 0.848597\n[180]\tvalid_0's rmse: 0.848599\n[181]\tvalid_0's rmse: 0.84859\n[182]\tvalid_0's rmse: 0.848609\n[183]\tvalid_0's rmse: 0.848608\n[184]\tvalid_0's rmse: 0.848617\n[185]\tvalid_0's rmse: 0.848618\n[186]\tvalid_0's rmse: 0.848609\nEarly stopping, best iteration is:\n[176]\tvalid_0's rmse: 0.848585\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction, val_score: 0.847706: 100%|##########| 7/7 [00:32<00:00,  4.59s/it]\u001b[32m[I 2021-02-05 22:51:30,971]\u001b[0m Trial 6 finished with value: 0.8485846822407556 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.8477055332224409.\u001b[0m\nfeature_fraction, val_score: 0.847706: 100%|##########| 7/7 [00:32<00:00,  4.61s/it]\nnum_leaves, val_score: 0.847706:   0%|          | 0/20 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018980 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887767\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.88437\n[3]\tvalid_0's rmse: 0.881755\n[4]\tvalid_0's rmse: 0.879213\n[5]\tvalid_0's rmse: 0.877051\n[6]\tvalid_0's rmse: 0.874627\n[7]\tvalid_0's rmse: 0.872967\n[8]\tvalid_0's rmse: 0.87152\n[9]\tvalid_0's rmse: 0.870169\n[10]\tvalid_0's rmse: 0.868962\n[11]\tvalid_0's rmse: 0.867326\n[12]\tvalid_0's rmse: 0.866006\n[13]\tvalid_0's rmse: 0.86489\n[14]\tvalid_0's rmse: 0.863687\n[15]\tvalid_0's rmse: 0.862875\n[16]\tvalid_0's rmse: 0.862159\n[17]\tvalid_0's rmse: 0.861261\n[18]\tvalid_0's rmse: 0.860601\n[19]\tvalid_0's rmse: 0.859902\n[20]\tvalid_0's rmse: 0.859326\n[21]\tvalid_0's rmse: 0.85874\n[22]\tvalid_0's rmse: 0.858135\n[23]\tvalid_0's rmse: 0.857652\n[24]\tvalid_0's rmse: 0.857129\n[25]\tvalid_0's rmse: 0.85677\n[26]\tvalid_0's rmse: 0.856364\n[27]\tvalid_0's rmse: 0.855977\n[28]\tvalid_0's rmse: 0.855627\n[29]\tvalid_0's rmse: 0.855254\n[30]\tvalid_0's rmse: 0.854987\n[31]\tvalid_0's rmse: 0.854662\n[32]\tvalid_0's rmse: 0.854304\n[33]\tvalid_0's rmse: 0.854087\n[34]\tvalid_0's rmse: 0.853777\n[35]\tvalid_0's rmse: 0.853551\n[36]\tvalid_0's rmse: 0.853291\n[37]\tvalid_0's rmse: 0.853091\n[38]\tvalid_0's rmse: 0.852832\n[39]\tvalid_0's rmse: 0.8526\n[40]\tvalid_0's rmse: 0.852401\n[41]\tvalid_0's rmse: 0.852293\n[42]\tvalid_0's rmse: 0.852136\n[43]\tvalid_0's rmse: 0.851942\n[44]\tvalid_0's rmse: 0.851765\n[45]\tvalid_0's rmse: 0.85158\n[46]\tvalid_0's rmse: 0.851494\n[47]\tvalid_0's rmse: 0.851342\n[48]\tvalid_0's rmse: 0.851235\n[49]\tvalid_0's rmse: 0.851127\n[50]\tvalid_0's rmse: 0.851022\n[51]\tvalid_0's rmse: 0.851025\n[52]\tvalid_0's rmse: 0.850844\n[53]\tvalid_0's rmse: 0.850701\n[54]\tvalid_0's rmse: 0.850608\n[55]\tvalid_0's rmse: 0.850583\n[56]\tvalid_0's rmse: 0.850479\n[57]\tvalid_0's rmse: 0.850355\n[58]\tvalid_0's rmse: 0.850284\n[59]\tvalid_0's rmse: 0.850209\n[60]\tvalid_0's rmse: 0.850156\n[61]\tvalid_0's rmse: 0.85016\n[62]\tvalid_0's rmse: 0.850135\n[63]\tvalid_0's rmse: 0.850076\n[64]\tvalid_0's rmse: 0.849969\n[65]\tvalid_0's rmse: 0.849853\n[66]\tvalid_0's rmse: 0.849818\n[67]\tvalid_0's rmse: 0.84983\n[68]\tvalid_0's rmse: 0.849722\n[69]\tvalid_0's rmse: 0.849655\n[70]\tvalid_0's rmse: 0.849644\n[71]\tvalid_0's rmse: 0.849585\n[72]\tvalid_0's rmse: 0.849592\n[73]\tvalid_0's rmse: 0.849548\n[74]\tvalid_0's rmse: 0.849584\n[75]\tvalid_0's rmse: 0.849515\n[76]\tvalid_0's rmse: 0.849416\n[77]\tvalid_0's rmse: 0.849397\n[78]\tvalid_0's rmse: 0.849332\n[79]\tvalid_0's rmse: 0.849276\n[80]\tvalid_0's rmse: 0.849257\n[81]\tvalid_0's rmse: 0.849249\n[82]\tvalid_0's rmse: 0.849227\n[83]\tvalid_0's rmse: 0.849238\n[84]\tvalid_0's rmse: 0.849236\n[85]\tvalid_0's rmse: 0.849258\n[86]\tvalid_0's rmse: 0.849277\n[87]\tvalid_0's rmse: 0.849265\n[88]\tvalid_0's rmse: 0.849217\n[89]\tvalid_0's rmse: 0.849193\n[90]\tvalid_0's rmse: 0.849197\n[91]\tvalid_0's rmse: 0.849227\n[92]\tvalid_0's rmse: 0.849208\n[93]\tvalid_0's rmse: 0.849171\n[94]\tvalid_0's rmse: 0.849202\n[95]\tvalid_0's rmse: 0.849181\n[96]\tvalid_0's rmse: 0.849172\n[97]\tvalid_0's rmse: 0.849137\n[98]\tvalid_0's rmse: 0.84912\n[99]\tvalid_0's rmse: 0.84914\n[100]\tvalid_0's rmse: 0.849161\n[101]\tvalid_0's rmse: 0.849172\n[102]\tvalid_0's rmse: 0.84913\n[103]\tvalid_0's rmse: 0.849167\n[104]\tvalid_0's rmse: 0.849145\n[105]\tvalid_0's rmse: 0.849118\n[106]\tvalid_0's rmse: 0.849074\n[107]\tvalid_0's rmse: 0.849053\n[108]\tvalid_0's rmse: 0.849081\n[109]\tvalid_0's rmse: 0.849104\n[110]\tvalid_0's rmse: 0.849103\n[111]\tvalid_0's rmse: 0.849111\n[112]\tvalid_0's rmse: 0.849088\n[113]\tvalid_0's rmse: 0.849103\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847706:   5%|5         | 1/20 [00:04<01:28,  4.68s/it]\u001b[32m[I 2021-02-05 22:51:35,659]\u001b[0m Trial 7 finished with value: 0.849053269037849 and parameters: {'num_leaves': 186}. Best is trial 7 with value: 0.849053269037849.\u001b[0m\nnum_leaves, val_score: 0.847706:   5%|5         | 1/20 [00:04<01:28,  4.68s/it]","name":"stderr"},{"output_type":"stream","text":"[114]\tvalid_0's rmse: 0.849117\n[115]\tvalid_0's rmse: 0.849154\n[116]\tvalid_0's rmse: 0.849166\n[117]\tvalid_0's rmse: 0.84914\nEarly stopping, best iteration is:\n[107]\tvalid_0's rmse: 0.849053\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019327 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888494\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885841\n[3]\tvalid_0's rmse: 0.88372\n[4]\tvalid_0's rmse: 0.881601\n[5]\tvalid_0's rmse: 0.879817\n[6]\tvalid_0's rmse: 0.877821\n[7]\tvalid_0's rmse: 0.876386\n[8]\tvalid_0's rmse: 0.875201\n[9]\tvalid_0's rmse: 0.874108\n[10]\tvalid_0's rmse: 0.873081\n[11]\tvalid_0's rmse: 0.871737\n[12]\tvalid_0's rmse: 0.870552\n[13]\tvalid_0's rmse: 0.86954\n[14]\tvalid_0's rmse: 0.868552\n[15]\tvalid_0's rmse: 0.867876\n[16]\tvalid_0's rmse: 0.86711\n[17]\tvalid_0's rmse: 0.866309\n[18]\tvalid_0's rmse: 0.865694\n[19]\tvalid_0's rmse: 0.865021\n[20]\tvalid_0's rmse: 0.864472\n[21]\tvalid_0's rmse: 0.863959\n[22]\tvalid_0's rmse: 0.863317\n[23]\tvalid_0's rmse: 0.862829\n[24]\tvalid_0's rmse: 0.86228\n[25]\tvalid_0's rmse: 0.861858\n[26]\tvalid_0's rmse: 0.861435\n[27]\tvalid_0's rmse: 0.861061\n[28]\tvalid_0's rmse: 0.860685\n[29]\tvalid_0's rmse: 0.860318\n[30]\tvalid_0's rmse: 0.86004\n[31]\tvalid_0's rmse: 0.859686\n[32]\tvalid_0's rmse: 0.85931\n[33]\tvalid_0's rmse: 0.858981\n[34]\tvalid_0's rmse: 0.85863\n[35]\tvalid_0's rmse: 0.858423\n[36]\tvalid_0's rmse: 0.858128\n[37]\tvalid_0's rmse: 0.857843\n[38]\tvalid_0's rmse: 0.857555\n[39]\tvalid_0's rmse: 0.857279\n[40]\tvalid_0's rmse: 0.857035\n[41]\tvalid_0's rmse: 0.856863\n[42]\tvalid_0's rmse: 0.856633\n[43]\tvalid_0's rmse: 0.856487\n[44]\tvalid_0's rmse: 0.856263\n[45]\tvalid_0's rmse: 0.856019\n[46]\tvalid_0's rmse: 0.855881\n[47]\tvalid_0's rmse: 0.855748\n[48]\tvalid_0's rmse: 0.855594\n[49]\tvalid_0's rmse: 0.855396\n[50]\tvalid_0's rmse: 0.855218\n[51]\tvalid_0's rmse: 0.855095\n[52]\tvalid_0's rmse: 0.854961\n[53]\tvalid_0's rmse: 0.854787\n[54]\tvalid_0's rmse: 0.854629\n[55]\tvalid_0's rmse: 0.854499\n[56]\tvalid_0's rmse: 0.854197\n[57]\tvalid_0's rmse: 0.854061\n[58]\tvalid_0's rmse: 0.853895\n[59]\tvalid_0's rmse: 0.853743\n[60]\tvalid_0's rmse: 0.853589\n[61]\tvalid_0's rmse: 0.853477\n[62]\tvalid_0's rmse: 0.853381\n[63]\tvalid_0's rmse: 0.853178\n[64]\tvalid_0's rmse: 0.852999\n[65]\tvalid_0's rmse: 0.852867\n[66]\tvalid_0's rmse: 0.852773\n[67]\tvalid_0's rmse: 0.852714\n[68]\tvalid_0's rmse: 0.852635\n[69]\tvalid_0's rmse: 0.852525\n[70]\tvalid_0's rmse: 0.852425\n[71]\tvalid_0's rmse: 0.852341\n[72]\tvalid_0's rmse: 0.852256\n[73]\tvalid_0's rmse: 0.852184\n[74]\tvalid_0's rmse: 0.852101\n[75]\tvalid_0's rmse: 0.851989\n[76]\tvalid_0's rmse: 0.851883\n[77]\tvalid_0's rmse: 0.851793\n[78]\tvalid_0's rmse: 0.851686\n[79]\tvalid_0's rmse: 0.851579\n[80]\tvalid_0's rmse: 0.851501\n[81]\tvalid_0's rmse: 0.851427\n[82]\tvalid_0's rmse: 0.851356\n[83]\tvalid_0's rmse: 0.851305\n[84]\tvalid_0's rmse: 0.851209\n[85]\tvalid_0's rmse: 0.851149\n[86]\tvalid_0's rmse: 0.851076\n[87]\tvalid_0's rmse: 0.851025\n[88]\tvalid_0's rmse: 0.850861\n[89]\tvalid_0's rmse: 0.850816\n[90]\tvalid_0's rmse: 0.850741\n[91]\tvalid_0's rmse: 0.850689\n[92]\tvalid_0's rmse: 0.850648\n[93]\tvalid_0's rmse: 0.850555\n[94]\tvalid_0's rmse: 0.850486\n[95]\tvalid_0's rmse: 0.850425\n[96]\tvalid_0's rmse: 0.850375\n[97]\tvalid_0's rmse: 0.850357\n[98]\tvalid_0's rmse: 0.850231\n[99]\tvalid_0's rmse: 0.850197\n[100]\tvalid_0's rmse: 0.850163\n[101]\tvalid_0's rmse: 0.850109\n[102]\tvalid_0's rmse: 0.850036\n[103]\tvalid_0's rmse: 0.849969\n[104]\tvalid_0's rmse: 0.849904\n[105]\tvalid_0's rmse: 0.849858\n[106]\tvalid_0's rmse: 0.849804\n[107]\tvalid_0's rmse: 0.849744\n[108]\tvalid_0's rmse: 0.849688\n[109]\tvalid_0's rmse: 0.849607\n[110]\tvalid_0's rmse: 0.849569\n[111]\tvalid_0's rmse: 0.849476\n[112]\tvalid_0's rmse: 0.849423\n[113]\tvalid_0's rmse: 0.849397\n[114]\tvalid_0's rmse: 0.849402\n[115]\tvalid_0's rmse: 0.849367\n[116]\tvalid_0's rmse: 0.849331\n[117]\tvalid_0's rmse: 0.849285\n[118]\tvalid_0's rmse: 0.849236\n[119]\tvalid_0's rmse: 0.849221\n[120]\tvalid_0's rmse: 0.849185\n[121]\tvalid_0's rmse: 0.84912\n[122]\tvalid_0's rmse: 0.849095\n[123]\tvalid_0's rmse: 0.84906\n[124]\tvalid_0's rmse: 0.849031\n[125]\tvalid_0's rmse: 0.849014\n[126]\tvalid_0's rmse: 0.848996\n[127]\tvalid_0's rmse: 0.848965\n[128]\tvalid_0's rmse: 0.848936\n[129]\tvalid_0's rmse: 0.848936\n[130]\tvalid_0's rmse: 0.848908\n[131]\tvalid_0's rmse: 0.848896\n[132]\tvalid_0's rmse: 0.848872\n[133]\tvalid_0's rmse: 0.848864\n[134]\tvalid_0's rmse: 0.848864\n[135]\tvalid_0's rmse: 0.848869\n[136]\tvalid_0's rmse: 0.84884\n[137]\tvalid_0's rmse: 0.84881\n[138]\tvalid_0's rmse: 0.84882\n[139]\tvalid_0's rmse: 0.848769\n[140]\tvalid_0's rmse: 0.848765\n[141]\tvalid_0's rmse: 0.84872\n[142]\tvalid_0's rmse: 0.848697\n[143]\tvalid_0's rmse: 0.848685\n[144]\tvalid_0's rmse: 0.848658\n[145]\tvalid_0's rmse: 0.848635\n[146]\tvalid_0's rmse: 0.848615\n[147]\tvalid_0's rmse: 0.848609\n[148]\tvalid_0's rmse: 0.848561\n[149]\tvalid_0's rmse: 0.848499\n[150]\tvalid_0's rmse: 0.848483\n[151]\tvalid_0's rmse: 0.848468\n[152]\tvalid_0's rmse: 0.848451\n[153]\tvalid_0's rmse: 0.84842\n[154]\tvalid_0's rmse: 0.848434\n[155]\tvalid_0's rmse: 0.848416\n[156]\tvalid_0's rmse: 0.848402\n[157]\tvalid_0's rmse: 0.848397\n[158]\tvalid_0's rmse: 0.848408\n[159]\tvalid_0's rmse: 0.848408\n[160]\tvalid_0's rmse: 0.848399\n[161]\tvalid_0's rmse: 0.848391\n[162]\tvalid_0's rmse: 0.8484\n[163]\tvalid_0's rmse: 0.848402\n[164]\tvalid_0's rmse: 0.848397\n[165]\tvalid_0's rmse: 0.848375\n[166]\tvalid_0's rmse: 0.848363\n[167]\tvalid_0's rmse: 0.848346\n[168]\tvalid_0's rmse: 0.848335\n[169]\tvalid_0's rmse: 0.848329\n[170]\tvalid_0's rmse: 0.848333\n[171]\tvalid_0's rmse: 0.84833\n[172]\tvalid_0's rmse: 0.848274\n[173]\tvalid_0's rmse: 0.848279\n[174]\tvalid_0's rmse: 0.848254\n[175]\tvalid_0's rmse: 0.848244\n[176]\tvalid_0's rmse: 0.848227\n[177]\tvalid_0's rmse: 0.84823\n[178]\tvalid_0's rmse: 0.848208\n[179]\tvalid_0's rmse: 0.848171\n[180]\tvalid_0's rmse: 0.848155\n[181]\tvalid_0's rmse: 0.848129\n[182]\tvalid_0's rmse: 0.848137\n[183]\tvalid_0's rmse: 0.848097\n[184]\tvalid_0's rmse: 0.848083\n[185]\tvalid_0's rmse: 0.848071\n[186]\tvalid_0's rmse: 0.848072\n[187]\tvalid_0's rmse: 0.84808\n[188]\tvalid_0's rmse: 0.848063\n[189]\tvalid_0's rmse: 0.848064\n[190]\tvalid_0's rmse: 0.848055\n[191]\tvalid_0's rmse: 0.848042\n[192]\tvalid_0's rmse: 0.848028\n[193]\tvalid_0's rmse: 0.848022\n[194]\tvalid_0's rmse: 0.848026\n[195]\tvalid_0's rmse: 0.848034\n[196]\tvalid_0's rmse: 0.848016\n[197]\tvalid_0's rmse: 0.848016\n[198]\tvalid_0's rmse: 0.84801\n[199]\tvalid_0's rmse: 0.847986\n[200]\tvalid_0's rmse: 0.847989\n[201]\tvalid_0's rmse: 0.847981\n[202]\tvalid_0's rmse: 0.847983\n[203]\tvalid_0's rmse: 0.847969\n[204]\tvalid_0's rmse: 0.84796\n[205]\tvalid_0's rmse: 0.847947\n[206]\tvalid_0's rmse: 0.847948\n[207]\tvalid_0's rmse: 0.847948\n[208]\tvalid_0's rmse: 0.847913\n[209]\tvalid_0's rmse: 0.847895\n[210]\tvalid_0's rmse: 0.84789\n[211]\tvalid_0's rmse: 0.847893\n[212]\tvalid_0's rmse: 0.8479\n[213]\tvalid_0's rmse: 0.847875\n[214]\tvalid_0's rmse: 0.847877\n[215]\tvalid_0's rmse: 0.847876\n[216]\tvalid_0's rmse: 0.847885\n[217]\tvalid_0's rmse: 0.847878\n[218]\tvalid_0's rmse: 0.847863\n[219]\tvalid_0's rmse: 0.847876\n[220]\tvalid_0's rmse: 0.847872\n[221]\tvalid_0's rmse: 0.847861\n[222]\tvalid_0's rmse: 0.847873\n[223]\tvalid_0's rmse: 0.847879\n[224]\tvalid_0's rmse: 0.847857\n[225]\tvalid_0's rmse: 0.847862\n[226]\tvalid_0's rmse: 0.847839\n[227]\tvalid_0's rmse: 0.847819\n[228]\tvalid_0's rmse: 0.847801\n[229]\tvalid_0's rmse: 0.847803\n[230]\tvalid_0's rmse: 0.847769\n[231]\tvalid_0's rmse: 0.847743\n[232]\tvalid_0's rmse: 0.847736\n[233]\tvalid_0's rmse: 0.847738\n[234]\tvalid_0's rmse: 0.847748\n[235]\tvalid_0's rmse: 0.847742\n[236]\tvalid_0's rmse: 0.847756\n[237]\tvalid_0's rmse: 0.847746\n[238]\tvalid_0's rmse: 0.847745\n[239]\tvalid_0's rmse: 0.847744\n[240]\tvalid_0's rmse: 0.847739\n[241]\tvalid_0's rmse: 0.847731\n[242]\tvalid_0's rmse: 0.847733\n[243]\tvalid_0's rmse: 0.847718\n[244]\tvalid_0's rmse: 0.847722\n[245]\tvalid_0's rmse: 0.847714\n[246]\tvalid_0's rmse: 0.847699\n[247]\tvalid_0's rmse: 0.847716\n[248]\tvalid_0's rmse: 0.847702\n[249]\tvalid_0's rmse: 0.847686\n[250]\tvalid_0's rmse: 0.847674\n[251]\tvalid_0's rmse: 0.847686\n[252]\tvalid_0's rmse: 0.847669\n[253]\tvalid_0's rmse: 0.847699\n[254]\tvalid_0's rmse: 0.847693\n[255]\tvalid_0's rmse: 0.847668\n[256]\tvalid_0's rmse: 0.847649\n[257]\tvalid_0's rmse: 0.847648\n[258]\tvalid_0's rmse: 0.847646\n","name":"stdout"},{"output_type":"stream","text":"[259]\tvalid_0's rmse: 0.847645\n[260]\tvalid_0's rmse: 0.847624\n[261]\tvalid_0's rmse: 0.847625\n[262]\tvalid_0's rmse: 0.847623\n[263]\tvalid_0's rmse: 0.847631\n[264]\tvalid_0's rmse: 0.847637\n[265]\tvalid_0's rmse: 0.847632\n[266]\tvalid_0's rmse: 0.847627\n[267]\tvalid_0's rmse: 0.847622\n[268]\tvalid_0's rmse: 0.847623\n[269]\tvalid_0's rmse: 0.847617\n[270]\tvalid_0's rmse: 0.847626\n[271]\tvalid_0's rmse: 0.847633\n[272]\tvalid_0's rmse: 0.847615\n[273]\tvalid_0's rmse: 0.847622\n[274]\tvalid_0's rmse: 0.847626\n[275]\tvalid_0's rmse: 0.847626\n[276]\tvalid_0's rmse: 0.847617\n[277]\tvalid_0's rmse: 0.847614\n[278]\tvalid_0's rmse: 0.847621\n[279]\tvalid_0's rmse: 0.847612\n[280]\tvalid_0's rmse: 0.847598\n[281]\tvalid_0's rmse: 0.84759\n[282]\tvalid_0's rmse: 0.847598\n[283]\tvalid_0's rmse: 0.847592\n[284]\tvalid_0's rmse: 0.847555\n[285]\tvalid_0's rmse: 0.847551\n[286]\tvalid_0's rmse: 0.84755\n[287]\tvalid_0's rmse: 0.847522\n[288]\tvalid_0's rmse: 0.847522\n[289]\tvalid_0's rmse: 0.847535\n[290]\tvalid_0's rmse: 0.847544\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847522:  10%|#         | 2/20 [00:10<01:38,  5.48s/it]\u001b[32m[I 2021-02-05 22:51:41,704]\u001b[0m Trial 8 finished with value: 0.8475220986685417 and parameters: {'num_leaves': 26}. Best is trial 8 with value: 0.8475220986685417.\u001b[0m\nnum_leaves, val_score: 0.847522:  10%|#         | 2/20 [00:10<01:38,  5.48s/it]","name":"stderr"},{"output_type":"stream","text":"[291]\tvalid_0's rmse: 0.847538\n[292]\tvalid_0's rmse: 0.847548\n[293]\tvalid_0's rmse: 0.847528\n[294]\tvalid_0's rmse: 0.847538\n[295]\tvalid_0's rmse: 0.847543\n[296]\tvalid_0's rmse: 0.847558\n[297]\tvalid_0's rmse: 0.847558\nEarly stopping, best iteration is:\n[287]\tvalid_0's rmse: 0.847522\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018845 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88923\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.887223\n[3]\tvalid_0's rmse: 0.885591\n[4]\tvalid_0's rmse: 0.884047\n[5]\tvalid_0's rmse: 0.88269\n[6]\tvalid_0's rmse: 0.881193\n[7]\tvalid_0's rmse: 0.880058\n[8]\tvalid_0's rmse: 0.879106\n[9]\tvalid_0's rmse: 0.87829\n[10]\tvalid_0's rmse: 0.877488\n[11]\tvalid_0's rmse: 0.876396\n[12]\tvalid_0's rmse: 0.875468\n[13]\tvalid_0's rmse: 0.874659\n[14]\tvalid_0's rmse: 0.873851\n[15]\tvalid_0's rmse: 0.873277\n[16]\tvalid_0's rmse: 0.872656\n[17]\tvalid_0's rmse: 0.872064\n[18]\tvalid_0's rmse: 0.87158\n[19]\tvalid_0's rmse: 0.870994\n[20]\tvalid_0's rmse: 0.870492\n[21]\tvalid_0's rmse: 0.870022\n[22]\tvalid_0's rmse: 0.869533\n[23]\tvalid_0's rmse: 0.868991\n[24]\tvalid_0's rmse: 0.868595\n[25]\tvalid_0's rmse: 0.868227\n[26]\tvalid_0's rmse: 0.867854\n[27]\tvalid_0's rmse: 0.867474\n[28]\tvalid_0's rmse: 0.867128\n[29]\tvalid_0's rmse: 0.86685\n[30]\tvalid_0's rmse: 0.866524\n[31]\tvalid_0's rmse: 0.866188\n[32]\tvalid_0's rmse: 0.865859\n[33]\tvalid_0's rmse: 0.865546\n[34]\tvalid_0's rmse: 0.865253\n[35]\tvalid_0's rmse: 0.864997\n[36]\tvalid_0's rmse: 0.864753\n[37]\tvalid_0's rmse: 0.864493\n[38]\tvalid_0's rmse: 0.864237\n[39]\tvalid_0's rmse: 0.864049\n[40]\tvalid_0's rmse: 0.86379\n[41]\tvalid_0's rmse: 0.863555\n[42]\tvalid_0's rmse: 0.863368\n[43]\tvalid_0's rmse: 0.863184\n[44]\tvalid_0's rmse: 0.862924\n[45]\tvalid_0's rmse: 0.862688\n[46]\tvalid_0's rmse: 0.862447\n[47]\tvalid_0's rmse: 0.862271\n[48]\tvalid_0's rmse: 0.862103\n[49]\tvalid_0's rmse: 0.861802\n[50]\tvalid_0's rmse: 0.861648\n[51]\tvalid_0's rmse: 0.861454\n[52]\tvalid_0's rmse: 0.861221\n[53]\tvalid_0's rmse: 0.861056\n[54]\tvalid_0's rmse: 0.8608\n[55]\tvalid_0's rmse: 0.860644\n[56]\tvalid_0's rmse: 0.860434\n[57]\tvalid_0's rmse: 0.860293\n[58]\tvalid_0's rmse: 0.860138\n[59]\tvalid_0's rmse: 0.860013\n[60]\tvalid_0's rmse: 0.859823\n[61]\tvalid_0's rmse: 0.859677\n[62]\tvalid_0's rmse: 0.859496\n[63]\tvalid_0's rmse: 0.859352\n[64]\tvalid_0's rmse: 0.859196\n[65]\tvalid_0's rmse: 0.859081\n[66]\tvalid_0's rmse: 0.858956\n[67]\tvalid_0's rmse: 0.858836\n[68]\tvalid_0's rmse: 0.858708\n[69]\tvalid_0's rmse: 0.858553\n[70]\tvalid_0's rmse: 0.858441\n[71]\tvalid_0's rmse: 0.858337\n[72]\tvalid_0's rmse: 0.858209\n[73]\tvalid_0's rmse: 0.858093\n[74]\tvalid_0's rmse: 0.857974\n[75]\tvalid_0's rmse: 0.857871\n[76]\tvalid_0's rmse: 0.857753\n[77]\tvalid_0's rmse: 0.857638\n[78]\tvalid_0's rmse: 0.857551\n[79]\tvalid_0's rmse: 0.85746\n[80]\tvalid_0's rmse: 0.857351\n[81]\tvalid_0's rmse: 0.857267\n[82]\tvalid_0's rmse: 0.857179\n[83]\tvalid_0's rmse: 0.857057\n[84]\tvalid_0's rmse: 0.856944\n[85]\tvalid_0's rmse: 0.856874\n[86]\tvalid_0's rmse: 0.856788\n[87]\tvalid_0's rmse: 0.85672\n[88]\tvalid_0's rmse: 0.856638\n[89]\tvalid_0's rmse: 0.856544\n[90]\tvalid_0's rmse: 0.85649\n[91]\tvalid_0's rmse: 0.856387\n[92]\tvalid_0's rmse: 0.856267\n[93]\tvalid_0's rmse: 0.856163\n[94]\tvalid_0's rmse: 0.856079\n[95]\tvalid_0's rmse: 0.856028\n[96]\tvalid_0's rmse: 0.855959\n[97]\tvalid_0's rmse: 0.8559\n[98]\tvalid_0's rmse: 0.855829\n[99]\tvalid_0's rmse: 0.855777\n[100]\tvalid_0's rmse: 0.855722\n[101]\tvalid_0's rmse: 0.855635\n[102]\tvalid_0's rmse: 0.855576\n[103]\tvalid_0's rmse: 0.855506\n[104]\tvalid_0's rmse: 0.855443\n[105]\tvalid_0's rmse: 0.855378\n[106]\tvalid_0's rmse: 0.85534\n[107]\tvalid_0's rmse: 0.855279\n[108]\tvalid_0's rmse: 0.855205\n[109]\tvalid_0's rmse: 0.855163\n[110]\tvalid_0's rmse: 0.855128\n[111]\tvalid_0's rmse: 0.855071\n[112]\tvalid_0's rmse: 0.854994\n[113]\tvalid_0's rmse: 0.854948\n[114]\tvalid_0's rmse: 0.854862\n[115]\tvalid_0's rmse: 0.854806\n[116]\tvalid_0's rmse: 0.854759\n[117]\tvalid_0's rmse: 0.854675\n[118]\tvalid_0's rmse: 0.85462\n[119]\tvalid_0's rmse: 0.854565\n[120]\tvalid_0's rmse: 0.854515\n[121]\tvalid_0's rmse: 0.85445\n[122]\tvalid_0's rmse: 0.854395\n[123]\tvalid_0's rmse: 0.854335\n[124]\tvalid_0's rmse: 0.854264\n[125]\tvalid_0's rmse: 0.854216\n[126]\tvalid_0's rmse: 0.854152\n[127]\tvalid_0's rmse: 0.85406\n[128]\tvalid_0's rmse: 0.854006\n[129]\tvalid_0's rmse: 0.853977\n[130]\tvalid_0's rmse: 0.853936\n[131]\tvalid_0's rmse: 0.853871\n[132]\tvalid_0's rmse: 0.853824\n[133]\tvalid_0's rmse: 0.853774\n[134]\tvalid_0's rmse: 0.853718\n[135]\tvalid_0's rmse: 0.853622\n[136]\tvalid_0's rmse: 0.853573\n[137]\tvalid_0's rmse: 0.853494\n[138]\tvalid_0's rmse: 0.853423\n[139]\tvalid_0's rmse: 0.853387\n[140]\tvalid_0's rmse: 0.853341\n[141]\tvalid_0's rmse: 0.853297\n[142]\tvalid_0's rmse: 0.853258\n[143]\tvalid_0's rmse: 0.853193\n[144]\tvalid_0's rmse: 0.853168\n[145]\tvalid_0's rmse: 0.853124\n[146]\tvalid_0's rmse: 0.853077\n[147]\tvalid_0's rmse: 0.853039\n[148]\tvalid_0's rmse: 0.852984\n[149]\tvalid_0's rmse: 0.852933\n[150]\tvalid_0's rmse: 0.85288\n[151]\tvalid_0's rmse: 0.85283\n[152]\tvalid_0's rmse: 0.852804\n[153]\tvalid_0's rmse: 0.852752\n[154]\tvalid_0's rmse: 0.852701\n[155]\tvalid_0's rmse: 0.852662\n[156]\tvalid_0's rmse: 0.852632\n[157]\tvalid_0's rmse: 0.852602\n[158]\tvalid_0's rmse: 0.852573\n[159]\tvalid_0's rmse: 0.852528\n[160]\tvalid_0's rmse: 0.852419\n[161]\tvalid_0's rmse: 0.852371\n[162]\tvalid_0's rmse: 0.852328\n[163]\tvalid_0's rmse: 0.8523\n[164]\tvalid_0's rmse: 0.852286\n[165]\tvalid_0's rmse: 0.852269\n[166]\tvalid_0's rmse: 0.852254\n[167]\tvalid_0's rmse: 0.852208\n[168]\tvalid_0's rmse: 0.85218\n[169]\tvalid_0's rmse: 0.852154\n[170]\tvalid_0's rmse: 0.852148\n[171]\tvalid_0's rmse: 0.852103\n[172]\tvalid_0's rmse: 0.852078\n[173]\tvalid_0's rmse: 0.852038\n[174]\tvalid_0's rmse: 0.852\n[175]\tvalid_0's rmse: 0.851957\n[176]\tvalid_0's rmse: 0.851927\n[177]\tvalid_0's rmse: 0.851892\n[178]\tvalid_0's rmse: 0.851854\n[179]\tvalid_0's rmse: 0.851831\n[180]\tvalid_0's rmse: 0.851806\n[181]\tvalid_0's rmse: 0.851808\n[182]\tvalid_0's rmse: 0.851796\n[183]\tvalid_0's rmse: 0.851768\n[184]\tvalid_0's rmse: 0.851754\n[185]\tvalid_0's rmse: 0.851716\n[186]\tvalid_0's rmse: 0.851708\n[187]\tvalid_0's rmse: 0.851633\n[188]\tvalid_0's rmse: 0.851539\n[189]\tvalid_0's rmse: 0.851498\n[190]\tvalid_0's rmse: 0.851426\n[191]\tvalid_0's rmse: 0.851401\n[192]\tvalid_0's rmse: 0.851357\n[193]\tvalid_0's rmse: 0.851313\n[194]\tvalid_0's rmse: 0.85127\n[195]\tvalid_0's rmse: 0.851277\n[196]\tvalid_0's rmse: 0.851259\n[197]\tvalid_0's rmse: 0.851256\n[198]\tvalid_0's rmse: 0.851241\n[199]\tvalid_0's rmse: 0.851215\n[200]\tvalid_0's rmse: 0.851199\n[201]\tvalid_0's rmse: 0.851165\n[202]\tvalid_0's rmse: 0.851114\n[203]\tvalid_0's rmse: 0.851086\n[204]\tvalid_0's rmse: 0.851066\n[205]\tvalid_0's rmse: 0.851032\n[206]\tvalid_0's rmse: 0.851002\n[207]\tvalid_0's rmse: 0.85099\n[208]\tvalid_0's rmse: 0.850983\n[209]\tvalid_0's rmse: 0.850951\n[210]\tvalid_0's rmse: 0.850915\n[211]\tvalid_0's rmse: 0.85091\n[212]\tvalid_0's rmse: 0.850896\n[213]\tvalid_0's rmse: 0.85089\n[214]\tvalid_0's rmse: 0.850878\n[215]\tvalid_0's rmse: 0.85085\n[216]\tvalid_0's rmse: 0.850845\n[217]\tvalid_0's rmse: 0.850815\n[218]\tvalid_0's rmse: 0.850798\n[219]\tvalid_0's rmse: 0.850772\n[220]\tvalid_0's rmse: 0.850751\n[221]\tvalid_0's rmse: 0.850732\n[222]\tvalid_0's rmse: 0.850721\n[223]\tvalid_0's rmse: 0.850718\n[224]\tvalid_0's rmse: 0.850693\n[225]\tvalid_0's rmse: 0.850647\n[226]\tvalid_0's rmse: 0.850638\n[227]\tvalid_0's rmse: 0.850615\n[228]\tvalid_0's rmse: 0.850545\n[229]\tvalid_0's rmse: 0.850505\n[230]\tvalid_0's rmse: 0.850487\n[231]\tvalid_0's rmse: 0.850477\n[232]\tvalid_0's rmse: 0.850469\n[233]\tvalid_0's rmse: 0.850463\n[234]\tvalid_0's rmse: 0.850434\n[235]\tvalid_0's rmse: 0.850412\n[236]\tvalid_0's rmse: 0.850412\n[237]\tvalid_0's rmse: 0.850351\n[238]\tvalid_0's rmse: 0.85035\n[239]\tvalid_0's rmse: 0.85032\n[240]\tvalid_0's rmse: 0.850313\n[241]\tvalid_0's rmse: 0.850299\n[242]\tvalid_0's rmse: 0.850288\n[243]\tvalid_0's rmse: 0.850255\n[244]\tvalid_0's rmse: 0.850221\n[245]\tvalid_0's rmse: 0.8502\n[246]\tvalid_0's rmse: 0.850189\n[247]\tvalid_0's rmse: 0.850174\n","name":"stdout"},{"output_type":"stream","text":"[248]\tvalid_0's rmse: 0.850159\n[249]\tvalid_0's rmse: 0.850143\n[250]\tvalid_0's rmse: 0.850144\n[251]\tvalid_0's rmse: 0.850139\n[252]\tvalid_0's rmse: 0.850139\n[253]\tvalid_0's rmse: 0.850138\n[254]\tvalid_0's rmse: 0.85014\n[255]\tvalid_0's rmse: 0.850143\n[256]\tvalid_0's rmse: 0.85014\n[257]\tvalid_0's rmse: 0.850117\n[258]\tvalid_0's rmse: 0.850104\n[259]\tvalid_0's rmse: 0.850065\n[260]\tvalid_0's rmse: 0.850069\n[261]\tvalid_0's rmse: 0.850063\n[262]\tvalid_0's rmse: 0.850035\n[263]\tvalid_0's rmse: 0.85002\n[264]\tvalid_0's rmse: 0.849998\n[265]\tvalid_0's rmse: 0.850002\n[266]\tvalid_0's rmse: 0.849987\n[267]\tvalid_0's rmse: 0.849982\n[268]\tvalid_0's rmse: 0.849976\n[269]\tvalid_0's rmse: 0.849967\n[270]\tvalid_0's rmse: 0.849946\n[271]\tvalid_0's rmse: 0.849887\n[272]\tvalid_0's rmse: 0.849873\n[273]\tvalid_0's rmse: 0.849851\n[274]\tvalid_0's rmse: 0.849834\n[275]\tvalid_0's rmse: 0.849798\n[276]\tvalid_0's rmse: 0.84979\n[277]\tvalid_0's rmse: 0.849777\n[278]\tvalid_0's rmse: 0.849753\n[279]\tvalid_0's rmse: 0.849749\n[280]\tvalid_0's rmse: 0.849735\n[281]\tvalid_0's rmse: 0.849738\n[282]\tvalid_0's rmse: 0.849725\n[283]\tvalid_0's rmse: 0.849723\n[284]\tvalid_0's rmse: 0.849704\n[285]\tvalid_0's rmse: 0.849715\n[286]\tvalid_0's rmse: 0.849719\n[287]\tvalid_0's rmse: 0.849717\n[288]\tvalid_0's rmse: 0.849727\n[289]\tvalid_0's rmse: 0.849724\n[290]\tvalid_0's rmse: 0.849725\n[291]\tvalid_0's rmse: 0.849713\n[292]\tvalid_0's rmse: 0.849677\n[293]\tvalid_0's rmse: 0.849655\n[294]\tvalid_0's rmse: 0.849626\n[295]\tvalid_0's rmse: 0.849614\n[296]\tvalid_0's rmse: 0.849606\n[297]\tvalid_0's rmse: 0.849605\n[298]\tvalid_0's rmse: 0.849595\n[299]\tvalid_0's rmse: 0.84958\n[300]\tvalid_0's rmse: 0.849553\n[301]\tvalid_0's rmse: 0.849547\n[302]\tvalid_0's rmse: 0.84953\n[303]\tvalid_0's rmse: 0.849533\n[304]\tvalid_0's rmse: 0.849533\n[305]\tvalid_0's rmse: 0.849516\n[306]\tvalid_0's rmse: 0.849493\n[307]\tvalid_0's rmse: 0.849493\n[308]\tvalid_0's rmse: 0.849485\n[309]\tvalid_0's rmse: 0.849487\n[310]\tvalid_0's rmse: 0.849481\n[311]\tvalid_0's rmse: 0.849482\n[312]\tvalid_0's rmse: 0.84948\n[313]\tvalid_0's rmse: 0.849479\n[314]\tvalid_0's rmse: 0.849482\n[315]\tvalid_0's rmse: 0.849467\n[316]\tvalid_0's rmse: 0.849439\n[317]\tvalid_0's rmse: 0.849429\n[318]\tvalid_0's rmse: 0.849424\n[319]\tvalid_0's rmse: 0.849381\n[320]\tvalid_0's rmse: 0.849362\n[321]\tvalid_0's rmse: 0.849357\n[322]\tvalid_0's rmse: 0.849346\n[323]\tvalid_0's rmse: 0.849339\n[324]\tvalid_0's rmse: 0.849339\n[325]\tvalid_0's rmse: 0.84934\n[326]\tvalid_0's rmse: 0.849336\n[327]\tvalid_0's rmse: 0.849332\n[328]\tvalid_0's rmse: 0.849325\n[329]\tvalid_0's rmse: 0.849317\n[330]\tvalid_0's rmse: 0.849283\n[331]\tvalid_0's rmse: 0.849276\n[332]\tvalid_0's rmse: 0.849264\n[333]\tvalid_0's rmse: 0.849264\n[334]\tvalid_0's rmse: 0.849265\n[335]\tvalid_0's rmse: 0.849267\n[336]\tvalid_0's rmse: 0.849259\n[337]\tvalid_0's rmse: 0.849254\n[338]\tvalid_0's rmse: 0.849265\n[339]\tvalid_0's rmse: 0.849264\n[340]\tvalid_0's rmse: 0.84925\n[341]\tvalid_0's rmse: 0.849228\n[342]\tvalid_0's rmse: 0.849211\n[343]\tvalid_0's rmse: 0.849182\n[344]\tvalid_0's rmse: 0.849179\n[345]\tvalid_0's rmse: 0.849155\n[346]\tvalid_0's rmse: 0.849157\n[347]\tvalid_0's rmse: 0.849148\n[348]\tvalid_0's rmse: 0.849126\n[349]\tvalid_0's rmse: 0.849115\n[350]\tvalid_0's rmse: 0.849114\n[351]\tvalid_0's rmse: 0.84909\n[352]\tvalid_0's rmse: 0.84909\n[353]\tvalid_0's rmse: 0.849092\n[354]\tvalid_0's rmse: 0.849091\n[355]\tvalid_0's rmse: 0.849097\n[356]\tvalid_0's rmse: 0.849103\n[357]\tvalid_0's rmse: 0.849103\n[358]\tvalid_0's rmse: 0.849104\n[359]\tvalid_0's rmse: 0.849098\n[360]\tvalid_0's rmse: 0.849095\n[361]\tvalid_0's rmse: 0.849086\n[362]\tvalid_0's rmse: 0.849083\n[363]\tvalid_0's rmse: 0.849085\n[364]\tvalid_0's rmse: 0.849089\n[365]\tvalid_0's rmse: 0.849068\n[366]\tvalid_0's rmse: 0.849054\n[367]\tvalid_0's rmse: 0.849032\n[368]\tvalid_0's rmse: 0.849013\n[369]\tvalid_0's rmse: 0.849014\n[370]\tvalid_0's rmse: 0.848972\n[371]\tvalid_0's rmse: 0.848973\n[372]\tvalid_0's rmse: 0.848966\n[373]\tvalid_0's rmse: 0.848974\n[374]\tvalid_0's rmse: 0.848969\n[375]\tvalid_0's rmse: 0.848966\n[376]\tvalid_0's rmse: 0.848965\n[377]\tvalid_0's rmse: 0.848944\n[378]\tvalid_0's rmse: 0.848935\n[379]\tvalid_0's rmse: 0.848933\n[380]\tvalid_0's rmse: 0.848928\n[381]\tvalid_0's rmse: 0.848905\n[382]\tvalid_0's rmse: 0.848897\n[383]\tvalid_0's rmse: 0.848886\n[384]\tvalid_0's rmse: 0.848871\n[385]\tvalid_0's rmse: 0.84886\n[386]\tvalid_0's rmse: 0.848863\n[387]\tvalid_0's rmse: 0.848865\n[388]\tvalid_0's rmse: 0.84886\n[389]\tvalid_0's rmse: 0.848857\n[390]\tvalid_0's rmse: 0.848854\n[391]\tvalid_0's rmse: 0.84884\n[392]\tvalid_0's rmse: 0.848836\n[393]\tvalid_0's rmse: 0.84883\n[394]\tvalid_0's rmse: 0.848825\n[395]\tvalid_0's rmse: 0.848822\n[396]\tvalid_0's rmse: 0.848817\n[397]\tvalid_0's rmse: 0.848805\n[398]\tvalid_0's rmse: 0.848794\n[399]\tvalid_0's rmse: 0.84877\n[400]\tvalid_0's rmse: 0.848767\n[401]\tvalid_0's rmse: 0.84876\n[402]\tvalid_0's rmse: 0.848757\n[403]\tvalid_0's rmse: 0.848761\n[404]\tvalid_0's rmse: 0.84875\n[405]\tvalid_0's rmse: 0.848751\n[406]\tvalid_0's rmse: 0.848748\n[407]\tvalid_0's rmse: 0.848739\n[408]\tvalid_0's rmse: 0.848712\n[409]\tvalid_0's rmse: 0.848694\n[410]\tvalid_0's rmse: 0.848701\n[411]\tvalid_0's rmse: 0.848694\n[412]\tvalid_0's rmse: 0.84868\n[413]\tvalid_0's rmse: 0.848685\n[414]\tvalid_0's rmse: 0.84868\n[415]\tvalid_0's rmse: 0.848684\n[416]\tvalid_0's rmse: 0.848682\n[417]\tvalid_0's rmse: 0.848676\n[418]\tvalid_0's rmse: 0.84866\n[419]\tvalid_0's rmse: 0.848652\n[420]\tvalid_0's rmse: 0.848638\n[421]\tvalid_0's rmse: 0.848627\n[422]\tvalid_0's rmse: 0.848622\n[423]\tvalid_0's rmse: 0.848625\n[424]\tvalid_0's rmse: 0.848628\n[425]\tvalid_0's rmse: 0.848603\n[426]\tvalid_0's rmse: 0.848593\n[427]\tvalid_0's rmse: 0.848598\n[428]\tvalid_0's rmse: 0.848594\n[429]\tvalid_0's rmse: 0.848596\n[430]\tvalid_0's rmse: 0.848598\n[431]\tvalid_0's rmse: 0.848606\n[432]\tvalid_0's rmse: 0.848605\n[433]\tvalid_0's rmse: 0.848605\n[434]\tvalid_0's rmse: 0.8486\n[435]\tvalid_0's rmse: 0.848579\n[436]\tvalid_0's rmse: 0.848576\n[437]\tvalid_0's rmse: 0.848578\n[438]\tvalid_0's rmse: 0.848569\n[439]\tvalid_0's rmse: 0.848552\n[440]\tvalid_0's rmse: 0.84855\n[441]\tvalid_0's rmse: 0.848549\n[442]\tvalid_0's rmse: 0.848546\n[443]\tvalid_0's rmse: 0.848535\n[444]\tvalid_0's rmse: 0.848536\n[445]\tvalid_0's rmse: 0.84851\n[446]\tvalid_0's rmse: 0.848504\n[447]\tvalid_0's rmse: 0.848496\n[448]\tvalid_0's rmse: 0.848492\n[449]\tvalid_0's rmse: 0.848485\n[450]\tvalid_0's rmse: 0.848482\n[451]\tvalid_0's rmse: 0.848483\n[452]\tvalid_0's rmse: 0.848482\n[453]\tvalid_0's rmse: 0.848479\n[454]\tvalid_0's rmse: 0.848477\n[455]\tvalid_0's rmse: 0.848465\n[456]\tvalid_0's rmse: 0.848461\n[457]\tvalid_0's rmse: 0.84846\n[458]\tvalid_0's rmse: 0.848455\n[459]\tvalid_0's rmse: 0.848452\n[460]\tvalid_0's rmse: 0.848452\n[461]\tvalid_0's rmse: 0.848449\n[462]\tvalid_0's rmse: 0.848451\n[463]\tvalid_0's rmse: 0.848447\n[464]\tvalid_0's rmse: 0.848433\n[465]\tvalid_0's rmse: 0.848439\n[466]\tvalid_0's rmse: 0.848446\n[467]\tvalid_0's rmse: 0.848441\n[468]\tvalid_0's rmse: 0.84844\n[469]\tvalid_0's rmse: 0.848442\n[470]\tvalid_0's rmse: 0.84844\n[471]\tvalid_0's rmse: 0.848436\n[472]\tvalid_0's rmse: 0.848423\n[473]\tvalid_0's rmse: 0.848392\n[474]\tvalid_0's rmse: 0.848391\n[475]\tvalid_0's rmse: 0.848389\n[476]\tvalid_0's rmse: 0.848391\n[477]\tvalid_0's rmse: 0.848388\n[478]\tvalid_0's rmse: 0.848392\n[479]\tvalid_0's rmse: 0.848395\n[480]\tvalid_0's rmse: 0.8484\n[481]\tvalid_0's rmse: 0.848404\n[482]\tvalid_0's rmse: 0.848394\n[483]\tvalid_0's rmse: 0.848394\n[484]\tvalid_0's rmse: 0.84839\n[485]\tvalid_0's rmse: 0.848381\n[486]\tvalid_0's rmse: 0.848383\n[487]\tvalid_0's rmse: 0.848364\n[488]\tvalid_0's rmse: 0.848354\n[489]\tvalid_0's rmse: 0.848352\n[490]\tvalid_0's rmse: 0.848355\n[491]\tvalid_0's rmse: 0.848346\n[492]\tvalid_0's rmse: 0.848348\n[493]\tvalid_0's rmse: 0.84835\n[494]\tvalid_0's rmse: 0.848353\n[495]\tvalid_0's rmse: 0.848352\n[496]\tvalid_0's rmse: 0.848352\n[497]\tvalid_0's rmse: 0.848342\n[498]\tvalid_0's rmse: 0.848336\n[499]\tvalid_0's rmse: 0.848333\n[500]\tvalid_0's rmse: 0.848339\n[501]\tvalid_0's rmse: 0.848327\n[502]\tvalid_0's rmse: 0.848327\n[503]\tvalid_0's rmse: 0.848321\n[504]\tvalid_0's rmse: 0.848319\n[505]\tvalid_0's rmse: 0.848302\n[506]\tvalid_0's rmse: 0.848304\n[507]\tvalid_0's rmse: 0.848307\n[508]\tvalid_0's rmse: 0.848285\n[509]\tvalid_0's rmse: 0.848285\n[510]\tvalid_0's rmse: 0.848264\n[511]\tvalid_0's rmse: 0.848268\n[512]\tvalid_0's rmse: 0.84826\n[513]\tvalid_0's rmse: 0.848261\n[514]\tvalid_0's rmse: 0.848263\n[515]\tvalid_0's rmse: 0.848265\n[516]\tvalid_0's rmse: 0.84826\n[517]\tvalid_0's rmse: 0.848255\n[518]\tvalid_0's rmse: 0.848245\n[519]\tvalid_0's rmse: 0.84824\n","name":"stdout"},{"output_type":"stream","text":"[520]\tvalid_0's rmse: 0.848236\n[521]\tvalid_0's rmse: 0.848224\n[522]\tvalid_0's rmse: 0.848215\n[523]\tvalid_0's rmse: 0.848204\n[524]\tvalid_0's rmse: 0.848205\n[525]\tvalid_0's rmse: 0.848187\n[526]\tvalid_0's rmse: 0.848182\n[527]\tvalid_0's rmse: 0.848171\n[528]\tvalid_0's rmse: 0.848163\n[529]\tvalid_0's rmse: 0.848157\n[530]\tvalid_0's rmse: 0.84815\n[531]\tvalid_0's rmse: 0.848132\n[532]\tvalid_0's rmse: 0.848127\n[533]\tvalid_0's rmse: 0.848124\n[534]\tvalid_0's rmse: 0.848108\n[535]\tvalid_0's rmse: 0.848112\n[536]\tvalid_0's rmse: 0.848113\n[537]\tvalid_0's rmse: 0.848113","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847522:  15%|#5        | 3/20 [00:18<01:53,  6.69s/it]\u001b[32m[I 2021-02-05 22:51:49,842]\u001b[0m Trial 9 finished with value: 0.8480884566616065 and parameters: {'num_leaves': 7}. Best is trial 8 with value: 0.8475220986685417.\u001b[0m\nnum_leaves, val_score: 0.847522:  15%|#5        | 3/20 [00:18<01:53,  6.69s/it]","name":"stderr"},{"output_type":"stream","text":"\n[538]\tvalid_0's rmse: 0.848108\n[539]\tvalid_0's rmse: 0.848089\n[540]\tvalid_0's rmse: 0.848091\n[541]\tvalid_0's rmse: 0.848088\n[542]\tvalid_0's rmse: 0.848095\n[543]\tvalid_0's rmse: 0.848092\n[544]\tvalid_0's rmse: 0.848094\n[545]\tvalid_0's rmse: 0.848092\n[546]\tvalid_0's rmse: 0.848091\n[547]\tvalid_0's rmse: 0.848095\n[548]\tvalid_0's rmse: 0.848095\n[549]\tvalid_0's rmse: 0.848089\n[550]\tvalid_0's rmse: 0.84809\n[551]\tvalid_0's rmse: 0.848092\nEarly stopping, best iteration is:\n[541]\tvalid_0's rmse: 0.848088\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018943 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887749\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884333\n[3]\tvalid_0's rmse: 0.881709\n[4]\tvalid_0's rmse: 0.879172\n[5]\tvalid_0's rmse: 0.877009\n[6]\tvalid_0's rmse: 0.874589\n[7]\tvalid_0's rmse: 0.872934\n[8]\tvalid_0's rmse: 0.87149\n[9]\tvalid_0's rmse: 0.870125\n[10]\tvalid_0's rmse: 0.868919\n[11]\tvalid_0's rmse: 0.867274\n[12]\tvalid_0's rmse: 0.865963\n[13]\tvalid_0's rmse: 0.864804\n[14]\tvalid_0's rmse: 0.863589\n[15]\tvalid_0's rmse: 0.862798\n[16]\tvalid_0's rmse: 0.862059\n[17]\tvalid_0's rmse: 0.861152\n[18]\tvalid_0's rmse: 0.860483\n[19]\tvalid_0's rmse: 0.859798\n[20]\tvalid_0's rmse: 0.859215\n[21]\tvalid_0's rmse: 0.858632\n[22]\tvalid_0's rmse: 0.858029\n[23]\tvalid_0's rmse: 0.857513\n[24]\tvalid_0's rmse: 0.857029\n[25]\tvalid_0's rmse: 0.856689\n[26]\tvalid_0's rmse: 0.856333\n[27]\tvalid_0's rmse: 0.856043\n[28]\tvalid_0's rmse: 0.855668\n[29]\tvalid_0's rmse: 0.855299\n[30]\tvalid_0's rmse: 0.855014\n[31]\tvalid_0's rmse: 0.854696\n[32]\tvalid_0's rmse: 0.854381\n[33]\tvalid_0's rmse: 0.854146\n[34]\tvalid_0's rmse: 0.85386\n[35]\tvalid_0's rmse: 0.853588\n[36]\tvalid_0's rmse: 0.853327\n[37]\tvalid_0's rmse: 0.853105\n[38]\tvalid_0's rmse: 0.852854\n[39]\tvalid_0's rmse: 0.852641\n[40]\tvalid_0's rmse: 0.852443\n[41]\tvalid_0's rmse: 0.852351\n[42]\tvalid_0's rmse: 0.85218\n[43]\tvalid_0's rmse: 0.852007\n[44]\tvalid_0's rmse: 0.851867\n[45]\tvalid_0's rmse: 0.851695\n[46]\tvalid_0's rmse: 0.851595\n[47]\tvalid_0's rmse: 0.851468\n[48]\tvalid_0's rmse: 0.851338\n[49]\tvalid_0's rmse: 0.851213\n[50]\tvalid_0's rmse: 0.851108\n[51]\tvalid_0's rmse: 0.85109\n[52]\tvalid_0's rmse: 0.850961\n[53]\tvalid_0's rmse: 0.850806\n[54]\tvalid_0's rmse: 0.850691\n[55]\tvalid_0's rmse: 0.850671\n[56]\tvalid_0's rmse: 0.850578\n[57]\tvalid_0's rmse: 0.850446\n[58]\tvalid_0's rmse: 0.850322\n[59]\tvalid_0's rmse: 0.850272\n[60]\tvalid_0's rmse: 0.850186\n[61]\tvalid_0's rmse: 0.850132\n[62]\tvalid_0's rmse: 0.850089\n[63]\tvalid_0's rmse: 0.849971\n[64]\tvalid_0's rmse: 0.849862\n[65]\tvalid_0's rmse: 0.849741\n[66]\tvalid_0's rmse: 0.849678\n[67]\tvalid_0's rmse: 0.8496\n[68]\tvalid_0's rmse: 0.849618\n[69]\tvalid_0's rmse: 0.849514\n[70]\tvalid_0's rmse: 0.84945\n[71]\tvalid_0's rmse: 0.849425\n[72]\tvalid_0's rmse: 0.84936\n[73]\tvalid_0's rmse: 0.849348\n[74]\tvalid_0's rmse: 0.849299\n[75]\tvalid_0's rmse: 0.849277\n[76]\tvalid_0's rmse: 0.849241\n[77]\tvalid_0's rmse: 0.849214\n[78]\tvalid_0's rmse: 0.849179\n[79]\tvalid_0's rmse: 0.849159\n[80]\tvalid_0's rmse: 0.849164\n[81]\tvalid_0's rmse: 0.849144\n[82]\tvalid_0's rmse: 0.849105\n[83]\tvalid_0's rmse: 0.849129\n[84]\tvalid_0's rmse: 0.849079\n[85]\tvalid_0's rmse: 0.849087\n[86]\tvalid_0's rmse: 0.84912\n[87]\tvalid_0's rmse: 0.849186\n[88]\tvalid_0's rmse: 0.84913\n[89]\tvalid_0's rmse: 0.849056\n[90]\tvalid_0's rmse: 0.849059\n[91]\tvalid_0's rmse: 0.849042\n[92]\tvalid_0's rmse: 0.849055\n[93]\tvalid_0's rmse: 0.849055\n[94]\tvalid_0's rmse: 0.84907\n[95]\tvalid_0's rmse: 0.849081\n[96]\tvalid_0's rmse: 0.849075\n[97]\tvalid_0's rmse: 0.8491\n[98]\tvalid_0's rmse: 0.849109\n[99]\tvalid_0's rmse: 0.849134\n[100]\tvalid_0's rmse: 0.849126\n[101]\tvalid_0's rmse: 0.849171\nEarly stopping, best iteration is:\n[91]\tvalid_0's rmse: 0.849042\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847522:  20%|##        | 4/20 [00:23<01:32,  5.77s/it]\u001b[32m[I 2021-02-05 22:51:54,194]\u001b[0m Trial 10 finished with value: 0.849041884664496 and parameters: {'num_leaves': 197}. Best is trial 8 with value: 0.8475220986685417.\u001b[0m\nnum_leaves, val_score: 0.847522:  20%|##        | 4/20 [00:23<01:32,  5.77s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018964 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887986\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884813\n[3]\tvalid_0's rmse: 0.882292\n[4]\tvalid_0's rmse: 0.879881\n[5]\tvalid_0's rmse: 0.877812\n[6]\tvalid_0's rmse: 0.875485\n[7]\tvalid_0's rmse: 0.873907\n[8]\tvalid_0's rmse: 0.87256\n[9]\tvalid_0's rmse: 0.871255\n[10]\tvalid_0's rmse: 0.870096\n[11]\tvalid_0's rmse: 0.868547\n[12]\tvalid_0's rmse: 0.867289\n[13]\tvalid_0's rmse: 0.866209\n[14]\tvalid_0's rmse: 0.865022\n[15]\tvalid_0's rmse: 0.864253\n[16]\tvalid_0's rmse: 0.863491\n[17]\tvalid_0's rmse: 0.862686\n[18]\tvalid_0's rmse: 0.862047\n[19]\tvalid_0's rmse: 0.861359\n[20]\tvalid_0's rmse: 0.860741\n[21]\tvalid_0's rmse: 0.860165\n[22]\tvalid_0's rmse: 0.859481\n[23]\tvalid_0's rmse: 0.858939\n[24]\tvalid_0's rmse: 0.858416\n[25]\tvalid_0's rmse: 0.858054\n[26]\tvalid_0's rmse: 0.857618\n[27]\tvalid_0's rmse: 0.857266\n[28]\tvalid_0's rmse: 0.856879\n[29]\tvalid_0's rmse: 0.856505\n[30]\tvalid_0's rmse: 0.856194\n[31]\tvalid_0's rmse: 0.855896\n[32]\tvalid_0's rmse: 0.855567\n[33]\tvalid_0's rmse: 0.855286\n[34]\tvalid_0's rmse: 0.854966\n[35]\tvalid_0's rmse: 0.854706\n[36]\tvalid_0's rmse: 0.854401\n[37]\tvalid_0's rmse: 0.8542\n[38]\tvalid_0's rmse: 0.853963\n[39]\tvalid_0's rmse: 0.853697\n[40]\tvalid_0's rmse: 0.853471\n[41]\tvalid_0's rmse: 0.853343\n[42]\tvalid_0's rmse: 0.853155\n[43]\tvalid_0's rmse: 0.852992\n[44]\tvalid_0's rmse: 0.85278\n[45]\tvalid_0's rmse: 0.852597\n[46]\tvalid_0's rmse: 0.852495\n[47]\tvalid_0's rmse: 0.852309\n[48]\tvalid_0's rmse: 0.852145\n[49]\tvalid_0's rmse: 0.852011\n[50]\tvalid_0's rmse: 0.851883\n[51]\tvalid_0's rmse: 0.851816\n[52]\tvalid_0's rmse: 0.85167\n[53]\tvalid_0's rmse: 0.851517\n[54]\tvalid_0's rmse: 0.851337\n[55]\tvalid_0's rmse: 0.851251\n[56]\tvalid_0's rmse: 0.851118\n[57]\tvalid_0's rmse: 0.85099\n[58]\tvalid_0's rmse: 0.850921\n[59]\tvalid_0's rmse: 0.850834\n[60]\tvalid_0's rmse: 0.850745\n[61]\tvalid_0's rmse: 0.850704\n[62]\tvalid_0's rmse: 0.850627\n[63]\tvalid_0's rmse: 0.850518\n[64]\tvalid_0's rmse: 0.850405\n[65]\tvalid_0's rmse: 0.850335\n[66]\tvalid_0's rmse: 0.850266\n[67]\tvalid_0's rmse: 0.85025\n[68]\tvalid_0's rmse: 0.850185\n[69]\tvalid_0's rmse: 0.850105\n[70]\tvalid_0's rmse: 0.850022\n[71]\tvalid_0's rmse: 0.849967\n[72]\tvalid_0's rmse: 0.849935\n[73]\tvalid_0's rmse: 0.849911\n[74]\tvalid_0's rmse: 0.849865\n[75]\tvalid_0's rmse: 0.849756\n[76]\tvalid_0's rmse: 0.849676\n[77]\tvalid_0's rmse: 0.849612\n[78]\tvalid_0's rmse: 0.849519\n[79]\tvalid_0's rmse: 0.84944\n[80]\tvalid_0's rmse: 0.849399\n[81]\tvalid_0's rmse: 0.849376\n[82]\tvalid_0's rmse: 0.849332\n[83]\tvalid_0's rmse: 0.849265\n[84]\tvalid_0's rmse: 0.849227\n[85]\tvalid_0's rmse: 0.849201\n[86]\tvalid_0's rmse: 0.849209\n[87]\tvalid_0's rmse: 0.849133\n[88]\tvalid_0's rmse: 0.849046\n[89]\tvalid_0's rmse: 0.849059\n[90]\tvalid_0's rmse: 0.849005\n[91]\tvalid_0's rmse: 0.848955\n[92]\tvalid_0's rmse: 0.848911\n[93]\tvalid_0's rmse: 0.848875\n[94]\tvalid_0's rmse: 0.848866\n[95]\tvalid_0's rmse: 0.848756\n[96]\tvalid_0's rmse: 0.848708\n[97]\tvalid_0's rmse: 0.848682\n[98]\tvalid_0's rmse: 0.848637\n[99]\tvalid_0's rmse: 0.848613\n[100]\tvalid_0's rmse: 0.848601\n[101]\tvalid_0's rmse: 0.848581\n[102]\tvalid_0's rmse: 0.848574\n[103]\tvalid_0's rmse: 0.848537\n[104]\tvalid_0's rmse: 0.848542\n[105]\tvalid_0's rmse: 0.84846\n[106]\tvalid_0's rmse: 0.848428\n[107]\tvalid_0's rmse: 0.848414\n[108]\tvalid_0's rmse: 0.848367\n[109]\tvalid_0's rmse: 0.848379\n[110]\tvalid_0's rmse: 0.848374\n[111]\tvalid_0's rmse: 0.848391\n[112]\tvalid_0's rmse: 0.848394\n[113]\tvalid_0's rmse: 0.848388\n[114]\tvalid_0's rmse: 0.848429\n[115]\tvalid_0's rmse: 0.848399\n[116]\tvalid_0's rmse: 0.848394\n[117]\tvalid_0's rmse: 0.848371\n[118]\tvalid_0's rmse: 0.848359\n[119]\tvalid_0's rmse: 0.84836\n[120]\tvalid_0's rmse: 0.848384\n[121]\tvalid_0's rmse: 0.848373\n[122]\tvalid_0's rmse: 0.848342\n[123]\tvalid_0's rmse: 0.848312\n[124]\tvalid_0's rmse: 0.848292\n[125]\tvalid_0's rmse: 0.848279\n[126]\tvalid_0's rmse: 0.848307\n[127]\tvalid_0's rmse: 0.848247\n[128]\tvalid_0's rmse: 0.848258\n[129]\tvalid_0's rmse: 0.848232\n[130]\tvalid_0's rmse: 0.848228\n[131]\tvalid_0's rmse: 0.848224\n[132]\tvalid_0's rmse: 0.848206\n[133]\tvalid_0's rmse: 0.848228\n[134]\tvalid_0's rmse: 0.84821\n[135]\tvalid_0's rmse: 0.848185\n[136]\tvalid_0's rmse: 0.848136\n[137]\tvalid_0's rmse: 0.848108\n[138]\tvalid_0's rmse: 0.848074\n[139]\tvalid_0's rmse: 0.848097\n[140]\tvalid_0's rmse: 0.848141\n[141]\tvalid_0's rmse: 0.848146\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847522:  25%|##5       | 5/20 [00:27<01:19,  5.31s/it]\u001b[32m[I 2021-02-05 22:51:58,697]\u001b[0m Trial 11 finished with value: 0.8480743616672648 and parameters: {'num_leaves': 87}. Best is trial 8 with value: 0.8475220986685417.\u001b[0m\nnum_leaves, val_score: 0.847522:  25%|##5       | 5/20 [00:27<01:19,  5.31s/it]","name":"stderr"},{"output_type":"stream","text":"[142]\tvalid_0's rmse: 0.848132\n[143]\tvalid_0's rmse: 0.848138\n[144]\tvalid_0's rmse: 0.848158\n[145]\tvalid_0's rmse: 0.848168\n[146]\tvalid_0's rmse: 0.848163\n[147]\tvalid_0's rmse: 0.848166\n[148]\tvalid_0's rmse: 0.848159\nEarly stopping, best iteration is:\n[138]\tvalid_0's rmse: 0.848074\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019694 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888098\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885082\n[3]\tvalid_0's rmse: 0.882648\n[4]\tvalid_0's rmse: 0.880301\n[5]\tvalid_0's rmse: 0.878291\n[6]\tvalid_0's rmse: 0.876047\n[7]\tvalid_0's rmse: 0.874548\n[8]\tvalid_0's rmse: 0.87324\n[9]\tvalid_0's rmse: 0.871998\n[10]\tvalid_0's rmse: 0.870869\n[11]\tvalid_0's rmse: 0.869348\n[12]\tvalid_0's rmse: 0.868097\n[13]\tvalid_0's rmse: 0.866985\n[14]\tvalid_0's rmse: 0.86583\n[15]\tvalid_0's rmse: 0.865081\n[16]\tvalid_0's rmse: 0.864316\n[17]\tvalid_0's rmse: 0.863469\n[18]\tvalid_0's rmse: 0.862855\n[19]\tvalid_0's rmse: 0.862148\n[20]\tvalid_0's rmse: 0.861553\n[21]\tvalid_0's rmse: 0.861\n[22]\tvalid_0's rmse: 0.860356\n[23]\tvalid_0's rmse: 0.859843\n[24]\tvalid_0's rmse: 0.859314\n[25]\tvalid_0's rmse: 0.858904\n[26]\tvalid_0's rmse: 0.858476\n[27]\tvalid_0's rmse: 0.858126\n[28]\tvalid_0's rmse: 0.857727\n[29]\tvalid_0's rmse: 0.857318\n[30]\tvalid_0's rmse: 0.857003\n[31]\tvalid_0's rmse: 0.856682\n[32]\tvalid_0's rmse: 0.856291\n[33]\tvalid_0's rmse: 0.855991\n[34]\tvalid_0's rmse: 0.855624\n[35]\tvalid_0's rmse: 0.855383\n[36]\tvalid_0's rmse: 0.855077\n[37]\tvalid_0's rmse: 0.854826\n[38]\tvalid_0's rmse: 0.854564\n[39]\tvalid_0's rmse: 0.854306\n[40]\tvalid_0's rmse: 0.854084\n[41]\tvalid_0's rmse: 0.85395\n[42]\tvalid_0's rmse: 0.853764\n[43]\tvalid_0's rmse: 0.853588\n[44]\tvalid_0's rmse: 0.853413\n[45]\tvalid_0's rmse: 0.853178\n[46]\tvalid_0's rmse: 0.853047\n[47]\tvalid_0's rmse: 0.852868\n[48]\tvalid_0's rmse: 0.852731\n[49]\tvalid_0's rmse: 0.852557\n[50]\tvalid_0's rmse: 0.85242\n[51]\tvalid_0's rmse: 0.85235\n[52]\tvalid_0's rmse: 0.852206\n[53]\tvalid_0's rmse: 0.852046\n[54]\tvalid_0's rmse: 0.851923\n[55]\tvalid_0's rmse: 0.851805\n[56]\tvalid_0's rmse: 0.851613\n[57]\tvalid_0's rmse: 0.851483\n[58]\tvalid_0's rmse: 0.851345\n[59]\tvalid_0's rmse: 0.851272\n[60]\tvalid_0's rmse: 0.8512\n[61]\tvalid_0's rmse: 0.851073\n[62]\tvalid_0's rmse: 0.851006\n[63]\tvalid_0's rmse: 0.850887\n[64]\tvalid_0's rmse: 0.850781\n[65]\tvalid_0's rmse: 0.850631\n[66]\tvalid_0's rmse: 0.850526\n[67]\tvalid_0's rmse: 0.850466\n[68]\tvalid_0's rmse: 0.850377\n[69]\tvalid_0's rmse: 0.85027\n[70]\tvalid_0's rmse: 0.850195\n[71]\tvalid_0's rmse: 0.850141\n[72]\tvalid_0's rmse: 0.850076\n[73]\tvalid_0's rmse: 0.850024\n[74]\tvalid_0's rmse: 0.849978\n[75]\tvalid_0's rmse: 0.849922\n[76]\tvalid_0's rmse: 0.849882\n[77]\tvalid_0's rmse: 0.849823\n[78]\tvalid_0's rmse: 0.849762\n[79]\tvalid_0's rmse: 0.849707\n[80]\tvalid_0's rmse: 0.849679\n[81]\tvalid_0's rmse: 0.84962\n[82]\tvalid_0's rmse: 0.849575\n[83]\tvalid_0's rmse: 0.849526\n[84]\tvalid_0's rmse: 0.849463\n[85]\tvalid_0's rmse: 0.849458\n[86]\tvalid_0's rmse: 0.849416\n[87]\tvalid_0's rmse: 0.84941\n[88]\tvalid_0's rmse: 0.849316\n[89]\tvalid_0's rmse: 0.849291\n[90]\tvalid_0's rmse: 0.849241\n[91]\tvalid_0's rmse: 0.849167\n[92]\tvalid_0's rmse: 0.849145\n[93]\tvalid_0's rmse: 0.849104\n[94]\tvalid_0's rmse: 0.849082\n[95]\tvalid_0's rmse: 0.849007\n[96]\tvalid_0's rmse: 0.849015\n[97]\tvalid_0's rmse: 0.848965\n[98]\tvalid_0's rmse: 0.84891\n[99]\tvalid_0's rmse: 0.848889\n[100]\tvalid_0's rmse: 0.848861\n[101]\tvalid_0's rmse: 0.848841\n[102]\tvalid_0's rmse: 0.848768\n[103]\tvalid_0's rmse: 0.848769\n[104]\tvalid_0's rmse: 0.848737\n[105]\tvalid_0's rmse: 0.848728\n[106]\tvalid_0's rmse: 0.848734\n[107]\tvalid_0's rmse: 0.848647\n[108]\tvalid_0's rmse: 0.848625\n[109]\tvalid_0's rmse: 0.848563\n[110]\tvalid_0's rmse: 0.848575\n[111]\tvalid_0's rmse: 0.848544\n[112]\tvalid_0's rmse: 0.84853\n[113]\tvalid_0's rmse: 0.848516\n[114]\tvalid_0's rmse: 0.848526\n[115]\tvalid_0's rmse: 0.848519\n[116]\tvalid_0's rmse: 0.848475\n[117]\tvalid_0's rmse: 0.848434\n[118]\tvalid_0's rmse: 0.848395\n[119]\tvalid_0's rmse: 0.848381\n[120]\tvalid_0's rmse: 0.848379\n[121]\tvalid_0's rmse: 0.848342\n[122]\tvalid_0's rmse: 0.848325\n[123]\tvalid_0's rmse: 0.84833\n[124]\tvalid_0's rmse: 0.848325\n[125]\tvalid_0's rmse: 0.848346\n[126]\tvalid_0's rmse: 0.848338\n[127]\tvalid_0's rmse: 0.848335\n[128]\tvalid_0's rmse: 0.848309\n[129]\tvalid_0's rmse: 0.848305\n[130]\tvalid_0's rmse: 0.848308\n[131]\tvalid_0's rmse: 0.84831\n[132]\tvalid_0's rmse: 0.84829\n[133]\tvalid_0's rmse: 0.848285\n[134]\tvalid_0's rmse: 0.848268\n[135]\tvalid_0's rmse: 0.848274\n[136]\tvalid_0's rmse: 0.848292\n[137]\tvalid_0's rmse: 0.848244\n[138]\tvalid_0's rmse: 0.84827\n[139]\tvalid_0's rmse: 0.848212\n[140]\tvalid_0's rmse: 0.848191\n[141]\tvalid_0's rmse: 0.848188\n[142]\tvalid_0's rmse: 0.848167\n[143]\tvalid_0's rmse: 0.848165\n[144]\tvalid_0's rmse: 0.848166\n[145]\tvalid_0's rmse: 0.848148\n[146]\tvalid_0's rmse: 0.848114\n[147]\tvalid_0's rmse: 0.848118\n[148]\tvalid_0's rmse: 0.848131\n[149]\tvalid_0's rmse: 0.848078\n[150]\tvalid_0's rmse: 0.848115\n[151]\tvalid_0's rmse: 0.848099\n[152]\tvalid_0's rmse: 0.848107\n[153]\tvalid_0's rmse: 0.848129\n[154]\tvalid_0's rmse: 0.848131\n[155]\tvalid_0's rmse: 0.848143\n[156]\tvalid_0's rmse: 0.848125\n[157]\tvalid_0's rmse: 0.848103\n[158]\tvalid_0's rmse: 0.848082\n[159]\tvalid_0's rmse: 0.848106\nEarly stopping, best iteration is:\n[149]\tvalid_0's rmse: 0.848078\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847522:  30%|###       | 6/20 [00:33<01:14,  5.35s/it]\u001b[32m[I 2021-02-05 22:52:04,106]\u001b[0m Trial 12 finished with value: 0.8480779080066863 and parameters: {'num_leaves': 65}. Best is trial 8 with value: 0.8475220986685417.\u001b[0m\nnum_leaves, val_score: 0.847522:  30%|###       | 6/20 [00:33<01:14,  5.35s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018947 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887947\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884727\n[3]\tvalid_0's rmse: 0.882185\n[4]\tvalid_0's rmse: 0.879738\n[5]\tvalid_0's rmse: 0.877652\n[6]\tvalid_0's rmse: 0.875352\n[7]\tvalid_0's rmse: 0.87375\n[8]\tvalid_0's rmse: 0.87237\n[9]\tvalid_0's rmse: 0.871077\n[10]\tvalid_0's rmse: 0.869939\n[11]\tvalid_0's rmse: 0.868389\n[12]\tvalid_0's rmse: 0.867109\n[13]\tvalid_0's rmse: 0.866046\n[14]\tvalid_0's rmse: 0.864886\n[15]\tvalid_0's rmse: 0.864126\n[16]\tvalid_0's rmse: 0.863374\n[17]\tvalid_0's rmse: 0.862527\n[18]\tvalid_0's rmse: 0.861891\n[19]\tvalid_0's rmse: 0.861186\n[20]\tvalid_0's rmse: 0.860666\n[21]\tvalid_0's rmse: 0.860066\n[22]\tvalid_0's rmse: 0.859419\n[23]\tvalid_0's rmse: 0.858881\n[24]\tvalid_0's rmse: 0.858363\n[25]\tvalid_0's rmse: 0.857995\n[26]\tvalid_0's rmse: 0.857597\n[27]\tvalid_0's rmse: 0.857242\n[28]\tvalid_0's rmse: 0.856868\n[29]\tvalid_0's rmse: 0.856485\n[30]\tvalid_0's rmse: 0.856179\n[31]\tvalid_0's rmse: 0.855863\n[32]\tvalid_0's rmse: 0.855465\n[33]\tvalid_0's rmse: 0.855199\n[34]\tvalid_0's rmse: 0.854859\n[35]\tvalid_0's rmse: 0.854581\n[36]\tvalid_0's rmse: 0.854293\n[37]\tvalid_0's rmse: 0.85405\n[38]\tvalid_0's rmse: 0.853822\n[39]\tvalid_0's rmse: 0.853528\n[40]\tvalid_0's rmse: 0.85329\n[41]\tvalid_0's rmse: 0.853172\n[42]\tvalid_0's rmse: 0.852987\n[43]\tvalid_0's rmse: 0.852824\n[44]\tvalid_0's rmse: 0.85249\n[45]\tvalid_0's rmse: 0.852323\n[46]\tvalid_0's rmse: 0.852222\n[47]\tvalid_0's rmse: 0.85202\n[48]\tvalid_0's rmse: 0.851841\n[49]\tvalid_0's rmse: 0.851734\n[50]\tvalid_0's rmse: 0.851636\n[51]\tvalid_0's rmse: 0.851568\n[52]\tvalid_0's rmse: 0.851411\n[53]\tvalid_0's rmse: 0.85126\n[54]\tvalid_0's rmse: 0.85112\n[55]\tvalid_0's rmse: 0.851061\n[56]\tvalid_0's rmse: 0.850948\n[57]\tvalid_0's rmse: 0.850856\n[58]\tvalid_0's rmse: 0.850793\n[59]\tvalid_0's rmse: 0.850674\n[60]\tvalid_0's rmse: 0.8506\n[61]\tvalid_0's rmse: 0.850524\n[62]\tvalid_0's rmse: 0.850463\n[63]\tvalid_0's rmse: 0.850309\n[64]\tvalid_0's rmse: 0.850173\n[65]\tvalid_0's rmse: 0.850086\n[66]\tvalid_0's rmse: 0.850026\n[67]\tvalid_0's rmse: 0.849959\n[68]\tvalid_0's rmse: 0.849914\n[69]\tvalid_0's rmse: 0.849856\n[70]\tvalid_0's rmse: 0.849764\n[71]\tvalid_0's rmse: 0.849721\n[72]\tvalid_0's rmse: 0.849709\n[73]\tvalid_0's rmse: 0.849657\n[74]\tvalid_0's rmse: 0.849631\n[75]\tvalid_0's rmse: 0.849629\n[76]\tvalid_0's rmse: 0.849533\n[77]\tvalid_0's rmse: 0.849516\n[78]\tvalid_0's rmse: 0.849446\n[79]\tvalid_0's rmse: 0.849357\n[80]\tvalid_0's rmse: 0.849358\n[81]\tvalid_0's rmse: 0.849292\n[82]\tvalid_0's rmse: 0.849284\n[83]\tvalid_0's rmse: 0.849258\n[84]\tvalid_0's rmse: 0.849221\n[85]\tvalid_0's rmse: 0.849209\n[86]\tvalid_0's rmse: 0.849149\n[87]\tvalid_0's rmse: 0.849119\n[88]\tvalid_0's rmse: 0.849041\n[89]\tvalid_0's rmse: 0.848998\n[90]\tvalid_0's rmse: 0.848984\n[91]\tvalid_0's rmse: 0.848972\n[92]\tvalid_0's rmse: 0.848962\n[93]\tvalid_0's rmse: 0.848911\n[94]\tvalid_0's rmse: 0.848879\n[95]\tvalid_0's rmse: 0.848826\n[96]\tvalid_0's rmse: 0.848788\n[97]\tvalid_0's rmse: 0.848734\n[98]\tvalid_0's rmse: 0.848671\n[99]\tvalid_0's rmse: 0.848663\n[100]\tvalid_0's rmse: 0.848629\n[101]\tvalid_0's rmse: 0.848568\n[102]\tvalid_0's rmse: 0.848536\n[103]\tvalid_0's rmse: 0.848513\n[104]\tvalid_0's rmse: 0.848531\n[105]\tvalid_0's rmse: 0.848521\n[106]\tvalid_0's rmse: 0.848512\n[107]\tvalid_0's rmse: 0.848465\n[108]\tvalid_0's rmse: 0.848452\n[109]\tvalid_0's rmse: 0.848442\n[110]\tvalid_0's rmse: 0.84843\n[111]\tvalid_0's rmse: 0.848379\n[112]\tvalid_0's rmse: 0.848379\n[113]\tvalid_0's rmse: 0.848363\n[114]\tvalid_0's rmse: 0.848343\n[115]\tvalid_0's rmse: 0.848368\n[116]\tvalid_0's rmse: 0.848382\n[117]\tvalid_0's rmse: 0.848383\n[118]\tvalid_0's rmse: 0.848375\n[119]\tvalid_0's rmse: 0.848335\n[120]\tvalid_0's rmse: 0.848351\n[121]\tvalid_0's rmse: 0.848364\n[122]\tvalid_0's rmse: 0.848337\n[123]\tvalid_0's rmse: 0.848338\n[124]\tvalid_0's rmse: 0.848334\n[125]\tvalid_0's rmse: 0.848342\n[126]\tvalid_0's rmse: 0.848353\n[127]\tvalid_0's rmse: 0.848371\n[128]\tvalid_0's rmse: 0.848361\n[129]\tvalid_0's rmse: 0.848374\n[130]\tvalid_0's rmse: 0.848394\n[131]\tvalid_0's rmse: 0.848376\n[132]\tvalid_0's rmse: 0.848365\n[133]\tvalid_0's rmse: 0.848325\n[134]\tvalid_0's rmse: 0.848261\n[135]\tvalid_0's rmse: 0.848219\n[136]\tvalid_0's rmse: 0.848199\n[137]\tvalid_0's rmse: 0.848212\n[138]\tvalid_0's rmse: 0.848209\n[139]\tvalid_0's rmse: 0.848174\n[140]\tvalid_0's rmse: 0.848194\n[141]\tvalid_0's rmse: 0.84821\n[142]\tvalid_0's rmse: 0.848225\n[143]\tvalid_0's rmse: 0.848212\n[144]\tvalid_0's rmse: 0.84823\n[145]\tvalid_0's rmse: 0.848228\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847522:  35%|###5      | 7/20 [00:37<01:06,  5.11s/it]\u001b[32m[I 2021-02-05 22:52:08,735]\u001b[0m Trial 13 finished with value: 0.8481743525105832 and parameters: {'num_leaves': 98}. Best is trial 8 with value: 0.8475220986685417.\u001b[0m\nnum_leaves, val_score: 0.847522:  35%|###5      | 7/20 [00:37<01:06,  5.11s/it]","name":"stderr"},{"output_type":"stream","text":"[146]\tvalid_0's rmse: 0.848216\n[147]\tvalid_0's rmse: 0.848227\n[148]\tvalid_0's rmse: 0.848216\n[149]\tvalid_0's rmse: 0.848251\nEarly stopping, best iteration is:\n[139]\tvalid_0's rmse: 0.848174\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019034 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887826\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884506\n[3]\tvalid_0's rmse: 0.88196\n[4]\tvalid_0's rmse: 0.879425\n[5]\tvalid_0's rmse: 0.877276\n[6]\tvalid_0's rmse: 0.874878\n[7]\tvalid_0's rmse: 0.873247\n[8]\tvalid_0's rmse: 0.871848\n[9]\tvalid_0's rmse: 0.870523\n[10]\tvalid_0's rmse: 0.869389\n[11]\tvalid_0's rmse: 0.867757\n[12]\tvalid_0's rmse: 0.866461\n[13]\tvalid_0's rmse: 0.865359\n[14]\tvalid_0's rmse: 0.86416\n[15]\tvalid_0's rmse: 0.863384\n[16]\tvalid_0's rmse: 0.862645\n[17]\tvalid_0's rmse: 0.861808\n[18]\tvalid_0's rmse: 0.861158\n[19]\tvalid_0's rmse: 0.860491\n[20]\tvalid_0's rmse: 0.859914\n[21]\tvalid_0's rmse: 0.859274\n[22]\tvalid_0's rmse: 0.858661\n[23]\tvalid_0's rmse: 0.858067\n[24]\tvalid_0's rmse: 0.857538\n[25]\tvalid_0's rmse: 0.857165\n[26]\tvalid_0's rmse: 0.856749\n[27]\tvalid_0's rmse: 0.85643\n[28]\tvalid_0's rmse: 0.856053\n[29]\tvalid_0's rmse: 0.855695\n[30]\tvalid_0's rmse: 0.855397\n[31]\tvalid_0's rmse: 0.85511\n[32]\tvalid_0's rmse: 0.854782\n[33]\tvalid_0's rmse: 0.854546\n[34]\tvalid_0's rmse: 0.854201\n[35]\tvalid_0's rmse: 0.853979\n[36]\tvalid_0's rmse: 0.853722\n[37]\tvalid_0's rmse: 0.853537\n[38]\tvalid_0's rmse: 0.853279\n[39]\tvalid_0's rmse: 0.853035\n[40]\tvalid_0's rmse: 0.852821\n[41]\tvalid_0's rmse: 0.852697\n[42]\tvalid_0's rmse: 0.852513\n[43]\tvalid_0's rmse: 0.852352\n[44]\tvalid_0's rmse: 0.852146\n[45]\tvalid_0's rmse: 0.851953\n[46]\tvalid_0's rmse: 0.851802\n[47]\tvalid_0's rmse: 0.851651\n[48]\tvalid_0's rmse: 0.851544\n[49]\tvalid_0's rmse: 0.851422\n[50]\tvalid_0's rmse: 0.851294\n[51]\tvalid_0's rmse: 0.851198\n[52]\tvalid_0's rmse: 0.851043\n[53]\tvalid_0's rmse: 0.850849\n[54]\tvalid_0's rmse: 0.850744\n[55]\tvalid_0's rmse: 0.850663\n[56]\tvalid_0's rmse: 0.850579\n[57]\tvalid_0's rmse: 0.850469\n[58]\tvalid_0's rmse: 0.85038\n[59]\tvalid_0's rmse: 0.850284\n[60]\tvalid_0's rmse: 0.850158\n[61]\tvalid_0's rmse: 0.850087\n[62]\tvalid_0's rmse: 0.85003\n[63]\tvalid_0's rmse: 0.849964\n[64]\tvalid_0's rmse: 0.849886\n[65]\tvalid_0's rmse: 0.849815\n[66]\tvalid_0's rmse: 0.849752\n[67]\tvalid_0's rmse: 0.849726\n[68]\tvalid_0's rmse: 0.849665\n[69]\tvalid_0's rmse: 0.849541\n[70]\tvalid_0's rmse: 0.84948\n[71]\tvalid_0's rmse: 0.849419\n[72]\tvalid_0's rmse: 0.849381\n[73]\tvalid_0's rmse: 0.849371\n[74]\tvalid_0's rmse: 0.849341\n[75]\tvalid_0's rmse: 0.8493\n[76]\tvalid_0's rmse: 0.849263\n[77]\tvalid_0's rmse: 0.849196\n[78]\tvalid_0's rmse: 0.849162\n[79]\tvalid_0's rmse: 0.849078\n[80]\tvalid_0's rmse: 0.849051\n[81]\tvalid_0's rmse: 0.848986\n[82]\tvalid_0's rmse: 0.848995\n[83]\tvalid_0's rmse: 0.848983\n[84]\tvalid_0's rmse: 0.848957\n[85]\tvalid_0's rmse: 0.848914\n[86]\tvalid_0's rmse: 0.848916\n[87]\tvalid_0's rmse: 0.84891\n[88]\tvalid_0's rmse: 0.848845\n[89]\tvalid_0's rmse: 0.848831\n[90]\tvalid_0's rmse: 0.848864\n[91]\tvalid_0's rmse: 0.848883\n[92]\tvalid_0's rmse: 0.848885\n[93]\tvalid_0's rmse: 0.84882\n[94]\tvalid_0's rmse: 0.848816\n[95]\tvalid_0's rmse: 0.848782\n[96]\tvalid_0's rmse: 0.848756\n[97]\tvalid_0's rmse: 0.848791\n[98]\tvalid_0's rmse: 0.848773\n[99]\tvalid_0's rmse: 0.848768\n[100]\tvalid_0's rmse: 0.848769\n[101]\tvalid_0's rmse: 0.848781\n[102]\tvalid_0's rmse: 0.848746\n[103]\tvalid_0's rmse: 0.848751\n[104]\tvalid_0's rmse: 0.848809\n[105]\tvalid_0's rmse: 0.848785\n[106]\tvalid_0's rmse: 0.848785\n[107]\tvalid_0's rmse: 0.848771\n[108]\tvalid_0's rmse: 0.848797\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847522:  40%|####      | 8/20 [00:42<00:58,  4.91s/it]\u001b[32m[I 2021-02-05 22:52:13,209]\u001b[0m Trial 14 finished with value: 0.8487461413354657 and parameters: {'num_leaves': 145}. Best is trial 8 with value: 0.8475220986685417.\u001b[0m\nnum_leaves, val_score: 0.847522:  40%|####      | 8/20 [00:42<00:58,  4.91s/it]","name":"stderr"},{"output_type":"stream","text":"[109]\tvalid_0's rmse: 0.84878\n[110]\tvalid_0's rmse: 0.848755\n[111]\tvalid_0's rmse: 0.848748\n[112]\tvalid_0's rmse: 0.848747\nEarly stopping, best iteration is:\n[102]\tvalid_0's rmse: 0.848746\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019124 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848117\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847948\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n","name":"stdout"},{"output_type":"stream","text":"[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  45%|####5     | 9/20 [00:47<00:56,  5.10s/it]\u001b[32m[I 2021-02-05 22:52:18,739]\u001b[0m Trial 15 finished with value: 0.8474653536625801 and parameters: {'num_leaves': 34}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  45%|####5     | 9/20 [00:47<00:56,  5.10s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018902 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887794\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884454\n[3]\tvalid_0's rmse: 0.881889\n[4]\tvalid_0's rmse: 0.879327\n[5]\tvalid_0's rmse: 0.877175\n[6]\tvalid_0's rmse: 0.874782\n[7]\tvalid_0's rmse: 0.873148\n[8]\tvalid_0's rmse: 0.871766\n[9]\tvalid_0's rmse: 0.870432\n[10]\tvalid_0's rmse: 0.869273\n[11]\tvalid_0's rmse: 0.867664\n[12]\tvalid_0's rmse: 0.866369\n[13]\tvalid_0's rmse: 0.865255\n[14]\tvalid_0's rmse: 0.864064\n[15]\tvalid_0's rmse: 0.863278\n[16]\tvalid_0's rmse: 0.862542\n[17]\tvalid_0's rmse: 0.86167\n[18]\tvalid_0's rmse: 0.860989\n[19]\tvalid_0's rmse: 0.860317\n[20]\tvalid_0's rmse: 0.859736\n[21]\tvalid_0's rmse: 0.859107\n[22]\tvalid_0's rmse: 0.858491\n[23]\tvalid_0's rmse: 0.857924\n[24]\tvalid_0's rmse: 0.857366\n[25]\tvalid_0's rmse: 0.856996\n[26]\tvalid_0's rmse: 0.856578\n[27]\tvalid_0's rmse: 0.856271\n[28]\tvalid_0's rmse: 0.855876\n[29]\tvalid_0's rmse: 0.855535\n[30]\tvalid_0's rmse: 0.855257\n[31]\tvalid_0's rmse: 0.854923\n[32]\tvalid_0's rmse: 0.854566\n[33]\tvalid_0's rmse: 0.854306\n[34]\tvalid_0's rmse: 0.853984\n[35]\tvalid_0's rmse: 0.853745\n[36]\tvalid_0's rmse: 0.853468\n[37]\tvalid_0's rmse: 0.85324\n[38]\tvalid_0's rmse: 0.852984\n[39]\tvalid_0's rmse: 0.852725\n[40]\tvalid_0's rmse: 0.852506\n[41]\tvalid_0's rmse: 0.852407\n[42]\tvalid_0's rmse: 0.852244\n[43]\tvalid_0's rmse: 0.852115\n[44]\tvalid_0's rmse: 0.85196\n[45]\tvalid_0's rmse: 0.851742\n[46]\tvalid_0's rmse: 0.851664\n[47]\tvalid_0's rmse: 0.851515\n[48]\tvalid_0's rmse: 0.85134\n[49]\tvalid_0's rmse: 0.851215\n[50]\tvalid_0's rmse: 0.85109\n[51]\tvalid_0's rmse: 0.851066\n[52]\tvalid_0's rmse: 0.85091\n[53]\tvalid_0's rmse: 0.850786\n[54]\tvalid_0's rmse: 0.850651\n[55]\tvalid_0's rmse: 0.850593\n[56]\tvalid_0's rmse: 0.850472\n[57]\tvalid_0's rmse: 0.850409\n[58]\tvalid_0's rmse: 0.850333\n[59]\tvalid_0's rmse: 0.850228\n[60]\tvalid_0's rmse: 0.850103\n[61]\tvalid_0's rmse: 0.849995\n[62]\tvalid_0's rmse: 0.849976\n[63]\tvalid_0's rmse: 0.849926\n[64]\tvalid_0's rmse: 0.849836\n[65]\tvalid_0's rmse: 0.849754\n[66]\tvalid_0's rmse: 0.849687\n[67]\tvalid_0's rmse: 0.849645\n[68]\tvalid_0's rmse: 0.849578\n[69]\tvalid_0's rmse: 0.849519\n[70]\tvalid_0's rmse: 0.849402\n[71]\tvalid_0's rmse: 0.849351\n[72]\tvalid_0's rmse: 0.849321\n[73]\tvalid_0's rmse: 0.8493\n[74]\tvalid_0's rmse: 0.849293\n[75]\tvalid_0's rmse: 0.849283\n[76]\tvalid_0's rmse: 0.849193\n[77]\tvalid_0's rmse: 0.849193\n[78]\tvalid_0's rmse: 0.849126\n[79]\tvalid_0's rmse: 0.849006\n[80]\tvalid_0's rmse: 0.848969\n[81]\tvalid_0's rmse: 0.848945\n[82]\tvalid_0's rmse: 0.848893\n[83]\tvalid_0's rmse: 0.84885\n[84]\tvalid_0's rmse: 0.848858\n[85]\tvalid_0's rmse: 0.848843\n[86]\tvalid_0's rmse: 0.848867\n[87]\tvalid_0's rmse: 0.848833\n[88]\tvalid_0's rmse: 0.848787\n[89]\tvalid_0's rmse: 0.848757\n[90]\tvalid_0's rmse: 0.848756\n[91]\tvalid_0's rmse: 0.84876\n[92]\tvalid_0's rmse: 0.848759\n[93]\tvalid_0's rmse: 0.848734\n[94]\tvalid_0's rmse: 0.848752\n[95]\tvalid_0's rmse: 0.848748\n[96]\tvalid_0's rmse: 0.848715\n[97]\tvalid_0's rmse: 0.848675\n[98]\tvalid_0's rmse: 0.848656\n[99]\tvalid_0's rmse: 0.848682\n[100]\tvalid_0's rmse: 0.848716\n[101]\tvalid_0's rmse: 0.848729\n[102]\tvalid_0's rmse: 0.848693\n","name":"stdout"},{"output_type":"stream","text":"\rnum_leaves, val_score: 0.847465:  45%|####5     | 9/20 [00:52<00:56,  5.10s/it]","name":"stderr"},{"output_type":"stream","text":"[103]\tvalid_0's rmse: 0.848692\n[104]\tvalid_0's rmse: 0.848753\n[105]\tvalid_0's rmse: 0.84868\n[106]\tvalid_0's rmse: 0.848706\n[107]\tvalid_0's rmse: 0.848698\n[108]\tvalid_0's rmse: 0.848661\nEarly stopping, best iteration is:\n[98]\tvalid_0's rmse: 0.848656\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  50%|#####     | 10/20 [00:52<00:49,  4.94s/it]\u001b[32m[I 2021-02-05 22:52:23,303]\u001b[0m Trial 16 finished with value: 0.8486556696905403 and parameters: {'num_leaves': 155}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  50%|#####     | 10/20 [00:52<00:49,  4.94s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018911 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888239\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885328\n[3]\tvalid_0's rmse: 0.882986\n[4]\tvalid_0's rmse: 0.880769\n[5]\tvalid_0's rmse: 0.878853\n[6]\tvalid_0's rmse: 0.876715\n[7]\tvalid_0's rmse: 0.875234\n[8]\tvalid_0's rmse: 0.873966\n[9]\tvalid_0's rmse: 0.872786\n[10]\tvalid_0's rmse: 0.871672\n[11]\tvalid_0's rmse: 0.870221\n[12]\tvalid_0's rmse: 0.869017\n[13]\tvalid_0's rmse: 0.867943\n[14]\tvalid_0's rmse: 0.866852\n[15]\tvalid_0's rmse: 0.866136\n[16]\tvalid_0's rmse: 0.86537\n[17]\tvalid_0's rmse: 0.864556\n[18]\tvalid_0's rmse: 0.863926\n[19]\tvalid_0's rmse: 0.863225\n[20]\tvalid_0's rmse: 0.862626\n[21]\tvalid_0's rmse: 0.862068\n[22]\tvalid_0's rmse: 0.861431\n[23]\tvalid_0's rmse: 0.860902\n[24]\tvalid_0's rmse: 0.860345\n[25]\tvalid_0's rmse: 0.859982\n[26]\tvalid_0's rmse: 0.859569\n[27]\tvalid_0's rmse: 0.859254\n[28]\tvalid_0's rmse: 0.858881\n[29]\tvalid_0's rmse: 0.858499\n[30]\tvalid_0's rmse: 0.858133\n[31]\tvalid_0's rmse: 0.857808\n[32]\tvalid_0's rmse: 0.85747\n[33]\tvalid_0's rmse: 0.857161\n[34]\tvalid_0's rmse: 0.856813\n[35]\tvalid_0's rmse: 0.85662\n[36]\tvalid_0's rmse: 0.856278\n[37]\tvalid_0's rmse: 0.856005\n[38]\tvalid_0's rmse: 0.855739\n[39]\tvalid_0's rmse: 0.855453\n[40]\tvalid_0's rmse: 0.855253\n[41]\tvalid_0's rmse: 0.855083\n[42]\tvalid_0's rmse: 0.854854\n[43]\tvalid_0's rmse: 0.854663\n[44]\tvalid_0's rmse: 0.854471\n[45]\tvalid_0's rmse: 0.854239\n[46]\tvalid_0's rmse: 0.85408\n[47]\tvalid_0's rmse: 0.853907\n[48]\tvalid_0's rmse: 0.8537\n[49]\tvalid_0's rmse: 0.853544\n[50]\tvalid_0's rmse: 0.853381\n[51]\tvalid_0's rmse: 0.853282\n[52]\tvalid_0's rmse: 0.853161\n[53]\tvalid_0's rmse: 0.852986\n[54]\tvalid_0's rmse: 0.852849\n[55]\tvalid_0's rmse: 0.852755\n[56]\tvalid_0's rmse: 0.852576\n[57]\tvalid_0's rmse: 0.852464\n[58]\tvalid_0's rmse: 0.852306\n[59]\tvalid_0's rmse: 0.852224\n[60]\tvalid_0's rmse: 0.852128\n[61]\tvalid_0's rmse: 0.85203\n[62]\tvalid_0's rmse: 0.851933\n[63]\tvalid_0's rmse: 0.851796\n[64]\tvalid_0's rmse: 0.851663\n[65]\tvalid_0's rmse: 0.851565\n[66]\tvalid_0's rmse: 0.851467\n[67]\tvalid_0's rmse: 0.851405\n[68]\tvalid_0's rmse: 0.851308\n[69]\tvalid_0's rmse: 0.851208\n[70]\tvalid_0's rmse: 0.851052\n[71]\tvalid_0's rmse: 0.850983\n[72]\tvalid_0's rmse: 0.850835\n[73]\tvalid_0's rmse: 0.850789\n[74]\tvalid_0's rmse: 0.850703\n[75]\tvalid_0's rmse: 0.850609\n[76]\tvalid_0's rmse: 0.850516\n[77]\tvalid_0's rmse: 0.85045\n[78]\tvalid_0's rmse: 0.850373\n[79]\tvalid_0's rmse: 0.850318\n[80]\tvalid_0's rmse: 0.850253\n[81]\tvalid_0's rmse: 0.850185\n[82]\tvalid_0's rmse: 0.850099\n[83]\tvalid_0's rmse: 0.850009\n[84]\tvalid_0's rmse: 0.849915\n[85]\tvalid_0's rmse: 0.849865\n[86]\tvalid_0's rmse: 0.849821\n[87]\tvalid_0's rmse: 0.849788\n[88]\tvalid_0's rmse: 0.849686\n[89]\tvalid_0's rmse: 0.849635\n[90]\tvalid_0's rmse: 0.849632\n[91]\tvalid_0's rmse: 0.849563\n[92]\tvalid_0's rmse: 0.8495\n[93]\tvalid_0's rmse: 0.849448\n[94]\tvalid_0's rmse: 0.849414\n[95]\tvalid_0's rmse: 0.849354\n[96]\tvalid_0's rmse: 0.849321\n[97]\tvalid_0's rmse: 0.849287\n[98]\tvalid_0's rmse: 0.849257\n[99]\tvalid_0's rmse: 0.849239\n[100]\tvalid_0's rmse: 0.849195\n[101]\tvalid_0's rmse: 0.849194\n[102]\tvalid_0's rmse: 0.84912\n[103]\tvalid_0's rmse: 0.849107\n[104]\tvalid_0's rmse: 0.849068\n[105]\tvalid_0's rmse: 0.848958\n[106]\tvalid_0's rmse: 0.848932\n[107]\tvalid_0's rmse: 0.848907\n[108]\tvalid_0's rmse: 0.848844\n[109]\tvalid_0's rmse: 0.84879\n[110]\tvalid_0's rmse: 0.84876\n[111]\tvalid_0's rmse: 0.848721\n[112]\tvalid_0's rmse: 0.848713\n[113]\tvalid_0's rmse: 0.848669\n[114]\tvalid_0's rmse: 0.84866\n[115]\tvalid_0's rmse: 0.848652\n[116]\tvalid_0's rmse: 0.848645\n[117]\tvalid_0's rmse: 0.848612\n[118]\tvalid_0's rmse: 0.848573\n[119]\tvalid_0's rmse: 0.848574\n[120]\tvalid_0's rmse: 0.84856\n[121]\tvalid_0's rmse: 0.848514\n[122]\tvalid_0's rmse: 0.848491\n[123]\tvalid_0's rmse: 0.848486\n[124]\tvalid_0's rmse: 0.848456\n[125]\tvalid_0's rmse: 0.848417\n[126]\tvalid_0's rmse: 0.848423\n[127]\tvalid_0's rmse: 0.848428\n[128]\tvalid_0's rmse: 0.848409\n[129]\tvalid_0's rmse: 0.848398\n[130]\tvalid_0's rmse: 0.848403\n[131]\tvalid_0's rmse: 0.848353\n[132]\tvalid_0's rmse: 0.848338\n[133]\tvalid_0's rmse: 0.848333\n[134]\tvalid_0's rmse: 0.848343\n[135]\tvalid_0's rmse: 0.848331\n[136]\tvalid_0's rmse: 0.84831\n[137]\tvalid_0's rmse: 0.848294\n[138]\tvalid_0's rmse: 0.84832\n[139]\tvalid_0's rmse: 0.848299\n[140]\tvalid_0's rmse: 0.848277\n[141]\tvalid_0's rmse: 0.848267\n[142]\tvalid_0's rmse: 0.848255\n[143]\tvalid_0's rmse: 0.848209\n[144]\tvalid_0's rmse: 0.848191\n[145]\tvalid_0's rmse: 0.848198\n[146]\tvalid_0's rmse: 0.848156\n[147]\tvalid_0's rmse: 0.848147\n[148]\tvalid_0's rmse: 0.848124\n[149]\tvalid_0's rmse: 0.848022\n[150]\tvalid_0's rmse: 0.848056\n[151]\tvalid_0's rmse: 0.848025\n[152]\tvalid_0's rmse: 0.848004\n[153]\tvalid_0's rmse: 0.848016\n[154]\tvalid_0's rmse: 0.848036\n[155]\tvalid_0's rmse: 0.848026\n[156]\tvalid_0's rmse: 0.84802\n[157]\tvalid_0's rmse: 0.848016\n[158]\tvalid_0's rmse: 0.848015\n[159]\tvalid_0's rmse: 0.848002\n[160]\tvalid_0's rmse: 0.847991\n[161]\tvalid_0's rmse: 0.847973\n[162]\tvalid_0's rmse: 0.84795\n[163]\tvalid_0's rmse: 0.847951\n[164]\tvalid_0's rmse: 0.847952\n[165]\tvalid_0's rmse: 0.847939\n[166]\tvalid_0's rmse: 0.847927\n[167]\tvalid_0's rmse: 0.847918\n[168]\tvalid_0's rmse: 0.847915\n[169]\tvalid_0's rmse: 0.847909\n[170]\tvalid_0's rmse: 0.847911\n[171]\tvalid_0's rmse: 0.847909\n[172]\tvalid_0's rmse: 0.847905\n[173]\tvalid_0's rmse: 0.847901\n[174]\tvalid_0's rmse: 0.847897\n[175]\tvalid_0's rmse: 0.847914\n[176]\tvalid_0's rmse: 0.847911\n[177]\tvalid_0's rmse: 0.847903\n[178]\tvalid_0's rmse: 0.847861\n[179]\tvalid_0's rmse: 0.847859\n[180]\tvalid_0's rmse: 0.847856\n[181]\tvalid_0's rmse: 0.847823\n[182]\tvalid_0's rmse: 0.847813\n[183]\tvalid_0's rmse: 0.847822\n[184]\tvalid_0's rmse: 0.847833\n[185]\tvalid_0's rmse: 0.84781\n[186]\tvalid_0's rmse: 0.847793\n[187]\tvalid_0's rmse: 0.847798\n[188]\tvalid_0's rmse: 0.847777\n[189]\tvalid_0's rmse: 0.847762\n[190]\tvalid_0's rmse: 0.847767\n[191]\tvalid_0's rmse: 0.847776\n[192]\tvalid_0's rmse: 0.847776\n[193]\tvalid_0's rmse: 0.847775\n[194]\tvalid_0's rmse: 0.847787\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  55%|#####5    | 11/20 [00:57<00:44,  4.90s/it]\u001b[32m[I 2021-02-05 22:52:28,111]\u001b[0m Trial 17 finished with value: 0.8477619597633969 and parameters: {'num_leaves': 45}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  55%|#####5    | 11/20 [00:57<00:44,  4.90s/it]","name":"stderr"},{"output_type":"stream","text":"[195]\tvalid_0's rmse: 0.847803\n[196]\tvalid_0's rmse: 0.847809\n[197]\tvalid_0's rmse: 0.847825\n[198]\tvalid_0's rmse: 0.847836\n[199]\tvalid_0's rmse: 0.847848\nEarly stopping, best iteration is:\n[189]\tvalid_0's rmse: 0.847762\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020061 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888741\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.886353\n[3]\tvalid_0's rmse: 0.884414\n[4]\tvalid_0's rmse: 0.882497\n[5]\tvalid_0's rmse: 0.880831\n[6]\tvalid_0's rmse: 0.879091\n[7]\tvalid_0's rmse: 0.877756\n[8]\tvalid_0's rmse: 0.876659\n[9]\tvalid_0's rmse: 0.875644\n[10]\tvalid_0's rmse: 0.874714\n[11]\tvalid_0's rmse: 0.873447\n[12]\tvalid_0's rmse: 0.872328\n[13]\tvalid_0's rmse: 0.871391\n[14]\tvalid_0's rmse: 0.870418\n[15]\tvalid_0's rmse: 0.869774\n[16]\tvalid_0's rmse: 0.869087\n[17]\tvalid_0's rmse: 0.868363\n[18]\tvalid_0's rmse: 0.867838\n[19]\tvalid_0's rmse: 0.867175\n[20]\tvalid_0's rmse: 0.866618\n[21]\tvalid_0's rmse: 0.866152\n[22]\tvalid_0's rmse: 0.865567\n[23]\tvalid_0's rmse: 0.865126\n[24]\tvalid_0's rmse: 0.864653\n[25]\tvalid_0's rmse: 0.86425\n[26]\tvalid_0's rmse: 0.863845\n[27]\tvalid_0's rmse: 0.863425\n[28]\tvalid_0's rmse: 0.863044\n[29]\tvalid_0's rmse: 0.862737\n[30]\tvalid_0's rmse: 0.862398\n[31]\tvalid_0's rmse: 0.862023\n[32]\tvalid_0's rmse: 0.861675\n[33]\tvalid_0's rmse: 0.861313\n[34]\tvalid_0's rmse: 0.860965\n[35]\tvalid_0's rmse: 0.860744\n[36]\tvalid_0's rmse: 0.860459\n[37]\tvalid_0's rmse: 0.860158\n[38]\tvalid_0's rmse: 0.859854\n[39]\tvalid_0's rmse: 0.859608\n[40]\tvalid_0's rmse: 0.859371\n[41]\tvalid_0's rmse: 0.859185\n[42]\tvalid_0's rmse: 0.858992\n[43]\tvalid_0's rmse: 0.858771\n[44]\tvalid_0's rmse: 0.858536\n[45]\tvalid_0's rmse: 0.858327\n[46]\tvalid_0's rmse: 0.858158\n[47]\tvalid_0's rmse: 0.857978\n[48]\tvalid_0's rmse: 0.857813\n[49]\tvalid_0's rmse: 0.857657\n[50]\tvalid_0's rmse: 0.857488\n[51]\tvalid_0's rmse: 0.857378\n[52]\tvalid_0's rmse: 0.857189\n[53]\tvalid_0's rmse: 0.856996\n[54]\tvalid_0's rmse: 0.856798\n[55]\tvalid_0's rmse: 0.856681\n[56]\tvalid_0's rmse: 0.856454\n[57]\tvalid_0's rmse: 0.856306\n[58]\tvalid_0's rmse: 0.856163\n[59]\tvalid_0's rmse: 0.856019\n[60]\tvalid_0's rmse: 0.855889\n[61]\tvalid_0's rmse: 0.855757\n[62]\tvalid_0's rmse: 0.855592\n[63]\tvalid_0's rmse: 0.85539\n[64]\tvalid_0's rmse: 0.855287\n[65]\tvalid_0's rmse: 0.855189\n[66]\tvalid_0's rmse: 0.855086\n[67]\tvalid_0's rmse: 0.854996\n[68]\tvalid_0's rmse: 0.854904\n[69]\tvalid_0's rmse: 0.854777\n[70]\tvalid_0's rmse: 0.85468\n[71]\tvalid_0's rmse: 0.854604\n[72]\tvalid_0's rmse: 0.854508\n[73]\tvalid_0's rmse: 0.854449\n[74]\tvalid_0's rmse: 0.854342\n[75]\tvalid_0's rmse: 0.854242\n[76]\tvalid_0's rmse: 0.854103\n[77]\tvalid_0's rmse: 0.853968\n[78]\tvalid_0's rmse: 0.853859\n[79]\tvalid_0's rmse: 0.853748\n[80]\tvalid_0's rmse: 0.85366\n[81]\tvalid_0's rmse: 0.853575\n[82]\tvalid_0's rmse: 0.853488\n[83]\tvalid_0's rmse: 0.853373\n[84]\tvalid_0's rmse: 0.853264\n[85]\tvalid_0's rmse: 0.853195\n[86]\tvalid_0's rmse: 0.85311\n[87]\tvalid_0's rmse: 0.853025\n[88]\tvalid_0's rmse: 0.852895\n[89]\tvalid_0's rmse: 0.852826\n[90]\tvalid_0's rmse: 0.85275\n[91]\tvalid_0's rmse: 0.852664\n[92]\tvalid_0's rmse: 0.852593\n[93]\tvalid_0's rmse: 0.852525\n[94]\tvalid_0's rmse: 0.85248\n[95]\tvalid_0's rmse: 0.852308\n[96]\tvalid_0's rmse: 0.852245\n[97]\tvalid_0's rmse: 0.852169\n[98]\tvalid_0's rmse: 0.852089\n[99]\tvalid_0's rmse: 0.852035\n[100]\tvalid_0's rmse: 0.851985\n[101]\tvalid_0's rmse: 0.851902\n[102]\tvalid_0's rmse: 0.851817\n[103]\tvalid_0's rmse: 0.851736\n[104]\tvalid_0's rmse: 0.851671\n[105]\tvalid_0's rmse: 0.851597\n[106]\tvalid_0's rmse: 0.85157\n[107]\tvalid_0's rmse: 0.851486\n[108]\tvalid_0's rmse: 0.851417\n[109]\tvalid_0's rmse: 0.851389\n[110]\tvalid_0's rmse: 0.851352\n[111]\tvalid_0's rmse: 0.851217\n[112]\tvalid_0's rmse: 0.851154\n[113]\tvalid_0's rmse: 0.85111\n[114]\tvalid_0's rmse: 0.85108\n[115]\tvalid_0's rmse: 0.851043\n[116]\tvalid_0's rmse: 0.850993\n[117]\tvalid_0's rmse: 0.850897\n[118]\tvalid_0's rmse: 0.850863\n[119]\tvalid_0's rmse: 0.850821\n[120]\tvalid_0's rmse: 0.85078\n[121]\tvalid_0's rmse: 0.850736\n[122]\tvalid_0's rmse: 0.850704\n[123]\tvalid_0's rmse: 0.85066\n[124]\tvalid_0's rmse: 0.850633\n[125]\tvalid_0's rmse: 0.850568\n[126]\tvalid_0's rmse: 0.850539\n[127]\tvalid_0's rmse: 0.850506\n[128]\tvalid_0's rmse: 0.850479\n[129]\tvalid_0's rmse: 0.850448\n[130]\tvalid_0's rmse: 0.850405\n[131]\tvalid_0's rmse: 0.850356\n[132]\tvalid_0's rmse: 0.850348\n[133]\tvalid_0's rmse: 0.850328\n[134]\tvalid_0's rmse: 0.850294\n[135]\tvalid_0's rmse: 0.850236\n[136]\tvalid_0's rmse: 0.850192\n[137]\tvalid_0's rmse: 0.850158\n[138]\tvalid_0's rmse: 0.850124\n[139]\tvalid_0's rmse: 0.850084\n[140]\tvalid_0's rmse: 0.850065\n[141]\tvalid_0's rmse: 0.850028\n[142]\tvalid_0's rmse: 0.850005\n[143]\tvalid_0's rmse: 0.849969\n[144]\tvalid_0's rmse: 0.84995\n[145]\tvalid_0's rmse: 0.849928\n[146]\tvalid_0's rmse: 0.849909\n[147]\tvalid_0's rmse: 0.849886\n[148]\tvalid_0's rmse: 0.849848\n[149]\tvalid_0's rmse: 0.849817\n[150]\tvalid_0's rmse: 0.849807\n[151]\tvalid_0's rmse: 0.849729\n[152]\tvalid_0's rmse: 0.849718\n[153]\tvalid_0's rmse: 0.84971\n[154]\tvalid_0's rmse: 0.849683\n[155]\tvalid_0's rmse: 0.849686\n[156]\tvalid_0's rmse: 0.849661\n[157]\tvalid_0's rmse: 0.849631\n[158]\tvalid_0's rmse: 0.849609\n[159]\tvalid_0's rmse: 0.849609\n[160]\tvalid_0's rmse: 0.849559\n[161]\tvalid_0's rmse: 0.849531\n[162]\tvalid_0's rmse: 0.849507\n[163]\tvalid_0's rmse: 0.849494\n[164]\tvalid_0's rmse: 0.8495\n[165]\tvalid_0's rmse: 0.849501\n[166]\tvalid_0's rmse: 0.849498\n[167]\tvalid_0's rmse: 0.849496\n[168]\tvalid_0's rmse: 0.849462\n[169]\tvalid_0's rmse: 0.849451\n[170]\tvalid_0's rmse: 0.84944\n[171]\tvalid_0's rmse: 0.849431\n[172]\tvalid_0's rmse: 0.849419\n[173]\tvalid_0's rmse: 0.849379\n[174]\tvalid_0's rmse: 0.849375\n[175]\tvalid_0's rmse: 0.849365\n[176]\tvalid_0's rmse: 0.849335\n[177]\tvalid_0's rmse: 0.849329\n[178]\tvalid_0's rmse: 0.849282\n[179]\tvalid_0's rmse: 0.84927\n[180]\tvalid_0's rmse: 0.849271\n[181]\tvalid_0's rmse: 0.849249\n[182]\tvalid_0's rmse: 0.849223\n[183]\tvalid_0's rmse: 0.849201\n[184]\tvalid_0's rmse: 0.849198\n[185]\tvalid_0's rmse: 0.849144\n[186]\tvalid_0's rmse: 0.849131\n[187]\tvalid_0's rmse: 0.849147\n[188]\tvalid_0's rmse: 0.849136\n[189]\tvalid_0's rmse: 0.84913\n[190]\tvalid_0's rmse: 0.849112\n[191]\tvalid_0's rmse: 0.849111\n[192]\tvalid_0's rmse: 0.849112\n[193]\tvalid_0's rmse: 0.84911\n[194]\tvalid_0's rmse: 0.849086\n[195]\tvalid_0's rmse: 0.849081\n[196]\tvalid_0's rmse: 0.849077\n[197]\tvalid_0's rmse: 0.849074\n[198]\tvalid_0's rmse: 0.849073\n[199]\tvalid_0's rmse: 0.849076\n[200]\tvalid_0's rmse: 0.849049\n[201]\tvalid_0's rmse: 0.84905\n[202]\tvalid_0's rmse: 0.849018\n[203]\tvalid_0's rmse: 0.849027\n[204]\tvalid_0's rmse: 0.849017\n[205]\tvalid_0's rmse: 0.848985\n[206]\tvalid_0's rmse: 0.848965\n[207]\tvalid_0's rmse: 0.848959\n[208]\tvalid_0's rmse: 0.848913\n[209]\tvalid_0's rmse: 0.848901\n[210]\tvalid_0's rmse: 0.848874\n[211]\tvalid_0's rmse: 0.848869\n[212]\tvalid_0's rmse: 0.848863\n[213]\tvalid_0's rmse: 0.848852\n[214]\tvalid_0's rmse: 0.848854\n[215]\tvalid_0's rmse: 0.848852\n[216]\tvalid_0's rmse: 0.848846\n[217]\tvalid_0's rmse: 0.848847\n[218]\tvalid_0's rmse: 0.848845\n[219]\tvalid_0's rmse: 0.848838\n[220]\tvalid_0's rmse: 0.848823\n[221]\tvalid_0's rmse: 0.8488\n[222]\tvalid_0's rmse: 0.848798\n[223]\tvalid_0's rmse: 0.8488\n[224]\tvalid_0's rmse: 0.848794\n[225]\tvalid_0's rmse: 0.848789\n[226]\tvalid_0's rmse: 0.848743\n[227]\tvalid_0's rmse: 0.848723\n[228]\tvalid_0's rmse: 0.848723\n[229]\tvalid_0's rmse: 0.848728\n[230]\tvalid_0's rmse: 0.848711\n[231]\tvalid_0's rmse: 0.848702\n[232]\tvalid_0's rmse: 0.848695\n[233]\tvalid_0's rmse: 0.848693\n[234]\tvalid_0's rmse: 0.848685\n[235]\tvalid_0's rmse: 0.848679\n[236]\tvalid_0's rmse: 0.848679\n[237]\tvalid_0's rmse: 0.848655\n[238]\tvalid_0's rmse: 0.848637\n[239]\tvalid_0's rmse: 0.848633\n[240]\tvalid_0's rmse: 0.848636\n[241]\tvalid_0's rmse: 0.848606\n[242]\tvalid_0's rmse: 0.848613\n[243]\tvalid_0's rmse: 0.848611\n[244]\tvalid_0's rmse: 0.848601\n[245]\tvalid_0's rmse: 0.848579\n[246]\tvalid_0's rmse: 0.848565\n[247]\tvalid_0's rmse: 0.848557\n[248]\tvalid_0's rmse: 0.848551\n[249]\tvalid_0's rmse: 0.84855\n[250]\tvalid_0's rmse: 0.848549\n[251]\tvalid_0's rmse: 0.84857\n","name":"stdout"},{"output_type":"stream","text":"[252]\tvalid_0's rmse: 0.848566\n[253]\tvalid_0's rmse: 0.848555\n[254]\tvalid_0's rmse: 0.848547\n[255]\tvalid_0's rmse: 0.848541\n[256]\tvalid_0's rmse: 0.848543\n[257]\tvalid_0's rmse: 0.848515\n[258]\tvalid_0's rmse: 0.848509\n[259]\tvalid_0's rmse: 0.848498\n[260]\tvalid_0's rmse: 0.848497\n[261]\tvalid_0's rmse: 0.848497\n[262]\tvalid_0's rmse: 0.848495\n[263]\tvalid_0's rmse: 0.848484\n[264]\tvalid_0's rmse: 0.848477\n[265]\tvalid_0's rmse: 0.848475\n[266]\tvalid_0's rmse: 0.848472\n[267]\tvalid_0's rmse: 0.848475\n[268]\tvalid_0's rmse: 0.848464\n[269]\tvalid_0's rmse: 0.848463\n[270]\tvalid_0's rmse: 0.848456\n[271]\tvalid_0's rmse: 0.848447\n[272]\tvalid_0's rmse: 0.848441\n[273]\tvalid_0's rmse: 0.848438\n[274]\tvalid_0's rmse: 0.848431\n[275]\tvalid_0's rmse: 0.848406\n[276]\tvalid_0's rmse: 0.848384\n[277]\tvalid_0's rmse: 0.848381\n[278]\tvalid_0's rmse: 0.84836\n[279]\tvalid_0's rmse: 0.848346\n[280]\tvalid_0's rmse: 0.848315\n[281]\tvalid_0's rmse: 0.848289\n[282]\tvalid_0's rmse: 0.848292\n[283]\tvalid_0's rmse: 0.848275\n[284]\tvalid_0's rmse: 0.848255\n[285]\tvalid_0's rmse: 0.848242\n[286]\tvalid_0's rmse: 0.84824\n[287]\tvalid_0's rmse: 0.848223\n[288]\tvalid_0's rmse: 0.848217\n[289]\tvalid_0's rmse: 0.848213\n[290]\tvalid_0's rmse: 0.848215\n[291]\tvalid_0's rmse: 0.848215\n[292]\tvalid_0's rmse: 0.848215\n[293]\tvalid_0's rmse: 0.848218\n[294]\tvalid_0's rmse: 0.848223\n[295]\tvalid_0's rmse: 0.848216\n[296]\tvalid_0's rmse: 0.848217\n[297]\tvalid_0's rmse: 0.848212\n[298]\tvalid_0's rmse: 0.848217\n[299]\tvalid_0's rmse: 0.848213\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  60%|######    | 12/20 [01:03<00:43,  5.43s/it]\u001b[32m[I 2021-02-05 22:52:34,767]\u001b[0m Trial 18 finished with value: 0.8481943030818763 and parameters: {'num_leaves': 15}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  60%|######    | 12/20 [01:03<00:43,  5.43s/it]","name":"stderr"},{"output_type":"stream","text":"[300]\tvalid_0's rmse: 0.84822\n[301]\tvalid_0's rmse: 0.848216\n[302]\tvalid_0's rmse: 0.848219\n[303]\tvalid_0's rmse: 0.848196\n[304]\tvalid_0's rmse: 0.848194\n[305]\tvalid_0's rmse: 0.848207\n[306]\tvalid_0's rmse: 0.848213\n[307]\tvalid_0's rmse: 0.848215\n[308]\tvalid_0's rmse: 0.848225\n[309]\tvalid_0's rmse: 0.84824\n[310]\tvalid_0's rmse: 0.84825\n[311]\tvalid_0's rmse: 0.848226\n[312]\tvalid_0's rmse: 0.848224\n[313]\tvalid_0's rmse: 0.848212\n[314]\tvalid_0's rmse: 0.848212\nEarly stopping, best iteration is:\n[304]\tvalid_0's rmse: 0.848194\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019111 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88769\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884181\n[3]\tvalid_0's rmse: 0.881523\n[4]\tvalid_0's rmse: 0.878968\n[5]\tvalid_0's rmse: 0.876779\n[6]\tvalid_0's rmse: 0.874302\n[7]\tvalid_0's rmse: 0.872641\n[8]\tvalid_0's rmse: 0.87116\n[9]\tvalid_0's rmse: 0.869761\n[10]\tvalid_0's rmse: 0.86855\n[11]\tvalid_0's rmse: 0.866908\n[12]\tvalid_0's rmse: 0.865576\n[13]\tvalid_0's rmse: 0.864391\n[14]\tvalid_0's rmse: 0.863181\n[15]\tvalid_0's rmse: 0.862366\n[16]\tvalid_0's rmse: 0.861646\n[17]\tvalid_0's rmse: 0.860743\n[18]\tvalid_0's rmse: 0.86005\n[19]\tvalid_0's rmse: 0.859381\n[20]\tvalid_0's rmse: 0.858822\n[21]\tvalid_0's rmse: 0.858219\n[22]\tvalid_0's rmse: 0.857579\n[23]\tvalid_0's rmse: 0.857068\n[24]\tvalid_0's rmse: 0.856579\n[25]\tvalid_0's rmse: 0.856245\n[26]\tvalid_0's rmse: 0.855841\n[27]\tvalid_0's rmse: 0.855571\n[28]\tvalid_0's rmse: 0.855217\n[29]\tvalid_0's rmse: 0.854918\n[30]\tvalid_0's rmse: 0.854662\n[31]\tvalid_0's rmse: 0.854356\n[32]\tvalid_0's rmse: 0.854019\n[33]\tvalid_0's rmse: 0.853776\n[34]\tvalid_0's rmse: 0.853469\n[35]\tvalid_0's rmse: 0.853293\n[36]\tvalid_0's rmse: 0.853078\n[37]\tvalid_0's rmse: 0.852849\n[38]\tvalid_0's rmse: 0.852592\n[39]\tvalid_0's rmse: 0.852379\n[40]\tvalid_0's rmse: 0.852206\n[41]\tvalid_0's rmse: 0.85213\n[42]\tvalid_0's rmse: 0.851968\n[43]\tvalid_0's rmse: 0.85181\n[44]\tvalid_0's rmse: 0.851656\n[45]\tvalid_0's rmse: 0.851453\n[46]\tvalid_0's rmse: 0.851416\n[47]\tvalid_0's rmse: 0.851259\n[48]\tvalid_0's rmse: 0.851164\n[49]\tvalid_0's rmse: 0.851077\n[50]\tvalid_0's rmse: 0.850991\n[51]\tvalid_0's rmse: 0.850945\n[52]\tvalid_0's rmse: 0.850805\n[53]\tvalid_0's rmse: 0.850695\n[54]\tvalid_0's rmse: 0.850595\n[55]\tvalid_0's rmse: 0.850588\n[56]\tvalid_0's rmse: 0.850515\n[57]\tvalid_0's rmse: 0.850416\n[58]\tvalid_0's rmse: 0.850359\n[59]\tvalid_0's rmse: 0.850284\n[60]\tvalid_0's rmse: 0.850204\n[61]\tvalid_0's rmse: 0.850164\n[62]\tvalid_0's rmse: 0.850215\n[63]\tvalid_0's rmse: 0.85017\n[64]\tvalid_0's rmse: 0.850077\n[65]\tvalid_0's rmse: 0.849978\n[66]\tvalid_0's rmse: 0.849939\n[67]\tvalid_0's rmse: 0.849926\n[68]\tvalid_0's rmse: 0.849819\n[69]\tvalid_0's rmse: 0.84977\n[70]\tvalid_0's rmse: 0.849708\n[71]\tvalid_0's rmse: 0.849719\n[72]\tvalid_0's rmse: 0.849673\n[73]\tvalid_0's rmse: 0.849662\n[74]\tvalid_0's rmse: 0.849639\n[75]\tvalid_0's rmse: 0.84964\n[76]\tvalid_0's rmse: 0.849543\n[77]\tvalid_0's rmse: 0.849483\n[78]\tvalid_0's rmse: 0.849442\n[79]\tvalid_0's rmse: 0.849399\n[80]\tvalid_0's rmse: 0.849384\n[81]\tvalid_0's rmse: 0.849344\n[82]\tvalid_0's rmse: 0.849318\n[83]\tvalid_0's rmse: 0.849299\n[84]\tvalid_0's rmse: 0.849294\n[85]\tvalid_0's rmse: 0.849306\n[86]\tvalid_0's rmse: 0.849275\n[87]\tvalid_0's rmse: 0.849352\n[88]\tvalid_0's rmse: 0.849212\n[89]\tvalid_0's rmse: 0.849177\n[90]\tvalid_0's rmse: 0.849201\n[91]\tvalid_0's rmse: 0.849223\n[92]\tvalid_0's rmse: 0.849224\n[93]\tvalid_0's rmse: 0.849167\n[94]\tvalid_0's rmse: 0.849135\n[95]\tvalid_0's rmse: 0.84913\n[96]\tvalid_0's rmse: 0.849185\n[97]\tvalid_0's rmse: 0.849178\n[98]\tvalid_0's rmse: 0.849153\n[99]\tvalid_0's rmse: 0.849128\n[100]\tvalid_0's rmse: 0.849137\n[101]\tvalid_0's rmse: 0.849148\n[102]\tvalid_0's rmse: 0.849097\n[103]\tvalid_0's rmse: 0.849076\n[104]\tvalid_0's rmse: 0.849127\n[105]\tvalid_0's rmse: 0.84911\n[106]\tvalid_0's rmse: 0.849096\n[107]\tvalid_0's rmse: 0.849056\n[108]\tvalid_0's rmse: 0.849088\n[109]\tvalid_0's rmse: 0.849068\n[110]\tvalid_0's rmse: 0.849085\n[111]\tvalid_0's rmse: 0.849094\n[112]\tvalid_0's rmse: 0.849135\n[113]\tvalid_0's rmse: 0.849165\n[114]\tvalid_0's rmse: 0.849141\n[115]\tvalid_0's rmse: 0.849162\n[116]\tvalid_0's rmse: 0.849157\n[117]\tvalid_0's rmse: 0.849129\nEarly stopping, best iteration is:\n[107]\tvalid_0's rmse: 0.849056\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  65%|######5   | 13/20 [01:08<00:37,  5.35s/it]\u001b[32m[I 2021-02-05 22:52:39,914]\u001b[0m Trial 19 finished with value: 0.8490561511256932 and parameters: {'num_leaves': 249}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  65%|######5   | 13/20 [01:08<00:37,  5.35s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019123 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888471\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885803\n[3]\tvalid_0's rmse: 0.883651\n[4]\tvalid_0's rmse: 0.88153\n[5]\tvalid_0's rmse: 0.879733\n[6]\tvalid_0's rmse: 0.877734\n[7]\tvalid_0's rmse: 0.876282\n[8]\tvalid_0's rmse: 0.875083\n[9]\tvalid_0's rmse: 0.873979\n[10]\tvalid_0's rmse: 0.872957\n[11]\tvalid_0's rmse: 0.871605\n[12]\tvalid_0's rmse: 0.870413\n[13]\tvalid_0's rmse: 0.869397\n[14]\tvalid_0's rmse: 0.868403\n[15]\tvalid_0's rmse: 0.867732\n[16]\tvalid_0's rmse: 0.866973\n[17]\tvalid_0's rmse: 0.86617\n[18]\tvalid_0's rmse: 0.865542\n[19]\tvalid_0's rmse: 0.864848\n[20]\tvalid_0's rmse: 0.864318\n[21]\tvalid_0's rmse: 0.863804\n[22]\tvalid_0's rmse: 0.863165\n[23]\tvalid_0's rmse: 0.862643\n[24]\tvalid_0's rmse: 0.862124\n[25]\tvalid_0's rmse: 0.861715\n[26]\tvalid_0's rmse: 0.861346\n[27]\tvalid_0's rmse: 0.860966\n[28]\tvalid_0's rmse: 0.86058\n[29]\tvalid_0's rmse: 0.860224\n[30]\tvalid_0's rmse: 0.859876\n[31]\tvalid_0's rmse: 0.859491\n[32]\tvalid_0's rmse: 0.859114\n[33]\tvalid_0's rmse: 0.858781\n[34]\tvalid_0's rmse: 0.858458\n[35]\tvalid_0's rmse: 0.858197\n[36]\tvalid_0's rmse: 0.857878\n[37]\tvalid_0's rmse: 0.857595\n[38]\tvalid_0's rmse: 0.857305\n[39]\tvalid_0's rmse: 0.857023\n[40]\tvalid_0's rmse: 0.856755\n[41]\tvalid_0's rmse: 0.856581\n[42]\tvalid_0's rmse: 0.856382\n[43]\tvalid_0's rmse: 0.856206\n[44]\tvalid_0's rmse: 0.855861\n[45]\tvalid_0's rmse: 0.855676\n[46]\tvalid_0's rmse: 0.855504\n[47]\tvalid_0's rmse: 0.85537\n[48]\tvalid_0's rmse: 0.855217\n[49]\tvalid_0's rmse: 0.85507\n[50]\tvalid_0's rmse: 0.854927\n[51]\tvalid_0's rmse: 0.854814\n[52]\tvalid_0's rmse: 0.854634\n[53]\tvalid_0's rmse: 0.854474\n[54]\tvalid_0's rmse: 0.854267\n[55]\tvalid_0's rmse: 0.854157\n[56]\tvalid_0's rmse: 0.853879\n[57]\tvalid_0's rmse: 0.853729\n[58]\tvalid_0's rmse: 0.853564\n[59]\tvalid_0's rmse: 0.853475\n[60]\tvalid_0's rmse: 0.85339\n[61]\tvalid_0's rmse: 0.85328\n[62]\tvalid_0's rmse: 0.853188\n[63]\tvalid_0's rmse: 0.85296\n[64]\tvalid_0's rmse: 0.852766\n[65]\tvalid_0's rmse: 0.852653\n[66]\tvalid_0's rmse: 0.852558\n[67]\tvalid_0's rmse: 0.852481\n[68]\tvalid_0's rmse: 0.852374\n[69]\tvalid_0's rmse: 0.852247\n[70]\tvalid_0's rmse: 0.852148\n[71]\tvalid_0's rmse: 0.852069\n[72]\tvalid_0's rmse: 0.851988\n[73]\tvalid_0's rmse: 0.851905\n[74]\tvalid_0's rmse: 0.85184\n[75]\tvalid_0's rmse: 0.851756\n[76]\tvalid_0's rmse: 0.851626\n[77]\tvalid_0's rmse: 0.851489\n[78]\tvalid_0's rmse: 0.851387\n[79]\tvalid_0's rmse: 0.851309\n[80]\tvalid_0's rmse: 0.851273\n[81]\tvalid_0's rmse: 0.851191\n[82]\tvalid_0's rmse: 0.851122\n[83]\tvalid_0's rmse: 0.851085\n[84]\tvalid_0's rmse: 0.851003\n[85]\tvalid_0's rmse: 0.850944\n[86]\tvalid_0's rmse: 0.850861\n[87]\tvalid_0's rmse: 0.850746\n[88]\tvalid_0's rmse: 0.850655\n[89]\tvalid_0's rmse: 0.850624\n[90]\tvalid_0's rmse: 0.850551\n[91]\tvalid_0's rmse: 0.850515\n[92]\tvalid_0's rmse: 0.850437\n[93]\tvalid_0's rmse: 0.8504\n[94]\tvalid_0's rmse: 0.850344\n[95]\tvalid_0's rmse: 0.850214\n[96]\tvalid_0's rmse: 0.850174\n[97]\tvalid_0's rmse: 0.850128\n[98]\tvalid_0's rmse: 0.850072\n[99]\tvalid_0's rmse: 0.850051\n[100]\tvalid_0's rmse: 0.850026\n[101]\tvalid_0's rmse: 0.849948\n[102]\tvalid_0's rmse: 0.849891\n[103]\tvalid_0's rmse: 0.849825\n[104]\tvalid_0's rmse: 0.849769\n[105]\tvalid_0's rmse: 0.84974\n[106]\tvalid_0's rmse: 0.849719\n[107]\tvalid_0's rmse: 0.849681\n[108]\tvalid_0's rmse: 0.849619\n[109]\tvalid_0's rmse: 0.849566\n[110]\tvalid_0's rmse: 0.849541\n[111]\tvalid_0's rmse: 0.849505\n[112]\tvalid_0's rmse: 0.849461\n[113]\tvalid_0's rmse: 0.849429\n[114]\tvalid_0's rmse: 0.849337\n[115]\tvalid_0's rmse: 0.849293\n[116]\tvalid_0's rmse: 0.849278\n[117]\tvalid_0's rmse: 0.849229\n[118]\tvalid_0's rmse: 0.84916\n[119]\tvalid_0's rmse: 0.849122\n[120]\tvalid_0's rmse: 0.849096\n[121]\tvalid_0's rmse: 0.849046\n[122]\tvalid_0's rmse: 0.84901\n[123]\tvalid_0's rmse: 0.848986\n[124]\tvalid_0's rmse: 0.848976\n[125]\tvalid_0's rmse: 0.848949\n[126]\tvalid_0's rmse: 0.84895\n[127]\tvalid_0's rmse: 0.848949\n[128]\tvalid_0's rmse: 0.848918\n[129]\tvalid_0's rmse: 0.848877\n[130]\tvalid_0's rmse: 0.848882\n[131]\tvalid_0's rmse: 0.84883\n[132]\tvalid_0's rmse: 0.848825\n[133]\tvalid_0's rmse: 0.848812\n[134]\tvalid_0's rmse: 0.848794\n[135]\tvalid_0's rmse: 0.848809\n[136]\tvalid_0's rmse: 0.848805\n[137]\tvalid_0's rmse: 0.848784\n[138]\tvalid_0's rmse: 0.84878\n[139]\tvalid_0's rmse: 0.84871\n[140]\tvalid_0's rmse: 0.848695\n[141]\tvalid_0's rmse: 0.848658\n[142]\tvalid_0's rmse: 0.848664\n[143]\tvalid_0's rmse: 0.848651\n[144]\tvalid_0's rmse: 0.848636\n[145]\tvalid_0's rmse: 0.848603\n[146]\tvalid_0's rmse: 0.848546\n[147]\tvalid_0's rmse: 0.848519\n[148]\tvalid_0's rmse: 0.848506\n[149]\tvalid_0's rmse: 0.848523\n[150]\tvalid_0's rmse: 0.848494\n[151]\tvalid_0's rmse: 0.848511\n[152]\tvalid_0's rmse: 0.848514\n[153]\tvalid_0's rmse: 0.848506\n[154]\tvalid_0's rmse: 0.84849\n[155]\tvalid_0's rmse: 0.848484\n[156]\tvalid_0's rmse: 0.848488\n[157]\tvalid_0's rmse: 0.848458\n[158]\tvalid_0's rmse: 0.84846\n[159]\tvalid_0's rmse: 0.848405\n[160]\tvalid_0's rmse: 0.848346\n[161]\tvalid_0's rmse: 0.848332\n[162]\tvalid_0's rmse: 0.848329\n[163]\tvalid_0's rmse: 0.848315\n[164]\tvalid_0's rmse: 0.848325\n[165]\tvalid_0's rmse: 0.848325\n[166]\tvalid_0's rmse: 0.848296\n[167]\tvalid_0's rmse: 0.848298\n[168]\tvalid_0's rmse: 0.848287\n[169]\tvalid_0's rmse: 0.848302\n[170]\tvalid_0's rmse: 0.84829\n[171]\tvalid_0's rmse: 0.848294\n[172]\tvalid_0's rmse: 0.848283\n[173]\tvalid_0's rmse: 0.848266\n[174]\tvalid_0's rmse: 0.84825\n[175]\tvalid_0's rmse: 0.848234\n[176]\tvalid_0's rmse: 0.848217\n[177]\tvalid_0's rmse: 0.848206\n[178]\tvalid_0's rmse: 0.84822\n[179]\tvalid_0's rmse: 0.848219\n[180]\tvalid_0's rmse: 0.8482\n[181]\tvalid_0's rmse: 0.84819\n[182]\tvalid_0's rmse: 0.848186\n[183]\tvalid_0's rmse: 0.848173\n[184]\tvalid_0's rmse: 0.84819\n[185]\tvalid_0's rmse: 0.848211\n[186]\tvalid_0's rmse: 0.8482\n[187]\tvalid_0's rmse: 0.848207\n[188]\tvalid_0's rmse: 0.848205\n[189]\tvalid_0's rmse: 0.848211\n[190]\tvalid_0's rmse: 0.848213\n[191]\tvalid_0's rmse: 0.848193\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  70%|#######   | 14/20 [01:13<00:30,  5.09s/it]\u001b[32m[I 2021-02-05 22:52:44,428]\u001b[0m Trial 20 finished with value: 0.8481727837260863 and parameters: {'num_leaves': 27}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  70%|#######   | 14/20 [01:13<00:30,  5.09s/it]","name":"stderr"},{"output_type":"stream","text":"[192]\tvalid_0's rmse: 0.84819\n[193]\tvalid_0's rmse: 0.848186\nEarly stopping, best iteration is:\n[183]\tvalid_0's rmse: 0.848173\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019662 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887937\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884693\n[3]\tvalid_0's rmse: 0.88215\n[4]\tvalid_0's rmse: 0.879699\n[5]\tvalid_0's rmse: 0.877596\n[6]\tvalid_0's rmse: 0.875246\n[7]\tvalid_0's rmse: 0.873574\n[8]\tvalid_0's rmse: 0.872203\n[9]\tvalid_0's rmse: 0.870895\n[10]\tvalid_0's rmse: 0.86973\n[11]\tvalid_0's rmse: 0.868178\n[12]\tvalid_0's rmse: 0.866872\n[13]\tvalid_0's rmse: 0.865803\n[14]\tvalid_0's rmse: 0.864639\n[15]\tvalid_0's rmse: 0.863889\n[16]\tvalid_0's rmse: 0.863137\n[17]\tvalid_0's rmse: 0.862284\n[18]\tvalid_0's rmse: 0.861658\n[19]\tvalid_0's rmse: 0.860993\n[20]\tvalid_0's rmse: 0.860411\n[21]\tvalid_0's rmse: 0.85982\n[22]\tvalid_0's rmse: 0.859221\n[23]\tvalid_0's rmse: 0.858642\n[24]\tvalid_0's rmse: 0.858071\n[25]\tvalid_0's rmse: 0.857684\n[26]\tvalid_0's rmse: 0.857243\n[27]\tvalid_0's rmse: 0.856863\n[28]\tvalid_0's rmse: 0.856481\n[29]\tvalid_0's rmse: 0.856084\n[30]\tvalid_0's rmse: 0.855761\n[31]\tvalid_0's rmse: 0.855472\n[32]\tvalid_0's rmse: 0.855078\n[33]\tvalid_0's rmse: 0.854805\n[34]\tvalid_0's rmse: 0.854463\n[35]\tvalid_0's rmse: 0.854234\n[36]\tvalid_0's rmse: 0.853939\n[37]\tvalid_0's rmse: 0.853732\n[38]\tvalid_0's rmse: 0.853474\n[39]\tvalid_0's rmse: 0.853209\n[40]\tvalid_0's rmse: 0.853018\n[41]\tvalid_0's rmse: 0.852913\n[42]\tvalid_0's rmse: 0.852754\n[43]\tvalid_0's rmse: 0.852612\n[44]\tvalid_0's rmse: 0.852436\n[45]\tvalid_0's rmse: 0.852263\n[46]\tvalid_0's rmse: 0.852181\n[47]\tvalid_0's rmse: 0.852032\n[48]\tvalid_0's rmse: 0.851919\n[49]\tvalid_0's rmse: 0.85178\n[50]\tvalid_0's rmse: 0.85166\n[51]\tvalid_0's rmse: 0.851622\n[52]\tvalid_0's rmse: 0.851474\n[53]\tvalid_0's rmse: 0.851322\n[54]\tvalid_0's rmse: 0.851169\n[55]\tvalid_0's rmse: 0.851095\n[56]\tvalid_0's rmse: 0.850967\n[57]\tvalid_0's rmse: 0.850856\n[58]\tvalid_0's rmse: 0.850744\n[59]\tvalid_0's rmse: 0.850652\n[60]\tvalid_0's rmse: 0.850573\n[61]\tvalid_0's rmse: 0.850507\n[62]\tvalid_0's rmse: 0.850414\n[63]\tvalid_0's rmse: 0.850301\n[64]\tvalid_0's rmse: 0.850188\n[65]\tvalid_0's rmse: 0.850109\n[66]\tvalid_0's rmse: 0.850044\n[67]\tvalid_0's rmse: 0.849985\n[68]\tvalid_0's rmse: 0.849888\n[69]\tvalid_0's rmse: 0.849801\n[70]\tvalid_0's rmse: 0.84972\n[71]\tvalid_0's rmse: 0.849671\n[72]\tvalid_0's rmse: 0.849625\n[73]\tvalid_0's rmse: 0.849571\n[74]\tvalid_0's rmse: 0.849543\n[75]\tvalid_0's rmse: 0.849465\n[76]\tvalid_0's rmse: 0.849423\n[77]\tvalid_0's rmse: 0.84934\n[78]\tvalid_0's rmse: 0.849269\n[79]\tvalid_0's rmse: 0.849233\n[80]\tvalid_0's rmse: 0.849169\n[81]\tvalid_0's rmse: 0.849109\n[82]\tvalid_0's rmse: 0.849059\n[83]\tvalid_0's rmse: 0.849012\n[84]\tvalid_0's rmse: 0.848998\n[85]\tvalid_0's rmse: 0.848965\n[86]\tvalid_0's rmse: 0.848958\n[87]\tvalid_0's rmse: 0.848898\n[88]\tvalid_0's rmse: 0.848856\n[89]\tvalid_0's rmse: 0.848841\n[90]\tvalid_0's rmse: 0.848818\n[91]\tvalid_0's rmse: 0.848816\n[92]\tvalid_0's rmse: 0.848811\n[93]\tvalid_0's rmse: 0.848804\n[94]\tvalid_0's rmse: 0.848806\n[95]\tvalid_0's rmse: 0.848727\n[96]\tvalid_0's rmse: 0.848765\n[97]\tvalid_0's rmse: 0.848785\n[98]\tvalid_0's rmse: 0.848764\n[99]\tvalid_0's rmse: 0.84875\n[100]\tvalid_0's rmse: 0.848748\n[101]\tvalid_0's rmse: 0.848746\n[102]\tvalid_0's rmse: 0.848703\n[103]\tvalid_0's rmse: 0.848729\n[104]\tvalid_0's rmse: 0.848744\n[105]\tvalid_0's rmse: 0.848758\n[106]\tvalid_0's rmse: 0.848705\n[107]\tvalid_0's rmse: 0.848674\n[108]\tvalid_0's rmse: 0.848658\n[109]\tvalid_0's rmse: 0.848654\n[110]\tvalid_0's rmse: 0.848678\n[111]\tvalid_0's rmse: 0.848653\n[112]\tvalid_0's rmse: 0.848668\n[113]\tvalid_0's rmse: 0.848642\n[114]\tvalid_0's rmse: 0.848631\n[115]\tvalid_0's rmse: 0.848591\n[116]\tvalid_0's rmse: 0.848603\n[117]\tvalid_0's rmse: 0.848603\n[118]\tvalid_0's rmse: 0.848596\n[119]\tvalid_0's rmse: 0.848601\n[120]\tvalid_0's rmse: 0.848567\n[121]\tvalid_0's rmse: 0.848526\n[122]\tvalid_0's rmse: 0.848493\n[123]\tvalid_0's rmse: 0.848505\n[124]\tvalid_0's rmse: 0.848521\n[125]\tvalid_0's rmse: 0.84849\n[126]\tvalid_0's rmse: 0.848503\n[127]\tvalid_0's rmse: 0.848494\n[128]\tvalid_0's rmse: 0.848517\n[129]\tvalid_0's rmse: 0.848528\n[130]\tvalid_0's rmse: 0.848525\n[131]\tvalid_0's rmse: 0.848516\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  75%|#######5  | 15/20 [01:17<00:24,  4.89s/it]\u001b[32m[I 2021-02-05 22:52:48,843]\u001b[0m Trial 21 finished with value: 0.8484900080420754 and parameters: {'num_leaves': 104}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  75%|#######5  | 15/20 [01:17<00:24,  4.89s/it]","name":"stderr"},{"output_type":"stream","text":"[132]\tvalid_0's rmse: 0.848542\n[133]\tvalid_0's rmse: 0.848556\n[134]\tvalid_0's rmse: 0.848538\n[135]\tvalid_0's rmse: 0.848507\nEarly stopping, best iteration is:\n[125]\tvalid_0's rmse: 0.84849\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019090 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888125\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885132\n[3]\tvalid_0's rmse: 0.882725\n[4]\tvalid_0's rmse: 0.880396\n[5]\tvalid_0's rmse: 0.878404\n[6]\tvalid_0's rmse: 0.876191\n[7]\tvalid_0's rmse: 0.874705\n[8]\tvalid_0's rmse: 0.873411\n[9]\tvalid_0's rmse: 0.872178\n[10]\tvalid_0's rmse: 0.8711\n[11]\tvalid_0's rmse: 0.869601\n[12]\tvalid_0's rmse: 0.868354\n[13]\tvalid_0's rmse: 0.867304\n[14]\tvalid_0's rmse: 0.866153\n[15]\tvalid_0's rmse: 0.865423\n[16]\tvalid_0's rmse: 0.864666\n[17]\tvalid_0's rmse: 0.863848\n[18]\tvalid_0's rmse: 0.863193\n[19]\tvalid_0's rmse: 0.862491\n[20]\tvalid_0's rmse: 0.861902\n[21]\tvalid_0's rmse: 0.861339\n[22]\tvalid_0's rmse: 0.860685\n[23]\tvalid_0's rmse: 0.860154\n[24]\tvalid_0's rmse: 0.859608\n[25]\tvalid_0's rmse: 0.859195\n[26]\tvalid_0's rmse: 0.85877\n[27]\tvalid_0's rmse: 0.858433\n[28]\tvalid_0's rmse: 0.858052\n[29]\tvalid_0's rmse: 0.857658\n[30]\tvalid_0's rmse: 0.857386\n[31]\tvalid_0's rmse: 0.857075\n[32]\tvalid_0's rmse: 0.856727\n[33]\tvalid_0's rmse: 0.856439\n[34]\tvalid_0's rmse: 0.856099\n[35]\tvalid_0's rmse: 0.855866\n[36]\tvalid_0's rmse: 0.855546\n[37]\tvalid_0's rmse: 0.855284\n[38]\tvalid_0's rmse: 0.855005\n[39]\tvalid_0's rmse: 0.854692\n[40]\tvalid_0's rmse: 0.854468\n[41]\tvalid_0's rmse: 0.854302\n[42]\tvalid_0's rmse: 0.854107\n[43]\tvalid_0's rmse: 0.853969\n[44]\tvalid_0's rmse: 0.853787\n[45]\tvalid_0's rmse: 0.853556\n[46]\tvalid_0's rmse: 0.85342\n[47]\tvalid_0's rmse: 0.853239\n[48]\tvalid_0's rmse: 0.853082\n[49]\tvalid_0's rmse: 0.852912\n[50]\tvalid_0's rmse: 0.852771\n[51]\tvalid_0's rmse: 0.852682\n[52]\tvalid_0's rmse: 0.852542\n[53]\tvalid_0's rmse: 0.852357\n[54]\tvalid_0's rmse: 0.852185\n[55]\tvalid_0's rmse: 0.852074\n[56]\tvalid_0's rmse: 0.851916\n[57]\tvalid_0's rmse: 0.851823\n[58]\tvalid_0's rmse: 0.851735\n[59]\tvalid_0's rmse: 0.851667\n[60]\tvalid_0's rmse: 0.851589\n[61]\tvalid_0's rmse: 0.851511\n[62]\tvalid_0's rmse: 0.851393\n[63]\tvalid_0's rmse: 0.851197\n[64]\tvalid_0's rmse: 0.85109\n[65]\tvalid_0's rmse: 0.851022\n[66]\tvalid_0's rmse: 0.850939\n[67]\tvalid_0's rmse: 0.850858\n[68]\tvalid_0's rmse: 0.850748\n[69]\tvalid_0's rmse: 0.850665\n[70]\tvalid_0's rmse: 0.85056\n[71]\tvalid_0's rmse: 0.850515\n[72]\tvalid_0's rmse: 0.850465\n[73]\tvalid_0's rmse: 0.850401\n[74]\tvalid_0's rmse: 0.850346\n[75]\tvalid_0's rmse: 0.850291\n[76]\tvalid_0's rmse: 0.850224\n[77]\tvalid_0's rmse: 0.850172\n[78]\tvalid_0's rmse: 0.850085\n[79]\tvalid_0's rmse: 0.850058\n[80]\tvalid_0's rmse: 0.85004\n[81]\tvalid_0's rmse: 0.849975\n[82]\tvalid_0's rmse: 0.849959\n[83]\tvalid_0's rmse: 0.849918\n[84]\tvalid_0's rmse: 0.84986\n[85]\tvalid_0's rmse: 0.849827\n[86]\tvalid_0's rmse: 0.849772\n[87]\tvalid_0's rmse: 0.849721\n[88]\tvalid_0's rmse: 0.849589\n[89]\tvalid_0's rmse: 0.849561\n[90]\tvalid_0's rmse: 0.849518\n[91]\tvalid_0's rmse: 0.849465\n[92]\tvalid_0's rmse: 0.849429\n[93]\tvalid_0's rmse: 0.849346\n[94]\tvalid_0's rmse: 0.849329\n[95]\tvalid_0's rmse: 0.849199\n[96]\tvalid_0's rmse: 0.849168\n[97]\tvalid_0's rmse: 0.849126\n[98]\tvalid_0's rmse: 0.849051\n[99]\tvalid_0's rmse: 0.849046\n[100]\tvalid_0's rmse: 0.849006\n[101]\tvalid_0's rmse: 0.848997\n[102]\tvalid_0's rmse: 0.848969\n[103]\tvalid_0's rmse: 0.848933\n[104]\tvalid_0's rmse: 0.84895\n[105]\tvalid_0's rmse: 0.848897\n[106]\tvalid_0's rmse: 0.848866\n[107]\tvalid_0's rmse: 0.848793\n[108]\tvalid_0's rmse: 0.848724\n[109]\tvalid_0's rmse: 0.8487\n[110]\tvalid_0's rmse: 0.848677\n[111]\tvalid_0's rmse: 0.848658\n[112]\tvalid_0's rmse: 0.848636\n[113]\tvalid_0's rmse: 0.848607\n[114]\tvalid_0's rmse: 0.848597\n[115]\tvalid_0's rmse: 0.848592\n[116]\tvalid_0's rmse: 0.848574\n[117]\tvalid_0's rmse: 0.848538\n[118]\tvalid_0's rmse: 0.848516\n[119]\tvalid_0's rmse: 0.848516\n[120]\tvalid_0's rmse: 0.848501\n[121]\tvalid_0's rmse: 0.848462\n[122]\tvalid_0's rmse: 0.848447\n[123]\tvalid_0's rmse: 0.848448\n[124]\tvalid_0's rmse: 0.848379\n[125]\tvalid_0's rmse: 0.84835\n[126]\tvalid_0's rmse: 0.848374\n[127]\tvalid_0's rmse: 0.848361\n[128]\tvalid_0's rmse: 0.848349\n[129]\tvalid_0's rmse: 0.84837\n[130]\tvalid_0's rmse: 0.848369\n[131]\tvalid_0's rmse: 0.848363\n[132]\tvalid_0's rmse: 0.848386\n[133]\tvalid_0's rmse: 0.848355\n[134]\tvalid_0's rmse: 0.848346\n[135]\tvalid_0's rmse: 0.848347\n[136]\tvalid_0's rmse: 0.848348\n[137]\tvalid_0's rmse: 0.848301\n[138]\tvalid_0's rmse: 0.848307\n[139]\tvalid_0's rmse: 0.848283\n[140]\tvalid_0's rmse: 0.848288\n[141]\tvalid_0's rmse: 0.848297\n[142]\tvalid_0's rmse: 0.848311\n[143]\tvalid_0's rmse: 0.848296\n[144]\tvalid_0's rmse: 0.848297\n[145]\tvalid_0's rmse: 0.848294\n[146]\tvalid_0's rmse: 0.848271\n[147]\tvalid_0's rmse: 0.848246\n[148]\tvalid_0's rmse: 0.848234\n[149]\tvalid_0's rmse: 0.848272\n[150]\tvalid_0's rmse: 0.848268\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.848229\n[153]\tvalid_0's rmse: 0.848215\n[154]\tvalid_0's rmse: 0.848219\n[155]\tvalid_0's rmse: 0.848184\n[156]\tvalid_0's rmse: 0.848182\n[157]\tvalid_0's rmse: 0.84817\n[158]\tvalid_0's rmse: 0.848153\n[159]\tvalid_0's rmse: 0.848168\n[160]\tvalid_0's rmse: 0.848112\n[161]\tvalid_0's rmse: 0.848079\n[162]\tvalid_0's rmse: 0.848082\n[163]\tvalid_0's rmse: 0.848063\n[164]\tvalid_0's rmse: 0.848072\n[165]\tvalid_0's rmse: 0.848063\n[166]\tvalid_0's rmse: 0.848062\n[167]\tvalid_0's rmse: 0.848045\n[168]\tvalid_0's rmse: 0.84806\n[169]\tvalid_0's rmse: 0.848056\n[170]\tvalid_0's rmse: 0.848044\n[171]\tvalid_0's rmse: 0.848043\n[172]\tvalid_0's rmse: 0.848036\n[173]\tvalid_0's rmse: 0.848063\n[174]\tvalid_0's rmse: 0.848057\n[175]\tvalid_0's rmse: 0.848041\n[176]\tvalid_0's rmse: 0.848041\n[177]\tvalid_0's rmse: 0.848057\n[178]\tvalid_0's rmse: 0.84802\n[179]\tvalid_0's rmse: 0.848005\n[180]\tvalid_0's rmse: 0.848019\n[181]\tvalid_0's rmse: 0.848033\n[182]\tvalid_0's rmse: 0.848024\n[183]\tvalid_0's rmse: 0.848048\n[184]\tvalid_0's rmse: 0.848037\n[185]\tvalid_0's rmse: 0.84803\n[186]\tvalid_0's rmse: 0.847998\n[187]\tvalid_0's rmse: 0.847995\n[188]\tvalid_0's rmse: 0.847987\n[189]\tvalid_0's rmse: 0.847961\n[190]\tvalid_0's rmse: 0.84795\n[191]\tvalid_0's rmse: 0.84794\n[192]\tvalid_0's rmse: 0.847943\n[193]\tvalid_0's rmse: 0.847926\n[194]\tvalid_0's rmse: 0.847921\n[195]\tvalid_0's rmse: 0.847911\n[196]\tvalid_0's rmse: 0.847909\n[197]\tvalid_0's rmse: 0.847911\n[198]\tvalid_0's rmse: 0.847928\n[199]\tvalid_0's rmse: 0.847932\n[200]\tvalid_0's rmse: 0.847958\n[201]\tvalid_0's rmse: 0.847953\n[202]\tvalid_0's rmse: 0.84795\n[203]\tvalid_0's rmse: 0.847955\n[204]\tvalid_0's rmse: 0.847959\n[205]\tvalid_0's rmse: 0.847951\n[206]\tvalid_0's rmse: 0.847973\nEarly stopping, best iteration is:\n[196]\tvalid_0's rmse: 0.847909\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  80%|########  | 16/20 [01:22<00:19,  4.96s/it]\u001b[32m[I 2021-02-05 22:52:53,964]\u001b[0m Trial 22 finished with value: 0.8479085207212964 and parameters: {'num_leaves': 60}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  80%|########  | 16/20 [01:22<00:19,  4.96s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019382 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.889927\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.888493\n[3]\tvalid_0's rmse: 0.887424\n[4]\tvalid_0's rmse: 0.886375\n[5]\tvalid_0's rmse: 0.88554\n[6]\tvalid_0's rmse: 0.884469\n[7]\tvalid_0's rmse: 0.883812\n[8]\tvalid_0's rmse: 0.883238\n[9]\tvalid_0's rmse: 0.882736\n[10]\tvalid_0's rmse: 0.882334\n[11]\tvalid_0's rmse: 0.881544\n[12]\tvalid_0's rmse: 0.880884\n[13]\tvalid_0's rmse: 0.880329\n[14]\tvalid_0's rmse: 0.87977\n[15]\tvalid_0's rmse: 0.879372\n[16]\tvalid_0's rmse: 0.87891\n[17]\tvalid_0's rmse: 0.878485\n[18]\tvalid_0's rmse: 0.878001\n[19]\tvalid_0's rmse: 0.877532\n[20]\tvalid_0's rmse: 0.877111\n[21]\tvalid_0's rmse: 0.876718\n[22]\tvalid_0's rmse: 0.876314\n[23]\tvalid_0's rmse: 0.875965\n[24]\tvalid_0's rmse: 0.875647\n[25]\tvalid_0's rmse: 0.875191\n[26]\tvalid_0's rmse: 0.874908\n[27]\tvalid_0's rmse: 0.874634\n[28]\tvalid_0's rmse: 0.874275\n[29]\tvalid_0's rmse: 0.874003\n[30]\tvalid_0's rmse: 0.873732\n[31]\tvalid_0's rmse: 0.873445\n[32]\tvalid_0's rmse: 0.873151\n[33]\tvalid_0's rmse: 0.872887\n[34]\tvalid_0's rmse: 0.872608\n[35]\tvalid_0's rmse: 0.872289\n[36]\tvalid_0's rmse: 0.872011\n[37]\tvalid_0's rmse: 0.871734\n[38]\tvalid_0's rmse: 0.871489\n[39]\tvalid_0's rmse: 0.871241\n[40]\tvalid_0's rmse: 0.871025\n[41]\tvalid_0's rmse: 0.87081\n[42]\tvalid_0's rmse: 0.870566\n[43]\tvalid_0's rmse: 0.870346\n[44]\tvalid_0's rmse: 0.870077\n[45]\tvalid_0's rmse: 0.869833\n[46]\tvalid_0's rmse: 0.869661\n[47]\tvalid_0's rmse: 0.869487\n[48]\tvalid_0's rmse: 0.869321\n[49]\tvalid_0's rmse: 0.869125\n[50]\tvalid_0's rmse: 0.868967\n[51]\tvalid_0's rmse: 0.868803\n[52]\tvalid_0's rmse: 0.86862\n[53]\tvalid_0's rmse: 0.868433\n[54]\tvalid_0's rmse: 0.868255\n[55]\tvalid_0's rmse: 0.868108\n[56]\tvalid_0's rmse: 0.86791\n[57]\tvalid_0's rmse: 0.86773\n[58]\tvalid_0's rmse: 0.867537\n[59]\tvalid_0's rmse: 0.867402\n[60]\tvalid_0's rmse: 0.867244\n[61]\tvalid_0's rmse: 0.867127\n[62]\tvalid_0's rmse: 0.867012\n[63]\tvalid_0's rmse: 0.866877\n[64]\tvalid_0's rmse: 0.866732\n[65]\tvalid_0's rmse: 0.866571\n[66]\tvalid_0's rmse: 0.86645\n[67]\tvalid_0's rmse: 0.8663\n[68]\tvalid_0's rmse: 0.866153\n[69]\tvalid_0's rmse: 0.866029\n[70]\tvalid_0's rmse: 0.865906\n[71]\tvalid_0's rmse: 0.865798\n[72]\tvalid_0's rmse: 0.865629\n[73]\tvalid_0's rmse: 0.865506\n[74]\tvalid_0's rmse: 0.865412\n[75]\tvalid_0's rmse: 0.865299\n[76]\tvalid_0's rmse: 0.865195\n[77]\tvalid_0's rmse: 0.865084\n[78]\tvalid_0's rmse: 0.864958\n[79]\tvalid_0's rmse: 0.864832\n[80]\tvalid_0's rmse: 0.864716\n[81]\tvalid_0's rmse: 0.864602\n[82]\tvalid_0's rmse: 0.864509\n[83]\tvalid_0's rmse: 0.864435\n[84]\tvalid_0's rmse: 0.864307\n[85]\tvalid_0's rmse: 0.86423\n[86]\tvalid_0's rmse: 0.864143\n[87]\tvalid_0's rmse: 0.863984\n[88]\tvalid_0's rmse: 0.86385\n[89]\tvalid_0's rmse: 0.863721\n[90]\tvalid_0's rmse: 0.8636\n[91]\tvalid_0's rmse: 0.863495\n[92]\tvalid_0's rmse: 0.863374\n[93]\tvalid_0's rmse: 0.863275\n[94]\tvalid_0's rmse: 0.863198\n[95]\tvalid_0's rmse: 0.86311\n[96]\tvalid_0's rmse: 0.86303\n[97]\tvalid_0's rmse: 0.862932\n[98]\tvalid_0's rmse: 0.862847\n[99]\tvalid_0's rmse: 0.862758\n[100]\tvalid_0's rmse: 0.862669\n[101]\tvalid_0's rmse: 0.862567\n[102]\tvalid_0's rmse: 0.862487\n[103]\tvalid_0's rmse: 0.862412\n[104]\tvalid_0's rmse: 0.862336\n[105]\tvalid_0's rmse: 0.862255\n[106]\tvalid_0's rmse: 0.862187\n[107]\tvalid_0's rmse: 0.862118\n[108]\tvalid_0's rmse: 0.862045\n[109]\tvalid_0's rmse: 0.861978\n[110]\tvalid_0's rmse: 0.86191\n[111]\tvalid_0's rmse: 0.861836\n[112]\tvalid_0's rmse: 0.86179\n[113]\tvalid_0's rmse: 0.861686\n[114]\tvalid_0's rmse: 0.86162\n[115]\tvalid_0's rmse: 0.861548\n[116]\tvalid_0's rmse: 0.8615\n[117]\tvalid_0's rmse: 0.861445\n[118]\tvalid_0's rmse: 0.861382\n[119]\tvalid_0's rmse: 0.861298\n[120]\tvalid_0's rmse: 0.861206\n[121]\tvalid_0's rmse: 0.861145\n[122]\tvalid_0's rmse: 0.861079\n[123]\tvalid_0's rmse: 0.861033\n[124]\tvalid_0's rmse: 0.860974\n[125]\tvalid_0's rmse: 0.860921\n[126]\tvalid_0's rmse: 0.860872\n[127]\tvalid_0's rmse: 0.860814\n[128]\tvalid_0's rmse: 0.860762\n[129]\tvalid_0's rmse: 0.860707\n[130]\tvalid_0's rmse: 0.860659\n[131]\tvalid_0's rmse: 0.860588\n[132]\tvalid_0's rmse: 0.860556\n[133]\tvalid_0's rmse: 0.86051\n[134]\tvalid_0's rmse: 0.860434\n[135]\tvalid_0's rmse: 0.860375\n[136]\tvalid_0's rmse: 0.860292\n[137]\tvalid_0's rmse: 0.860237\n[138]\tvalid_0's rmse: 0.860174\n[139]\tvalid_0's rmse: 0.860134\n[140]\tvalid_0's rmse: 0.860082\n[141]\tvalid_0's rmse: 0.86003\n[142]\tvalid_0's rmse: 0.860001\n[143]\tvalid_0's rmse: 0.859951\n[144]\tvalid_0's rmse: 0.859905\n[145]\tvalid_0's rmse: 0.859856\n[146]\tvalid_0's rmse: 0.859814\n[147]\tvalid_0's rmse: 0.85975\n[148]\tvalid_0's rmse: 0.859716\n[149]\tvalid_0's rmse: 0.859659\n[150]\tvalid_0's rmse: 0.859602\n[151]\tvalid_0's rmse: 0.859565\n[152]\tvalid_0's rmse: 0.85952\n[153]\tvalid_0's rmse: 0.859458\n[154]\tvalid_0's rmse: 0.859414\n[155]\tvalid_0's rmse: 0.859366\n[156]\tvalid_0's rmse: 0.859331\n[157]\tvalid_0's rmse: 0.85929\n[158]\tvalid_0's rmse: 0.859253\n[159]\tvalid_0's rmse: 0.859217\n[160]\tvalid_0's rmse: 0.859179\n[161]\tvalid_0's rmse: 0.859149\n[162]\tvalid_0's rmse: 0.859127\n[163]\tvalid_0's rmse: 0.859084\n[164]\tvalid_0's rmse: 0.859055\n[165]\tvalid_0's rmse: 0.859021\n[166]\tvalid_0's rmse: 0.858981\n[167]\tvalid_0's rmse: 0.858946\n[168]\tvalid_0's rmse: 0.858903\n[169]\tvalid_0's rmse: 0.858876\n[170]\tvalid_0's rmse: 0.858821\n[171]\tvalid_0's rmse: 0.858765\n[172]\tvalid_0's rmse: 0.858709\n[173]\tvalid_0's rmse: 0.858676\n[174]\tvalid_0's rmse: 0.858629\n[175]\tvalid_0's rmse: 0.85859\n[176]\tvalid_0's rmse: 0.85856\n[177]\tvalid_0's rmse: 0.858502\n[178]\tvalid_0's rmse: 0.858478\n[179]\tvalid_0's rmse: 0.858432\n[180]\tvalid_0's rmse: 0.858393\n[181]\tvalid_0's rmse: 0.85834\n[182]\tvalid_0's rmse: 0.858324\n[183]\tvalid_0's rmse: 0.858292\n[184]\tvalid_0's rmse: 0.858248\n[185]\tvalid_0's rmse: 0.858213\n[186]\tvalid_0's rmse: 0.8582\n[187]\tvalid_0's rmse: 0.858177\n[188]\tvalid_0's rmse: 0.858135\n[189]\tvalid_0's rmse: 0.85811\n[190]\tvalid_0's rmse: 0.858088\n[191]\tvalid_0's rmse: 0.858048\n[192]\tvalid_0's rmse: 0.858011\n[193]\tvalid_0's rmse: 0.85797\n[194]\tvalid_0's rmse: 0.857944\n[195]\tvalid_0's rmse: 0.857925\n[196]\tvalid_0's rmse: 0.857899\n[197]\tvalid_0's rmse: 0.85787\n[198]\tvalid_0's rmse: 0.857847\n[199]\tvalid_0's rmse: 0.8578\n[200]\tvalid_0's rmse: 0.85777\n[201]\tvalid_0's rmse: 0.857741\n[202]\tvalid_0's rmse: 0.857704\n[203]\tvalid_0's rmse: 0.85767\n[204]\tvalid_0's rmse: 0.857645\n[205]\tvalid_0's rmse: 0.857632\n[206]\tvalid_0's rmse: 0.857614\n[207]\tvalid_0's rmse: 0.85758\n[208]\tvalid_0's rmse: 0.857557\n[209]\tvalid_0's rmse: 0.857537\n[210]\tvalid_0's rmse: 0.857499\n[211]\tvalid_0's rmse: 0.857485\n[212]\tvalid_0's rmse: 0.85746\n[213]\tvalid_0's rmse: 0.857429\n[214]\tvalid_0's rmse: 0.857392\n[215]\tvalid_0's rmse: 0.857371\n[216]\tvalid_0's rmse: 0.857357\n[217]\tvalid_0's rmse: 0.85732\n[218]\tvalid_0's rmse: 0.857301\n[219]\tvalid_0's rmse: 0.857277\n[220]\tvalid_0's rmse: 0.85724\n[221]\tvalid_0's rmse: 0.85721\n[222]\tvalid_0's rmse: 0.857184\n[223]\tvalid_0's rmse: 0.857163\n[224]\tvalid_0's rmse: 0.857133\n[225]\tvalid_0's rmse: 0.857103\n[226]\tvalid_0's rmse: 0.857081\n[227]\tvalid_0's rmse: 0.857055\n[228]\tvalid_0's rmse: 0.857032\n[229]\tvalid_0's rmse: 0.857006\n[230]\tvalid_0's rmse: 0.856995\n[231]\tvalid_0's rmse: 0.856969\n[232]\tvalid_0's rmse: 0.856933\n[233]\tvalid_0's rmse: 0.856918\n[234]\tvalid_0's rmse: 0.856904\n[235]\tvalid_0's rmse: 0.856879\n[236]\tvalid_0's rmse: 0.856871\n[237]\tvalid_0's rmse: 0.856833\n[238]\tvalid_0's rmse: 0.856804\n[239]\tvalid_0's rmse: 0.856785\n[240]\tvalid_0's rmse: 0.85676\n[241]\tvalid_0's rmse: 0.856734\n[242]\tvalid_0's rmse: 0.856703\n[243]\tvalid_0's rmse: 0.856678\n[244]\tvalid_0's rmse: 0.856627\n[245]\tvalid_0's rmse: 0.856588\n[246]\tvalid_0's rmse: 0.856561\n[247]\tvalid_0's rmse: 0.856532\n[248]\tvalid_0's rmse: 0.856506\n[249]\tvalid_0's rmse: 0.856494\n[250]\tvalid_0's rmse: 0.856472\n[251]\tvalid_0's rmse: 0.856459\n[252]\tvalid_0's rmse: 0.856438\n[253]\tvalid_0's rmse: 0.856425\n[254]\tvalid_0's rmse: 0.856409\n[255]\tvalid_0's rmse: 0.856391\n","name":"stdout"},{"output_type":"stream","text":"[256]\tvalid_0's rmse: 0.856384\n[257]\tvalid_0's rmse: 0.856374\n[258]\tvalid_0's rmse: 0.85635\n[259]\tvalid_0's rmse: 0.856329\n[260]\tvalid_0's rmse: 0.856305\n[261]\tvalid_0's rmse: 0.856294\n[262]\tvalid_0's rmse: 0.856275\n[263]\tvalid_0's rmse: 0.856241\n[264]\tvalid_0's rmse: 0.856178\n[265]\tvalid_0's rmse: 0.856178\n[266]\tvalid_0's rmse: 0.856159\n[267]\tvalid_0's rmse: 0.856125\n[268]\tvalid_0's rmse: 0.856102\n[269]\tvalid_0's rmse: 0.85608\n[270]\tvalid_0's rmse: 0.856055\n[271]\tvalid_0's rmse: 0.856026\n[272]\tvalid_0's rmse: 0.856015\n[273]\tvalid_0's rmse: 0.856004\n[274]\tvalid_0's rmse: 0.855989\n[275]\tvalid_0's rmse: 0.855975\n[276]\tvalid_0's rmse: 0.855962\n[277]\tvalid_0's rmse: 0.855935\n[278]\tvalid_0's rmse: 0.855929\n[279]\tvalid_0's rmse: 0.855916\n[280]\tvalid_0's rmse: 0.855904\n[281]\tvalid_0's rmse: 0.855853\n[282]\tvalid_0's rmse: 0.855826\n[283]\tvalid_0's rmse: 0.855802\n[284]\tvalid_0's rmse: 0.855788\n[285]\tvalid_0's rmse: 0.855779\n[286]\tvalid_0's rmse: 0.855763\n[287]\tvalid_0's rmse: 0.855738\n[288]\tvalid_0's rmse: 0.85572\n[289]\tvalid_0's rmse: 0.855699\n[290]\tvalid_0's rmse: 0.855664\n[291]\tvalid_0's rmse: 0.855643\n[292]\tvalid_0's rmse: 0.855616\n[293]\tvalid_0's rmse: 0.855576\n[294]\tvalid_0's rmse: 0.855549\n[295]\tvalid_0's rmse: 0.8555\n[296]\tvalid_0's rmse: 0.855475\n[297]\tvalid_0's rmse: 0.855453\n[298]\tvalid_0's rmse: 0.85543\n[299]\tvalid_0's rmse: 0.855423\n[300]\tvalid_0's rmse: 0.855408\n[301]\tvalid_0's rmse: 0.855397\n[302]\tvalid_0's rmse: 0.855394\n[303]\tvalid_0's rmse: 0.855346\n[304]\tvalid_0's rmse: 0.855326\n[305]\tvalid_0's rmse: 0.855311\n[306]\tvalid_0's rmse: 0.855271\n[307]\tvalid_0's rmse: 0.855219\n[308]\tvalid_0's rmse: 0.855188\n[309]\tvalid_0's rmse: 0.855166\n[310]\tvalid_0's rmse: 0.855142\n[311]\tvalid_0's rmse: 0.85512\n[312]\tvalid_0's rmse: 0.855117\n[313]\tvalid_0's rmse: 0.855079\n[314]\tvalid_0's rmse: 0.855071\n[315]\tvalid_0's rmse: 0.855046\n[316]\tvalid_0's rmse: 0.855031\n[317]\tvalid_0's rmse: 0.855017\n[318]\tvalid_0's rmse: 0.855001\n[319]\tvalid_0's rmse: 0.854997\n[320]\tvalid_0's rmse: 0.854968\n[321]\tvalid_0's rmse: 0.854955\n[322]\tvalid_0's rmse: 0.854935\n[323]\tvalid_0's rmse: 0.8549\n[324]\tvalid_0's rmse: 0.854887\n[325]\tvalid_0's rmse: 0.854866\n[326]\tvalid_0's rmse: 0.854855\n[327]\tvalid_0's rmse: 0.854852\n[328]\tvalid_0's rmse: 0.854827\n[329]\tvalid_0's rmse: 0.854815\n[330]\tvalid_0's rmse: 0.854811\n[331]\tvalid_0's rmse: 0.854799\n[332]\tvalid_0's rmse: 0.854774\n[333]\tvalid_0's rmse: 0.854759\n[334]\tvalid_0's rmse: 0.854743\n[335]\tvalid_0's rmse: 0.854738\n[336]\tvalid_0's rmse: 0.854718\n[337]\tvalid_0's rmse: 0.854708\n[338]\tvalid_0's rmse: 0.854699\n[339]\tvalid_0's rmse: 0.854689\n[340]\tvalid_0's rmse: 0.854671\n[341]\tvalid_0's rmse: 0.854647\n[342]\tvalid_0's rmse: 0.854625\n[343]\tvalid_0's rmse: 0.854606\n[344]\tvalid_0's rmse: 0.85458\n[345]\tvalid_0's rmse: 0.854564\n[346]\tvalid_0's rmse: 0.854531\n[347]\tvalid_0's rmse: 0.854518\n[348]\tvalid_0's rmse: 0.854517\n[349]\tvalid_0's rmse: 0.854507\n[350]\tvalid_0's rmse: 0.854496\n[351]\tvalid_0's rmse: 0.854484\n[352]\tvalid_0's rmse: 0.854466\n[353]\tvalid_0's rmse: 0.854455\n[354]\tvalid_0's rmse: 0.854435\n[355]\tvalid_0's rmse: 0.854422\n[356]\tvalid_0's rmse: 0.854422\n[357]\tvalid_0's rmse: 0.854407\n[358]\tvalid_0's rmse: 0.8544\n[359]\tvalid_0's rmse: 0.854376\n[360]\tvalid_0's rmse: 0.854369\n[361]\tvalid_0's rmse: 0.854352\n[362]\tvalid_0's rmse: 0.854341\n[363]\tvalid_0's rmse: 0.854331\n[364]\tvalid_0's rmse: 0.854324\n[365]\tvalid_0's rmse: 0.854312\n[366]\tvalid_0's rmse: 0.854276\n[367]\tvalid_0's rmse: 0.854242\n[368]\tvalid_0's rmse: 0.854228\n[369]\tvalid_0's rmse: 0.854213\n[370]\tvalid_0's rmse: 0.854187\n[371]\tvalid_0's rmse: 0.854182\n[372]\tvalid_0's rmse: 0.854154\n[373]\tvalid_0's rmse: 0.854138\n[374]\tvalid_0's rmse: 0.854119\n[375]\tvalid_0's rmse: 0.854115\n[376]\tvalid_0's rmse: 0.854115\n[377]\tvalid_0's rmse: 0.8541\n[378]\tvalid_0's rmse: 0.854084\n[379]\tvalid_0's rmse: 0.854067\n[380]\tvalid_0's rmse: 0.854057\n[381]\tvalid_0's rmse: 0.854029\n[382]\tvalid_0's rmse: 0.853992\n[383]\tvalid_0's rmse: 0.853971\n[384]\tvalid_0's rmse: 0.853954\n[385]\tvalid_0's rmse: 0.853941\n[386]\tvalid_0's rmse: 0.853908\n[387]\tvalid_0's rmse: 0.853897\n[388]\tvalid_0's rmse: 0.853882\n[389]\tvalid_0's rmse: 0.853877\n[390]\tvalid_0's rmse: 0.853864\n[391]\tvalid_0's rmse: 0.853844\n[392]\tvalid_0's rmse: 0.853838\n[393]\tvalid_0's rmse: 0.85383\n[394]\tvalid_0's rmse: 0.853801\n[395]\tvalid_0's rmse: 0.85377\n[396]\tvalid_0's rmse: 0.853758\n[397]\tvalid_0's rmse: 0.853759\n[398]\tvalid_0's rmse: 0.85375\n[399]\tvalid_0's rmse: 0.85373\n[400]\tvalid_0's rmse: 0.85371\n[401]\tvalid_0's rmse: 0.853711\n[402]\tvalid_0's rmse: 0.853677\n[403]\tvalid_0's rmse: 0.853662\n[404]\tvalid_0's rmse: 0.853644\n[405]\tvalid_0's rmse: 0.853625\n[406]\tvalid_0's rmse: 0.853616\n[407]\tvalid_0's rmse: 0.853607\n[408]\tvalid_0's rmse: 0.853589\n[409]\tvalid_0's rmse: 0.85358\n[410]\tvalid_0's rmse: 0.853557\n[411]\tvalid_0's rmse: 0.853544\n[412]\tvalid_0's rmse: 0.853531\n[413]\tvalid_0's rmse: 0.853517\n[414]\tvalid_0's rmse: 0.853505\n[415]\tvalid_0's rmse: 0.85349\n[416]\tvalid_0's rmse: 0.853488\n[417]\tvalid_0's rmse: 0.853474\n[418]\tvalid_0's rmse: 0.853466\n[419]\tvalid_0's rmse: 0.853437\n[420]\tvalid_0's rmse: 0.853427\n[421]\tvalid_0's rmse: 0.853412\n[422]\tvalid_0's rmse: 0.853406\n[423]\tvalid_0's rmse: 0.853394\n[424]\tvalid_0's rmse: 0.853375\n[425]\tvalid_0's rmse: 0.853373\n[426]\tvalid_0's rmse: 0.853348\n[427]\tvalid_0's rmse: 0.853336\n[428]\tvalid_0's rmse: 0.853315\n[429]\tvalid_0's rmse: 0.853306\n[430]\tvalid_0's rmse: 0.853303\n[431]\tvalid_0's rmse: 0.853285\n[432]\tvalid_0's rmse: 0.853268\n[433]\tvalid_0's rmse: 0.853263\n[434]\tvalid_0's rmse: 0.853262\n[435]\tvalid_0's rmse: 0.853247\n[436]\tvalid_0's rmse: 0.853242\n[437]\tvalid_0's rmse: 0.853234\n[438]\tvalid_0's rmse: 0.853225\n[439]\tvalid_0's rmse: 0.853219\n[440]\tvalid_0's rmse: 0.85321\n[441]\tvalid_0's rmse: 0.853203\n[442]\tvalid_0's rmse: 0.853202\n[443]\tvalid_0's rmse: 0.853191\n[444]\tvalid_0's rmse: 0.853176\n[445]\tvalid_0's rmse: 0.853161\n[446]\tvalid_0's rmse: 0.853155\n[447]\tvalid_0's rmse: 0.85315\n[448]\tvalid_0's rmse: 0.853132\n[449]\tvalid_0's rmse: 0.853125\n[450]\tvalid_0's rmse: 0.853119\n[451]\tvalid_0's rmse: 0.853112\n[452]\tvalid_0's rmse: 0.853097\n[453]\tvalid_0's rmse: 0.853086\n[454]\tvalid_0's rmse: 0.853074\n[455]\tvalid_0's rmse: 0.853061\n[456]\tvalid_0's rmse: 0.853052\n[457]\tvalid_0's rmse: 0.853052\n[458]\tvalid_0's rmse: 0.853042\n[459]\tvalid_0's rmse: 0.85303\n[460]\tvalid_0's rmse: 0.853017\n[461]\tvalid_0's rmse: 0.852994\n[462]\tvalid_0's rmse: 0.852987\n[463]\tvalid_0's rmse: 0.852974\n[464]\tvalid_0's rmse: 0.852968\n[465]\tvalid_0's rmse: 0.852967\n[466]\tvalid_0's rmse: 0.852948\n[467]\tvalid_0's rmse: 0.852929\n[468]\tvalid_0's rmse: 0.852918\n[469]\tvalid_0's rmse: 0.852903\n[470]\tvalid_0's rmse: 0.852893\n[471]\tvalid_0's rmse: 0.852879\n[472]\tvalid_0's rmse: 0.85287\n[473]\tvalid_0's rmse: 0.852859\n[474]\tvalid_0's rmse: 0.852845\n[475]\tvalid_0's rmse: 0.852817\n[476]\tvalid_0's rmse: 0.852801\n[477]\tvalid_0's rmse: 0.852795\n[478]\tvalid_0's rmse: 0.852784\n[479]\tvalid_0's rmse: 0.852776\n[480]\tvalid_0's rmse: 0.852763\n[481]\tvalid_0's rmse: 0.852756\n[482]\tvalid_0's rmse: 0.852749\n[483]\tvalid_0's rmse: 0.852743\n[484]\tvalid_0's rmse: 0.852729\n[485]\tvalid_0's rmse: 0.852729\n[486]\tvalid_0's rmse: 0.852727\n[487]\tvalid_0's rmse: 0.852713\n[488]\tvalid_0's rmse: 0.852695\n[489]\tvalid_0's rmse: 0.852681\n[490]\tvalid_0's rmse: 0.852686\n[491]\tvalid_0's rmse: 0.852676\n[492]\tvalid_0's rmse: 0.852667\n[493]\tvalid_0's rmse: 0.852655\n[494]\tvalid_0's rmse: 0.852651\n[495]\tvalid_0's rmse: 0.852647\n[496]\tvalid_0's rmse: 0.852639\n[497]\tvalid_0's rmse: 0.852618\n[498]\tvalid_0's rmse: 0.852617\n[499]\tvalid_0's rmse: 0.852608\n[500]\tvalid_0's rmse: 0.852602\n[501]\tvalid_0's rmse: 0.852581\n[502]\tvalid_0's rmse: 0.852568\n[503]\tvalid_0's rmse: 0.852552\n[504]\tvalid_0's rmse: 0.852544\n[505]\tvalid_0's rmse: 0.852531\n[506]\tvalid_0's rmse: 0.852523\n[507]\tvalid_0's rmse: 0.85252\n[508]\tvalid_0's rmse: 0.852519\n[509]\tvalid_0's rmse: 0.85252\n[510]\tvalid_0's rmse: 0.852497\n[511]\tvalid_0's rmse: 0.852493\n[512]\tvalid_0's rmse: 0.852493\n[513]\tvalid_0's rmse: 0.852485\n[514]\tvalid_0's rmse: 0.852478\n[515]\tvalid_0's rmse: 0.852473\n[516]\tvalid_0's rmse: 0.852471\n[517]\tvalid_0's rmse: 0.852475\n[518]\tvalid_0's rmse: 0.852464\n[519]\tvalid_0's rmse: 0.852463\n[520]\tvalid_0's rmse: 0.852465\n[521]\tvalid_0's rmse: 0.852455\n[522]\tvalid_0's rmse: 0.852456\n[523]\tvalid_0's rmse: 0.852452\n[524]\tvalid_0's rmse: 0.852442\n[525]\tvalid_0's rmse: 0.852439\n[526]\tvalid_0's rmse: 0.852432\n[527]\tvalid_0's rmse: 0.852422\n[528]\tvalid_0's rmse: 0.852408\n[529]\tvalid_0's rmse: 0.852397\n[530]\tvalid_0's rmse: 0.852397\n[531]\tvalid_0's rmse: 0.852391\n[532]\tvalid_0's rmse: 0.852386\n[533]\tvalid_0's rmse: 0.852365\n[534]\tvalid_0's rmse: 0.852347\n[535]\tvalid_0's rmse: 0.852339\n[536]\tvalid_0's rmse: 0.852322\n","name":"stdout"},{"output_type":"stream","text":"[537]\tvalid_0's rmse: 0.852318\n[538]\tvalid_0's rmse: 0.852303\n[539]\tvalid_0's rmse: 0.852287\n[540]\tvalid_0's rmse: 0.852281\n[541]\tvalid_0's rmse: 0.852278\n[542]\tvalid_0's rmse: 0.852272\n[543]\tvalid_0's rmse: 0.852268\n[544]\tvalid_0's rmse: 0.852262\n[545]\tvalid_0's rmse: 0.852259\n[546]\tvalid_0's rmse: 0.85224\n[547]\tvalid_0's rmse: 0.852238\n[548]\tvalid_0's rmse: 0.852225\n[549]\tvalid_0's rmse: 0.852218\n[550]\tvalid_0's rmse: 0.852215\n[551]\tvalid_0's rmse: 0.852207\n[552]\tvalid_0's rmse: 0.852183\n[553]\tvalid_0's rmse: 0.852177\n[554]\tvalid_0's rmse: 0.852169\n[555]\tvalid_0's rmse: 0.852169\n[556]\tvalid_0's rmse: 0.852166\n[557]\tvalid_0's rmse: 0.852142\n[558]\tvalid_0's rmse: 0.852134\n[559]\tvalid_0's rmse: 0.852123\n[560]\tvalid_0's rmse: 0.852104\n[561]\tvalid_0's rmse: 0.85206\n[562]\tvalid_0's rmse: 0.852047\n[563]\tvalid_0's rmse: 0.852033\n[564]\tvalid_0's rmse: 0.852021\n[565]\tvalid_0's rmse: 0.852015\n[566]\tvalid_0's rmse: 0.852011\n[567]\tvalid_0's rmse: 0.852004\n[568]\tvalid_0's rmse: 0.851999\n[569]\tvalid_0's rmse: 0.851986\n[570]\tvalid_0's rmse: 0.851966\n[571]\tvalid_0's rmse: 0.851961\n[572]\tvalid_0's rmse: 0.851928\n[573]\tvalid_0's rmse: 0.851921\n[574]\tvalid_0's rmse: 0.851919\n[575]\tvalid_0's rmse: 0.851916\n[576]\tvalid_0's rmse: 0.851916\n[577]\tvalid_0's rmse: 0.851906\n[578]\tvalid_0's rmse: 0.8519\n[579]\tvalid_0's rmse: 0.851891\n[580]\tvalid_0's rmse: 0.851884\n[581]\tvalid_0's rmse: 0.851882\n[582]\tvalid_0's rmse: 0.851882\n[583]\tvalid_0's rmse: 0.85187\n[584]\tvalid_0's rmse: 0.851858\n[585]\tvalid_0's rmse: 0.851849\n[586]\tvalid_0's rmse: 0.851837\n[587]\tvalid_0's rmse: 0.851821\n[588]\tvalid_0's rmse: 0.85181\n[589]\tvalid_0's rmse: 0.851799\n[590]\tvalid_0's rmse: 0.851796\n[591]\tvalid_0's rmse: 0.851797\n[592]\tvalid_0's rmse: 0.851782\n[593]\tvalid_0's rmse: 0.851776\n[594]\tvalid_0's rmse: 0.851765\n[595]\tvalid_0's rmse: 0.851762\n[596]\tvalid_0's rmse: 0.851751\n[597]\tvalid_0's rmse: 0.851743\n[598]\tvalid_0's rmse: 0.851723\n[599]\tvalid_0's rmse: 0.851713\n[600]\tvalid_0's rmse: 0.851698\n[601]\tvalid_0's rmse: 0.851682\n[602]\tvalid_0's rmse: 0.851673\n[603]\tvalid_0's rmse: 0.851672\n[604]\tvalid_0's rmse: 0.85167\n[605]\tvalid_0's rmse: 0.851639\n[606]\tvalid_0's rmse: 0.851636\n[607]\tvalid_0's rmse: 0.851629\n[608]\tvalid_0's rmse: 0.851621\n[609]\tvalid_0's rmse: 0.851606\n[610]\tvalid_0's rmse: 0.851601\n[611]\tvalid_0's rmse: 0.851602\n[612]\tvalid_0's rmse: 0.851581\n[613]\tvalid_0's rmse: 0.851578\n[614]\tvalid_0's rmse: 0.85156\n[615]\tvalid_0's rmse: 0.851554\n[616]\tvalid_0's rmse: 0.851546\n[617]\tvalid_0's rmse: 0.851543\n[618]\tvalid_0's rmse: 0.85154\n[619]\tvalid_0's rmse: 0.851547\n[620]\tvalid_0's rmse: 0.851541\n[621]\tvalid_0's rmse: 0.851534\n[622]\tvalid_0's rmse: 0.851523\n[623]\tvalid_0's rmse: 0.851522\n[624]\tvalid_0's rmse: 0.851515\n[625]\tvalid_0's rmse: 0.851509\n[626]\tvalid_0's rmse: 0.85151\n[627]\tvalid_0's rmse: 0.851503\n[628]\tvalid_0's rmse: 0.851497\n[629]\tvalid_0's rmse: 0.851477\n[630]\tvalid_0's rmse: 0.851471\n[631]\tvalid_0's rmse: 0.851468\n[632]\tvalid_0's rmse: 0.851467\n[633]\tvalid_0's rmse: 0.85145\n[634]\tvalid_0's rmse: 0.851447\n[635]\tvalid_0's rmse: 0.851443\n[636]\tvalid_0's rmse: 0.851431\n[637]\tvalid_0's rmse: 0.851419\n[638]\tvalid_0's rmse: 0.851421\n[639]\tvalid_0's rmse: 0.851414\n[640]\tvalid_0's rmse: 0.8514\n[641]\tvalid_0's rmse: 0.851391\n[642]\tvalid_0's rmse: 0.851388\n[643]\tvalid_0's rmse: 0.851363\n[644]\tvalid_0's rmse: 0.851362\n[645]\tvalid_0's rmse: 0.851357\n[646]\tvalid_0's rmse: 0.85135\n[647]\tvalid_0's rmse: 0.85134\n[648]\tvalid_0's rmse: 0.851338\n[649]\tvalid_0's rmse: 0.851328\n[650]\tvalid_0's rmse: 0.851322\n[651]\tvalid_0's rmse: 0.851317\n[652]\tvalid_0's rmse: 0.85131\n[653]\tvalid_0's rmse: 0.851305\n[654]\tvalid_0's rmse: 0.851303\n[655]\tvalid_0's rmse: 0.851286\n[656]\tvalid_0's rmse: 0.851278\n[657]\tvalid_0's rmse: 0.851277\n[658]\tvalid_0's rmse: 0.851277\n[659]\tvalid_0's rmse: 0.851275\n[660]\tvalid_0's rmse: 0.851272\n[661]\tvalid_0's rmse: 0.851271\n[662]\tvalid_0's rmse: 0.851256\n[663]\tvalid_0's rmse: 0.851248\n[664]\tvalid_0's rmse: 0.851239\n[665]\tvalid_0's rmse: 0.851228\n[666]\tvalid_0's rmse: 0.851222\n[667]\tvalid_0's rmse: 0.851222\n[668]\tvalid_0's rmse: 0.851219\n[669]\tvalid_0's rmse: 0.851223\n[670]\tvalid_0's rmse: 0.851219\n[671]\tvalid_0's rmse: 0.851211\n[672]\tvalid_0's rmse: 0.851206\n[673]\tvalid_0's rmse: 0.851205\n[674]\tvalid_0's rmse: 0.851198\n[675]\tvalid_0's rmse: 0.851173\n[676]\tvalid_0's rmse: 0.851168\n[677]\tvalid_0's rmse: 0.851159\n[678]\tvalid_0's rmse: 0.851156\n[679]\tvalid_0's rmse: 0.85114\n[680]\tvalid_0's rmse: 0.851135\n[681]\tvalid_0's rmse: 0.851126\n[682]\tvalid_0's rmse: 0.851104\n[683]\tvalid_0's rmse: 0.851091\n[684]\tvalid_0's rmse: 0.851087\n[685]\tvalid_0's rmse: 0.851087\n[686]\tvalid_0's rmse: 0.851087\n[687]\tvalid_0's rmse: 0.851079\n[688]\tvalid_0's rmse: 0.851067\n[689]\tvalid_0's rmse: 0.851064\n[690]\tvalid_0's rmse: 0.851064\n[691]\tvalid_0's rmse: 0.851065\n[692]\tvalid_0's rmse: 0.851063\n[693]\tvalid_0's rmse: 0.851049\n[694]\tvalid_0's rmse: 0.851045\n[695]\tvalid_0's rmse: 0.851045\n[696]\tvalid_0's rmse: 0.851038\n[697]\tvalid_0's rmse: 0.851034\n[698]\tvalid_0's rmse: 0.851029\n[699]\tvalid_0's rmse: 0.851021\n[700]\tvalid_0's rmse: 0.851013\n[701]\tvalid_0's rmse: 0.851\n[702]\tvalid_0's rmse: 0.850986\n[703]\tvalid_0's rmse: 0.850983\n[704]\tvalid_0's rmse: 0.850979\n[705]\tvalid_0's rmse: 0.850969\n[706]\tvalid_0's rmse: 0.850963\n[707]\tvalid_0's rmse: 0.850964\n[708]\tvalid_0's rmse: 0.850965\n[709]\tvalid_0's rmse: 0.850945\n[710]\tvalid_0's rmse: 0.850948\n[711]\tvalid_0's rmse: 0.850947\n[712]\tvalid_0's rmse: 0.850944\n[713]\tvalid_0's rmse: 0.850942\n[714]\tvalid_0's rmse: 0.850941\n[715]\tvalid_0's rmse: 0.850922\n[716]\tvalid_0's rmse: 0.850914\n[717]\tvalid_0's rmse: 0.850908\n[718]\tvalid_0's rmse: 0.850906\n[719]\tvalid_0's rmse: 0.8509\n[720]\tvalid_0's rmse: 0.850891\n[721]\tvalid_0's rmse: 0.850892\n[722]\tvalid_0's rmse: 0.850893\n[723]\tvalid_0's rmse: 0.850884\n[724]\tvalid_0's rmse: 0.850872\n[725]\tvalid_0's rmse: 0.850868\n[726]\tvalid_0's rmse: 0.850864\n[727]\tvalid_0's rmse: 0.850858\n[728]\tvalid_0's rmse: 0.850853\n[729]\tvalid_0's rmse: 0.850854\n[730]\tvalid_0's rmse: 0.850847\n[731]\tvalid_0's rmse: 0.850845\n[732]\tvalid_0's rmse: 0.85084\n[733]\tvalid_0's rmse: 0.850827\n[734]\tvalid_0's rmse: 0.850821\n[735]\tvalid_0's rmse: 0.850812\n[736]\tvalid_0's rmse: 0.850811\n[737]\tvalid_0's rmse: 0.85081\n[738]\tvalid_0's rmse: 0.85081\n[739]\tvalid_0's rmse: 0.850806\n[740]\tvalid_0's rmse: 0.850794\n[741]\tvalid_0's rmse: 0.850794\n[742]\tvalid_0's rmse: 0.8508\n[743]\tvalid_0's rmse: 0.850804\n[744]\tvalid_0's rmse: 0.85079\n[745]\tvalid_0's rmse: 0.850777\n[746]\tvalid_0's rmse: 0.850771\n[747]\tvalid_0's rmse: 0.850767\n[748]\tvalid_0's rmse: 0.850762\n[749]\tvalid_0's rmse: 0.850757\n[750]\tvalid_0's rmse: 0.850759\n[751]\tvalid_0's rmse: 0.850751\n[752]\tvalid_0's rmse: 0.850748\n[753]\tvalid_0's rmse: 0.850743\n[754]\tvalid_0's rmse: 0.850731\n[755]\tvalid_0's rmse: 0.85073\n[756]\tvalid_0's rmse: 0.850719\n[757]\tvalid_0's rmse: 0.850715\n[758]\tvalid_0's rmse: 0.850709\n[759]\tvalid_0's rmse: 0.850701\n[760]\tvalid_0's rmse: 0.850701\n[761]\tvalid_0's rmse: 0.850699\n[762]\tvalid_0's rmse: 0.850697\n[763]\tvalid_0's rmse: 0.850688\n[764]\tvalid_0's rmse: 0.850686\n[765]\tvalid_0's rmse: 0.850688\n[766]\tvalid_0's rmse: 0.850685\n[767]\tvalid_0's rmse: 0.850677\n[768]\tvalid_0's rmse: 0.850671\n[769]\tvalid_0's rmse: 0.850665\n[770]\tvalid_0's rmse: 0.850659\n[771]\tvalid_0's rmse: 0.850653\n[772]\tvalid_0's rmse: 0.850649\n[773]\tvalid_0's rmse: 0.85064\n[774]\tvalid_0's rmse: 0.850631\n[775]\tvalid_0's rmse: 0.850631\n[776]\tvalid_0's rmse: 0.850633\n[777]\tvalid_0's rmse: 0.850632\n[778]\tvalid_0's rmse: 0.850624\n[779]\tvalid_0's rmse: 0.850622\n[780]\tvalid_0's rmse: 0.850625\n[781]\tvalid_0's rmse: 0.850623\n[782]\tvalid_0's rmse: 0.850621\n[783]\tvalid_0's rmse: 0.850619\n[784]\tvalid_0's rmse: 0.850617\n[785]\tvalid_0's rmse: 0.850609\n[786]\tvalid_0's rmse: 0.850604\n[787]\tvalid_0's rmse: 0.850599\n[788]\tvalid_0's rmse: 0.850593\n[789]\tvalid_0's rmse: 0.850583\n[790]\tvalid_0's rmse: 0.85056\n[791]\tvalid_0's rmse: 0.85055\n[792]\tvalid_0's rmse: 0.850549\n[793]\tvalid_0's rmse: 0.850544\n[794]\tvalid_0's rmse: 0.850543\n[795]\tvalid_0's rmse: 0.850532\n[796]\tvalid_0's rmse: 0.850532\n[797]\tvalid_0's rmse: 0.850535\n[798]\tvalid_0's rmse: 0.850534\n[799]\tvalid_0's rmse: 0.850534\n[800]\tvalid_0's rmse: 0.85053\n[801]\tvalid_0's rmse: 0.850531\n[802]\tvalid_0's rmse: 0.850528\n","name":"stdout"},{"output_type":"stream","text":"[803]\tvalid_0's rmse: 0.850526\n[804]\tvalid_0's rmse: 0.850525\n[805]\tvalid_0's rmse: 0.850516\n[806]\tvalid_0's rmse: 0.850499\n[807]\tvalid_0's rmse: 0.850494\n[808]\tvalid_0's rmse: 0.850484\n[809]\tvalid_0's rmse: 0.850471\n[810]\tvalid_0's rmse: 0.850451\n[811]\tvalid_0's rmse: 0.850446\n[812]\tvalid_0's rmse: 0.850441\n[813]\tvalid_0's rmse: 0.850438\n[814]\tvalid_0's rmse: 0.85044\n[815]\tvalid_0's rmse: 0.850428\n[816]\tvalid_0's rmse: 0.850423\n[817]\tvalid_0's rmse: 0.850414\n[818]\tvalid_0's rmse: 0.850417\n[819]\tvalid_0's rmse: 0.850414\n[820]\tvalid_0's rmse: 0.85041\n[821]\tvalid_0's rmse: 0.850407\n[822]\tvalid_0's rmse: 0.850399\n[823]\tvalid_0's rmse: 0.850396\n[824]\tvalid_0's rmse: 0.850384\n[825]\tvalid_0's rmse: 0.850374\n[826]\tvalid_0's rmse: 0.850362\n[827]\tvalid_0's rmse: 0.850365\n[828]\tvalid_0's rmse: 0.850364\n[829]\tvalid_0's rmse: 0.850358\n[830]\tvalid_0's rmse: 0.850352\n[831]\tvalid_0's rmse: 0.850354\n[832]\tvalid_0's rmse: 0.850353\n[833]\tvalid_0's rmse: 0.850353\n[834]\tvalid_0's rmse: 0.850354\n[835]\tvalid_0's rmse: 0.850349\n[836]\tvalid_0's rmse: 0.850342\n[837]\tvalid_0's rmse: 0.850337\n[838]\tvalid_0's rmse: 0.850339\n[839]\tvalid_0's rmse: 0.850341\n[840]\tvalid_0's rmse: 0.850338\n[841]\tvalid_0's rmse: 0.850333\n[842]\tvalid_0's rmse: 0.850325\n[843]\tvalid_0's rmse: 0.85032\n[844]\tvalid_0's rmse: 0.850315\n[845]\tvalid_0's rmse: 0.850313\n[846]\tvalid_0's rmse: 0.850309\n[847]\tvalid_0's rmse: 0.850292\n[848]\tvalid_0's rmse: 0.850292\n[849]\tvalid_0's rmse: 0.850287\n[850]\tvalid_0's rmse: 0.850275\n[851]\tvalid_0's rmse: 0.850266\n[852]\tvalid_0's rmse: 0.85026\n[853]\tvalid_0's rmse: 0.850258\n[854]\tvalid_0's rmse: 0.850252\n[855]\tvalid_0's rmse: 0.850252\n[856]\tvalid_0's rmse: 0.850246\n[857]\tvalid_0's rmse: 0.850246\n[858]\tvalid_0's rmse: 0.850241\n[859]\tvalid_0's rmse: 0.85024\n[860]\tvalid_0's rmse: 0.850233\n[861]\tvalid_0's rmse: 0.850225\n[862]\tvalid_0's rmse: 0.850223\n[863]\tvalid_0's rmse: 0.85022\n[864]\tvalid_0's rmse: 0.850217\n[865]\tvalid_0's rmse: 0.850199\n[866]\tvalid_0's rmse: 0.850189\n[867]\tvalid_0's rmse: 0.85018\n[868]\tvalid_0's rmse: 0.850179\n[869]\tvalid_0's rmse: 0.850163\n[870]\tvalid_0's rmse: 0.850146\n[871]\tvalid_0's rmse: 0.85014\n[872]\tvalid_0's rmse: 0.850131\n[873]\tvalid_0's rmse: 0.850116\n[874]\tvalid_0's rmse: 0.850115\n[875]\tvalid_0's rmse: 0.850115\n[876]\tvalid_0's rmse: 0.850109\n[877]\tvalid_0's rmse: 0.850105\n[878]\tvalid_0's rmse: 0.8501\n[879]\tvalid_0's rmse: 0.850094\n[880]\tvalid_0's rmse: 0.850089\n[881]\tvalid_0's rmse: 0.850092\n[882]\tvalid_0's rmse: 0.850084\n[883]\tvalid_0's rmse: 0.850079\n[884]\tvalid_0's rmse: 0.85007\n[885]\tvalid_0's rmse: 0.850069\n[886]\tvalid_0's rmse: 0.850068\n[887]\tvalid_0's rmse: 0.850063\n[888]\tvalid_0's rmse: 0.850058\n[889]\tvalid_0's rmse: 0.850053\n[890]\tvalid_0's rmse: 0.85004\n[891]\tvalid_0's rmse: 0.850039\n[892]\tvalid_0's rmse: 0.85004\n[893]\tvalid_0's rmse: 0.850038\n[894]\tvalid_0's rmse: 0.850032\n[895]\tvalid_0's rmse: 0.850029\n[896]\tvalid_0's rmse: 0.850011\n[897]\tvalid_0's rmse: 0.850008\n[898]\tvalid_0's rmse: 0.850001\n[899]\tvalid_0's rmse: 0.849988\n[900]\tvalid_0's rmse: 0.84998\n[901]\tvalid_0's rmse: 0.849979\n[902]\tvalid_0's rmse: 0.849965\n[903]\tvalid_0's rmse: 0.849963\n[904]\tvalid_0's rmse: 0.849958\n[905]\tvalid_0's rmse: 0.849949\n[906]\tvalid_0's rmse: 0.849931\n[907]\tvalid_0's rmse: 0.849927\n[908]\tvalid_0's rmse: 0.849917\n[909]\tvalid_0's rmse: 0.849911\n[910]\tvalid_0's rmse: 0.849907\n[911]\tvalid_0's rmse: 0.849902\n[912]\tvalid_0's rmse: 0.8499\n[913]\tvalid_0's rmse: 0.849899\n[914]\tvalid_0's rmse: 0.849896\n[915]\tvalid_0's rmse: 0.849882\n[916]\tvalid_0's rmse: 0.84987\n[917]\tvalid_0's rmse: 0.849866\n[918]\tvalid_0's rmse: 0.849868\n[919]\tvalid_0's rmse: 0.849859\n[920]\tvalid_0's rmse: 0.849859\n[921]\tvalid_0's rmse: 0.849853\n[922]\tvalid_0's rmse: 0.849844\n[923]\tvalid_0's rmse: 0.849843\n[924]\tvalid_0's rmse: 0.849844\n[925]\tvalid_0's rmse: 0.849838\n[926]\tvalid_0's rmse: 0.849836\n[927]\tvalid_0's rmse: 0.849838\n[928]\tvalid_0's rmse: 0.849838\n[929]\tvalid_0's rmse: 0.849838\n[930]\tvalid_0's rmse: 0.849834\n[931]\tvalid_0's rmse: 0.849831\n[932]\tvalid_0's rmse: 0.849834\n[933]\tvalid_0's rmse: 0.849829\n[934]\tvalid_0's rmse: 0.849825\n[935]\tvalid_0's rmse: 0.849819\n[936]\tvalid_0's rmse: 0.849816\n[937]\tvalid_0's rmse: 0.849807\n[938]\tvalid_0's rmse: 0.849802\n[939]\tvalid_0's rmse: 0.849796\n[940]\tvalid_0's rmse: 0.84978\n[941]\tvalid_0's rmse: 0.849762\n[942]\tvalid_0's rmse: 0.849765\n[943]\tvalid_0's rmse: 0.849763\n[944]\tvalid_0's rmse: 0.84975\n[945]\tvalid_0's rmse: 0.849748\n[946]\tvalid_0's rmse: 0.84974\n[947]\tvalid_0's rmse: 0.849737\n[948]\tvalid_0's rmse: 0.849726\n[949]\tvalid_0's rmse: 0.849717\n[950]\tvalid_0's rmse: 0.849719\n[951]\tvalid_0's rmse: 0.849725\n[952]\tvalid_0's rmse: 0.849721\n[953]\tvalid_0's rmse: 0.849717\n[954]\tvalid_0's rmse: 0.849719\n[955]\tvalid_0's rmse: 0.849723\n[956]\tvalid_0's rmse: 0.84972\n[957]\tvalid_0's rmse: 0.849721\n[958]\tvalid_0's rmse: 0.849717\n[959]\tvalid_0's rmse: 0.84971\n[960]\tvalid_0's rmse: 0.849712\n[961]\tvalid_0's rmse: 0.849711\n[962]\tvalid_0's rmse: 0.849707\n[963]\tvalid_0's rmse: 0.849707\n[964]\tvalid_0's rmse: 0.849703\n[965]\tvalid_0's rmse: 0.849698\n[966]\tvalid_0's rmse: 0.849685\n[967]\tvalid_0's rmse: 0.849683\n[968]\tvalid_0's rmse: 0.849682\n[969]\tvalid_0's rmse: 0.849677\n[970]\tvalid_0's rmse: 0.849674\n[971]\tvalid_0's rmse: 0.849662\n[972]\tvalid_0's rmse: 0.849651\n[973]\tvalid_0's rmse: 0.849648\n[974]\tvalid_0's rmse: 0.849639\n[975]\tvalid_0's rmse: 0.84963\n[976]\tvalid_0's rmse: 0.849626\n[977]\tvalid_0's rmse: 0.849623\n[978]\tvalid_0's rmse: 0.849624\n[979]\tvalid_0's rmse: 0.849621\n[980]\tvalid_0's rmse: 0.849618\n[981]\tvalid_0's rmse: 0.849621\n[982]\tvalid_0's rmse: 0.849617\n[983]\tvalid_0's rmse: 0.849616\n[984]\tvalid_0's rmse: 0.849607\n[985]\tvalid_0's rmse: 0.849607\n[986]\tvalid_0's rmse: 0.849606\n[987]\tvalid_0's rmse: 0.849594\n[988]\tvalid_0's rmse: 0.849591\n[989]\tvalid_0's rmse: 0.849586\n[990]\tvalid_0's rmse: 0.849583\n[991]\tvalid_0's rmse: 0.849578\n[992]\tvalid_0's rmse: 0.849573\n[993]\tvalid_0's rmse: 0.849573\n[994]\tvalid_0's rmse: 0.849572\n[995]\tvalid_0's rmse: 0.849565\n[996]\tvalid_0's rmse: 0.849562\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  85%|########5 | 17/20 [01:35<00:21,  7.23s/it]\u001b[32m[I 2021-02-05 22:53:06,467]\u001b[0m Trial 23 finished with value: 0.8495535867872835 and parameters: {'num_leaves': 3}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  85%|########5 | 17/20 [01:35<00:21,  7.23s/it]","name":"stderr"},{"output_type":"stream","text":"[997]\tvalid_0's rmse: 0.849562\n[998]\tvalid_0's rmse: 0.849562\n[999]\tvalid_0's rmse: 0.849557\n[1000]\tvalid_0's rmse: 0.849554\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's rmse: 0.849554\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019267 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888179\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885206\n[3]\tvalid_0's rmse: 0.882817\n[4]\tvalid_0's rmse: 0.880558\n[5]\tvalid_0's rmse: 0.878602\n[6]\tvalid_0's rmse: 0.8764\n[7]\tvalid_0's rmse: 0.874909\n[8]\tvalid_0's rmse: 0.873619\n[9]\tvalid_0's rmse: 0.872393\n[10]\tvalid_0's rmse: 0.871282\n[11]\tvalid_0's rmse: 0.869819\n[12]\tvalid_0's rmse: 0.868609\n[13]\tvalid_0's rmse: 0.867527\n[14]\tvalid_0's rmse: 0.866404\n[15]\tvalid_0's rmse: 0.865683\n[16]\tvalid_0's rmse: 0.864926\n[17]\tvalid_0's rmse: 0.864125\n[18]\tvalid_0's rmse: 0.863476\n[19]\tvalid_0's rmse: 0.862796\n[20]\tvalid_0's rmse: 0.862212\n[21]\tvalid_0's rmse: 0.861636\n[22]\tvalid_0's rmse: 0.860978\n[23]\tvalid_0's rmse: 0.860428\n[24]\tvalid_0's rmse: 0.859891\n[25]\tvalid_0's rmse: 0.85947\n[26]\tvalid_0's rmse: 0.859072\n[27]\tvalid_0's rmse: 0.858733\n[28]\tvalid_0's rmse: 0.858337\n[29]\tvalid_0's rmse: 0.85797\n[30]\tvalid_0's rmse: 0.857685\n[31]\tvalid_0's rmse: 0.857355\n[32]\tvalid_0's rmse: 0.856994\n[33]\tvalid_0's rmse: 0.856715\n[34]\tvalid_0's rmse: 0.856396\n[35]\tvalid_0's rmse: 0.856125\n[36]\tvalid_0's rmse: 0.855817\n[37]\tvalid_0's rmse: 0.855571\n[38]\tvalid_0's rmse: 0.855233\n[39]\tvalid_0's rmse: 0.854953\n[40]\tvalid_0's rmse: 0.854712\n[41]\tvalid_0's rmse: 0.854546\n[42]\tvalid_0's rmse: 0.854363\n[43]\tvalid_0's rmse: 0.854189\n[44]\tvalid_0's rmse: 0.853952\n[45]\tvalid_0's rmse: 0.853751\n[46]\tvalid_0's rmse: 0.853618\n[47]\tvalid_0's rmse: 0.853467\n[48]\tvalid_0's rmse: 0.853286\n[49]\tvalid_0's rmse: 0.853145\n[50]\tvalid_0's rmse: 0.853016\n[51]\tvalid_0's rmse: 0.852939\n[52]\tvalid_0's rmse: 0.85277\n[53]\tvalid_0's rmse: 0.852634\n[54]\tvalid_0's rmse: 0.852475\n[55]\tvalid_0's rmse: 0.85236\n[56]\tvalid_0's rmse: 0.852154\n[57]\tvalid_0's rmse: 0.85204\n[58]\tvalid_0's rmse: 0.851881\n[59]\tvalid_0's rmse: 0.851728\n[60]\tvalid_0's rmse: 0.851659\n[61]\tvalid_0's rmse: 0.851577\n[62]\tvalid_0's rmse: 0.851467\n[63]\tvalid_0's rmse: 0.851397\n[64]\tvalid_0's rmse: 0.851263\n[65]\tvalid_0's rmse: 0.851099\n[66]\tvalid_0's rmse: 0.851039\n[67]\tvalid_0's rmse: 0.850978\n[68]\tvalid_0's rmse: 0.850893\n[69]\tvalid_0's rmse: 0.850834\n[70]\tvalid_0's rmse: 0.850736\n[71]\tvalid_0's rmse: 0.850663\n[72]\tvalid_0's rmse: 0.850588\n[73]\tvalid_0's rmse: 0.850511\n[74]\tvalid_0's rmse: 0.850478\n[75]\tvalid_0's rmse: 0.850384\n[76]\tvalid_0's rmse: 0.850287\n[77]\tvalid_0's rmse: 0.850221\n[78]\tvalid_0's rmse: 0.85015\n[79]\tvalid_0's rmse: 0.850047\n[80]\tvalid_0's rmse: 0.849995\n[81]\tvalid_0's rmse: 0.84997\n[82]\tvalid_0's rmse: 0.849913\n[83]\tvalid_0's rmse: 0.849866\n[84]\tvalid_0's rmse: 0.849819\n[85]\tvalid_0's rmse: 0.849783\n[86]\tvalid_0's rmse: 0.849786\n[87]\tvalid_0's rmse: 0.849686\n[88]\tvalid_0's rmse: 0.849601\n[89]\tvalid_0's rmse: 0.849496\n[90]\tvalid_0's rmse: 0.849439\n[91]\tvalid_0's rmse: 0.849369\n[92]\tvalid_0's rmse: 0.849329\n[93]\tvalid_0's rmse: 0.849275\n[94]\tvalid_0's rmse: 0.849237\n[95]\tvalid_0's rmse: 0.849116\n[96]\tvalid_0's rmse: 0.849053\n[97]\tvalid_0's rmse: 0.849045\n[98]\tvalid_0's rmse: 0.849027\n[99]\tvalid_0's rmse: 0.849021\n[100]\tvalid_0's rmse: 0.849005\n[101]\tvalid_0's rmse: 0.848916\n[102]\tvalid_0's rmse: 0.848855\n[103]\tvalid_0's rmse: 0.848843\n[104]\tvalid_0's rmse: 0.848791\n[105]\tvalid_0's rmse: 0.848748\n[106]\tvalid_0's rmse: 0.848753\n[107]\tvalid_0's rmse: 0.848743\n[108]\tvalid_0's rmse: 0.848668\n[109]\tvalid_0's rmse: 0.848656\n[110]\tvalid_0's rmse: 0.848639\n[111]\tvalid_0's rmse: 0.848612\n[112]\tvalid_0's rmse: 0.848581\n[113]\tvalid_0's rmse: 0.848539\n[114]\tvalid_0's rmse: 0.848493\n[115]\tvalid_0's rmse: 0.848502\n[116]\tvalid_0's rmse: 0.848471\n[117]\tvalid_0's rmse: 0.84843\n[118]\tvalid_0's rmse: 0.848379\n[119]\tvalid_0's rmse: 0.848361\n[120]\tvalid_0's rmse: 0.848346\n[121]\tvalid_0's rmse: 0.848297\n[122]\tvalid_0's rmse: 0.848268\n[123]\tvalid_0's rmse: 0.848261\n[124]\tvalid_0's rmse: 0.84827\n[125]\tvalid_0's rmse: 0.848277\n[126]\tvalid_0's rmse: 0.848239\n[127]\tvalid_0's rmse: 0.848217\n[128]\tvalid_0's rmse: 0.848216\n[129]\tvalid_0's rmse: 0.848232\n[130]\tvalid_0's rmse: 0.84825\n[131]\tvalid_0's rmse: 0.848244\n[132]\tvalid_0's rmse: 0.848247\n[133]\tvalid_0's rmse: 0.848238\n[134]\tvalid_0's rmse: 0.84824\n[135]\tvalid_0's rmse: 0.848236\n[136]\tvalid_0's rmse: 0.848236\n[137]\tvalid_0's rmse: 0.848214\n[138]\tvalid_0's rmse: 0.848208\n[139]\tvalid_0's rmse: 0.848197\n[140]\tvalid_0's rmse: 0.848225\n[141]\tvalid_0's rmse: 0.848221\n[142]\tvalid_0's rmse: 0.848224\n[143]\tvalid_0's rmse: 0.848211\n[144]\tvalid_0's rmse: 0.848206\n[145]\tvalid_0's rmse: 0.848177\n[146]\tvalid_0's rmse: 0.848145\n[147]\tvalid_0's rmse: 0.848155\n[148]\tvalid_0's rmse: 0.848151\n[149]\tvalid_0's rmse: 0.848132\n[150]\tvalid_0's rmse: 0.848121\n[151]\tvalid_0's rmse: 0.848069\n[152]\tvalid_0's rmse: 0.848045\n[153]\tvalid_0's rmse: 0.848041\n[154]\tvalid_0's rmse: 0.848051\n[155]\tvalid_0's rmse: 0.848055\n[156]\tvalid_0's rmse: 0.848052\n[157]\tvalid_0's rmse: 0.848027\n[158]\tvalid_0's rmse: 0.848036\n[159]\tvalid_0's rmse: 0.848011\n[160]\tvalid_0's rmse: 0.847953\n[161]\tvalid_0's rmse: 0.847926\n[162]\tvalid_0's rmse: 0.847937\n[163]\tvalid_0's rmse: 0.847932\n[164]\tvalid_0's rmse: 0.847934\n[165]\tvalid_0's rmse: 0.847929\n[166]\tvalid_0's rmse: 0.847888\n[167]\tvalid_0's rmse: 0.847884\n[168]\tvalid_0's rmse: 0.847881\n[169]\tvalid_0's rmse: 0.84787\n[170]\tvalid_0's rmse: 0.847875\n[171]\tvalid_0's rmse: 0.847866\n[172]\tvalid_0's rmse: 0.847891\n[173]\tvalid_0's rmse: 0.847928\n[174]\tvalid_0's rmse: 0.847914\n[175]\tvalid_0's rmse: 0.847917\n[176]\tvalid_0's rmse: 0.847922\n[177]\tvalid_0's rmse: 0.847885\n[178]\tvalid_0's rmse: 0.847915\n[179]\tvalid_0's rmse: 0.847934\n[180]\tvalid_0's rmse: 0.847909\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  90%|######### | 18/20 [01:40<00:12,  6.48s/it]\u001b[32m[I 2021-02-05 22:53:11,196]\u001b[0m Trial 24 finished with value: 0.8478655703760813 and parameters: {'num_leaves': 52}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  90%|######### | 18/20 [01:40<00:12,  6.48s/it]","name":"stderr"},{"output_type":"stream","text":"[181]\tvalid_0's rmse: 0.847878\nEarly stopping, best iteration is:\n[171]\tvalid_0's rmse: 0.847866\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019077 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888327\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.88553\n[3]\tvalid_0's rmse: 0.883277\n[4]\tvalid_0's rmse: 0.881101\n[5]\tvalid_0's rmse: 0.879222\n[6]\tvalid_0's rmse: 0.877163\n[7]\tvalid_0's rmse: 0.875673\n[8]\tvalid_0's rmse: 0.874417\n[9]\tvalid_0's rmse: 0.87325\n[10]\tvalid_0's rmse: 0.872176\n[11]\tvalid_0's rmse: 0.870788\n[12]\tvalid_0's rmse: 0.869586\n[13]\tvalid_0's rmse: 0.868556\n[14]\tvalid_0's rmse: 0.867516\n[15]\tvalid_0's rmse: 0.8668\n[16]\tvalid_0's rmse: 0.866026\n[17]\tvalid_0's rmse: 0.865197\n[18]\tvalid_0's rmse: 0.864563\n[19]\tvalid_0's rmse: 0.86388\n[20]\tvalid_0's rmse: 0.863259\n[21]\tvalid_0's rmse: 0.862719\n[22]\tvalid_0's rmse: 0.862076\n[23]\tvalid_0's rmse: 0.861554\n[24]\tvalid_0's rmse: 0.860993\n[25]\tvalid_0's rmse: 0.860671\n[26]\tvalid_0's rmse: 0.860248\n[27]\tvalid_0's rmse: 0.859854\n[28]\tvalid_0's rmse: 0.859462\n[29]\tvalid_0's rmse: 0.859089\n[30]\tvalid_0's rmse: 0.858726\n[31]\tvalid_0's rmse: 0.858412\n[32]\tvalid_0's rmse: 0.858036\n[33]\tvalid_0's rmse: 0.857754\n[34]\tvalid_0's rmse: 0.857394\n[35]\tvalid_0's rmse: 0.857133\n[36]\tvalid_0's rmse: 0.856816\n[37]\tvalid_0's rmse: 0.856551\n[38]\tvalid_0's rmse: 0.856248\n[39]\tvalid_0's rmse: 0.855961\n[40]\tvalid_0's rmse: 0.855708\n[41]\tvalid_0's rmse: 0.855551\n[42]\tvalid_0's rmse: 0.855327\n[43]\tvalid_0's rmse: 0.855137\n[44]\tvalid_0's rmse: 0.854845\n[45]\tvalid_0's rmse: 0.854645\n[46]\tvalid_0's rmse: 0.854487\n[47]\tvalid_0's rmse: 0.854342\n[48]\tvalid_0's rmse: 0.854183\n[49]\tvalid_0's rmse: 0.854043\n[50]\tvalid_0's rmse: 0.853917\n[51]\tvalid_0's rmse: 0.853823\n[52]\tvalid_0's rmse: 0.853656\n[53]\tvalid_0's rmse: 0.853491\n[54]\tvalid_0's rmse: 0.853332\n[55]\tvalid_0's rmse: 0.853227\n[56]\tvalid_0's rmse: 0.853031\n[57]\tvalid_0's rmse: 0.852912\n[58]\tvalid_0's rmse: 0.852773\n[59]\tvalid_0's rmse: 0.85269\n[60]\tvalid_0's rmse: 0.852552\n[61]\tvalid_0's rmse: 0.852445\n[62]\tvalid_0's rmse: 0.852328\n[63]\tvalid_0's rmse: 0.852181\n[64]\tvalid_0's rmse: 0.852048\n[65]\tvalid_0's rmse: 0.851935\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851777\n[68]\tvalid_0's rmse: 0.851686\n[69]\tvalid_0's rmse: 0.851591\n[70]\tvalid_0's rmse: 0.851471\n[71]\tvalid_0's rmse: 0.851382\n[72]\tvalid_0's rmse: 0.851339\n[73]\tvalid_0's rmse: 0.851308\n[74]\tvalid_0's rmse: 0.851227\n[75]\tvalid_0's rmse: 0.851131\n[76]\tvalid_0's rmse: 0.85106\n[77]\tvalid_0's rmse: 0.85099\n[78]\tvalid_0's rmse: 0.850936\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850795\n[81]\tvalid_0's rmse: 0.850735\n[82]\tvalid_0's rmse: 0.85067\n[83]\tvalid_0's rmse: 0.850602\n[84]\tvalid_0's rmse: 0.850516\n[85]\tvalid_0's rmse: 0.850457\n[86]\tvalid_0's rmse: 0.85039\n[87]\tvalid_0's rmse: 0.850354\n[88]\tvalid_0's rmse: 0.850253\n[89]\tvalid_0's rmse: 0.850211\n[90]\tvalid_0's rmse: 0.850156\n[91]\tvalid_0's rmse: 0.850075\n[92]\tvalid_0's rmse: 0.850046\n[93]\tvalid_0's rmse: 0.849995\n[94]\tvalid_0's rmse: 0.849943\n[95]\tvalid_0's rmse: 0.849841\n[96]\tvalid_0's rmse: 0.849809\n[97]\tvalid_0's rmse: 0.849765\n[98]\tvalid_0's rmse: 0.84974\n[99]\tvalid_0's rmse: 0.849712\n[100]\tvalid_0's rmse: 0.849652\n[101]\tvalid_0's rmse: 0.849592\n[102]\tvalid_0's rmse: 0.849517\n[103]\tvalid_0's rmse: 0.84948\n[104]\tvalid_0's rmse: 0.849452\n[105]\tvalid_0's rmse: 0.849398\n[106]\tvalid_0's rmse: 0.849387\n[107]\tvalid_0's rmse: 0.84936\n[108]\tvalid_0's rmse: 0.849305\n[109]\tvalid_0's rmse: 0.849254\n[110]\tvalid_0's rmse: 0.84921\n[111]\tvalid_0's rmse: 0.849106\n[112]\tvalid_0's rmse: 0.849087\n[113]\tvalid_0's rmse: 0.849047\n[114]\tvalid_0's rmse: 0.849014\n[115]\tvalid_0's rmse: 0.849018\n[116]\tvalid_0's rmse: 0.848986\n[117]\tvalid_0's rmse: 0.848936\n[118]\tvalid_0's rmse: 0.848918\n[119]\tvalid_0's rmse: 0.848886\n[120]\tvalid_0's rmse: 0.848889\n[121]\tvalid_0's rmse: 0.848846\n[122]\tvalid_0's rmse: 0.848844\n[123]\tvalid_0's rmse: 0.84881\n[124]\tvalid_0's rmse: 0.848796\n[125]\tvalid_0's rmse: 0.848766\n[126]\tvalid_0's rmse: 0.848763\n[127]\tvalid_0's rmse: 0.8487\n[128]\tvalid_0's rmse: 0.848672\n[129]\tvalid_0's rmse: 0.848648\n[130]\tvalid_0's rmse: 0.848615\n[131]\tvalid_0's rmse: 0.848594\n[132]\tvalid_0's rmse: 0.848612\n[133]\tvalid_0's rmse: 0.84858\n[134]\tvalid_0's rmse: 0.848549\n[135]\tvalid_0's rmse: 0.848528\n[136]\tvalid_0's rmse: 0.848511\n[137]\tvalid_0's rmse: 0.848435\n[138]\tvalid_0's rmse: 0.848448\n[139]\tvalid_0's rmse: 0.848425\n[140]\tvalid_0's rmse: 0.848433\n[141]\tvalid_0's rmse: 0.848409\n[142]\tvalid_0's rmse: 0.848387\n[143]\tvalid_0's rmse: 0.848369\n[144]\tvalid_0's rmse: 0.848369\n[145]\tvalid_0's rmse: 0.848372\n[146]\tvalid_0's rmse: 0.848354\n[147]\tvalid_0's rmse: 0.848287\n[148]\tvalid_0's rmse: 0.848279\n[149]\tvalid_0's rmse: 0.848305\n[150]\tvalid_0's rmse: 0.84827\n[151]\tvalid_0's rmse: 0.848259\n[152]\tvalid_0's rmse: 0.848266\n[153]\tvalid_0's rmse: 0.848247\n[154]\tvalid_0's rmse: 0.848268\n[155]\tvalid_0's rmse: 0.848281\n[156]\tvalid_0's rmse: 0.848275\n[157]\tvalid_0's rmse: 0.848276\n[158]\tvalid_0's rmse: 0.848267\n[159]\tvalid_0's rmse: 0.848214\n[160]\tvalid_0's rmse: 0.848202\n[161]\tvalid_0's rmse: 0.848144\n[162]\tvalid_0's rmse: 0.848163\n[163]\tvalid_0's rmse: 0.848181\n[164]\tvalid_0's rmse: 0.848177\n[165]\tvalid_0's rmse: 0.848174\n[166]\tvalid_0's rmse: 0.848143\n[167]\tvalid_0's rmse: 0.848166\n[168]\tvalid_0's rmse: 0.848169\n[169]\tvalid_0's rmse: 0.848178\n[170]\tvalid_0's rmse: 0.848174\n[171]\tvalid_0's rmse: 0.848152\n[172]\tvalid_0's rmse: 0.848138\n[173]\tvalid_0's rmse: 0.848137\n[174]\tvalid_0's rmse: 0.848135\n[175]\tvalid_0's rmse: 0.848132\n[176]\tvalid_0's rmse: 0.848121\n[177]\tvalid_0's rmse: 0.848118\n[178]\tvalid_0's rmse: 0.84811\n[179]\tvalid_0's rmse: 0.848094\n[180]\tvalid_0's rmse: 0.848106\n[181]\tvalid_0's rmse: 0.848115\n[182]\tvalid_0's rmse: 0.8481\n[183]\tvalid_0's rmse: 0.848075\n[184]\tvalid_0's rmse: 0.848092\n[185]\tvalid_0's rmse: 0.848087\n[186]\tvalid_0's rmse: 0.848096\n[187]\tvalid_0's rmse: 0.848064\n[188]\tvalid_0's rmse: 0.848057\n[189]\tvalid_0's rmse: 0.848044\n[190]\tvalid_0's rmse: 0.847997\n[191]\tvalid_0's rmse: 0.847992\n[192]\tvalid_0's rmse: 0.847973\n[193]\tvalid_0's rmse: 0.847987\n[194]\tvalid_0's rmse: 0.847971\n[195]\tvalid_0's rmse: 0.847997\n[196]\tvalid_0's rmse: 0.847996\n[197]\tvalid_0's rmse: 0.847981\n[198]\tvalid_0's rmse: 0.847974\n[199]\tvalid_0's rmse: 0.84795\n[200]\tvalid_0's rmse: 0.847948\n[201]\tvalid_0's rmse: 0.847934\n[202]\tvalid_0's rmse: 0.847936\n[203]\tvalid_0's rmse: 0.847947\n[204]\tvalid_0's rmse: 0.847945\n[205]\tvalid_0's rmse: 0.847937\n[206]\tvalid_0's rmse: 0.847935\n[207]\tvalid_0's rmse: 0.847932\n[208]\tvalid_0's rmse: 0.84791\n[209]\tvalid_0's rmse: 0.84791\n[210]\tvalid_0's rmse: 0.847895\n[211]\tvalid_0's rmse: 0.847897\n[212]\tvalid_0's rmse: 0.847857\n[213]\tvalid_0's rmse: 0.847844\n[214]\tvalid_0's rmse: 0.847836\n[215]\tvalid_0's rmse: 0.847833\n[216]\tvalid_0's rmse: 0.847835\n[217]\tvalid_0's rmse: 0.847842\n[218]\tvalid_0's rmse: 0.847829\n[219]\tvalid_0's rmse: 0.84784\n[220]\tvalid_0's rmse: 0.847827\n[221]\tvalid_0's rmse: 0.847832\n[222]\tvalid_0's rmse: 0.847837\n[223]\tvalid_0's rmse: 0.847834\n[224]\tvalid_0's rmse: 0.847838\n[225]\tvalid_0's rmse: 0.847851\n[226]\tvalid_0's rmse: 0.847839\n[227]\tvalid_0's rmse: 0.847826\n[228]\tvalid_0's rmse: 0.847831\n[229]\tvalid_0's rmse: 0.847845\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465:  95%|#########5| 19/20 [01:45<00:06,  6.14s/it]","name":"stderr"},{"output_type":"stream","text":"[230]\tvalid_0's rmse: 0.847822\n[231]\tvalid_0's rmse: 0.847816\n[232]\tvalid_0's rmse: 0.847819\n[233]\tvalid_0's rmse: 0.847821\n[234]\tvalid_0's rmse: 0.847818\n[235]\tvalid_0's rmse: 0.847837\n[236]\tvalid_0's rmse: 0.847843\n[237]\tvalid_0's rmse: 0.847839\n[238]\tvalid_0's rmse: 0.847821\n[239]\tvalid_0's rmse: 0.847818\n[240]\tvalid_0's rmse: 0.847821\n[241]\tvalid_0's rmse: 0.847825\nEarly stopping, best iteration is:\n[231]\tvalid_0's rmse: 0.847816\n","name":"stdout"},{"output_type":"stream","text":"\u001b[32m[I 2021-02-05 22:53:16,550]\u001b[0m Trial 25 finished with value: 0.8478159777558572 and parameters: {'num_leaves': 35}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465:  95%|#########5| 19/20 [01:45<00:06,  6.14s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019492 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88788\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.884603\n[3]\tvalid_0's rmse: 0.88207\n[4]\tvalid_0's rmse: 0.879603\n[5]\tvalid_0's rmse: 0.877474\n[6]\tvalid_0's rmse: 0.875105\n[7]\tvalid_0's rmse: 0.873489\n[8]\tvalid_0's rmse: 0.872088\n[9]\tvalid_0's rmse: 0.870766\n[10]\tvalid_0's rmse: 0.869594\n[11]\tvalid_0's rmse: 0.868015\n[12]\tvalid_0's rmse: 0.866718\n[13]\tvalid_0's rmse: 0.865603\n[14]\tvalid_0's rmse: 0.864434\n[15]\tvalid_0's rmse: 0.863634\n[16]\tvalid_0's rmse: 0.862892\n[17]\tvalid_0's rmse: 0.862045\n[18]\tvalid_0's rmse: 0.861402\n[19]\tvalid_0's rmse: 0.860696\n[20]\tvalid_0's rmse: 0.860113\n[21]\tvalid_0's rmse: 0.859516\n[22]\tvalid_0's rmse: 0.858938\n[23]\tvalid_0's rmse: 0.858426\n[24]\tvalid_0's rmse: 0.857897\n[25]\tvalid_0's rmse: 0.857537\n[26]\tvalid_0's rmse: 0.857106\n[27]\tvalid_0's rmse: 0.856786\n[28]\tvalid_0's rmse: 0.856386\n[29]\tvalid_0's rmse: 0.855989\n[30]\tvalid_0's rmse: 0.855701\n[31]\tvalid_0's rmse: 0.855428\n[32]\tvalid_0's rmse: 0.855026\n[33]\tvalid_0's rmse: 0.854718\n[34]\tvalid_0's rmse: 0.854372\n[35]\tvalid_0's rmse: 0.854141\n[36]\tvalid_0's rmse: 0.853872\n[37]\tvalid_0's rmse: 0.853676\n[38]\tvalid_0's rmse: 0.853411\n[39]\tvalid_0's rmse: 0.853155\n[40]\tvalid_0's rmse: 0.852932\n[41]\tvalid_0's rmse: 0.852787\n[42]\tvalid_0's rmse: 0.852609\n[43]\tvalid_0's rmse: 0.852464\n[44]\tvalid_0's rmse: 0.852224\n[45]\tvalid_0's rmse: 0.852049\n[46]\tvalid_0's rmse: 0.851944\n[47]\tvalid_0's rmse: 0.851772\n[48]\tvalid_0's rmse: 0.851592\n[49]\tvalid_0's rmse: 0.851488\n[50]\tvalid_0's rmse: 0.851371\n[51]\tvalid_0's rmse: 0.851332\n[52]\tvalid_0's rmse: 0.85118\n[53]\tvalid_0's rmse: 0.851016\n[54]\tvalid_0's rmse: 0.850911\n[55]\tvalid_0's rmse: 0.850873\n[56]\tvalid_0's rmse: 0.85077\n[57]\tvalid_0's rmse: 0.850612\n[58]\tvalid_0's rmse: 0.850535\n[59]\tvalid_0's rmse: 0.850459\n[60]\tvalid_0's rmse: 0.850378\n[61]\tvalid_0's rmse: 0.850271\n[62]\tvalid_0's rmse: 0.850228\n[63]\tvalid_0's rmse: 0.850095\n[64]\tvalid_0's rmse: 0.850032\n[65]\tvalid_0's rmse: 0.849905\n[66]\tvalid_0's rmse: 0.84983\n[67]\tvalid_0's rmse: 0.84979\n[68]\tvalid_0's rmse: 0.849719\n[69]\tvalid_0's rmse: 0.849636\n[70]\tvalid_0's rmse: 0.849545\n[71]\tvalid_0's rmse: 0.849503\n[72]\tvalid_0's rmse: 0.849455\n[73]\tvalid_0's rmse: 0.849392\n[74]\tvalid_0's rmse: 0.849346\n[75]\tvalid_0's rmse: 0.849257\n[76]\tvalid_0's rmse: 0.849157\n[77]\tvalid_0's rmse: 0.849138\n[78]\tvalid_0's rmse: 0.849123\n[79]\tvalid_0's rmse: 0.849054\n[80]\tvalid_0's rmse: 0.849021\n[81]\tvalid_0's rmse: 0.849021\n[82]\tvalid_0's rmse: 0.848994\n[83]\tvalid_0's rmse: 0.848974\n[84]\tvalid_0's rmse: 0.848923\n[85]\tvalid_0's rmse: 0.848922\n[86]\tvalid_0's rmse: 0.848938\n[87]\tvalid_0's rmse: 0.848906\n[88]\tvalid_0's rmse: 0.84887\n[89]\tvalid_0's rmse: 0.848855\n[90]\tvalid_0's rmse: 0.848826\n[91]\tvalid_0's rmse: 0.848816\n[92]\tvalid_0's rmse: 0.848784\n[93]\tvalid_0's rmse: 0.848727\n[94]\tvalid_0's rmse: 0.848722\n[95]\tvalid_0's rmse: 0.848694\n[96]\tvalid_0's rmse: 0.84871\n[97]\tvalid_0's rmse: 0.848758\n[98]\tvalid_0's rmse: 0.848689\n[99]\tvalid_0's rmse: 0.848661\n[100]\tvalid_0's rmse: 0.848621\n[101]\tvalid_0's rmse: 0.848609\n[102]\tvalid_0's rmse: 0.848617\n[103]\tvalid_0's rmse: 0.848573\n[104]\tvalid_0's rmse: 0.848517\n[105]\tvalid_0's rmse: 0.848514\n[106]\tvalid_0's rmse: 0.8485\n[107]\tvalid_0's rmse: 0.848491\n[108]\tvalid_0's rmse: 0.848516\n[109]\tvalid_0's rmse: 0.848499\n[110]\tvalid_0's rmse: 0.848515\n[111]\tvalid_0's rmse: 0.848551\n[112]\tvalid_0's rmse: 0.848528\n[113]\tvalid_0's rmse: 0.848495\n[114]\tvalid_0's rmse: 0.8485\n[115]\tvalid_0's rmse: 0.848479\n[116]\tvalid_0's rmse: 0.848474\n[117]\tvalid_0's rmse: 0.848456\n[118]\tvalid_0's rmse: 0.84845\n[119]\tvalid_0's rmse: 0.848463\n[120]\tvalid_0's rmse: 0.848494\n[121]\tvalid_0's rmse: 0.848463\n[122]\tvalid_0's rmse: 0.848437\n[123]\tvalid_0's rmse: 0.848425\n[124]\tvalid_0's rmse: 0.848422\n[125]\tvalid_0's rmse: 0.848396\n[126]\tvalid_0's rmse: 0.848407\n[127]\tvalid_0's rmse: 0.848364\n[128]\tvalid_0's rmse: 0.848359\n[129]\tvalid_0's rmse: 0.848342\n[130]\tvalid_0's rmse: 0.848386\n[131]\tvalid_0's rmse: 0.848397\n[132]\tvalid_0's rmse: 0.848441\n[133]\tvalid_0's rmse: 0.848442\n[134]\tvalid_0's rmse: 0.848447\n[135]\tvalid_0's rmse: 0.848436\n[136]\tvalid_0's rmse: 0.848425\n[137]\tvalid_0's rmse: 0.84842\n[138]\tvalid_0's rmse: 0.848443\n[139]\tvalid_0's rmse: 0.84842\nEarly stopping, best iteration is:\n[129]\tvalid_0's rmse: 0.848342\n","name":"stdout"},{"output_type":"stream","text":"num_leaves, val_score: 0.847465: 100%|##########| 20/20 [01:50<00:00,  5.72s/it]\u001b[32m[I 2021-02-05 22:53:21,279]\u001b[0m Trial 26 finished with value: 0.8483424593370189 and parameters: {'num_leaves': 121}. Best is trial 15 with value: 0.8474653536625801.\u001b[0m\nnum_leaves, val_score: 0.847465: 100%|##########| 20/20 [01:50<00:00,  5.52s/it]\nbagging, val_score: 0.847465:   0%|          | 0/10 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019636 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888369\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885611\n[3]\tvalid_0's rmse: 0.883442\n[4]\tvalid_0's rmse: 0.881293\n[5]\tvalid_0's rmse: 0.879428\n[6]\tvalid_0's rmse: 0.877352\n[7]\tvalid_0's rmse: 0.875753\n[8]\tvalid_0's rmse: 0.874521\n[9]\tvalid_0's rmse: 0.873369\n[10]\tvalid_0's rmse: 0.872303\n[11]\tvalid_0's rmse: 0.870885\n[12]\tvalid_0's rmse: 0.869663\n[13]\tvalid_0's rmse: 0.868633\n[14]\tvalid_0's rmse: 0.86758\n[15]\tvalid_0's rmse: 0.866901\n[16]\tvalid_0's rmse: 0.866167\n[17]\tvalid_0's rmse: 0.86536\n[18]\tvalid_0's rmse: 0.864618\n[19]\tvalid_0's rmse: 0.863948\n[20]\tvalid_0's rmse: 0.863338\n[21]\tvalid_0's rmse: 0.862786\n[22]\tvalid_0's rmse: 0.862172\n[23]\tvalid_0's rmse: 0.86166\n[24]\tvalid_0's rmse: 0.861131\n[25]\tvalid_0's rmse: 0.860666\n[26]\tvalid_0's rmse: 0.860237\n[27]\tvalid_0's rmse: 0.859864\n[28]\tvalid_0's rmse: 0.859469\n[29]\tvalid_0's rmse: 0.859059\n[30]\tvalid_0's rmse: 0.858779\n[31]\tvalid_0's rmse: 0.858387\n[32]\tvalid_0's rmse: 0.858073\n[33]\tvalid_0's rmse: 0.857786\n[34]\tvalid_0's rmse: 0.857465\n[35]\tvalid_0's rmse: 0.857254\n[36]\tvalid_0's rmse: 0.856918\n[37]\tvalid_0's rmse: 0.856652\n[38]\tvalid_0's rmse: 0.856299\n[39]\tvalid_0's rmse: 0.856038\n[40]\tvalid_0's rmse: 0.855752\n[41]\tvalid_0's rmse: 0.85555\n[42]\tvalid_0's rmse: 0.855364\n[43]\tvalid_0's rmse: 0.855134\n[44]\tvalid_0's rmse: 0.854944\n[45]\tvalid_0's rmse: 0.854718\n[46]\tvalid_0's rmse: 0.854458\n[47]\tvalid_0's rmse: 0.854322\n[48]\tvalid_0's rmse: 0.854156\n[49]\tvalid_0's rmse: 0.853941\n[50]\tvalid_0's rmse: 0.853765\n[51]\tvalid_0's rmse: 0.853649\n[52]\tvalid_0's rmse: 0.853418\n[53]\tvalid_0's rmse: 0.853157\n[54]\tvalid_0's rmse: 0.853019\n[55]\tvalid_0's rmse: 0.852935\n[56]\tvalid_0's rmse: 0.852742\n[57]\tvalid_0's rmse: 0.852615\n[58]\tvalid_0's rmse: 0.852477\n[59]\tvalid_0's rmse: 0.852394\n[60]\tvalid_0's rmse: 0.852252\n[61]\tvalid_0's rmse: 0.852171\n[62]\tvalid_0's rmse: 0.85206\n[63]\tvalid_0's rmse: 0.851923\n[64]\tvalid_0's rmse: 0.851758\n[65]\tvalid_0's rmse: 0.851622\n[66]\tvalid_0's rmse: 0.851528\n[67]\tvalid_0's rmse: 0.851477\n[68]\tvalid_0's rmse: 0.851384\n[69]\tvalid_0's rmse: 0.851251\n[70]\tvalid_0's rmse: 0.851229\n[71]\tvalid_0's rmse: 0.851146\n[72]\tvalid_0's rmse: 0.851111\n[73]\tvalid_0's rmse: 0.851028\n[74]\tvalid_0's rmse: 0.850989\n[75]\tvalid_0's rmse: 0.850913\n[76]\tvalid_0's rmse: 0.850797\n[77]\tvalid_0's rmse: 0.850718\n[78]\tvalid_0's rmse: 0.850681\n[79]\tvalid_0's rmse: 0.850581\n[80]\tvalid_0's rmse: 0.850546\n[81]\tvalid_0's rmse: 0.850503\n[82]\tvalid_0's rmse: 0.850462\n[83]\tvalid_0's rmse: 0.850358\n[84]\tvalid_0's rmse: 0.850262\n[85]\tvalid_0's rmse: 0.850176\n[86]\tvalid_0's rmse: 0.850166\n[87]\tvalid_0's rmse: 0.850067\n[88]\tvalid_0's rmse: 0.850013\n[89]\tvalid_0's rmse: 0.849925\n[90]\tvalid_0's rmse: 0.84986\n[91]\tvalid_0's rmse: 0.849767\n[92]\tvalid_0's rmse: 0.84971\n[93]\tvalid_0's rmse: 0.849663\n[94]\tvalid_0's rmse: 0.849608\n[95]\tvalid_0's rmse: 0.849569\n[96]\tvalid_0's rmse: 0.849508\n[97]\tvalid_0's rmse: 0.849497\n[98]\tvalid_0's rmse: 0.849439\n[99]\tvalid_0's rmse: 0.849415\n[100]\tvalid_0's rmse: 0.849388\n[101]\tvalid_0's rmse: 0.849373\n[102]\tvalid_0's rmse: 0.849324\n[103]\tvalid_0's rmse: 0.849298\n[104]\tvalid_0's rmse: 0.849239\n[105]\tvalid_0's rmse: 0.849207\n[106]\tvalid_0's rmse: 0.849207\n[107]\tvalid_0's rmse: 0.849195\n[108]\tvalid_0's rmse: 0.849159\n[109]\tvalid_0's rmse: 0.849129\n[110]\tvalid_0's rmse: 0.849124\n[111]\tvalid_0's rmse: 0.849103\n[112]\tvalid_0's rmse: 0.849045\n[113]\tvalid_0's rmse: 0.848992\n[114]\tvalid_0's rmse: 0.849001\n[115]\tvalid_0's rmse: 0.848974\n[116]\tvalid_0's rmse: 0.848954\n[117]\tvalid_0's rmse: 0.84894\n[118]\tvalid_0's rmse: 0.848891\n[119]\tvalid_0's rmse: 0.848891\n[120]\tvalid_0's rmse: 0.848875\n[121]\tvalid_0's rmse: 0.848794\n[122]\tvalid_0's rmse: 0.848727\n[123]\tvalid_0's rmse: 0.848726\n[124]\tvalid_0's rmse: 0.848688\n[125]\tvalid_0's rmse: 0.848676\n[126]\tvalid_0's rmse: 0.848651\n[127]\tvalid_0's rmse: 0.848629\n[128]\tvalid_0's rmse: 0.848601\n[129]\tvalid_0's rmse: 0.848597\n[130]\tvalid_0's rmse: 0.848617\n[131]\tvalid_0's rmse: 0.848616\n[132]\tvalid_0's rmse: 0.848607\n[133]\tvalid_0's rmse: 0.8486\n[134]\tvalid_0's rmse: 0.848573\n[135]\tvalid_0's rmse: 0.848523\n[136]\tvalid_0's rmse: 0.848478\n[137]\tvalid_0's rmse: 0.848469\n[138]\tvalid_0's rmse: 0.84844\n[139]\tvalid_0's rmse: 0.848406\n[140]\tvalid_0's rmse: 0.848401\n[141]\tvalid_0's rmse: 0.848379\n[142]\tvalid_0's rmse: 0.848342\n[143]\tvalid_0's rmse: 0.848357\n[144]\tvalid_0's rmse: 0.848345\n[145]\tvalid_0's rmse: 0.84833\n[146]\tvalid_0's rmse: 0.848321\n[147]\tvalid_0's rmse: 0.848316\n[148]\tvalid_0's rmse: 0.848297\n[149]\tvalid_0's rmse: 0.848253\n[150]\tvalid_0's rmse: 0.848229\n[151]\tvalid_0's rmse: 0.848215\n[152]\tvalid_0's rmse: 0.84819\n[153]\tvalid_0's rmse: 0.848193\n[154]\tvalid_0's rmse: 0.848161\n[155]\tvalid_0's rmse: 0.848137\n[156]\tvalid_0's rmse: 0.848143\n[157]\tvalid_0's rmse: 0.848148\n[158]\tvalid_0's rmse: 0.848152\n[159]\tvalid_0's rmse: 0.848143\n[160]\tvalid_0's rmse: 0.848102\n[161]\tvalid_0's rmse: 0.848055\n[162]\tvalid_0's rmse: 0.848072\n[163]\tvalid_0's rmse: 0.84805\n[164]\tvalid_0's rmse: 0.848052\n[165]\tvalid_0's rmse: 0.848032\n[166]\tvalid_0's rmse: 0.847982\n[167]\tvalid_0's rmse: 0.847942\n[168]\tvalid_0's rmse: 0.847928\n[169]\tvalid_0's rmse: 0.847928\n[170]\tvalid_0's rmse: 0.847926\n[171]\tvalid_0's rmse: 0.847928\n[172]\tvalid_0's rmse: 0.847922\n[173]\tvalid_0's rmse: 0.847894\n[174]\tvalid_0's rmse: 0.847884\n[175]\tvalid_0's rmse: 0.84787\n[176]\tvalid_0's rmse: 0.847871\n[177]\tvalid_0's rmse: 0.847847\n[178]\tvalid_0's rmse: 0.847799\n[179]\tvalid_0's rmse: 0.847793\n[180]\tvalid_0's rmse: 0.847785\n[181]\tvalid_0's rmse: 0.847801\n[182]\tvalid_0's rmse: 0.847793\n[183]\tvalid_0's rmse: 0.847793\n[184]\tvalid_0's rmse: 0.847794\n[185]\tvalid_0's rmse: 0.84779\n[186]\tvalid_0's rmse: 0.847805\n[187]\tvalid_0's rmse: 0.847801\n[188]\tvalid_0's rmse: 0.847754\n[189]\tvalid_0's rmse: 0.847734\n[190]\tvalid_0's rmse: 0.847705\n[191]\tvalid_0's rmse: 0.847702\n[192]\tvalid_0's rmse: 0.84769\n[193]\tvalid_0's rmse: 0.847653\n[194]\tvalid_0's rmse: 0.847629\n[195]\tvalid_0's rmse: 0.847637\n[196]\tvalid_0's rmse: 0.847629\n[197]\tvalid_0's rmse: 0.847638\n[198]\tvalid_0's rmse: 0.847613\n[199]\tvalid_0's rmse: 0.847619\n[200]\tvalid_0's rmse: 0.847615\n[201]\tvalid_0's rmse: 0.847584\n[202]\tvalid_0's rmse: 0.847581\n[203]\tvalid_0's rmse: 0.847593\n[204]\tvalid_0's rmse: 0.847607\n[205]\tvalid_0's rmse: 0.847593\n[206]\tvalid_0's rmse: 0.847597\n[207]\tvalid_0's rmse: 0.847591\n[208]\tvalid_0's rmse: 0.847574\n[209]\tvalid_0's rmse: 0.847597\n[210]\tvalid_0's rmse: 0.847606\n[211]\tvalid_0's rmse: 0.847595\n[212]\tvalid_0's rmse: 0.847602\n[213]\tvalid_0's rmse: 0.847597\n[214]\tvalid_0's rmse: 0.847594\n[215]\tvalid_0's rmse: 0.847583\n[216]\tvalid_0's rmse: 0.847589\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  10%|#         | 1/10 [00:06<00:58,  6.49s/it]\u001b[32m[I 2021-02-05 22:53:27,785]\u001b[0m Trial 27 finished with value: 0.8475737813884511 and parameters: {'bagging_fraction': 0.659747429104325, 'bagging_freq': 3}. Best is trial 27 with value: 0.8475737813884511.\u001b[0m\nbagging, val_score: 0.847465:  10%|#         | 1/10 [00:06<00:58,  6.49s/it]","name":"stderr"},{"output_type":"stream","text":"[217]\tvalid_0's rmse: 0.847593\n[218]\tvalid_0's rmse: 0.847576\nEarly stopping, best iteration is:\n[208]\tvalid_0's rmse: 0.847574\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019093 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88838\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885608\n[3]\tvalid_0's rmse: 0.883375\n[4]\tvalid_0's rmse: 0.881208\n[5]\tvalid_0's rmse: 0.879352\n[6]\tvalid_0's rmse: 0.877302\n[7]\tvalid_0's rmse: 0.875825\n[8]\tvalid_0's rmse: 0.874601\n[9]\tvalid_0's rmse: 0.873462\n[10]\tvalid_0's rmse: 0.87239\n[11]\tvalid_0's rmse: 0.87101\n[12]\tvalid_0's rmse: 0.869824\n[13]\tvalid_0's rmse: 0.868777\n[14]\tvalid_0's rmse: 0.867688\n[15]\tvalid_0's rmse: 0.866973\n[16]\tvalid_0's rmse: 0.866201\n[17]\tvalid_0's rmse: 0.865348\n[18]\tvalid_0's rmse: 0.864645\n[19]\tvalid_0's rmse: 0.863981\n[20]\tvalid_0's rmse: 0.863452\n[21]\tvalid_0's rmse: 0.862904\n[22]\tvalid_0's rmse: 0.862316\n[23]\tvalid_0's rmse: 0.861789\n[24]\tvalid_0's rmse: 0.861265\n[25]\tvalid_0's rmse: 0.860823\n[26]\tvalid_0's rmse: 0.860412\n[27]\tvalid_0's rmse: 0.860051\n[28]\tvalid_0's rmse: 0.859672\n[29]\tvalid_0's rmse: 0.859262\n[30]\tvalid_0's rmse: 0.858935\n[31]\tvalid_0's rmse: 0.858604\n[32]\tvalid_0's rmse: 0.858278\n[33]\tvalid_0's rmse: 0.857966\n[34]\tvalid_0's rmse: 0.857659\n[35]\tvalid_0's rmse: 0.857394\n[36]\tvalid_0's rmse: 0.857071\n[37]\tvalid_0's rmse: 0.856766\n[38]\tvalid_0's rmse: 0.856448\n[39]\tvalid_0's rmse: 0.85615\n[40]\tvalid_0's rmse: 0.855899\n[41]\tvalid_0's rmse: 0.855739\n[42]\tvalid_0's rmse: 0.855526\n[43]\tvalid_0's rmse: 0.855335\n[44]\tvalid_0's rmse: 0.855105\n[45]\tvalid_0's rmse: 0.854953\n[46]\tvalid_0's rmse: 0.85479\n[47]\tvalid_0's rmse: 0.8546\n[48]\tvalid_0's rmse: 0.85445\n[49]\tvalid_0's rmse: 0.854254\n[50]\tvalid_0's rmse: 0.854126\n[51]\tvalid_0's rmse: 0.85402\n[52]\tvalid_0's rmse: 0.853834\n[53]\tvalid_0's rmse: 0.853659\n[54]\tvalid_0's rmse: 0.853534\n[55]\tvalid_0's rmse: 0.853421\n[56]\tvalid_0's rmse: 0.853221\n[57]\tvalid_0's rmse: 0.853079\n[58]\tvalid_0's rmse: 0.852947\n[59]\tvalid_0's rmse: 0.852865\n[60]\tvalid_0's rmse: 0.852751\n[61]\tvalid_0's rmse: 0.852645\n[62]\tvalid_0's rmse: 0.852485\n[63]\tvalid_0's rmse: 0.852382\n[64]\tvalid_0's rmse: 0.852208\n[65]\tvalid_0's rmse: 0.852104\n[66]\tvalid_0's rmse: 0.852014\n[67]\tvalid_0's rmse: 0.851933\n[68]\tvalid_0's rmse: 0.851814\n[69]\tvalid_0's rmse: 0.851659\n[70]\tvalid_0's rmse: 0.851557\n[71]\tvalid_0's rmse: 0.851503\n[72]\tvalid_0's rmse: 0.851452\n[73]\tvalid_0's rmse: 0.8514\n[74]\tvalid_0's rmse: 0.851332\n[75]\tvalid_0's rmse: 0.851204\n[76]\tvalid_0's rmse: 0.851107\n[77]\tvalid_0's rmse: 0.85103\n[78]\tvalid_0's rmse: 0.850968\n[79]\tvalid_0's rmse: 0.850863\n[80]\tvalid_0's rmse: 0.850838\n[81]\tvalid_0's rmse: 0.85074\n[82]\tvalid_0's rmse: 0.850683\n[83]\tvalid_0's rmse: 0.850616\n[84]\tvalid_0's rmse: 0.850568\n[85]\tvalid_0's rmse: 0.850509\n[86]\tvalid_0's rmse: 0.85047\n[87]\tvalid_0's rmse: 0.850422\n[88]\tvalid_0's rmse: 0.850248\n[89]\tvalid_0's rmse: 0.850205\n[90]\tvalid_0's rmse: 0.850145\n[91]\tvalid_0's rmse: 0.850057\n[92]\tvalid_0's rmse: 0.850023\n[93]\tvalid_0's rmse: 0.849936\n[94]\tvalid_0's rmse: 0.849875\n[95]\tvalid_0's rmse: 0.849814\n[96]\tvalid_0's rmse: 0.84976\n[97]\tvalid_0's rmse: 0.849715\n[98]\tvalid_0's rmse: 0.849672\n[99]\tvalid_0's rmse: 0.849625\n[100]\tvalid_0's rmse: 0.849608\n[101]\tvalid_0's rmse: 0.849538\n[102]\tvalid_0's rmse: 0.849486\n[103]\tvalid_0's rmse: 0.849464\n[104]\tvalid_0's rmse: 0.849357\n[105]\tvalid_0's rmse: 0.849313\n[106]\tvalid_0's rmse: 0.849272\n[107]\tvalid_0's rmse: 0.849229\n[108]\tvalid_0's rmse: 0.84918\n[109]\tvalid_0's rmse: 0.849131\n[110]\tvalid_0's rmse: 0.849085\n[111]\tvalid_0's rmse: 0.849016\n[112]\tvalid_0's rmse: 0.848968\n[113]\tvalid_0's rmse: 0.848896\n[114]\tvalid_0's rmse: 0.848861\n[115]\tvalid_0's rmse: 0.848814\n[116]\tvalid_0's rmse: 0.848782\n[117]\tvalid_0's rmse: 0.848708\n[118]\tvalid_0's rmse: 0.848675\n[119]\tvalid_0's rmse: 0.848649\n[120]\tvalid_0's rmse: 0.848649\n[121]\tvalid_0's rmse: 0.848551\n[122]\tvalid_0's rmse: 0.848527\n[123]\tvalid_0's rmse: 0.848466\n[124]\tvalid_0's rmse: 0.848427\n[125]\tvalid_0's rmse: 0.848389\n[126]\tvalid_0's rmse: 0.848382\n[127]\tvalid_0's rmse: 0.848391\n[128]\tvalid_0's rmse: 0.848358\n[129]\tvalid_0's rmse: 0.848329\n[130]\tvalid_0's rmse: 0.848334\n[131]\tvalid_0's rmse: 0.848334\n[132]\tvalid_0's rmse: 0.848312\n[133]\tvalid_0's rmse: 0.84832\n[134]\tvalid_0's rmse: 0.848279\n[135]\tvalid_0's rmse: 0.848231\n[136]\tvalid_0's rmse: 0.848214\n[137]\tvalid_0's rmse: 0.848198\n[138]\tvalid_0's rmse: 0.848173\n[139]\tvalid_0's rmse: 0.848131\n[140]\tvalid_0's rmse: 0.848128\n[141]\tvalid_0's rmse: 0.84811\n[142]\tvalid_0's rmse: 0.848117\n[143]\tvalid_0's rmse: 0.848103\n[144]\tvalid_0's rmse: 0.848086\n[145]\tvalid_0's rmse: 0.848048\n[146]\tvalid_0's rmse: 0.848023\n[147]\tvalid_0's rmse: 0.848014\n[148]\tvalid_0's rmse: 0.847986\n[149]\tvalid_0's rmse: 0.847982\n[150]\tvalid_0's rmse: 0.847969\n[151]\tvalid_0's rmse: 0.847948\n[152]\tvalid_0's rmse: 0.847923\n[153]\tvalid_0's rmse: 0.847916\n[154]\tvalid_0's rmse: 0.847901\n[155]\tvalid_0's rmse: 0.84788\n[156]\tvalid_0's rmse: 0.847861\n[157]\tvalid_0's rmse: 0.847854\n[158]\tvalid_0's rmse: 0.847861\n[159]\tvalid_0's rmse: 0.847856\n[160]\tvalid_0's rmse: 0.847825\n[161]\tvalid_0's rmse: 0.847809\n[162]\tvalid_0's rmse: 0.847803\n[163]\tvalid_0's rmse: 0.847796\n[164]\tvalid_0's rmse: 0.847783\n[165]\tvalid_0's rmse: 0.847769\n[166]\tvalid_0's rmse: 0.847744\n[167]\tvalid_0's rmse: 0.847759\n[168]\tvalid_0's rmse: 0.847764\n[169]\tvalid_0's rmse: 0.847774\n[170]\tvalid_0's rmse: 0.84774\n[171]\tvalid_0's rmse: 0.847752\n[172]\tvalid_0's rmse: 0.847765\n[173]\tvalid_0's rmse: 0.847755\n[174]\tvalid_0's rmse: 0.847731\n[175]\tvalid_0's rmse: 0.847723\n[176]\tvalid_0's rmse: 0.847715\n[177]\tvalid_0's rmse: 0.847712\n[178]\tvalid_0's rmse: 0.847712\n[179]\tvalid_0's rmse: 0.847677\n[180]\tvalid_0's rmse: 0.847675\n[181]\tvalid_0's rmse: 0.847635\n[182]\tvalid_0's rmse: 0.847646\n[183]\tvalid_0's rmse: 0.847617\n[184]\tvalid_0's rmse: 0.8476\n[185]\tvalid_0's rmse: 0.847593\n[186]\tvalid_0's rmse: 0.847584\n[187]\tvalid_0's rmse: 0.847586\n[188]\tvalid_0's rmse: 0.847571\n[189]\tvalid_0's rmse: 0.847555\n[190]\tvalid_0's rmse: 0.847552\n[191]\tvalid_0's rmse: 0.847549\n[192]\tvalid_0's rmse: 0.847551\n[193]\tvalid_0's rmse: 0.847553\n[194]\tvalid_0's rmse: 0.847551\n[195]\tvalid_0's rmse: 0.84754\n[196]\tvalid_0's rmse: 0.84754\n[197]\tvalid_0's rmse: 0.847543\n[198]\tvalid_0's rmse: 0.847539\n[199]\tvalid_0's rmse: 0.847544\n[200]\tvalid_0's rmse: 0.847572\n[201]\tvalid_0's rmse: 0.847549\n[202]\tvalid_0's rmse: 0.847546\n[203]\tvalid_0's rmse: 0.847546\n[204]\tvalid_0's rmse: 0.847534\n[205]\tvalid_0's rmse: 0.847525\n[206]\tvalid_0's rmse: 0.847525\n[207]\tvalid_0's rmse: 0.847521\n[208]\tvalid_0's rmse: 0.847497\n[209]\tvalid_0's rmse: 0.847498\n[210]\tvalid_0's rmse: 0.847504\n[211]\tvalid_0's rmse: 0.847514\n[212]\tvalid_0's rmse: 0.847523\n[213]\tvalid_0's rmse: 0.847508\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  20%|##        | 2/10 [00:14<00:57,  7.22s/it]\u001b[32m[I 2021-02-05 22:53:35,511]\u001b[0m Trial 28 finished with value: 0.8474972961169717 and parameters: {'bagging_fraction': 0.8925509757381792, 'bagging_freq': 2}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465:  20%|##        | 2/10 [00:14<00:57,  7.22s/it]","name":"stderr"},{"output_type":"stream","text":"[214]\tvalid_0's rmse: 0.847522\n[215]\tvalid_0's rmse: 0.847522\n[216]\tvalid_0's rmse: 0.847545\n[217]\tvalid_0's rmse: 0.84753\n[218]\tvalid_0's rmse: 0.847527\nEarly stopping, best iteration is:\n[208]\tvalid_0's rmse: 0.847497\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019539 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888335\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885611\n[3]\tvalid_0's rmse: 0.883268\n[4]\tvalid_0's rmse: 0.88108\n[5]\tvalid_0's rmse: 0.879211\n[6]\tvalid_0's rmse: 0.877131\n[7]\tvalid_0's rmse: 0.875508\n[8]\tvalid_0's rmse: 0.874343\n[9]\tvalid_0's rmse: 0.873184\n[10]\tvalid_0's rmse: 0.872123\n[11]\tvalid_0's rmse: 0.870746\n[12]\tvalid_0's rmse: 0.869547\n[13]\tvalid_0's rmse: 0.868513\n[14]\tvalid_0's rmse: 0.867457\n[15]\tvalid_0's rmse: 0.86669\n[16]\tvalid_0's rmse: 0.865946\n[17]\tvalid_0's rmse: 0.865096\n[18]\tvalid_0's rmse: 0.864405\n[19]\tvalid_0's rmse: 0.863736\n[20]\tvalid_0's rmse: 0.863168\n[21]\tvalid_0's rmse: 0.862572\n[22]\tvalid_0's rmse: 0.86196\n[23]\tvalid_0's rmse: 0.861396\n[24]\tvalid_0's rmse: 0.860815\n[25]\tvalid_0's rmse: 0.860412\n[26]\tvalid_0's rmse: 0.85996\n[27]\tvalid_0's rmse: 0.859537\n[28]\tvalid_0's rmse: 0.859182\n[29]\tvalid_0's rmse: 0.858817\n[30]\tvalid_0's rmse: 0.858568\n[31]\tvalid_0's rmse: 0.858238\n[32]\tvalid_0's rmse: 0.857892\n[33]\tvalid_0's rmse: 0.857574\n[34]\tvalid_0's rmse: 0.85729\n[35]\tvalid_0's rmse: 0.856984\n[36]\tvalid_0's rmse: 0.856687\n[37]\tvalid_0's rmse: 0.856432\n[38]\tvalid_0's rmse: 0.85614\n[39]\tvalid_0's rmse: 0.85587\n[40]\tvalid_0's rmse: 0.855599\n[41]\tvalid_0's rmse: 0.855479\n[42]\tvalid_0's rmse: 0.855294\n[43]\tvalid_0's rmse: 0.855136\n[44]\tvalid_0's rmse: 0.854924\n[45]\tvalid_0's rmse: 0.854701\n[46]\tvalid_0's rmse: 0.854565\n[47]\tvalid_0's rmse: 0.854428\n[48]\tvalid_0's rmse: 0.854254\n[49]\tvalid_0's rmse: 0.854066\n[50]\tvalid_0's rmse: 0.853884\n[51]\tvalid_0's rmse: 0.853788\n[52]\tvalid_0's rmse: 0.85351\n[53]\tvalid_0's rmse: 0.853328\n[54]\tvalid_0's rmse: 0.85317\n[55]\tvalid_0's rmse: 0.853123\n[56]\tvalid_0's rmse: 0.852972\n[57]\tvalid_0's rmse: 0.852846\n[58]\tvalid_0's rmse: 0.85266\n[59]\tvalid_0's rmse: 0.852553\n[60]\tvalid_0's rmse: 0.852433\n[61]\tvalid_0's rmse: 0.852342\n[62]\tvalid_0's rmse: 0.852287\n[63]\tvalid_0's rmse: 0.852179\n[64]\tvalid_0's rmse: 0.852056\n[65]\tvalid_0's rmse: 0.851953\n[66]\tvalid_0's rmse: 0.851854\n[67]\tvalid_0's rmse: 0.851782\n[68]\tvalid_0's rmse: 0.851704\n[69]\tvalid_0's rmse: 0.851577\n[70]\tvalid_0's rmse: 0.851429\n[71]\tvalid_0's rmse: 0.851343\n[72]\tvalid_0's rmse: 0.851162\n[73]\tvalid_0's rmse: 0.851131\n[74]\tvalid_0's rmse: 0.851083\n[75]\tvalid_0's rmse: 0.851012\n[76]\tvalid_0's rmse: 0.850923\n[77]\tvalid_0's rmse: 0.850871\n[78]\tvalid_0's rmse: 0.850834\n[79]\tvalid_0's rmse: 0.850808\n[80]\tvalid_0's rmse: 0.850792\n[81]\tvalid_0's rmse: 0.850719\n[82]\tvalid_0's rmse: 0.850669\n[83]\tvalid_0's rmse: 0.850618\n[84]\tvalid_0's rmse: 0.850608\n[85]\tvalid_0's rmse: 0.850568\n[86]\tvalid_0's rmse: 0.850539\n[87]\tvalid_0's rmse: 0.850467\n[88]\tvalid_0's rmse: 0.850373\n[89]\tvalid_0's rmse: 0.850286\n[90]\tvalid_0's rmse: 0.850196\n[91]\tvalid_0's rmse: 0.850203\n[92]\tvalid_0's rmse: 0.850093\n[93]\tvalid_0's rmse: 0.850026\n[94]\tvalid_0's rmse: 0.849994\n[95]\tvalid_0's rmse: 0.849979\n[96]\tvalid_0's rmse: 0.849969\n[97]\tvalid_0's rmse: 0.849951\n[98]\tvalid_0's rmse: 0.849965\n[99]\tvalid_0's rmse: 0.849954\n[100]\tvalid_0's rmse: 0.849917\n[101]\tvalid_0's rmse: 0.849886\n[102]\tvalid_0's rmse: 0.849825\n[103]\tvalid_0's rmse: 0.849754\n[104]\tvalid_0's rmse: 0.849653\n[105]\tvalid_0's rmse: 0.849614\n[106]\tvalid_0's rmse: 0.84956\n[107]\tvalid_0's rmse: 0.849492\n[108]\tvalid_0's rmse: 0.849509\n[109]\tvalid_0's rmse: 0.849443\n[110]\tvalid_0's rmse: 0.84943\n[111]\tvalid_0's rmse: 0.84941\n[112]\tvalid_0's rmse: 0.849365\n[113]\tvalid_0's rmse: 0.849335\n[114]\tvalid_0's rmse: 0.849311\n[115]\tvalid_0's rmse: 0.849285\n[116]\tvalid_0's rmse: 0.849264\n[117]\tvalid_0's rmse: 0.849208\n[118]\tvalid_0's rmse: 0.849199\n[119]\tvalid_0's rmse: 0.849204\n[120]\tvalid_0's rmse: 0.849173\n[121]\tvalid_0's rmse: 0.849153\n[122]\tvalid_0's rmse: 0.849142\n[123]\tvalid_0's rmse: 0.849068\n[124]\tvalid_0's rmse: 0.849097\n[125]\tvalid_0's rmse: 0.849083\n[126]\tvalid_0's rmse: 0.849059\n[127]\tvalid_0's rmse: 0.849046\n[128]\tvalid_0's rmse: 0.849012\n[129]\tvalid_0's rmse: 0.849024\n[130]\tvalid_0's rmse: 0.849009\n[131]\tvalid_0's rmse: 0.848996\n[132]\tvalid_0's rmse: 0.848975\n[133]\tvalid_0's rmse: 0.848937\n[134]\tvalid_0's rmse: 0.848867\n[135]\tvalid_0's rmse: 0.848877\n[136]\tvalid_0's rmse: 0.848862\n[137]\tvalid_0's rmse: 0.848857\n[138]\tvalid_0's rmse: 0.848841\n[139]\tvalid_0's rmse: 0.848818\n[140]\tvalid_0's rmse: 0.84879\n[141]\tvalid_0's rmse: 0.848773\n[142]\tvalid_0's rmse: 0.848788\n[143]\tvalid_0's rmse: 0.848739\n[144]\tvalid_0's rmse: 0.848726\n[145]\tvalid_0's rmse: 0.848708\n[146]\tvalid_0's rmse: 0.848684\n[147]\tvalid_0's rmse: 0.848616\n[148]\tvalid_0's rmse: 0.848585\n[149]\tvalid_0's rmse: 0.848529\n[150]\tvalid_0's rmse: 0.848521\n[151]\tvalid_0's rmse: 0.848483\n[152]\tvalid_0's rmse: 0.848465\n[153]\tvalid_0's rmse: 0.848474\n[154]\tvalid_0's rmse: 0.84845\n[155]\tvalid_0's rmse: 0.848439\n[156]\tvalid_0's rmse: 0.84837\n[157]\tvalid_0's rmse: 0.848378\n[158]\tvalid_0's rmse: 0.848366\n[159]\tvalid_0's rmse: 0.848411\n[160]\tvalid_0's rmse: 0.848369\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  30%|###       | 3/10 [00:19<00:44,  6.33s/it]\u001b[32m[I 2021-02-05 22:53:40,793]\u001b[0m Trial 29 finished with value: 0.8483656447679561 and parameters: {'bagging_fraction': 0.4211316396637339, 'bagging_freq': 5}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465:  30%|###       | 3/10 [00:19<00:44,  6.33s/it]","name":"stderr"},{"output_type":"stream","text":"[161]\tvalid_0's rmse: 0.848367\n[162]\tvalid_0's rmse: 0.848398\n[163]\tvalid_0's rmse: 0.848412\n[164]\tvalid_0's rmse: 0.848413\n[165]\tvalid_0's rmse: 0.848401\n[166]\tvalid_0's rmse: 0.848418\n[167]\tvalid_0's rmse: 0.848432\n[168]\tvalid_0's rmse: 0.848403\nEarly stopping, best iteration is:\n[158]\tvalid_0's rmse: 0.848366\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019098 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888283\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885499\n[3]\tvalid_0's rmse: 0.883218\n[4]\tvalid_0's rmse: 0.881047\n[5]\tvalid_0's rmse: 0.879137\n[6]\tvalid_0's rmse: 0.877076\n[7]\tvalid_0's rmse: 0.875589\n[8]\tvalid_0's rmse: 0.874396\n[9]\tvalid_0's rmse: 0.873247\n[10]\tvalid_0's rmse: 0.872122\n[11]\tvalid_0's rmse: 0.870745\n[12]\tvalid_0's rmse: 0.869532\n[13]\tvalid_0's rmse: 0.868494\n[14]\tvalid_0's rmse: 0.86743\n[15]\tvalid_0's rmse: 0.866756\n[16]\tvalid_0's rmse: 0.865982\n[17]\tvalid_0's rmse: 0.865103\n[18]\tvalid_0's rmse: 0.864454\n[19]\tvalid_0's rmse: 0.863798\n[20]\tvalid_0's rmse: 0.863194\n[21]\tvalid_0's rmse: 0.862644\n[22]\tvalid_0's rmse: 0.86201\n[23]\tvalid_0's rmse: 0.861443\n[24]\tvalid_0's rmse: 0.86089\n[25]\tvalid_0's rmse: 0.860452\n[26]\tvalid_0's rmse: 0.860055\n[27]\tvalid_0's rmse: 0.859727\n[28]\tvalid_0's rmse: 0.859336\n[29]\tvalid_0's rmse: 0.85893\n[30]\tvalid_0's rmse: 0.858587\n[31]\tvalid_0's rmse: 0.858289\n[32]\tvalid_0's rmse: 0.857883\n[33]\tvalid_0's rmse: 0.857586\n[34]\tvalid_0's rmse: 0.857272\n[35]\tvalid_0's rmse: 0.856975\n[36]\tvalid_0's rmse: 0.856677\n[37]\tvalid_0's rmse: 0.856396\n[38]\tvalid_0's rmse: 0.856098\n[39]\tvalid_0's rmse: 0.855848\n[40]\tvalid_0's rmse: 0.855612\n[41]\tvalid_0's rmse: 0.855428\n[42]\tvalid_0's rmse: 0.855193\n[43]\tvalid_0's rmse: 0.855021\n[44]\tvalid_0's rmse: 0.854745\n[45]\tvalid_0's rmse: 0.85453\n[46]\tvalid_0's rmse: 0.854307\n[47]\tvalid_0's rmse: 0.854148\n[48]\tvalid_0's rmse: 0.85399\n[49]\tvalid_0's rmse: 0.853841\n[50]\tvalid_0's rmse: 0.853671\n[51]\tvalid_0's rmse: 0.853579\n[52]\tvalid_0's rmse: 0.853424\n[53]\tvalid_0's rmse: 0.853173\n[54]\tvalid_0's rmse: 0.852998\n[55]\tvalid_0's rmse: 0.852915\n[56]\tvalid_0's rmse: 0.85278\n[57]\tvalid_0's rmse: 0.852624\n[58]\tvalid_0's rmse: 0.852454\n[59]\tvalid_0's rmse: 0.852353\n[60]\tvalid_0's rmse: 0.852245\n[61]\tvalid_0's rmse: 0.852149\n[62]\tvalid_0's rmse: 0.852036\n[63]\tvalid_0's rmse: 0.851961\n[64]\tvalid_0's rmse: 0.851809\n[65]\tvalid_0's rmse: 0.851709\n[66]\tvalid_0's rmse: 0.851623\n[67]\tvalid_0's rmse: 0.851527\n[68]\tvalid_0's rmse: 0.851436\n[69]\tvalid_0's rmse: 0.851295\n[70]\tvalid_0's rmse: 0.85115\n[71]\tvalid_0's rmse: 0.85106\n[72]\tvalid_0's rmse: 0.850977\n[73]\tvalid_0's rmse: 0.850925\n[74]\tvalid_0's rmse: 0.850882\n[75]\tvalid_0's rmse: 0.850801\n[76]\tvalid_0's rmse: 0.850715\n[77]\tvalid_0's rmse: 0.850652\n[78]\tvalid_0's rmse: 0.850549\n[79]\tvalid_0's rmse: 0.850493\n[80]\tvalid_0's rmse: 0.850437\n[81]\tvalid_0's rmse: 0.850396\n[82]\tvalid_0's rmse: 0.850336\n[83]\tvalid_0's rmse: 0.850267\n[84]\tvalid_0's rmse: 0.850219\n[85]\tvalid_0's rmse: 0.850181\n[86]\tvalid_0's rmse: 0.850172\n[87]\tvalid_0's rmse: 0.850148\n[88]\tvalid_0's rmse: 0.850063\n[89]\tvalid_0's rmse: 0.849993\n[90]\tvalid_0's rmse: 0.849971\n[91]\tvalid_0's rmse: 0.849906\n[92]\tvalid_0's rmse: 0.849796\n[93]\tvalid_0's rmse: 0.849725\n[94]\tvalid_0's rmse: 0.849705\n[95]\tvalid_0's rmse: 0.849633\n[96]\tvalid_0's rmse: 0.849608\n[97]\tvalid_0's rmse: 0.849569\n[98]\tvalid_0's rmse: 0.849438\n[99]\tvalid_0's rmse: 0.849388\n[100]\tvalid_0's rmse: 0.849358\n[101]\tvalid_0's rmse: 0.849322\n[102]\tvalid_0's rmse: 0.849238\n[103]\tvalid_0's rmse: 0.849209\n[104]\tvalid_0's rmse: 0.849123\n[105]\tvalid_0's rmse: 0.849068\n[106]\tvalid_0's rmse: 0.849055\n[107]\tvalid_0's rmse: 0.84903\n[108]\tvalid_0's rmse: 0.849014\n[109]\tvalid_0's rmse: 0.848953\n[110]\tvalid_0's rmse: 0.848903\n[111]\tvalid_0's rmse: 0.848877\n[112]\tvalid_0's rmse: 0.848835\n[113]\tvalid_0's rmse: 0.848758\n[114]\tvalid_0's rmse: 0.84873\n[115]\tvalid_0's rmse: 0.848738\n[116]\tvalid_0's rmse: 0.848683\n[117]\tvalid_0's rmse: 0.848683\n[118]\tvalid_0's rmse: 0.848628\n[119]\tvalid_0's rmse: 0.848604\n[120]\tvalid_0's rmse: 0.848582\n[121]\tvalid_0's rmse: 0.848556\n[122]\tvalid_0's rmse: 0.848539\n[123]\tvalid_0's rmse: 0.848493\n[124]\tvalid_0's rmse: 0.8485\n[125]\tvalid_0's rmse: 0.848499\n[126]\tvalid_0's rmse: 0.848508\n[127]\tvalid_0's rmse: 0.848467\n[128]\tvalid_0's rmse: 0.848452\n[129]\tvalid_0's rmse: 0.848418\n[130]\tvalid_0's rmse: 0.848386\n[131]\tvalid_0's rmse: 0.848341\n[132]\tvalid_0's rmse: 0.848314\n[133]\tvalid_0's rmse: 0.848315\n[134]\tvalid_0's rmse: 0.84828\n[135]\tvalid_0's rmse: 0.848243\n[136]\tvalid_0's rmse: 0.848216\n[137]\tvalid_0's rmse: 0.848171\n[138]\tvalid_0's rmse: 0.848165\n[139]\tvalid_0's rmse: 0.848134\n[140]\tvalid_0's rmse: 0.848123\n[141]\tvalid_0's rmse: 0.848089\n[142]\tvalid_0's rmse: 0.848075\n[143]\tvalid_0's rmse: 0.848068\n[144]\tvalid_0's rmse: 0.848046\n[145]\tvalid_0's rmse: 0.848025\n[146]\tvalid_0's rmse: 0.848021\n[147]\tvalid_0's rmse: 0.848032\n[148]\tvalid_0's rmse: 0.848009\n[149]\tvalid_0's rmse: 0.848024\n[150]\tvalid_0's rmse: 0.848025\n[151]\tvalid_0's rmse: 0.84799\n[152]\tvalid_0's rmse: 0.847988\n[153]\tvalid_0's rmse: 0.847988\n[154]\tvalid_0's rmse: 0.847991\n[155]\tvalid_0's rmse: 0.847979\n[156]\tvalid_0's rmse: 0.847971\n[157]\tvalid_0's rmse: 0.847969\n[158]\tvalid_0's rmse: 0.847963\n[159]\tvalid_0's rmse: 0.847963\n[160]\tvalid_0's rmse: 0.847947\n[161]\tvalid_0's rmse: 0.847928\n[162]\tvalid_0's rmse: 0.847931\n[163]\tvalid_0's rmse: 0.847924\n[164]\tvalid_0's rmse: 0.847939\n[165]\tvalid_0's rmse: 0.847928\n[166]\tvalid_0's rmse: 0.847923\n[167]\tvalid_0's rmse: 0.84791\n[168]\tvalid_0's rmse: 0.84789\n[169]\tvalid_0's rmse: 0.847833\n[170]\tvalid_0's rmse: 0.847808\n[171]\tvalid_0's rmse: 0.847814\n[172]\tvalid_0's rmse: 0.847813\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  40%|####      | 4/10 [00:24<00:34,  5.68s/it]\u001b[32m[I 2021-02-05 22:53:45,462]\u001b[0m Trial 30 finished with value: 0.8478014003616801 and parameters: {'bagging_fraction': 0.7725746137716221, 'bagging_freq': 1}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465:  40%|####      | 4/10 [00:24<00:34,  5.68s/it]","name":"stderr"},{"output_type":"stream","text":"[173]\tvalid_0's rmse: 0.847802\n[174]\tvalid_0's rmse: 0.847801\n[175]\tvalid_0's rmse: 0.847819\n[176]\tvalid_0's rmse: 0.847819\n[177]\tvalid_0's rmse: 0.847834\n[178]\tvalid_0's rmse: 0.847838\n[179]\tvalid_0's rmse: 0.847832\n[180]\tvalid_0's rmse: 0.847826\n[181]\tvalid_0's rmse: 0.847811\n[182]\tvalid_0's rmse: 0.847802\n[183]\tvalid_0's rmse: 0.847811\n[184]\tvalid_0's rmse: 0.847805\nEarly stopping, best iteration is:\n[174]\tvalid_0's rmse: 0.847801\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019097 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888334\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885561\n[3]\tvalid_0's rmse: 0.883401\n[4]\tvalid_0's rmse: 0.881223\n[5]\tvalid_0's rmse: 0.879365\n[6]\tvalid_0's rmse: 0.877318\n[7]\tvalid_0's rmse: 0.875769\n[8]\tvalid_0's rmse: 0.874528\n[9]\tvalid_0's rmse: 0.873398\n[10]\tvalid_0's rmse: 0.872349\n[11]\tvalid_0's rmse: 0.870955\n[12]\tvalid_0's rmse: 0.869727\n[13]\tvalid_0's rmse: 0.868654\n[14]\tvalid_0's rmse: 0.867592\n[15]\tvalid_0's rmse: 0.866889\n[16]\tvalid_0's rmse: 0.866133\n[17]\tvalid_0's rmse: 0.865359\n[18]\tvalid_0's rmse: 0.864715\n[19]\tvalid_0's rmse: 0.863999\n[20]\tvalid_0's rmse: 0.863459\n[21]\tvalid_0's rmse: 0.862942\n[22]\tvalid_0's rmse: 0.862321\n[23]\tvalid_0's rmse: 0.861801\n[24]\tvalid_0's rmse: 0.861256\n[25]\tvalid_0's rmse: 0.860872\n[26]\tvalid_0's rmse: 0.86043\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859667\n[29]\tvalid_0's rmse: 0.859312\n[30]\tvalid_0's rmse: 0.859037\n[31]\tvalid_0's rmse: 0.858735\n[32]\tvalid_0's rmse: 0.858391\n[33]\tvalid_0's rmse: 0.858079\n[34]\tvalid_0's rmse: 0.857664\n[35]\tvalid_0's rmse: 0.857401\n[36]\tvalid_0's rmse: 0.857114\n[37]\tvalid_0's rmse: 0.856812\n[38]\tvalid_0's rmse: 0.856528\n[39]\tvalid_0's rmse: 0.85626\n[40]\tvalid_0's rmse: 0.856004\n[41]\tvalid_0's rmse: 0.85586\n[42]\tvalid_0's rmse: 0.855659\n[43]\tvalid_0's rmse: 0.855453\n[44]\tvalid_0's rmse: 0.8552\n[45]\tvalid_0's rmse: 0.855056\n[46]\tvalid_0's rmse: 0.854839\n[47]\tvalid_0's rmse: 0.854641\n[48]\tvalid_0's rmse: 0.854493\n[49]\tvalid_0's rmse: 0.854365\n[50]\tvalid_0's rmse: 0.854193\n[51]\tvalid_0's rmse: 0.854093\n[52]\tvalid_0's rmse: 0.853823\n[53]\tvalid_0's rmse: 0.853661\n[54]\tvalid_0's rmse: 0.853514\n[55]\tvalid_0's rmse: 0.853403\n[56]\tvalid_0's rmse: 0.853229\n[57]\tvalid_0's rmse: 0.853093\n[58]\tvalid_0's rmse: 0.852949\n[59]\tvalid_0's rmse: 0.852855\n[60]\tvalid_0's rmse: 0.852763\n[61]\tvalid_0's rmse: 0.852624\n[62]\tvalid_0's rmse: 0.852508\n[63]\tvalid_0's rmse: 0.852359\n[64]\tvalid_0's rmse: 0.852257\n[65]\tvalid_0's rmse: 0.85216\n[66]\tvalid_0's rmse: 0.852091\n[67]\tvalid_0's rmse: 0.852008\n[68]\tvalid_0's rmse: 0.851902\n[69]\tvalid_0's rmse: 0.851778\n[70]\tvalid_0's rmse: 0.851639\n[71]\tvalid_0's rmse: 0.851555\n[72]\tvalid_0's rmse: 0.851489\n[73]\tvalid_0's rmse: 0.85145\n[74]\tvalid_0's rmse: 0.851349\n[75]\tvalid_0's rmse: 0.851249\n[76]\tvalid_0's rmse: 0.851166\n[77]\tvalid_0's rmse: 0.851096\n[78]\tvalid_0's rmse: 0.851028\n[79]\tvalid_0's rmse: 0.850899\n[80]\tvalid_0's rmse: 0.850789\n[81]\tvalid_0's rmse: 0.850718\n[82]\tvalid_0's rmse: 0.85068\n[83]\tvalid_0's rmse: 0.850646\n[84]\tvalid_0's rmse: 0.850579\n[85]\tvalid_0's rmse: 0.850549\n[86]\tvalid_0's rmse: 0.850511\n[87]\tvalid_0's rmse: 0.850483\n[88]\tvalid_0's rmse: 0.850427\n[89]\tvalid_0's rmse: 0.850337\n[90]\tvalid_0's rmse: 0.850285\n[91]\tvalid_0's rmse: 0.8502\n[92]\tvalid_0's rmse: 0.850157\n[93]\tvalid_0's rmse: 0.850098\n[94]\tvalid_0's rmse: 0.850062\n[95]\tvalid_0's rmse: 0.850038\n[96]\tvalid_0's rmse: 0.849987\n[97]\tvalid_0's rmse: 0.849927\n[98]\tvalid_0's rmse: 0.849833\n[99]\tvalid_0's rmse: 0.849793\n[100]\tvalid_0's rmse: 0.849752\n[101]\tvalid_0's rmse: 0.849725\n[102]\tvalid_0's rmse: 0.84966\n[103]\tvalid_0's rmse: 0.849625\n[104]\tvalid_0's rmse: 0.849586\n[105]\tvalid_0's rmse: 0.84952\n[106]\tvalid_0's rmse: 0.849499\n[107]\tvalid_0's rmse: 0.849459\n[108]\tvalid_0's rmse: 0.84947\n[109]\tvalid_0's rmse: 0.849466\n[110]\tvalid_0's rmse: 0.849438\n[111]\tvalid_0's rmse: 0.849405\n[112]\tvalid_0's rmse: 0.849407\n[113]\tvalid_0's rmse: 0.84938\n[114]\tvalid_0's rmse: 0.84934\n[115]\tvalid_0's rmse: 0.849307\n[116]\tvalid_0's rmse: 0.8493\n[117]\tvalid_0's rmse: 0.849244\n[118]\tvalid_0's rmse: 0.84924\n[119]\tvalid_0's rmse: 0.849202\n[120]\tvalid_0's rmse: 0.849184\n[121]\tvalid_0's rmse: 0.849157\n[122]\tvalid_0's rmse: 0.849146\n[123]\tvalid_0's rmse: 0.849086\n[124]\tvalid_0's rmse: 0.849089\n[125]\tvalid_0's rmse: 0.849047\n[126]\tvalid_0's rmse: 0.849004\n[127]\tvalid_0's rmse: 0.849004\n[128]\tvalid_0's rmse: 0.848937\n[129]\tvalid_0's rmse: 0.848913\n[130]\tvalid_0's rmse: 0.848899\n[131]\tvalid_0's rmse: 0.848898\n[132]\tvalid_0's rmse: 0.848897\n[133]\tvalid_0's rmse: 0.848884\n[134]\tvalid_0's rmse: 0.848865\n[135]\tvalid_0's rmse: 0.848823\n[136]\tvalid_0's rmse: 0.848838\n[137]\tvalid_0's rmse: 0.848836\n[138]\tvalid_0's rmse: 0.84886\n[139]\tvalid_0's rmse: 0.84885\n[140]\tvalid_0's rmse: 0.848842\n[141]\tvalid_0's rmse: 0.848832\n[142]\tvalid_0's rmse: 0.848781\n[143]\tvalid_0's rmse: 0.848775\n[144]\tvalid_0's rmse: 0.84876\n[145]\tvalid_0's rmse: 0.84872\n[146]\tvalid_0's rmse: 0.848685\n[147]\tvalid_0's rmse: 0.84868\n[148]\tvalid_0's rmse: 0.848676\n[149]\tvalid_0's rmse: 0.848677\n[150]\tvalid_0's rmse: 0.848686\n[151]\tvalid_0's rmse: 0.848657\n[152]\tvalid_0's rmse: 0.848647\n[153]\tvalid_0's rmse: 0.848627\n[154]\tvalid_0's rmse: 0.848611\n[155]\tvalid_0's rmse: 0.84859\n[156]\tvalid_0's rmse: 0.848573\n[157]\tvalid_0's rmse: 0.848547\n[158]\tvalid_0's rmse: 0.84855\n[159]\tvalid_0's rmse: 0.848546\n[160]\tvalid_0's rmse: 0.848525\n[161]\tvalid_0's rmse: 0.848504\n[162]\tvalid_0's rmse: 0.848511\n[163]\tvalid_0's rmse: 0.848487\n[164]\tvalid_0's rmse: 0.848487\n[165]\tvalid_0's rmse: 0.848489\n[166]\tvalid_0's rmse: 0.848451\n[167]\tvalid_0's rmse: 0.84844\n[168]\tvalid_0's rmse: 0.848432\n[169]\tvalid_0's rmse: 0.848443\n[170]\tvalid_0's rmse: 0.848432\n[171]\tvalid_0's rmse: 0.848405\n[172]\tvalid_0's rmse: 0.848377\n[173]\tvalid_0's rmse: 0.848361\n[174]\tvalid_0's rmse: 0.848359\n[175]\tvalid_0's rmse: 0.848351\n[176]\tvalid_0's rmse: 0.848367\n[177]\tvalid_0's rmse: 0.848338\n[178]\tvalid_0's rmse: 0.848334\n[179]\tvalid_0's rmse: 0.848325\n[180]\tvalid_0's rmse: 0.848311\n[181]\tvalid_0's rmse: 0.848266\n[182]\tvalid_0's rmse: 0.848231\n[183]\tvalid_0's rmse: 0.848228\n[184]\tvalid_0's rmse: 0.848225\n[185]\tvalid_0's rmse: 0.848226\n[186]\tvalid_0's rmse: 0.84824\n[187]\tvalid_0's rmse: 0.848235\n[188]\tvalid_0's rmse: 0.848214\n[189]\tvalid_0's rmse: 0.848232\n[190]\tvalid_0's rmse: 0.848224\n[191]\tvalid_0's rmse: 0.848249\n[192]\tvalid_0's rmse: 0.8482\n[193]\tvalid_0's rmse: 0.848186\n[194]\tvalid_0's rmse: 0.848166\n[195]\tvalid_0's rmse: 0.84818\n[196]\tvalid_0's rmse: 0.84818\n[197]\tvalid_0's rmse: 0.848159\n[198]\tvalid_0's rmse: 0.848157\n[199]\tvalid_0's rmse: 0.848151\n[200]\tvalid_0's rmse: 0.848149\n[201]\tvalid_0's rmse: 0.848149\n[202]\tvalid_0's rmse: 0.848148\n[203]\tvalid_0's rmse: 0.848167\n[204]\tvalid_0's rmse: 0.848169\n[205]\tvalid_0's rmse: 0.848182\n[206]\tvalid_0's rmse: 0.848164\n[207]\tvalid_0's rmse: 0.848153\n[208]\tvalid_0's rmse: 0.848164\n[209]\tvalid_0's rmse: 0.848125\n[210]\tvalid_0's rmse: 0.848129\n[211]\tvalid_0's rmse: 0.848119\n[212]\tvalid_0's rmse: 0.848122\n[213]\tvalid_0's rmse: 0.848154\n[214]\tvalid_0's rmse: 0.848132\n[215]\tvalid_0's rmse: 0.848138\n[216]\tvalid_0's rmse: 0.848147\n[217]\tvalid_0's rmse: 0.848145\n[218]\tvalid_0's rmse: 0.848137\n[219]\tvalid_0's rmse: 0.848134\n[220]\tvalid_0's rmse: 0.848141\n[221]\tvalid_0's rmse: 0.848146\nEarly stopping, best iteration is:\n[211]\tvalid_0's rmse: 0.848119\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  50%|#####     | 5/10 [00:30<00:29,  5.89s/it]\u001b[32m[I 2021-02-05 22:53:51,744]\u001b[0m Trial 31 finished with value: 0.8481188499646142 and parameters: {'bagging_fraction': 0.693344861119093, 'bagging_freq': 6}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465:  50%|#####     | 5/10 [00:30<00:29,  5.89s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019270 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888376\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885602\n[3]\tvalid_0's rmse: 0.883412\n[4]\tvalid_0's rmse: 0.88122\n[5]\tvalid_0's rmse: 0.879364\n[6]\tvalid_0's rmse: 0.877353\n[7]\tvalid_0's rmse: 0.875823\n[8]\tvalid_0's rmse: 0.874627\n[9]\tvalid_0's rmse: 0.873458\n[10]\tvalid_0's rmse: 0.872371\n[11]\tvalid_0's rmse: 0.870968\n[12]\tvalid_0's rmse: 0.869744\n[13]\tvalid_0's rmse: 0.868682\n[14]\tvalid_0's rmse: 0.867597\n[15]\tvalid_0's rmse: 0.866888\n[16]\tvalid_0's rmse: 0.86612\n[17]\tvalid_0's rmse: 0.865309\n[18]\tvalid_0's rmse: 0.864649\n[19]\tvalid_0's rmse: 0.863945\n[20]\tvalid_0's rmse: 0.863392\n[21]\tvalid_0's rmse: 0.862871\n[22]\tvalid_0's rmse: 0.86221\n[23]\tvalid_0's rmse: 0.861677\n[24]\tvalid_0's rmse: 0.861153\n[25]\tvalid_0's rmse: 0.860772\n[26]\tvalid_0's rmse: 0.860336\n[27]\tvalid_0's rmse: 0.859989\n[28]\tvalid_0's rmse: 0.859592\n[29]\tvalid_0's rmse: 0.859225\n[30]\tvalid_0's rmse: 0.858882\n[31]\tvalid_0's rmse: 0.858514\n[32]\tvalid_0's rmse: 0.858167\n[33]\tvalid_0's rmse: 0.857842\n[34]\tvalid_0's rmse: 0.857509\n[35]\tvalid_0's rmse: 0.857278\n[36]\tvalid_0's rmse: 0.856991\n[37]\tvalid_0's rmse: 0.856686\n[38]\tvalid_0's rmse: 0.856429\n[39]\tvalid_0's rmse: 0.85615\n[40]\tvalid_0's rmse: 0.855903\n[41]\tvalid_0's rmse: 0.855769\n[42]\tvalid_0's rmse: 0.855546\n[43]\tvalid_0's rmse: 0.855342\n[44]\tvalid_0's rmse: 0.855051\n[45]\tvalid_0's rmse: 0.854872\n[46]\tvalid_0's rmse: 0.854683\n[47]\tvalid_0's rmse: 0.85449\n[48]\tvalid_0's rmse: 0.854323\n[49]\tvalid_0's rmse: 0.854171\n[50]\tvalid_0's rmse: 0.854004\n[51]\tvalid_0's rmse: 0.853877\n[52]\tvalid_0's rmse: 0.853647\n[53]\tvalid_0's rmse: 0.853465\n[54]\tvalid_0's rmse: 0.853299\n[55]\tvalid_0's rmse: 0.8532\n[56]\tvalid_0's rmse: 0.853042\n[57]\tvalid_0's rmse: 0.852921\n[58]\tvalid_0's rmse: 0.852776\n[59]\tvalid_0's rmse: 0.852697\n[60]\tvalid_0's rmse: 0.85259\n[61]\tvalid_0's rmse: 0.852454\n[62]\tvalid_0's rmse: 0.852366\n[63]\tvalid_0's rmse: 0.852219\n[64]\tvalid_0's rmse: 0.852104\n[65]\tvalid_0's rmse: 0.85201\n[66]\tvalid_0's rmse: 0.851889\n[67]\tvalid_0's rmse: 0.851834\n[68]\tvalid_0's rmse: 0.851702\n[69]\tvalid_0's rmse: 0.851603\n[70]\tvalid_0's rmse: 0.851496\n[71]\tvalid_0's rmse: 0.851455\n[72]\tvalid_0's rmse: 0.851399\n[73]\tvalid_0's rmse: 0.851329\n[74]\tvalid_0's rmse: 0.851257\n[75]\tvalid_0's rmse: 0.851172\n[76]\tvalid_0's rmse: 0.851009\n[77]\tvalid_0's rmse: 0.85096\n[78]\tvalid_0's rmse: 0.85088\n[79]\tvalid_0's rmse: 0.850809\n[80]\tvalid_0's rmse: 0.850701\n[81]\tvalid_0's rmse: 0.850623\n[82]\tvalid_0's rmse: 0.850528\n[83]\tvalid_0's rmse: 0.850485\n[84]\tvalid_0's rmse: 0.850438\n[85]\tvalid_0's rmse: 0.850404\n[86]\tvalid_0's rmse: 0.85037\n[87]\tvalid_0's rmse: 0.85034\n[88]\tvalid_0's rmse: 0.850257\n[89]\tvalid_0's rmse: 0.850155\n[90]\tvalid_0's rmse: 0.850119\n[91]\tvalid_0's rmse: 0.850086\n[92]\tvalid_0's rmse: 0.850027\n[93]\tvalid_0's rmse: 0.849957\n[94]\tvalid_0's rmse: 0.849924\n[95]\tvalid_0's rmse: 0.849885\n[96]\tvalid_0's rmse: 0.84986\n[97]\tvalid_0's rmse: 0.849766\n[98]\tvalid_0's rmse: 0.849651\n[99]\tvalid_0's rmse: 0.849593\n[100]\tvalid_0's rmse: 0.849556\n[101]\tvalid_0's rmse: 0.849469\n[102]\tvalid_0's rmse: 0.849433\n[103]\tvalid_0's rmse: 0.849374\n[104]\tvalid_0's rmse: 0.849294\n[105]\tvalid_0's rmse: 0.849253\n[106]\tvalid_0's rmse: 0.849216\n[107]\tvalid_0's rmse: 0.849178\n[108]\tvalid_0's rmse: 0.849138\n[109]\tvalid_0's rmse: 0.849065\n[110]\tvalid_0's rmse: 0.849025\n[111]\tvalid_0's rmse: 0.849005\n[112]\tvalid_0's rmse: 0.848962\n[113]\tvalid_0's rmse: 0.848937\n[114]\tvalid_0's rmse: 0.848897\n[115]\tvalid_0's rmse: 0.848886\n[116]\tvalid_0's rmse: 0.848892\n[117]\tvalid_0's rmse: 0.84885\n[118]\tvalid_0's rmse: 0.848834\n[119]\tvalid_0's rmse: 0.848807\n[120]\tvalid_0's rmse: 0.848791\n[121]\tvalid_0's rmse: 0.848745\n[122]\tvalid_0's rmse: 0.848711\n[123]\tvalid_0's rmse: 0.848661\n[124]\tvalid_0's rmse: 0.848629\n[125]\tvalid_0's rmse: 0.848619\n[126]\tvalid_0's rmse: 0.848589\n[127]\tvalid_0's rmse: 0.848554\n[128]\tvalid_0's rmse: 0.848533\n[129]\tvalid_0's rmse: 0.848512\n[130]\tvalid_0's rmse: 0.848509\n[131]\tvalid_0's rmse: 0.848432\n[132]\tvalid_0's rmse: 0.848404\n[133]\tvalid_0's rmse: 0.84841\n[134]\tvalid_0's rmse: 0.848403\n[135]\tvalid_0's rmse: 0.848381\n[136]\tvalid_0's rmse: 0.848364\n[137]\tvalid_0's rmse: 0.848359\n[138]\tvalid_0's rmse: 0.848343\n[139]\tvalid_0's rmse: 0.848328\n[140]\tvalid_0's rmse: 0.848333\n[141]\tvalid_0's rmse: 0.848329\n[142]\tvalid_0's rmse: 0.848296\n[143]\tvalid_0's rmse: 0.848273\n[144]\tvalid_0's rmse: 0.848278\n[145]\tvalid_0's rmse: 0.848225\n[146]\tvalid_0's rmse: 0.848213\n[147]\tvalid_0's rmse: 0.848185\n[148]\tvalid_0's rmse: 0.848182\n[149]\tvalid_0's rmse: 0.848144\n[150]\tvalid_0's rmse: 0.848138\n[151]\tvalid_0's rmse: 0.848138\n[152]\tvalid_0's rmse: 0.848133\n[153]\tvalid_0's rmse: 0.848101\n[154]\tvalid_0's rmse: 0.848114\n[155]\tvalid_0's rmse: 0.848088\n[156]\tvalid_0's rmse: 0.848078\n[157]\tvalid_0's rmse: 0.848047\n[158]\tvalid_0's rmse: 0.84803\n[159]\tvalid_0's rmse: 0.848015\n[160]\tvalid_0's rmse: 0.847982\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  60%|######    | 6/10 [00:34<00:21,  5.41s/it]\u001b[32m[I 2021-02-05 22:53:56,201]\u001b[0m Trial 32 finished with value: 0.8479814648151768 and parameters: {'bagging_fraction': 0.8930299563016154, 'bagging_freq': 1}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465:  60%|######    | 6/10 [00:34<00:21,  5.41s/it]","name":"stderr"},{"output_type":"stream","text":"[161]\tvalid_0's rmse: 0.847983\n[162]\tvalid_0's rmse: 0.847981\n[163]\tvalid_0's rmse: 0.847983\n[164]\tvalid_0's rmse: 0.848007\n[165]\tvalid_0's rmse: 0.848001\n[166]\tvalid_0's rmse: 0.848001\n[167]\tvalid_0's rmse: 0.848014\n[168]\tvalid_0's rmse: 0.848008\n[169]\tvalid_0's rmse: 0.847993\n[170]\tvalid_0's rmse: 0.848002\n[171]\tvalid_0's rmse: 0.847999\n[172]\tvalid_0's rmse: 0.848014\nEarly stopping, best iteration is:\n[162]\tvalid_0's rmse: 0.847981\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018830 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888352\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.88558\n[3]\tvalid_0's rmse: 0.883267\n[4]\tvalid_0's rmse: 0.881061\n[5]\tvalid_0's rmse: 0.879156\n[6]\tvalid_0's rmse: 0.877075\n[7]\tvalid_0's rmse: 0.875584\n[8]\tvalid_0's rmse: 0.874406\n[9]\tvalid_0's rmse: 0.873271\n[10]\tvalid_0's rmse: 0.872155\n[11]\tvalid_0's rmse: 0.870766\n[12]\tvalid_0's rmse: 0.869556\n[13]\tvalid_0's rmse: 0.868516\n[14]\tvalid_0's rmse: 0.867419\n[15]\tvalid_0's rmse: 0.866729\n[16]\tvalid_0's rmse: 0.865961\n[17]\tvalid_0's rmse: 0.86515\n[18]\tvalid_0's rmse: 0.864516\n[19]\tvalid_0's rmse: 0.863851\n[20]\tvalid_0's rmse: 0.863223\n[21]\tvalid_0's rmse: 0.862666\n[22]\tvalid_0's rmse: 0.862049\n[23]\tvalid_0's rmse: 0.861502\n[24]\tvalid_0's rmse: 0.860995\n[25]\tvalid_0's rmse: 0.860608\n[26]\tvalid_0's rmse: 0.86016\n[27]\tvalid_0's rmse: 0.859779\n[28]\tvalid_0's rmse: 0.859366\n[29]\tvalid_0's rmse: 0.858991\n[30]\tvalid_0's rmse: 0.858625\n[31]\tvalid_0's rmse: 0.858269\n[32]\tvalid_0's rmse: 0.857873\n[33]\tvalid_0's rmse: 0.857566\n[34]\tvalid_0's rmse: 0.857246\n[35]\tvalid_0's rmse: 0.857013\n[36]\tvalid_0's rmse: 0.856756\n[37]\tvalid_0's rmse: 0.856475\n[38]\tvalid_0's rmse: 0.856187\n[39]\tvalid_0's rmse: 0.855917\n[40]\tvalid_0's rmse: 0.855657\n[41]\tvalid_0's rmse: 0.855457\n[42]\tvalid_0's rmse: 0.855256\n[43]\tvalid_0's rmse: 0.855084\n[44]\tvalid_0's rmse: 0.854782\n[45]\tvalid_0's rmse: 0.85459\n[46]\tvalid_0's rmse: 0.854411\n[47]\tvalid_0's rmse: 0.854258\n[48]\tvalid_0's rmse: 0.854097\n[49]\tvalid_0's rmse: 0.853903\n[50]\tvalid_0's rmse: 0.853751\n[51]\tvalid_0's rmse: 0.853646\n[52]\tvalid_0's rmse: 0.853518\n[53]\tvalid_0's rmse: 0.853264\n[54]\tvalid_0's rmse: 0.853141\n[55]\tvalid_0's rmse: 0.853038\n[56]\tvalid_0's rmse: 0.852871\n[57]\tvalid_0's rmse: 0.852707\n[58]\tvalid_0's rmse: 0.852549\n[59]\tvalid_0's rmse: 0.852427\n[60]\tvalid_0's rmse: 0.85234\n[61]\tvalid_0's rmse: 0.852237\n[62]\tvalid_0's rmse: 0.852114\n[63]\tvalid_0's rmse: 0.85203\n[64]\tvalid_0's rmse: 0.851898\n[65]\tvalid_0's rmse: 0.851808\n[66]\tvalid_0's rmse: 0.851703\n[67]\tvalid_0's rmse: 0.851643\n[68]\tvalid_0's rmse: 0.851514\n[69]\tvalid_0's rmse: 0.851393\n[70]\tvalid_0's rmse: 0.851242\n[71]\tvalid_0's rmse: 0.851176\n[72]\tvalid_0's rmse: 0.851122\n[73]\tvalid_0's rmse: 0.851072\n[74]\tvalid_0's rmse: 0.85101\n[75]\tvalid_0's rmse: 0.850924\n[76]\tvalid_0's rmse: 0.85078\n[77]\tvalid_0's rmse: 0.850723\n[78]\tvalid_0's rmse: 0.850634\n[79]\tvalid_0's rmse: 0.850548\n[80]\tvalid_0's rmse: 0.850496\n[81]\tvalid_0's rmse: 0.850428\n[82]\tvalid_0's rmse: 0.850404\n[83]\tvalid_0's rmse: 0.850315\n[84]\tvalid_0's rmse: 0.850259\n[85]\tvalid_0's rmse: 0.850229\n[86]\tvalid_0's rmse: 0.85021\n[87]\tvalid_0's rmse: 0.850171\n[88]\tvalid_0's rmse: 0.850089\n[89]\tvalid_0's rmse: 0.850031\n[90]\tvalid_0's rmse: 0.849979\n[91]\tvalid_0's rmse: 0.849928\n[92]\tvalid_0's rmse: 0.849885\n[93]\tvalid_0's rmse: 0.849842\n[94]\tvalid_0's rmse: 0.849826\n[95]\tvalid_0's rmse: 0.849781\n[96]\tvalid_0's rmse: 0.849766\n[97]\tvalid_0's rmse: 0.849727\n[98]\tvalid_0's rmse: 0.849635\n[99]\tvalid_0's rmse: 0.849593\n[100]\tvalid_0's rmse: 0.849551\n[101]\tvalid_0's rmse: 0.849511\n[102]\tvalid_0's rmse: 0.849481\n[103]\tvalid_0's rmse: 0.849463\n[104]\tvalid_0's rmse: 0.849381\n[105]\tvalid_0's rmse: 0.849312\n[106]\tvalid_0's rmse: 0.849279\n[107]\tvalid_0's rmse: 0.849241\n[108]\tvalid_0's rmse: 0.84921\n[109]\tvalid_0's rmse: 0.849193\n[110]\tvalid_0's rmse: 0.849167\n[111]\tvalid_0's rmse: 0.849133\n[112]\tvalid_0's rmse: 0.849116\n[113]\tvalid_0's rmse: 0.849036\n[114]\tvalid_0's rmse: 0.84902\n[115]\tvalid_0's rmse: 0.849003\n[116]\tvalid_0's rmse: 0.848959\n[117]\tvalid_0's rmse: 0.848956\n[118]\tvalid_0's rmse: 0.848911\n[119]\tvalid_0's rmse: 0.848873\n[120]\tvalid_0's rmse: 0.84885\n[121]\tvalid_0's rmse: 0.848775\n[122]\tvalid_0's rmse: 0.848771\n[123]\tvalid_0's rmse: 0.848724\n[124]\tvalid_0's rmse: 0.848702\n[125]\tvalid_0's rmse: 0.848672\n[126]\tvalid_0's rmse: 0.84865\n[127]\tvalid_0's rmse: 0.848612\n[128]\tvalid_0's rmse: 0.848593\n[129]\tvalid_0's rmse: 0.848585\n[130]\tvalid_0's rmse: 0.848551\n[131]\tvalid_0's rmse: 0.848556\n[132]\tvalid_0's rmse: 0.848503\n[133]\tvalid_0's rmse: 0.848499\n[134]\tvalid_0's rmse: 0.848487\n[135]\tvalid_0's rmse: 0.848451\n[136]\tvalid_0's rmse: 0.848436\n[137]\tvalid_0's rmse: 0.848396\n[138]\tvalid_0's rmse: 0.848359\n[139]\tvalid_0's rmse: 0.848352\n[140]\tvalid_0's rmse: 0.848343\n[141]\tvalid_0's rmse: 0.848327\n[142]\tvalid_0's rmse: 0.848309\n[143]\tvalid_0's rmse: 0.848285\n[144]\tvalid_0's rmse: 0.848275\n[145]\tvalid_0's rmse: 0.848262\n[146]\tvalid_0's rmse: 0.848241\n[147]\tvalid_0's rmse: 0.848251\n[148]\tvalid_0's rmse: 0.848216\n[149]\tvalid_0's rmse: 0.848215\n[150]\tvalid_0's rmse: 0.848211\n[151]\tvalid_0's rmse: 0.848166\n[152]\tvalid_0's rmse: 0.848147\n[153]\tvalid_0's rmse: 0.848139\n[154]\tvalid_0's rmse: 0.848113\n[155]\tvalid_0's rmse: 0.848079\n[156]\tvalid_0's rmse: 0.848078\n[157]\tvalid_0's rmse: 0.848065\n[158]\tvalid_0's rmse: 0.848068\n[159]\tvalid_0's rmse: 0.848077\n[160]\tvalid_0's rmse: 0.848025\n[161]\tvalid_0's rmse: 0.848017\n[162]\tvalid_0's rmse: 0.848037\n[163]\tvalid_0's rmse: 0.848033\n[164]\tvalid_0's rmse: 0.84803\n[165]\tvalid_0's rmse: 0.84803\n[166]\tvalid_0's rmse: 0.848015\n[167]\tvalid_0's rmse: 0.848022\n[168]\tvalid_0's rmse: 0.848016\n[169]\tvalid_0's rmse: 0.847979\n[170]\tvalid_0's rmse: 0.847971\n[171]\tvalid_0's rmse: 0.847956\n[172]\tvalid_0's rmse: 0.847957\n[173]\tvalid_0's rmse: 0.847931\n[174]\tvalid_0's rmse: 0.847899\n[175]\tvalid_0's rmse: 0.847883\n[176]\tvalid_0's rmse: 0.847883\n[177]\tvalid_0's rmse: 0.847877\n[178]\tvalid_0's rmse: 0.847862\n[179]\tvalid_0's rmse: 0.847842\n[180]\tvalid_0's rmse: 0.847857\n[181]\tvalid_0's rmse: 0.847846\n[182]\tvalid_0's rmse: 0.847855\n[183]\tvalid_0's rmse: 0.847825\n[184]\tvalid_0's rmse: 0.847825\n[185]\tvalid_0's rmse: 0.847798\n[186]\tvalid_0's rmse: 0.847802\n[187]\tvalid_0's rmse: 0.847794\n[188]\tvalid_0's rmse: 0.847783\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  70%|#######   | 7/10 [00:40<00:15,  5.31s/it]\u001b[32m[I 2021-02-05 22:54:01,316]\u001b[0m Trial 33 finished with value: 0.8477812318770434 and parameters: {'bagging_fraction': 0.7580098850067442, 'bagging_freq': 1}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\n","name":"stderr"},{"output_type":"stream","text":"[189]\tvalid_0's rmse: 0.847781\n[190]\tvalid_0's rmse: 0.847784\n[191]\tvalid_0's rmse: 0.847806\n[192]\tvalid_0's rmse: 0.847809\n[193]\tvalid_0's rmse: 0.847829\n[194]\tvalid_0's rmse: 0.847826\n[195]\tvalid_0's rmse: 0.847828\n[196]\tvalid_0's rmse: 0.847819\n[197]\tvalid_0's rmse: 0.84784\n[198]\tvalid_0's rmse: 0.847845\n[199]\tvalid_0's rmse: 0.847847\nEarly stopping, best iteration is:\n[189]\tvalid_0's rmse: 0.847781\n","name":"stdout"},{"output_type":"stream","text":"\rbagging, val_score: 0.847465:  70%|#######   | 7/10 [00:40<00:15,  5.31s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019391 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88831\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885512\n[3]\tvalid_0's rmse: 0.883188\n[4]\tvalid_0's rmse: 0.88101\n[5]\tvalid_0's rmse: 0.879096\n[6]\tvalid_0's rmse: 0.877075\n[7]\tvalid_0's rmse: 0.875571\n[8]\tvalid_0's rmse: 0.874349\n[9]\tvalid_0's rmse: 0.873196\n[10]\tvalid_0's rmse: 0.87206\n[11]\tvalid_0's rmse: 0.870685\n[12]\tvalid_0's rmse: 0.869442\n[13]\tvalid_0's rmse: 0.868386\n[14]\tvalid_0's rmse: 0.867327\n[15]\tvalid_0's rmse: 0.866618\n[16]\tvalid_0's rmse: 0.86589\n[17]\tvalid_0's rmse: 0.865109\n[18]\tvalid_0's rmse: 0.864403\n[19]\tvalid_0's rmse: 0.863719\n[20]\tvalid_0's rmse: 0.863132\n[21]\tvalid_0's rmse: 0.862582\n[22]\tvalid_0's rmse: 0.86197\n[23]\tvalid_0's rmse: 0.861429\n[24]\tvalid_0's rmse: 0.860858\n[25]\tvalid_0's rmse: 0.860495\n[26]\tvalid_0's rmse: 0.859985\n[27]\tvalid_0's rmse: 0.859636\n[28]\tvalid_0's rmse: 0.859239\n[29]\tvalid_0's rmse: 0.85883\n[30]\tvalid_0's rmse: 0.858488\n[31]\tvalid_0's rmse: 0.858195\n[32]\tvalid_0's rmse: 0.857907\n[33]\tvalid_0's rmse: 0.857608\n[34]\tvalid_0's rmse: 0.857307\n[35]\tvalid_0's rmse: 0.857022\n[36]\tvalid_0's rmse: 0.856741\n[37]\tvalid_0's rmse: 0.856452\n[38]\tvalid_0's rmse: 0.856173\n[39]\tvalid_0's rmse: 0.855931\n[40]\tvalid_0's rmse: 0.855691\n[41]\tvalid_0's rmse: 0.855484\n[42]\tvalid_0's rmse: 0.855307\n[43]\tvalid_0's rmse: 0.855091\n[44]\tvalid_0's rmse: 0.854862\n[45]\tvalid_0's rmse: 0.854642\n[46]\tvalid_0's rmse: 0.854526\n[47]\tvalid_0's rmse: 0.85433\n[48]\tvalid_0's rmse: 0.85412\n[49]\tvalid_0's rmse: 0.85395\n[50]\tvalid_0's rmse: 0.853787\n[51]\tvalid_0's rmse: 0.853682\n[52]\tvalid_0's rmse: 0.853495\n[53]\tvalid_0's rmse: 0.853256\n[54]\tvalid_0's rmse: 0.853161\n[55]\tvalid_0's rmse: 0.853055\n[56]\tvalid_0's rmse: 0.852869\n[57]\tvalid_0's rmse: 0.852744\n[58]\tvalid_0's rmse: 0.852612\n[59]\tvalid_0's rmse: 0.852512\n[60]\tvalid_0's rmse: 0.852416\n[61]\tvalid_0's rmse: 0.852325\n[62]\tvalid_0's rmse: 0.852187\n[63]\tvalid_0's rmse: 0.852077\n[64]\tvalid_0's rmse: 0.851945\n[65]\tvalid_0's rmse: 0.851817\n[66]\tvalid_0's rmse: 0.851683\n[67]\tvalid_0's rmse: 0.851588\n[68]\tvalid_0's rmse: 0.851456\n[69]\tvalid_0's rmse: 0.851313\n[70]\tvalid_0's rmse: 0.851226\n[71]\tvalid_0's rmse: 0.851189\n[72]\tvalid_0's rmse: 0.851105\n[73]\tvalid_0's rmse: 0.851032\n[74]\tvalid_0's rmse: 0.850986\n[75]\tvalid_0's rmse: 0.850906\n[76]\tvalid_0's rmse: 0.850774\n[77]\tvalid_0's rmse: 0.850703\n[78]\tvalid_0's rmse: 0.850628\n[79]\tvalid_0's rmse: 0.85052\n[80]\tvalid_0's rmse: 0.850434\n[81]\tvalid_0's rmse: 0.850361\n[82]\tvalid_0's rmse: 0.850278\n[83]\tvalid_0's rmse: 0.850191\n[84]\tvalid_0's rmse: 0.850133\n[85]\tvalid_0's rmse: 0.850054\n[86]\tvalid_0's rmse: 0.850018\n[87]\tvalid_0's rmse: 0.849994\n[88]\tvalid_0's rmse: 0.849874\n[89]\tvalid_0's rmse: 0.849788\n[90]\tvalid_0's rmse: 0.849728\n[91]\tvalid_0's rmse: 0.849651\n[92]\tvalid_0's rmse: 0.849564\n[93]\tvalid_0's rmse: 0.849519\n[94]\tvalid_0's rmse: 0.849497\n[95]\tvalid_0's rmse: 0.849449\n[96]\tvalid_0's rmse: 0.849412\n[97]\tvalid_0's rmse: 0.84938\n[98]\tvalid_0's rmse: 0.849294\n[99]\tvalid_0's rmse: 0.849294\n[100]\tvalid_0's rmse: 0.849275\n[101]\tvalid_0's rmse: 0.849249\n[102]\tvalid_0's rmse: 0.849181\n[103]\tvalid_0's rmse: 0.849178\n[104]\tvalid_0's rmse: 0.849101\n[105]\tvalid_0's rmse: 0.849064\n[106]\tvalid_0's rmse: 0.849051\n[107]\tvalid_0's rmse: 0.848974\n[108]\tvalid_0's rmse: 0.848941\n[109]\tvalid_0's rmse: 0.848923\n[110]\tvalid_0's rmse: 0.848927\n[111]\tvalid_0's rmse: 0.848911\n[112]\tvalid_0's rmse: 0.848877\n[113]\tvalid_0's rmse: 0.848874\n[114]\tvalid_0's rmse: 0.848761\n[115]\tvalid_0's rmse: 0.848716\n[116]\tvalid_0's rmse: 0.848693\n[117]\tvalid_0's rmse: 0.848583\n[118]\tvalid_0's rmse: 0.848559\n[119]\tvalid_0's rmse: 0.848521\n[120]\tvalid_0's rmse: 0.848544\n[121]\tvalid_0's rmse: 0.848509\n[122]\tvalid_0's rmse: 0.848487\n[123]\tvalid_0's rmse: 0.848435\n[124]\tvalid_0's rmse: 0.848434\n[125]\tvalid_0's rmse: 0.84841\n[126]\tvalid_0's rmse: 0.848402\n[127]\tvalid_0's rmse: 0.848376\n[128]\tvalid_0's rmse: 0.848329\n[129]\tvalid_0's rmse: 0.848275\n[130]\tvalid_0's rmse: 0.8483\n[131]\tvalid_0's rmse: 0.848262\n[132]\tvalid_0's rmse: 0.848237\n[133]\tvalid_0's rmse: 0.848211\n[134]\tvalid_0's rmse: 0.848177\n[135]\tvalid_0's rmse: 0.848152\n[136]\tvalid_0's rmse: 0.848145\n[137]\tvalid_0's rmse: 0.848116\n[138]\tvalid_0's rmse: 0.848108\n[139]\tvalid_0's rmse: 0.84809\n[140]\tvalid_0's rmse: 0.848088\n[141]\tvalid_0's rmse: 0.848075\n[142]\tvalid_0's rmse: 0.848035\n[143]\tvalid_0's rmse: 0.848039\n[144]\tvalid_0's rmse: 0.848017\n[145]\tvalid_0's rmse: 0.848014\n[146]\tvalid_0's rmse: 0.847997\n[147]\tvalid_0's rmse: 0.848009\n[148]\tvalid_0's rmse: 0.847973\n[149]\tvalid_0's rmse: 0.847951\n[150]\tvalid_0's rmse: 0.847939\n[151]\tvalid_0's rmse: 0.847949\n[152]\tvalid_0's rmse: 0.847968\n[153]\tvalid_0's rmse: 0.847955\n[154]\tvalid_0's rmse: 0.847932\n[155]\tvalid_0's rmse: 0.847935\n[156]\tvalid_0's rmse: 0.84793\n[157]\tvalid_0's rmse: 0.847906\n[158]\tvalid_0's rmse: 0.847921\n[159]\tvalid_0's rmse: 0.847925\n[160]\tvalid_0's rmse: 0.847904\n[161]\tvalid_0's rmse: 0.847908\n[162]\tvalid_0's rmse: 0.84791\n[163]\tvalid_0's rmse: 0.847891\n[164]\tvalid_0's rmse: 0.847873\n[165]\tvalid_0's rmse: 0.847892\n[166]\tvalid_0's rmse: 0.847888\n[167]\tvalid_0's rmse: 0.847875\n[168]\tvalid_0's rmse: 0.847881\n[169]\tvalid_0's rmse: 0.847884\n[170]\tvalid_0's rmse: 0.847851\n[171]\tvalid_0's rmse: 0.847878\n[172]\tvalid_0's rmse: 0.847866\n[173]\tvalid_0's rmse: 0.847847\n[174]\tvalid_0's rmse: 0.847838\n[175]\tvalid_0's rmse: 0.847844\n[176]\tvalid_0's rmse: 0.847833\n[177]\tvalid_0's rmse: 0.847821\n[178]\tvalid_0's rmse: 0.847801\n[179]\tvalid_0's rmse: 0.847797\n[180]\tvalid_0's rmse: 0.847787\n[181]\tvalid_0's rmse: 0.847796\n[182]\tvalid_0's rmse: 0.847731\n[183]\tvalid_0's rmse: 0.84771\n[184]\tvalid_0's rmse: 0.847702\n[185]\tvalid_0's rmse: 0.847708\n[186]\tvalid_0's rmse: 0.847724\n[187]\tvalid_0's rmse: 0.847728\n[188]\tvalid_0's rmse: 0.847729\n[189]\tvalid_0's rmse: 0.847733\n[190]\tvalid_0's rmse: 0.847722\n[191]\tvalid_0's rmse: 0.84771\n[192]\tvalid_0's rmse: 0.84772\n[193]\tvalid_0's rmse: 0.847711\n[194]\tvalid_0's rmse: 0.847683\n[195]\tvalid_0's rmse: 0.847667\n[196]\tvalid_0's rmse: 0.847664\n[197]\tvalid_0's rmse: 0.847653\n[198]\tvalid_0's rmse: 0.847654\n[199]\tvalid_0's rmse: 0.847669\n[200]\tvalid_0's rmse: 0.847702\n[201]\tvalid_0's rmse: 0.847675\n[202]\tvalid_0's rmse: 0.84766\n[203]\tvalid_0's rmse: 0.847642\n[204]\tvalid_0's rmse: 0.847645\n[205]\tvalid_0's rmse: 0.847648\n[206]\tvalid_0's rmse: 0.847654\n[207]\tvalid_0's rmse: 0.847655\n[208]\tvalid_0's rmse: 0.847636\n[209]\tvalid_0's rmse: 0.847642\n[210]\tvalid_0's rmse: 0.84763\n[211]\tvalid_0's rmse: 0.847619\n[212]\tvalid_0's rmse: 0.847608\n[213]\tvalid_0's rmse: 0.847608\n[214]\tvalid_0's rmse: 0.847607\n[215]\tvalid_0's rmse: 0.847598\n[216]\tvalid_0's rmse: 0.847609\n[217]\tvalid_0's rmse: 0.847613\n[218]\tvalid_0's rmse: 0.847627\n[219]\tvalid_0's rmse: 0.847641\n[220]\tvalid_0's rmse: 0.847642\n[221]\tvalid_0's rmse: 0.847632\n[222]\tvalid_0's rmse: 0.847652\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  80%|########  | 8/10 [00:45<00:10,  5.34s/it]\u001b[32m[I 2021-02-05 22:54:06,702]\u001b[0m Trial 34 finished with value: 0.8475983226172658 and parameters: {'bagging_fraction': 0.6048270700326779, 'bagging_freq': 1}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465:  80%|########  | 8/10 [00:45<00:10,  5.34s/it]","name":"stderr"},{"output_type":"stream","text":"[223]\tvalid_0's rmse: 0.847635\n[224]\tvalid_0's rmse: 0.847644\n[225]\tvalid_0's rmse: 0.847649\nEarly stopping, best iteration is:\n[215]\tvalid_0's rmse: 0.847598\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018962 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888334\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885553\n[3]\tvalid_0's rmse: 0.883378\n[4]\tvalid_0's rmse: 0.88119\n[5]\tvalid_0's rmse: 0.879347\n[6]\tvalid_0's rmse: 0.877265\n[7]\tvalid_0's rmse: 0.875776\n[8]\tvalid_0's rmse: 0.874516\n[9]\tvalid_0's rmse: 0.873376\n[10]\tvalid_0's rmse: 0.872223\n[11]\tvalid_0's rmse: 0.870864\n[12]\tvalid_0's rmse: 0.869632\n[13]\tvalid_0's rmse: 0.8686\n[14]\tvalid_0's rmse: 0.867506\n[15]\tvalid_0's rmse: 0.866783\n[16]\tvalid_0's rmse: 0.866067\n[17]\tvalid_0's rmse: 0.865279\n[18]\tvalid_0's rmse: 0.864674\n[19]\tvalid_0's rmse: 0.864013\n[20]\tvalid_0's rmse: 0.863424\n[21]\tvalid_0's rmse: 0.862915\n[22]\tvalid_0's rmse: 0.862299\n[23]\tvalid_0's rmse: 0.861823\n[24]\tvalid_0's rmse: 0.861339\n[25]\tvalid_0's rmse: 0.860964\n[26]\tvalid_0's rmse: 0.860527\n[27]\tvalid_0's rmse: 0.860122\n[28]\tvalid_0's rmse: 0.859732\n[29]\tvalid_0's rmse: 0.859326\n[30]\tvalid_0's rmse: 0.859013\n[31]\tvalid_0's rmse: 0.858729\n[32]\tvalid_0's rmse: 0.858319\n[33]\tvalid_0's rmse: 0.858035\n[34]\tvalid_0's rmse: 0.857642\n[35]\tvalid_0's rmse: 0.857347\n[36]\tvalid_0's rmse: 0.857085\n[37]\tvalid_0's rmse: 0.856811\n[38]\tvalid_0's rmse: 0.856519\n[39]\tvalid_0's rmse: 0.856266\n[40]\tvalid_0's rmse: 0.85602\n[41]\tvalid_0's rmse: 0.855882\n[42]\tvalid_0's rmse: 0.855706\n[43]\tvalid_0's rmse: 0.855524\n[44]\tvalid_0's rmse: 0.855249\n[45]\tvalid_0's rmse: 0.855016\n[46]\tvalid_0's rmse: 0.854889\n[47]\tvalid_0's rmse: 0.854693\n[48]\tvalid_0's rmse: 0.854547\n[49]\tvalid_0's rmse: 0.854413\n[50]\tvalid_0's rmse: 0.854288\n[51]\tvalid_0's rmse: 0.85418\n[52]\tvalid_0's rmse: 0.853931\n[53]\tvalid_0's rmse: 0.853703\n[54]\tvalid_0's rmse: 0.853521\n[55]\tvalid_0's rmse: 0.853389\n[56]\tvalid_0's rmse: 0.853207\n[57]\tvalid_0's rmse: 0.853068\n[58]\tvalid_0's rmse: 0.852983\n[59]\tvalid_0's rmse: 0.852878\n[60]\tvalid_0's rmse: 0.852803\n[61]\tvalid_0's rmse: 0.852713\n[62]\tvalid_0's rmse: 0.852584\n[63]\tvalid_0's rmse: 0.852493\n[64]\tvalid_0's rmse: 0.852322\n[65]\tvalid_0's rmse: 0.852145\n[66]\tvalid_0's rmse: 0.85204\n[67]\tvalid_0's rmse: 0.85198\n[68]\tvalid_0's rmse: 0.85189\n[69]\tvalid_0's rmse: 0.851762\n[70]\tvalid_0's rmse: 0.85166\n[71]\tvalid_0's rmse: 0.85157\n[72]\tvalid_0's rmse: 0.851503\n[73]\tvalid_0's rmse: 0.851424\n[74]\tvalid_0's rmse: 0.851334\n[75]\tvalid_0's rmse: 0.851269\n[76]\tvalid_0's rmse: 0.85119\n[77]\tvalid_0's rmse: 0.851121\n[78]\tvalid_0's rmse: 0.851037\n[79]\tvalid_0's rmse: 0.850977\n[80]\tvalid_0's rmse: 0.850921\n[81]\tvalid_0's rmse: 0.850875\n[82]\tvalid_0's rmse: 0.850788\n[83]\tvalid_0's rmse: 0.850739\n[84]\tvalid_0's rmse: 0.850729\n[85]\tvalid_0's rmse: 0.850691\n[86]\tvalid_0's rmse: 0.850643\n[87]\tvalid_0's rmse: 0.850569\n[88]\tvalid_0's rmse: 0.85045\n[89]\tvalid_0's rmse: 0.850414\n[90]\tvalid_0's rmse: 0.850367\n[91]\tvalid_0's rmse: 0.850328\n[92]\tvalid_0's rmse: 0.850247\n[93]\tvalid_0's rmse: 0.850191\n[94]\tvalid_0's rmse: 0.850166\n[95]\tvalid_0's rmse: 0.850118\n[96]\tvalid_0's rmse: 0.850107\n[97]\tvalid_0's rmse: 0.850078\n[98]\tvalid_0's rmse: 0.850031\n[99]\tvalid_0's rmse: 0.85001\n[100]\tvalid_0's rmse: 0.84995\n[101]\tvalid_0's rmse: 0.84989\n[102]\tvalid_0's rmse: 0.84984\n[103]\tvalid_0's rmse: 0.849803\n[104]\tvalid_0's rmse: 0.8497\n[105]\tvalid_0's rmse: 0.849653\n[106]\tvalid_0's rmse: 0.84956\n[107]\tvalid_0's rmse: 0.849542\n[108]\tvalid_0's rmse: 0.849516\n[109]\tvalid_0's rmse: 0.849487\n[110]\tvalid_0's rmse: 0.849449\n[111]\tvalid_0's rmse: 0.849379\n[112]\tvalid_0's rmse: 0.849372\n[113]\tvalid_0's rmse: 0.849304\n[114]\tvalid_0's rmse: 0.849296\n[115]\tvalid_0's rmse: 0.849249\n[116]\tvalid_0's rmse: 0.849268\n[117]\tvalid_0's rmse: 0.849231\n[118]\tvalid_0's rmse: 0.849195\n[119]\tvalid_0's rmse: 0.849154\n[120]\tvalid_0's rmse: 0.849116\n[121]\tvalid_0's rmse: 0.849058\n[122]\tvalid_0's rmse: 0.849034\n[123]\tvalid_0's rmse: 0.848973\n[124]\tvalid_0's rmse: 0.848945\n[125]\tvalid_0's rmse: 0.848902\n[126]\tvalid_0's rmse: 0.848901\n[127]\tvalid_0's rmse: 0.848897\n[128]\tvalid_0's rmse: 0.84885\n[129]\tvalid_0's rmse: 0.848842\n[130]\tvalid_0's rmse: 0.848828\n[131]\tvalid_0's rmse: 0.848797\n[132]\tvalid_0's rmse: 0.848773\n[133]\tvalid_0's rmse: 0.848755\n[134]\tvalid_0's rmse: 0.848729\n[135]\tvalid_0's rmse: 0.848744\n[136]\tvalid_0's rmse: 0.848725\n[137]\tvalid_0's rmse: 0.848689\n[138]\tvalid_0's rmse: 0.848663\n[139]\tvalid_0's rmse: 0.848662\n[140]\tvalid_0's rmse: 0.848653\n[141]\tvalid_0's rmse: 0.848643\n[142]\tvalid_0's rmse: 0.848631\n[143]\tvalid_0's rmse: 0.848648\n[144]\tvalid_0's rmse: 0.848629\n[145]\tvalid_0's rmse: 0.848651\n[146]\tvalid_0's rmse: 0.84862\n[147]\tvalid_0's rmse: 0.848604\n[148]\tvalid_0's rmse: 0.848571\n[149]\tvalid_0's rmse: 0.848522\n[150]\tvalid_0's rmse: 0.848531\n[151]\tvalid_0's rmse: 0.848474\n[152]\tvalid_0's rmse: 0.848469\n[153]\tvalid_0's rmse: 0.848451\n[154]\tvalid_0's rmse: 0.848476\n[155]\tvalid_0's rmse: 0.848473\n[156]\tvalid_0's rmse: 0.848486\n[157]\tvalid_0's rmse: 0.848479\n[158]\tvalid_0's rmse: 0.848449\n[159]\tvalid_0's rmse: 0.848452\n[160]\tvalid_0's rmse: 0.848408\n[161]\tvalid_0's rmse: 0.848366\n[162]\tvalid_0's rmse: 0.848352\n[163]\tvalid_0's rmse: 0.848319\n[164]\tvalid_0's rmse: 0.848333\n[165]\tvalid_0's rmse: 0.848337\n[166]\tvalid_0's rmse: 0.848327\n[167]\tvalid_0's rmse: 0.848342\n[168]\tvalid_0's rmse: 0.848336\n[169]\tvalid_0's rmse: 0.848353\n[170]\tvalid_0's rmse: 0.848337\n[171]\tvalid_0's rmse: 0.848331\n[172]\tvalid_0's rmse: 0.8483\n[173]\tvalid_0's rmse: 0.848304\n[174]\tvalid_0's rmse: 0.848311\n[175]\tvalid_0's rmse: 0.848297\n[176]\tvalid_0's rmse: 0.848321\n[177]\tvalid_0's rmse: 0.848303\n[178]\tvalid_0's rmse: 0.848261\n[179]\tvalid_0's rmse: 0.848236\n[180]\tvalid_0's rmse: 0.84821\n[181]\tvalid_0's rmse: 0.848161\n[182]\tvalid_0's rmse: 0.848136\n[183]\tvalid_0's rmse: 0.848111\n[184]\tvalid_0's rmse: 0.848097\n[185]\tvalid_0's rmse: 0.848091\n[186]\tvalid_0's rmse: 0.84811\n[187]\tvalid_0's rmse: 0.848061\n[188]\tvalid_0's rmse: 0.848038\n[189]\tvalid_0's rmse: 0.847994\n[190]\tvalid_0's rmse: 0.847978\n[191]\tvalid_0's rmse: 0.847975\n[192]\tvalid_0's rmse: 0.847951\n[193]\tvalid_0's rmse: 0.847927\n[194]\tvalid_0's rmse: 0.847916\n[195]\tvalid_0's rmse: 0.847929\n[196]\tvalid_0's rmse: 0.847933\n[197]\tvalid_0's rmse: 0.847942\n[198]\tvalid_0's rmse: 0.847949\n[199]\tvalid_0's rmse: 0.847965\n[200]\tvalid_0's rmse: 0.847945\n[201]\tvalid_0's rmse: 0.847926\n[202]\tvalid_0's rmse: 0.847912\n[203]\tvalid_0's rmse: 0.847879\n[204]\tvalid_0's rmse: 0.847878\n[205]\tvalid_0's rmse: 0.847878\n[206]\tvalid_0's rmse: 0.847853\n[207]\tvalid_0's rmse: 0.847853\n[208]\tvalid_0's rmse: 0.847853\n[209]\tvalid_0's rmse: 0.847861\n[210]\tvalid_0's rmse: 0.847861\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465:  90%|######### | 9/10 [00:52<00:05,  5.92s/it]\u001b[32m[I 2021-02-05 22:54:13,909]\u001b[0m Trial 35 finished with value: 0.8478525091300972 and parameters: {'bagging_fraction': 0.7002768721561039, 'bagging_freq': 4}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465:  90%|######### | 9/10 [00:52<00:05,  5.92s/it]","name":"stderr"},{"output_type":"stream","text":"[211]\tvalid_0's rmse: 0.847866\n[212]\tvalid_0's rmse: 0.847876\n[213]\tvalid_0's rmse: 0.847885\n[214]\tvalid_0's rmse: 0.847876\n[215]\tvalid_0's rmse: 0.847857\n[216]\tvalid_0's rmse: 0.847864\n[217]\tvalid_0's rmse: 0.847864\nEarly stopping, best iteration is:\n[207]\tvalid_0's rmse: 0.847853\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019029 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88834\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.88556\n[3]\tvalid_0's rmse: 0.883382\n[4]\tvalid_0's rmse: 0.881191\n[5]\tvalid_0's rmse: 0.879302\n[6]\tvalid_0's rmse: 0.877242\n[7]\tvalid_0's rmse: 0.875727\n[8]\tvalid_0's rmse: 0.874466\n[9]\tvalid_0's rmse: 0.873304\n[10]\tvalid_0's rmse: 0.872279\n[11]\tvalid_0's rmse: 0.870904\n[12]\tvalid_0's rmse: 0.869684\n[13]\tvalid_0's rmse: 0.868615\n[14]\tvalid_0's rmse: 0.867539\n[15]\tvalid_0's rmse: 0.866831\n[16]\tvalid_0's rmse: 0.866105\n[17]\tvalid_0's rmse: 0.865234\n[18]\tvalid_0's rmse: 0.864626\n[19]\tvalid_0's rmse: 0.863959\n[20]\tvalid_0's rmse: 0.863413\n[21]\tvalid_0's rmse: 0.862843\n[22]\tvalid_0's rmse: 0.862243\n[23]\tvalid_0's rmse: 0.861763\n[24]\tvalid_0's rmse: 0.861246\n[25]\tvalid_0's rmse: 0.860737\n[26]\tvalid_0's rmse: 0.860364\n[27]\tvalid_0's rmse: 0.860007\n[28]\tvalid_0's rmse: 0.85962\n[29]\tvalid_0's rmse: 0.85926\n[30]\tvalid_0's rmse: 0.858925\n[31]\tvalid_0's rmse: 0.858642\n[32]\tvalid_0's rmse: 0.858269\n[33]\tvalid_0's rmse: 0.857892\n[34]\tvalid_0's rmse: 0.857535\n[35]\tvalid_0's rmse: 0.857251\n[36]\tvalid_0's rmse: 0.856974\n[37]\tvalid_0's rmse: 0.856718\n[38]\tvalid_0's rmse: 0.856448\n[39]\tvalid_0's rmse: 0.856157\n[40]\tvalid_0's rmse: 0.85591\n[41]\tvalid_0's rmse: 0.855732\n[42]\tvalid_0's rmse: 0.855508\n[43]\tvalid_0's rmse: 0.85531\n[44]\tvalid_0's rmse: 0.854977\n[45]\tvalid_0's rmse: 0.854782\n[46]\tvalid_0's rmse: 0.854621\n[47]\tvalid_0's rmse: 0.854428\n[48]\tvalid_0's rmse: 0.854289\n[49]\tvalid_0's rmse: 0.854112\n[50]\tvalid_0's rmse: 0.853948\n[51]\tvalid_0's rmse: 0.853866\n[52]\tvalid_0's rmse: 0.853627\n[53]\tvalid_0's rmse: 0.853476\n[54]\tvalid_0's rmse: 0.85334\n[55]\tvalid_0's rmse: 0.853237\n[56]\tvalid_0's rmse: 0.853051\n[57]\tvalid_0's rmse: 0.852897\n[58]\tvalid_0's rmse: 0.85274\n[59]\tvalid_0's rmse: 0.852624\n[60]\tvalid_0's rmse: 0.852523\n[61]\tvalid_0's rmse: 0.852424\n[62]\tvalid_0's rmse: 0.852338\n[63]\tvalid_0's rmse: 0.852191\n[64]\tvalid_0's rmse: 0.852032\n[65]\tvalid_0's rmse: 0.851913\n[66]\tvalid_0's rmse: 0.851834\n[67]\tvalid_0's rmse: 0.851763\n[68]\tvalid_0's rmse: 0.851656\n[69]\tvalid_0's rmse: 0.851481\n[70]\tvalid_0's rmse: 0.851383\n[71]\tvalid_0's rmse: 0.851274\n[72]\tvalid_0's rmse: 0.851193\n[73]\tvalid_0's rmse: 0.851113\n[74]\tvalid_0's rmse: 0.851012\n[75]\tvalid_0's rmse: 0.850933\n[76]\tvalid_0's rmse: 0.850845\n[77]\tvalid_0's rmse: 0.850766\n[78]\tvalid_0's rmse: 0.850702\n[79]\tvalid_0's rmse: 0.850645\n[80]\tvalid_0's rmse: 0.850596\n[81]\tvalid_0's rmse: 0.850497\n[82]\tvalid_0's rmse: 0.850431\n[83]\tvalid_0's rmse: 0.850361\n[84]\tvalid_0's rmse: 0.850274\n[85]\tvalid_0's rmse: 0.850188\n[86]\tvalid_0's rmse: 0.85015\n[87]\tvalid_0's rmse: 0.850115\n[88]\tvalid_0's rmse: 0.850018\n[89]\tvalid_0's rmse: 0.84997\n[90]\tvalid_0's rmse: 0.849929\n[91]\tvalid_0's rmse: 0.849893\n[92]\tvalid_0's rmse: 0.849828\n[93]\tvalid_0's rmse: 0.849781\n[94]\tvalid_0's rmse: 0.849729\n[95]\tvalid_0's rmse: 0.849687\n[96]\tvalid_0's rmse: 0.849642\n[97]\tvalid_0's rmse: 0.84961\n[98]\tvalid_0's rmse: 0.84957\n[99]\tvalid_0's rmse: 0.849545\n[100]\tvalid_0's rmse: 0.849507\n[101]\tvalid_0's rmse: 0.849466\n[102]\tvalid_0's rmse: 0.849394\n[103]\tvalid_0's rmse: 0.849374\n[104]\tvalid_0's rmse: 0.849355\n[105]\tvalid_0's rmse: 0.849319\n[106]\tvalid_0's rmse: 0.849276\n[107]\tvalid_0's rmse: 0.849247\n[108]\tvalid_0's rmse: 0.849205\n[109]\tvalid_0's rmse: 0.849144\n[110]\tvalid_0's rmse: 0.849092\n[111]\tvalid_0's rmse: 0.849091\n[112]\tvalid_0's rmse: 0.849069\n[113]\tvalid_0's rmse: 0.849075\n[114]\tvalid_0's rmse: 0.84905\n[115]\tvalid_0's rmse: 0.849004\n[116]\tvalid_0's rmse: 0.848978\n[117]\tvalid_0's rmse: 0.848882\n[118]\tvalid_0's rmse: 0.84884\n[119]\tvalid_0's rmse: 0.848796\n[120]\tvalid_0's rmse: 0.848788\n[121]\tvalid_0's rmse: 0.848738\n[122]\tvalid_0's rmse: 0.848716\n[123]\tvalid_0's rmse: 0.848697\n[124]\tvalid_0's rmse: 0.848712\n[125]\tvalid_0's rmse: 0.848667\n[126]\tvalid_0's rmse: 0.848625\n[127]\tvalid_0's rmse: 0.848617\n[128]\tvalid_0's rmse: 0.848593\n[129]\tvalid_0's rmse: 0.848581\n[130]\tvalid_0's rmse: 0.84855\n[131]\tvalid_0's rmse: 0.84852\n[132]\tvalid_0's rmse: 0.848537\n[133]\tvalid_0's rmse: 0.848502\n[134]\tvalid_0's rmse: 0.848481\n[135]\tvalid_0's rmse: 0.848475\n[136]\tvalid_0's rmse: 0.848458\n[137]\tvalid_0's rmse: 0.848456\n[138]\tvalid_0's rmse: 0.848446\n[139]\tvalid_0's rmse: 0.848454\n[140]\tvalid_0's rmse: 0.848451\n[141]\tvalid_0's rmse: 0.848418\n[142]\tvalid_0's rmse: 0.848424\n[143]\tvalid_0's rmse: 0.84839\n[144]\tvalid_0's rmse: 0.848372\n[145]\tvalid_0's rmse: 0.848369\n[146]\tvalid_0's rmse: 0.848334\n[147]\tvalid_0's rmse: 0.848303\n[148]\tvalid_0's rmse: 0.848263\n[149]\tvalid_0's rmse: 0.848247\n[150]\tvalid_0's rmse: 0.848225\n[151]\tvalid_0's rmse: 0.848157\n[152]\tvalid_0's rmse: 0.848137\n[153]\tvalid_0's rmse: 0.848126\n[154]\tvalid_0's rmse: 0.848081\n[155]\tvalid_0's rmse: 0.848087\n[156]\tvalid_0's rmse: 0.848093\n[157]\tvalid_0's rmse: 0.848075\n[158]\tvalid_0's rmse: 0.848085\n[159]\tvalid_0's rmse: 0.848087\n[160]\tvalid_0's rmse: 0.848022\n[161]\tvalid_0's rmse: 0.847998\n[162]\tvalid_0's rmse: 0.847968\n[163]\tvalid_0's rmse: 0.847983\n[164]\tvalid_0's rmse: 0.847961\n[165]\tvalid_0's rmse: 0.847958\n[166]\tvalid_0's rmse: 0.847957\n[167]\tvalid_0's rmse: 0.847948\n[168]\tvalid_0's rmse: 0.847937\n[169]\tvalid_0's rmse: 0.84793\n[170]\tvalid_0's rmse: 0.847946\n[171]\tvalid_0's rmse: 0.847959\n[172]\tvalid_0's rmse: 0.847923\n[173]\tvalid_0's rmse: 0.847903\n[174]\tvalid_0's rmse: 0.847904\n[175]\tvalid_0's rmse: 0.847864\n[176]\tvalid_0's rmse: 0.847864\n[177]\tvalid_0's rmse: 0.847875\n[178]\tvalid_0's rmse: 0.847813\n[179]\tvalid_0's rmse: 0.847816\n[180]\tvalid_0's rmse: 0.847839\n[181]\tvalid_0's rmse: 0.847842\n[182]\tvalid_0's rmse: 0.84784\n[183]\tvalid_0's rmse: 0.84783\n[184]\tvalid_0's rmse: 0.847819\n[185]\tvalid_0's rmse: 0.847815\n[186]\tvalid_0's rmse: 0.847815\n[187]\tvalid_0's rmse: 0.84781\n[188]\tvalid_0's rmse: 0.847788\n[189]\tvalid_0's rmse: 0.847801\n[190]\tvalid_0's rmse: 0.847799\n","name":"stdout"},{"output_type":"stream","text":"bagging, val_score: 0.847465: 100%|##########| 10/10 [00:58<00:00,  5.86s/it]\u001b[32m[I 2021-02-05 22:54:19,628]\u001b[0m Trial 36 finished with value: 0.8477876940864277 and parameters: {'bagging_fraction': 0.6839554149692575, 'bagging_freq': 5}. Best is trial 28 with value: 0.8474972961169717.\u001b[0m\nbagging, val_score: 0.847465: 100%|##########| 10/10 [00:58<00:00,  5.83s/it]\nfeature_fraction_stage2, val_score: 0.847465:   0%|          | 0/3 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"[191]\tvalid_0's rmse: 0.847812\n[192]\tvalid_0's rmse: 0.847829\n[193]\tvalid_0's rmse: 0.847837\n[194]\tvalid_0's rmse: 0.847827\n[195]\tvalid_0's rmse: 0.847828\n[196]\tvalid_0's rmse: 0.847809\n[197]\tvalid_0's rmse: 0.847818\n[198]\tvalid_0's rmse: 0.847811\nEarly stopping, best iteration is:\n[188]\tvalid_0's rmse: 0.847788\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019642 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885538\n[3]\tvalid_0's rmse: 0.882641\n[4]\tvalid_0's rmse: 0.880465\n[5]\tvalid_0's rmse: 0.878597\n[6]\tvalid_0's rmse: 0.876721\n[7]\tvalid_0's rmse: 0.875188\n[8]\tvalid_0's rmse: 0.873934\n[9]\tvalid_0's rmse: 0.87277\n[10]\tvalid_0's rmse: 0.871686\n[11]\tvalid_0's rmse: 0.870275\n[12]\tvalid_0's rmse: 0.869172\n[13]\tvalid_0's rmse: 0.86816\n[14]\tvalid_0's rmse: 0.867154\n[15]\tvalid_0's rmse: 0.866458\n[16]\tvalid_0's rmse: 0.865743\n[17]\tvalid_0's rmse: 0.864926\n[18]\tvalid_0's rmse: 0.864276\n[19]\tvalid_0's rmse: 0.863632\n[20]\tvalid_0's rmse: 0.863068\n[21]\tvalid_0's rmse: 0.862553\n[22]\tvalid_0's rmse: 0.86202\n[23]\tvalid_0's rmse: 0.861471\n[24]\tvalid_0's rmse: 0.860971\n[25]\tvalid_0's rmse: 0.860573\n[26]\tvalid_0's rmse: 0.860187\n[27]\tvalid_0's rmse: 0.859822\n[28]\tvalid_0's rmse: 0.859489\n[29]\tvalid_0's rmse: 0.859112\n[30]\tvalid_0's rmse: 0.858807\n[31]\tvalid_0's rmse: 0.858422\n[32]\tvalid_0's rmse: 0.858073\n[33]\tvalid_0's rmse: 0.857748\n[34]\tvalid_0's rmse: 0.857363\n[35]\tvalid_0's rmse: 0.857108\n[36]\tvalid_0's rmse: 0.856813\n[37]\tvalid_0's rmse: 0.856532\n[38]\tvalid_0's rmse: 0.856272\n[39]\tvalid_0's rmse: 0.85602\n[40]\tvalid_0's rmse: 0.855769\n[41]\tvalid_0's rmse: 0.855604\n[42]\tvalid_0's rmse: 0.8554\n[43]\tvalid_0's rmse: 0.855241\n[44]\tvalid_0's rmse: 0.854961\n[45]\tvalid_0's rmse: 0.854754\n[46]\tvalid_0's rmse: 0.854603\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854121\n[50]\tvalid_0's rmse: 0.853942\n[51]\tvalid_0's rmse: 0.853836\n[52]\tvalid_0's rmse: 0.853689\n[53]\tvalid_0's rmse: 0.853514\n[54]\tvalid_0's rmse: 0.853269\n[55]\tvalid_0's rmse: 0.853128\n[56]\tvalid_0's rmse: 0.852931\n[57]\tvalid_0's rmse: 0.852832\n[58]\tvalid_0's rmse: 0.85269\n[59]\tvalid_0's rmse: 0.852591\n[60]\tvalid_0's rmse: 0.85248\n[61]\tvalid_0's rmse: 0.852371\n[62]\tvalid_0's rmse: 0.852264\n[63]\tvalid_0's rmse: 0.852182\n[64]\tvalid_0's rmse: 0.852055\n[65]\tvalid_0's rmse: 0.851936\n[66]\tvalid_0's rmse: 0.85185\n[67]\tvalid_0's rmse: 0.851783\n[68]\tvalid_0's rmse: 0.851716\n[69]\tvalid_0's rmse: 0.851606\n[70]\tvalid_0's rmse: 0.851478\n[71]\tvalid_0's rmse: 0.851437\n[72]\tvalid_0's rmse: 0.851356\n[73]\tvalid_0's rmse: 0.851277\n[74]\tvalid_0's rmse: 0.85121\n[75]\tvalid_0's rmse: 0.851122\n[76]\tvalid_0's rmse: 0.850974\n[77]\tvalid_0's rmse: 0.850922\n[78]\tvalid_0's rmse: 0.850843\n[79]\tvalid_0's rmse: 0.85075\n[80]\tvalid_0's rmse: 0.85068\n[81]\tvalid_0's rmse: 0.850598\n[82]\tvalid_0's rmse: 0.850511\n[83]\tvalid_0's rmse: 0.850437\n[84]\tvalid_0's rmse: 0.850333\n[85]\tvalid_0's rmse: 0.850245\n[86]\tvalid_0's rmse: 0.850199\n[87]\tvalid_0's rmse: 0.850153\n[88]\tvalid_0's rmse: 0.850053\n[89]\tvalid_0's rmse: 0.849988\n[90]\tvalid_0's rmse: 0.849933\n[91]\tvalid_0's rmse: 0.849857\n[92]\tvalid_0's rmse: 0.849792\n[93]\tvalid_0's rmse: 0.849734\n[94]\tvalid_0's rmse: 0.849692\n[95]\tvalid_0's rmse: 0.849631\n[96]\tvalid_0's rmse: 0.849557\n[97]\tvalid_0's rmse: 0.849507\n[98]\tvalid_0's rmse: 0.849404\n[99]\tvalid_0's rmse: 0.849372\n[100]\tvalid_0's rmse: 0.849332\n[101]\tvalid_0's rmse: 0.849296\n[102]\tvalid_0's rmse: 0.849227\n[103]\tvalid_0's rmse: 0.849211\n[104]\tvalid_0's rmse: 0.849169\n[105]\tvalid_0's rmse: 0.849137\n[106]\tvalid_0's rmse: 0.84909\n[107]\tvalid_0's rmse: 0.849073\n[108]\tvalid_0's rmse: 0.84901\n[109]\tvalid_0's rmse: 0.848959\n[110]\tvalid_0's rmse: 0.848935\n[111]\tvalid_0's rmse: 0.848877\n[112]\tvalid_0's rmse: 0.848852\n[113]\tvalid_0's rmse: 0.848812\n[114]\tvalid_0's rmse: 0.848798\n[115]\tvalid_0's rmse: 0.848766\n[116]\tvalid_0's rmse: 0.848736\n[117]\tvalid_0's rmse: 0.848713\n[118]\tvalid_0's rmse: 0.848696\n[119]\tvalid_0's rmse: 0.848667\n[120]\tvalid_0's rmse: 0.848628\n[121]\tvalid_0's rmse: 0.848591\n[122]\tvalid_0's rmse: 0.848572\n[123]\tvalid_0's rmse: 0.848575\n[124]\tvalid_0's rmse: 0.84856\n[125]\tvalid_0's rmse: 0.84854\n[126]\tvalid_0's rmse: 0.848516\n[127]\tvalid_0's rmse: 0.848468\n[128]\tvalid_0's rmse: 0.848444\n[129]\tvalid_0's rmse: 0.848436\n[130]\tvalid_0's rmse: 0.848422\n[131]\tvalid_0's rmse: 0.848431\n[132]\tvalid_0's rmse: 0.848437\n[133]\tvalid_0's rmse: 0.848417\n[134]\tvalid_0's rmse: 0.848406\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848326\n[137]\tvalid_0's rmse: 0.848319\n[138]\tvalid_0's rmse: 0.848307\n[139]\tvalid_0's rmse: 0.84828\n[140]\tvalid_0's rmse: 0.848239\n[141]\tvalid_0's rmse: 0.848233\n[142]\tvalid_0's rmse: 0.848215\n[143]\tvalid_0's rmse: 0.848215\n[144]\tvalid_0's rmse: 0.848197\n[145]\tvalid_0's rmse: 0.848184\n[146]\tvalid_0's rmse: 0.848139\n[147]\tvalid_0's rmse: 0.848117\n[148]\tvalid_0's rmse: 0.848114\n[149]\tvalid_0's rmse: 0.848096\n[150]\tvalid_0's rmse: 0.848111\n[151]\tvalid_0's rmse: 0.848124\n[152]\tvalid_0's rmse: 0.848125\n[153]\tvalid_0's rmse: 0.848074\n[154]\tvalid_0's rmse: 0.848087\n[155]\tvalid_0's rmse: 0.848081\n[156]\tvalid_0's rmse: 0.848041\n[157]\tvalid_0's rmse: 0.84804\n[158]\tvalid_0's rmse: 0.848049\n[159]\tvalid_0's rmse: 0.84804\n[160]\tvalid_0's rmse: 0.848048\n[161]\tvalid_0's rmse: 0.848049\n[162]\tvalid_0's rmse: 0.84804\n[163]\tvalid_0's rmse: 0.848023\n[164]\tvalid_0's rmse: 0.848013\n[165]\tvalid_0's rmse: 0.848034\n[166]\tvalid_0's rmse: 0.84802\n[167]\tvalid_0's rmse: 0.848015\n[168]\tvalid_0's rmse: 0.847985\n[169]\tvalid_0's rmse: 0.847988\n[170]\tvalid_0's rmse: 0.847967\n[171]\tvalid_0's rmse: 0.847963\n[172]\tvalid_0's rmse: 0.847947\n[173]\tvalid_0's rmse: 0.84792\n[174]\tvalid_0's rmse: 0.847898\n[175]\tvalid_0's rmse: 0.847877\n[176]\tvalid_0's rmse: 0.847863\n[177]\tvalid_0's rmse: 0.847853\n[178]\tvalid_0's rmse: 0.847866\n[179]\tvalid_0's rmse: 0.847844\n[180]\tvalid_0's rmse: 0.847839\n[181]\tvalid_0's rmse: 0.847825\n[182]\tvalid_0's rmse: 0.847817\n[183]\tvalid_0's rmse: 0.847822\n[184]\tvalid_0's rmse: 0.84782\n[185]\tvalid_0's rmse: 0.847806\n[186]\tvalid_0's rmse: 0.847799\n[187]\tvalid_0's rmse: 0.847801\n[188]\tvalid_0's rmse: 0.847816\n[189]\tvalid_0's rmse: 0.847818\n[190]\tvalid_0's rmse: 0.847826\n[191]\tvalid_0's rmse: 0.847854\n[192]\tvalid_0's rmse: 0.847863\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction_stage2, val_score: 0.847465:  33%|###3      | 1/3 [00:04<00:09,  4.75s/it]\u001b[32m[I 2021-02-05 22:54:24,393]\u001b[0m Trial 37 finished with value: 0.8477993296415717 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.8477993296415717.\u001b[0m\nfeature_fraction_stage2, val_score: 0.847465:  33%|###3      | 1/3 [00:04<00:09,  4.75s/it]","name":"stderr"},{"output_type":"stream","text":"[193]\tvalid_0's rmse: 0.847834\n[194]\tvalid_0's rmse: 0.847835\n[195]\tvalid_0's rmse: 0.84782\n[196]\tvalid_0's rmse: 0.847821\nEarly stopping, best iteration is:\n[186]\tvalid_0's rmse: 0.847799\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019227 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.887457\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.88486\n[3]\tvalid_0's rmse: 0.882225\n[4]\tvalid_0's rmse: 0.880097\n[5]\tvalid_0's rmse: 0.878228\n[6]\tvalid_0's rmse: 0.876297\n[7]\tvalid_0's rmse: 0.874846\n[8]\tvalid_0's rmse: 0.873627\n[9]\tvalid_0's rmse: 0.872499\n[10]\tvalid_0's rmse: 0.871373\n[11]\tvalid_0's rmse: 0.870059\n[12]\tvalid_0's rmse: 0.869042\n[13]\tvalid_0's rmse: 0.868007\n[14]\tvalid_0's rmse: 0.867077\n[15]\tvalid_0's rmse: 0.866403\n[16]\tvalid_0's rmse: 0.865742\n[17]\tvalid_0's rmse: 0.864908\n[18]\tvalid_0's rmse: 0.864246\n[19]\tvalid_0's rmse: 0.86356\n[20]\tvalid_0's rmse: 0.862986\n[21]\tvalid_0's rmse: 0.862471\n[22]\tvalid_0's rmse: 0.861991\n[23]\tvalid_0's rmse: 0.861494\n[24]\tvalid_0's rmse: 0.861092\n[25]\tvalid_0's rmse: 0.860684\n[26]\tvalid_0's rmse: 0.860298\n[27]\tvalid_0's rmse: 0.859839\n[28]\tvalid_0's rmse: 0.859566\n[29]\tvalid_0's rmse: 0.859224\n[30]\tvalid_0's rmse: 0.858902\n[31]\tvalid_0's rmse: 0.858579\n[32]\tvalid_0's rmse: 0.858228\n[33]\tvalid_0's rmse: 0.857908\n[34]\tvalid_0's rmse: 0.857666\n[35]\tvalid_0's rmse: 0.857443\n[36]\tvalid_0's rmse: 0.85715\n[37]\tvalid_0's rmse: 0.856943\n[38]\tvalid_0's rmse: 0.856759\n[39]\tvalid_0's rmse: 0.856497\n[40]\tvalid_0's rmse: 0.856269\n[41]\tvalid_0's rmse: 0.856101\n[42]\tvalid_0's rmse: 0.855914\n[43]\tvalid_0's rmse: 0.855767\n[44]\tvalid_0's rmse: 0.855437\n[45]\tvalid_0's rmse: 0.855251\n[46]\tvalid_0's rmse: 0.855078\n[47]\tvalid_0's rmse: 0.854853\n[48]\tvalid_0's rmse: 0.854624\n[49]\tvalid_0's rmse: 0.85434\n[50]\tvalid_0's rmse: 0.854187\n[51]\tvalid_0's rmse: 0.854069\n[52]\tvalid_0's rmse: 0.853908\n[53]\tvalid_0's rmse: 0.853718\n[54]\tvalid_0's rmse: 0.853596\n[55]\tvalid_0's rmse: 0.853478\n[56]\tvalid_0's rmse: 0.853304\n[57]\tvalid_0's rmse: 0.853206\n[58]\tvalid_0's rmse: 0.853088\n[59]\tvalid_0's rmse: 0.852944\n[60]\tvalid_0's rmse: 0.852802\n[61]\tvalid_0's rmse: 0.852709\n[62]\tvalid_0's rmse: 0.852648\n[63]\tvalid_0's rmse: 0.852571\n[64]\tvalid_0's rmse: 0.852454\n[65]\tvalid_0's rmse: 0.852339\n[66]\tvalid_0's rmse: 0.852232\n[67]\tvalid_0's rmse: 0.852181\n[68]\tvalid_0's rmse: 0.852119\n[69]\tvalid_0's rmse: 0.852003\n[70]\tvalid_0's rmse: 0.851912\n[71]\tvalid_0's rmse: 0.851805\n[72]\tvalid_0's rmse: 0.851724\n[73]\tvalid_0's rmse: 0.851664\n[74]\tvalid_0's rmse: 0.851617\n[75]\tvalid_0's rmse: 0.851498\n[76]\tvalid_0's rmse: 0.851431\n[77]\tvalid_0's rmse: 0.851329\n[78]\tvalid_0's rmse: 0.851258\n[79]\tvalid_0's rmse: 0.851197\n[80]\tvalid_0's rmse: 0.851141\n[81]\tvalid_0's rmse: 0.851051\n[82]\tvalid_0's rmse: 0.850991\n[83]\tvalid_0's rmse: 0.850896\n[84]\tvalid_0's rmse: 0.850799\n[85]\tvalid_0's rmse: 0.850758\n[86]\tvalid_0's rmse: 0.85068\n[87]\tvalid_0's rmse: 0.850606\n[88]\tvalid_0's rmse: 0.850519\n[89]\tvalid_0's rmse: 0.850473\n[90]\tvalid_0's rmse: 0.850424\n[91]\tvalid_0's rmse: 0.850346\n[92]\tvalid_0's rmse: 0.850315\n[93]\tvalid_0's rmse: 0.850244\n[94]\tvalid_0's rmse: 0.850221\n[95]\tvalid_0's rmse: 0.850162\n[96]\tvalid_0's rmse: 0.850079\n[97]\tvalid_0's rmse: 0.85005\n[98]\tvalid_0's rmse: 0.849979\n[99]\tvalid_0's rmse: 0.849983\n[100]\tvalid_0's rmse: 0.849932\n[101]\tvalid_0's rmse: 0.849878\n[102]\tvalid_0's rmse: 0.849775\n[103]\tvalid_0's rmse: 0.849725\n[104]\tvalid_0's rmse: 0.84967\n[105]\tvalid_0's rmse: 0.84963\n[106]\tvalid_0's rmse: 0.849603\n[107]\tvalid_0's rmse: 0.849542\n[108]\tvalid_0's rmse: 0.849515\n[109]\tvalid_0's rmse: 0.849454\n[110]\tvalid_0's rmse: 0.849414\n[111]\tvalid_0's rmse: 0.849386\n[112]\tvalid_0's rmse: 0.849395\n[113]\tvalid_0's rmse: 0.84934\n[114]\tvalid_0's rmse: 0.849302\n[115]\tvalid_0's rmse: 0.849265\n[116]\tvalid_0's rmse: 0.849244\n[117]\tvalid_0's rmse: 0.849182\n[118]\tvalid_0's rmse: 0.849151\n[119]\tvalid_0's rmse: 0.849127\n[120]\tvalid_0's rmse: 0.84911\n[121]\tvalid_0's rmse: 0.849088\n[122]\tvalid_0's rmse: 0.849087\n[123]\tvalid_0's rmse: 0.849049\n[124]\tvalid_0's rmse: 0.84903\n[125]\tvalid_0's rmse: 0.84901\n[126]\tvalid_0's rmse: 0.848997\n[127]\tvalid_0's rmse: 0.848976\n[128]\tvalid_0's rmse: 0.848955\n[129]\tvalid_0's rmse: 0.848914\n[130]\tvalid_0's rmse: 0.848911\n[131]\tvalid_0's rmse: 0.848913\n[132]\tvalid_0's rmse: 0.848921\n[133]\tvalid_0's rmse: 0.848916\n[134]\tvalid_0's rmse: 0.848914\n[135]\tvalid_0's rmse: 0.848883\n[136]\tvalid_0's rmse: 0.848861\n[137]\tvalid_0's rmse: 0.84887\n[138]\tvalid_0's rmse: 0.848897\n[139]\tvalid_0's rmse: 0.848888\n[140]\tvalid_0's rmse: 0.848885\n[141]\tvalid_0's rmse: 0.848905\n[142]\tvalid_0's rmse: 0.848875\n[143]\tvalid_0's rmse: 0.848867\n[144]\tvalid_0's rmse: 0.848855\n[145]\tvalid_0's rmse: 0.848843\n[146]\tvalid_0's rmse: 0.848833\n[147]\tvalid_0's rmse: 0.848846\n[148]\tvalid_0's rmse: 0.84882\n[149]\tvalid_0's rmse: 0.848765\n[150]\tvalid_0's rmse: 0.848751\n[151]\tvalid_0's rmse: 0.848726\n[152]\tvalid_0's rmse: 0.848721\n[153]\tvalid_0's rmse: 0.848708\n[154]\tvalid_0's rmse: 0.848707\n[155]\tvalid_0's rmse: 0.848687\n[156]\tvalid_0's rmse: 0.848665\n[157]\tvalid_0's rmse: 0.848667\n[158]\tvalid_0's rmse: 0.848656\n[159]\tvalid_0's rmse: 0.848621\n[160]\tvalid_0's rmse: 0.848624\n[161]\tvalid_0's rmse: 0.848605\n[162]\tvalid_0's rmse: 0.848616\n[163]\tvalid_0's rmse: 0.848625\n[164]\tvalid_0's rmse: 0.848631\n[165]\tvalid_0's rmse: 0.84862\n[166]\tvalid_0's rmse: 0.848563\n[167]\tvalid_0's rmse: 0.848566\n[168]\tvalid_0's rmse: 0.848577\n[169]\tvalid_0's rmse: 0.84857\n[170]\tvalid_0's rmse: 0.84859\n[171]\tvalid_0's rmse: 0.848575\n[172]\tvalid_0's rmse: 0.848564\n[173]\tvalid_0's rmse: 0.848563\n[174]\tvalid_0's rmse: 0.848557\n[175]\tvalid_0's rmse: 0.848547\n[176]\tvalid_0's rmse: 0.848533\n[177]\tvalid_0's rmse: 0.848533\n[178]\tvalid_0's rmse: 0.848529\n[179]\tvalid_0's rmse: 0.848518\n[180]\tvalid_0's rmse: 0.848513\n[181]\tvalid_0's rmse: 0.848513\n[182]\tvalid_0's rmse: 0.848525\n[183]\tvalid_0's rmse: 0.848498\n[184]\tvalid_0's rmse: 0.848499\n[185]\tvalid_0's rmse: 0.84849\n[186]\tvalid_0's rmse: 0.848477\n[187]\tvalid_0's rmse: 0.848456\n[188]\tvalid_0's rmse: 0.848474\n[189]\tvalid_0's rmse: 0.848483\n[190]\tvalid_0's rmse: 0.848456\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction_stage2, val_score: 0.847465:  67%|######6   | 2/3 [00:09<00:04,  4.67s/it]\u001b[32m[I 2021-02-05 22:54:29,013]\u001b[0m Trial 38 finished with value: 0.848455571197463 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.8477993296415717.\u001b[0m\nfeature_fraction_stage2, val_score: 0.847465:  67%|######6   | 2/3 [00:09<00:04,  4.67s/it]","name":"stderr"},{"output_type":"stream","text":"[191]\tvalid_0's rmse: 0.848457\n[192]\tvalid_0's rmse: 0.848459\n[193]\tvalid_0's rmse: 0.848464\n[194]\tvalid_0's rmse: 0.848471\n[195]\tvalid_0's rmse: 0.848465\n[196]\tvalid_0's rmse: 0.848471\n[197]\tvalid_0's rmse: 0.848477\n[198]\tvalid_0's rmse: 0.848481\n[199]\tvalid_0's rmse: 0.848474\n[200]\tvalid_0's rmse: 0.848481\nEarly stopping, best iteration is:\n[190]\tvalid_0's rmse: 0.848456\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019699 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885538\n[3]\tvalid_0's rmse: 0.882641\n[4]\tvalid_0's rmse: 0.880465\n[5]\tvalid_0's rmse: 0.87859\n[6]\tvalid_0's rmse: 0.876689\n[7]\tvalid_0's rmse: 0.875149\n[8]\tvalid_0's rmse: 0.873916\n[9]\tvalid_0's rmse: 0.87275\n[10]\tvalid_0's rmse: 0.871695\n[11]\tvalid_0's rmse: 0.870285\n[12]\tvalid_0's rmse: 0.869162\n[13]\tvalid_0's rmse: 0.868123\n[14]\tvalid_0's rmse: 0.867103\n[15]\tvalid_0's rmse: 0.866431\n[16]\tvalid_0's rmse: 0.865722\n[17]\tvalid_0's rmse: 0.864933\n[18]\tvalid_0's rmse: 0.864272\n[19]\tvalid_0's rmse: 0.863609\n[20]\tvalid_0's rmse: 0.863028\n[21]\tvalid_0's rmse: 0.862502\n[22]\tvalid_0's rmse: 0.861982\n[23]\tvalid_0's rmse: 0.861467\n[24]\tvalid_0's rmse: 0.86101\n[25]\tvalid_0's rmse: 0.86063\n[26]\tvalid_0's rmse: 0.860233\n[27]\tvalid_0's rmse: 0.85987\n[28]\tvalid_0's rmse: 0.859542\n[29]\tvalid_0's rmse: 0.859099\n[30]\tvalid_0's rmse: 0.858709\n[31]\tvalid_0's rmse: 0.858381\n[32]\tvalid_0's rmse: 0.858006\n[33]\tvalid_0's rmse: 0.857685\n[34]\tvalid_0's rmse: 0.85738\n[35]\tvalid_0's rmse: 0.857146\n[36]\tvalid_0's rmse: 0.856863\n[37]\tvalid_0's rmse: 0.856595\n[38]\tvalid_0's rmse: 0.856339\n[39]\tvalid_0's rmse: 0.856097\n[40]\tvalid_0's rmse: 0.855863\n[41]\tvalid_0's rmse: 0.855717\n[42]\tvalid_0's rmse: 0.855527\n[43]\tvalid_0's rmse: 0.855309\n[44]\tvalid_0's rmse: 0.855056\n[45]\tvalid_0's rmse: 0.854829\n[46]\tvalid_0's rmse: 0.854668\n[47]\tvalid_0's rmse: 0.854509\n[48]\tvalid_0's rmse: 0.854331\n[49]\tvalid_0's rmse: 0.854186\n[50]\tvalid_0's rmse: 0.853999\n[51]\tvalid_0's rmse: 0.853904\n[52]\tvalid_0's rmse: 0.853773\n[53]\tvalid_0's rmse: 0.853587\n[54]\tvalid_0's rmse: 0.853439\n[55]\tvalid_0's rmse: 0.853284\n[56]\tvalid_0's rmse: 0.85312\n[57]\tvalid_0's rmse: 0.853034\n[58]\tvalid_0's rmse: 0.852939\n[59]\tvalid_0's rmse: 0.852801\n[60]\tvalid_0's rmse: 0.852658\n[61]\tvalid_0's rmse: 0.852574\n[62]\tvalid_0's rmse: 0.852469\n[63]\tvalid_0's rmse: 0.852363\n[64]\tvalid_0's rmse: 0.85224\n[65]\tvalid_0's rmse: 0.852146\n[66]\tvalid_0's rmse: 0.852054\n[67]\tvalid_0's rmse: 0.851986\n[68]\tvalid_0's rmse: 0.85192\n[69]\tvalid_0's rmse: 0.851776\n[70]\tvalid_0's rmse: 0.851681\n[71]\tvalid_0's rmse: 0.851638\n[72]\tvalid_0's rmse: 0.851521\n[73]\tvalid_0's rmse: 0.851443\n[74]\tvalid_0's rmse: 0.851378\n[75]\tvalid_0's rmse: 0.851295\n[76]\tvalid_0's rmse: 0.851244\n[77]\tvalid_0's rmse: 0.851159\n[78]\tvalid_0's rmse: 0.851099\n[79]\tvalid_0's rmse: 0.850989\n[80]\tvalid_0's rmse: 0.850908\n[81]\tvalid_0's rmse: 0.850827\n[82]\tvalid_0's rmse: 0.850755\n[83]\tvalid_0's rmse: 0.850711\n[84]\tvalid_0's rmse: 0.850599\n[85]\tvalid_0's rmse: 0.850564\n[86]\tvalid_0's rmse: 0.850493\n[87]\tvalid_0's rmse: 0.850392\n[88]\tvalid_0's rmse: 0.850295\n[89]\tvalid_0's rmse: 0.850196\n[90]\tvalid_0's rmse: 0.850184\n[91]\tvalid_0's rmse: 0.850113\n[92]\tvalid_0's rmse: 0.850067\n[93]\tvalid_0's rmse: 0.850001\n[94]\tvalid_0's rmse: 0.849963\n[95]\tvalid_0's rmse: 0.849899\n[96]\tvalid_0's rmse: 0.849838\n[97]\tvalid_0's rmse: 0.849793\n[98]\tvalid_0's rmse: 0.84975\n[99]\tvalid_0's rmse: 0.849669\n[100]\tvalid_0's rmse: 0.849626\n[101]\tvalid_0's rmse: 0.849578\n[102]\tvalid_0's rmse: 0.849521\n[103]\tvalid_0's rmse: 0.849493\n[104]\tvalid_0's rmse: 0.849376\n[105]\tvalid_0's rmse: 0.849338\n[106]\tvalid_0's rmse: 0.849309\n[107]\tvalid_0's rmse: 0.849313\n[108]\tvalid_0's rmse: 0.849272\n[109]\tvalid_0's rmse: 0.849227\n[110]\tvalid_0's rmse: 0.849196\n[111]\tvalid_0's rmse: 0.849172\n[112]\tvalid_0's rmse: 0.849145\n[113]\tvalid_0's rmse: 0.849116\n[114]\tvalid_0's rmse: 0.849063\n[115]\tvalid_0's rmse: 0.849062\n[116]\tvalid_0's rmse: 0.849047\n[117]\tvalid_0's rmse: 0.848978\n[118]\tvalid_0's rmse: 0.848945\n[119]\tvalid_0's rmse: 0.848935\n[120]\tvalid_0's rmse: 0.848898\n[121]\tvalid_0's rmse: 0.848844\n[122]\tvalid_0's rmse: 0.848835\n[123]\tvalid_0's rmse: 0.848854\n[124]\tvalid_0's rmse: 0.848812\n[125]\tvalid_0's rmse: 0.848766\n[126]\tvalid_0's rmse: 0.848734\n[127]\tvalid_0's rmse: 0.848673\n[128]\tvalid_0's rmse: 0.84866\n[129]\tvalid_0's rmse: 0.848643\n[130]\tvalid_0's rmse: 0.84864\n[131]\tvalid_0's rmse: 0.848575\n[132]\tvalid_0's rmse: 0.848544\n[133]\tvalid_0's rmse: 0.848541\n[134]\tvalid_0's rmse: 0.848508\n[135]\tvalid_0's rmse: 0.848511\n[136]\tvalid_0's rmse: 0.848471\n[137]\tvalid_0's rmse: 0.848476\n[138]\tvalid_0's rmse: 0.848458\n[139]\tvalid_0's rmse: 0.848462\n[140]\tvalid_0's rmse: 0.848486\n[141]\tvalid_0's rmse: 0.848455\n[142]\tvalid_0's rmse: 0.848443\n[143]\tvalid_0's rmse: 0.848438\n[144]\tvalid_0's rmse: 0.848428\n[145]\tvalid_0's rmse: 0.848445\n[146]\tvalid_0's rmse: 0.848407\n[147]\tvalid_0's rmse: 0.848398\n[148]\tvalid_0's rmse: 0.848373\n[149]\tvalid_0's rmse: 0.848378\n[150]\tvalid_0's rmse: 0.848354\n[151]\tvalid_0's rmse: 0.848359\n[152]\tvalid_0's rmse: 0.848353\n[153]\tvalid_0's rmse: 0.848362\n[154]\tvalid_0's rmse: 0.848349\n[155]\tvalid_0's rmse: 0.848356\n[156]\tvalid_0's rmse: 0.84837\n[157]\tvalid_0's rmse: 0.848355\n[158]\tvalid_0's rmse: 0.848333\n[159]\tvalid_0's rmse: 0.848355\n[160]\tvalid_0's rmse: 0.848327\n[161]\tvalid_0's rmse: 0.848318\n[162]\tvalid_0's rmse: 0.848302\n[163]\tvalid_0's rmse: 0.848294\n[164]\tvalid_0's rmse: 0.84829\n[165]\tvalid_0's rmse: 0.848284\n[166]\tvalid_0's rmse: 0.84828\n[167]\tvalid_0's rmse: 0.848259\n[168]\tvalid_0's rmse: 0.848235\n[169]\tvalid_0's rmse: 0.848239\n[170]\tvalid_0's rmse: 0.848231\n[171]\tvalid_0's rmse: 0.848224\n[172]\tvalid_0's rmse: 0.848212\n[173]\tvalid_0's rmse: 0.848175\n[174]\tvalid_0's rmse: 0.848149\n[175]\tvalid_0's rmse: 0.848116\n[176]\tvalid_0's rmse: 0.848094\n[177]\tvalid_0's rmse: 0.848044\n[178]\tvalid_0's rmse: 0.84805\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction_stage2, val_score: 0.847465: 100%|##########| 3/3 [00:14<00:00,  4.67s/it]\u001b[32m[I 2021-02-05 22:54:33,692]\u001b[0m Trial 39 finished with value: 0.8480440997194085 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.8477993296415717.\u001b[0m\n","name":"stderr"},{"output_type":"stream","text":"[179]\tvalid_0's rmse: 0.848053\n[180]\tvalid_0's rmse: 0.848058\n[181]\tvalid_0's rmse: 0.848071\n[182]\tvalid_0's rmse: 0.848087\n[183]\tvalid_0's rmse: 0.848087\n[184]\tvalid_0's rmse: 0.848071\n[185]\tvalid_0's rmse: 0.848069\n[186]\tvalid_0's rmse: 0.848082\n[187]\tvalid_0's rmse: 0.848068\nEarly stopping, best iteration is:\n[177]\tvalid_0's rmse: 0.848044\n","name":"stdout"},{"output_type":"stream","text":"feature_fraction_stage2, val_score: 0.847465: 100%|##########| 3/3 [00:14<00:00,  4.69s/it]\nregularization_factors, val_score: 0.847465:   0%|          | 0/20 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018767 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848117\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847948\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847566\n[230]\tvalid_0's rmse: 0.847548\n[231]\tvalid_0's rmse: 0.847554\n[232]\tvalid_0's rmse: 0.847539\n[233]\tvalid_0's rmse: 0.847515\n[234]\tvalid_0's rmse: 0.847501\n[235]\tvalid_0's rmse: 0.847502\n[236]\tvalid_0's rmse: 0.847501\n[237]\tvalid_0's rmse: 0.847512\n[238]\tvalid_0's rmse: 0.847495\n[239]\tvalid_0's rmse: 0.847494\n[240]\tvalid_0's rmse: 0.84749\n[241]\tvalid_0's rmse: 0.847502\n[242]\tvalid_0's rmse: 0.847485\n[243]\tvalid_0's rmse: 0.847504\n[244]\tvalid_0's rmse: 0.847506\n[245]\tvalid_0's rmse: 0.847508\n[246]\tvalid_0's rmse: 0.847512\n[247]\tvalid_0's rmse: 0.847508\n[248]\tvalid_0's rmse: 0.847521\n[249]\tvalid_0's rmse: 0.847533\n[250]\tvalid_0's rmse: 0.847529\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:   5%|5         | 1/20 [00:05<01:42,  5.38s/it]\u001b[32m[I 2021-02-05 22:54:39,087]\u001b[0m Trial 40 finished with value: 0.8474854744807965 and parameters: {'lambda_l1': 3.1249242602688635e-05, 'lambda_l2': 2.2239377171501156e-05}. Best is trial 40 with value: 0.8474854744807965.\u001b[0m\nregularization_factors, val_score: 0.847465:   5%|5         | 1/20 [00:05<01:42,  5.38s/it]","name":"stderr"},{"output_type":"stream","text":"[251]\tvalid_0's rmse: 0.847533\n[252]\tvalid_0's rmse: 0.847515\nEarly stopping, best iteration is:\n[242]\tvalid_0's rmse: 0.847485\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019075 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885547\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874469\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.872271\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.86615\n[17]\tvalid_0's rmse: 0.865325\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864003\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860809\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859616\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858573\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857222\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854986\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853866\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852946\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852714\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852231\n[64]\tvalid_0's rmse: 0.852095\n[65]\tvalid_0's rmse: 0.851945\n[66]\tvalid_0's rmse: 0.851852\n[67]\tvalid_0's rmse: 0.851798\n[68]\tvalid_0's rmse: 0.851701\n[69]\tvalid_0's rmse: 0.85165\n[70]\tvalid_0's rmse: 0.851512\n[71]\tvalid_0's rmse: 0.851456\n[72]\tvalid_0's rmse: 0.851399\n[73]\tvalid_0's rmse: 0.851365\n[74]\tvalid_0's rmse: 0.851268\n[75]\tvalid_0's rmse: 0.851162\n[76]\tvalid_0's rmse: 0.851062\n[77]\tvalid_0's rmse: 0.850969\n[78]\tvalid_0's rmse: 0.850909\n[79]\tvalid_0's rmse: 0.85086\n[80]\tvalid_0's rmse: 0.850799\n[81]\tvalid_0's rmse: 0.850749\n[82]\tvalid_0's rmse: 0.850689\n[83]\tvalid_0's rmse: 0.850636\n[84]\tvalid_0's rmse: 0.850555\n[85]\tvalid_0's rmse: 0.850492\n[86]\tvalid_0's rmse: 0.850463\n[87]\tvalid_0's rmse: 0.850409\n[88]\tvalid_0's rmse: 0.850266\n[89]\tvalid_0's rmse: 0.850253\n[90]\tvalid_0's rmse: 0.850181\n[91]\tvalid_0's rmse: 0.850119\n[92]\tvalid_0's rmse: 0.850065\n[93]\tvalid_0's rmse: 0.85001\n[94]\tvalid_0's rmse: 0.849959\n[95]\tvalid_0's rmse: 0.849912\n[96]\tvalid_0's rmse: 0.849904\n[97]\tvalid_0's rmse: 0.849867\n[98]\tvalid_0's rmse: 0.849751\n[99]\tvalid_0's rmse: 0.849731\n[100]\tvalid_0's rmse: 0.849684\n[101]\tvalid_0's rmse: 0.849601\n[102]\tvalid_0's rmse: 0.849514\n[103]\tvalid_0's rmse: 0.84947\n[104]\tvalid_0's rmse: 0.849416\n[105]\tvalid_0's rmse: 0.849367\n[106]\tvalid_0's rmse: 0.84936\n[107]\tvalid_0's rmse: 0.849343\n[108]\tvalid_0's rmse: 0.849301\n[109]\tvalid_0's rmse: 0.849249\n[110]\tvalid_0's rmse: 0.849226\n[111]\tvalid_0's rmse: 0.849198\n[112]\tvalid_0's rmse: 0.849174\n[113]\tvalid_0's rmse: 0.849163\n[114]\tvalid_0's rmse: 0.849157\n[115]\tvalid_0's rmse: 0.84914\n[116]\tvalid_0's rmse: 0.849148\n[117]\tvalid_0's rmse: 0.849077\n[118]\tvalid_0's rmse: 0.849055\n[119]\tvalid_0's rmse: 0.84898\n[120]\tvalid_0's rmse: 0.848947\n[121]\tvalid_0's rmse: 0.848882\n[122]\tvalid_0's rmse: 0.848875\n[123]\tvalid_0's rmse: 0.848821\n[124]\tvalid_0's rmse: 0.848831\n[125]\tvalid_0's rmse: 0.848811\n[126]\tvalid_0's rmse: 0.848778\n[127]\tvalid_0's rmse: 0.848766\n[128]\tvalid_0's rmse: 0.848745\n[129]\tvalid_0's rmse: 0.848705\n[130]\tvalid_0's rmse: 0.848673\n[131]\tvalid_0's rmse: 0.848629\n[132]\tvalid_0's rmse: 0.848633\n[133]\tvalid_0's rmse: 0.848628\n[134]\tvalid_0's rmse: 0.848609\n[135]\tvalid_0's rmse: 0.848597\n[136]\tvalid_0's rmse: 0.848584\n[137]\tvalid_0's rmse: 0.848561\n[138]\tvalid_0's rmse: 0.848565\n[139]\tvalid_0's rmse: 0.848559\n[140]\tvalid_0's rmse: 0.848568\n[141]\tvalid_0's rmse: 0.848548\n[142]\tvalid_0's rmse: 0.848496\n[143]\tvalid_0's rmse: 0.848483\n[144]\tvalid_0's rmse: 0.848467\n[145]\tvalid_0's rmse: 0.848443\n[146]\tvalid_0's rmse: 0.848407\n[147]\tvalid_0's rmse: 0.848396\n[148]\tvalid_0's rmse: 0.848397\n[149]\tvalid_0's rmse: 0.848418\n[150]\tvalid_0's rmse: 0.848421\n[151]\tvalid_0's rmse: 0.84841\n[152]\tvalid_0's rmse: 0.84839\n[153]\tvalid_0's rmse: 0.848383\n[154]\tvalid_0's rmse: 0.848407\n[155]\tvalid_0's rmse: 0.84839\n[156]\tvalid_0's rmse: 0.848386\n[157]\tvalid_0's rmse: 0.848361\n[158]\tvalid_0's rmse: 0.848353\n[159]\tvalid_0's rmse: 0.848332\n[160]\tvalid_0's rmse: 0.848309\n[161]\tvalid_0's rmse: 0.848295\n[162]\tvalid_0's rmse: 0.848303\n[163]\tvalid_0's rmse: 0.848312\n[164]\tvalid_0's rmse: 0.848309\n[165]\tvalid_0's rmse: 0.848329\n[166]\tvalid_0's rmse: 0.848319\n[167]\tvalid_0's rmse: 0.84831\n[168]\tvalid_0's rmse: 0.848315\n[169]\tvalid_0's rmse: 0.848303\n[170]\tvalid_0's rmse: 0.84828\n[171]\tvalid_0's rmse: 0.848274\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  10%|#         | 2/20 [00:09<01:27,  4.84s/it]\u001b[32m[I 2021-02-05 22:54:43,557]\u001b[0m Trial 41 finished with value: 0.8482362253042413 and parameters: {'lambda_l1': 8.179086174356382e-06, 'lambda_l2': 0.07777394675242191}. Best is trial 40 with value: 0.8474854744807965.\u001b[0m\n","name":"stderr"},{"output_type":"stream","text":"[172]\tvalid_0's rmse: 0.848262\n[173]\tvalid_0's rmse: 0.848241\n[174]\tvalid_0's rmse: 0.848236\n[175]\tvalid_0's rmse: 0.848248\n[176]\tvalid_0's rmse: 0.848249\n[177]\tvalid_0's rmse: 0.848263\n[178]\tvalid_0's rmse: 0.848251\n[179]\tvalid_0's rmse: 0.848259\n[180]\tvalid_0's rmse: 0.848244\n[181]\tvalid_0's rmse: 0.84825\n[182]\tvalid_0's rmse: 0.848238\n[183]\tvalid_0's rmse: 0.84824\n[184]\tvalid_0's rmse: 0.848246\nEarly stopping, best iteration is:\n[174]\tvalid_0's rmse: 0.848236\n","name":"stdout"},{"output_type":"stream","text":"\rregularization_factors, val_score: 0.847465:  10%|#         | 2/20 [00:09<01:27,  4.84s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.240198 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.872271\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849654\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849329\n[105]\tvalid_0's rmse: 0.849287\n[106]\tvalid_0's rmse: 0.849228\n[107]\tvalid_0's rmse: 0.849184\n[108]\tvalid_0's rmse: 0.849144\n[109]\tvalid_0's rmse: 0.849076\n[110]\tvalid_0's rmse: 0.84907\n[111]\tvalid_0's rmse: 0.849031\n[112]\tvalid_0's rmse: 0.849007\n[113]\tvalid_0's rmse: 0.84898\n[114]\tvalid_0's rmse: 0.848949\n[115]\tvalid_0's rmse: 0.848954\n[116]\tvalid_0's rmse: 0.848914\n[117]\tvalid_0's rmse: 0.848867\n[118]\tvalid_0's rmse: 0.848846\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848737\n[121]\tvalid_0's rmse: 0.848629\n[122]\tvalid_0's rmse: 0.848601\n[123]\tvalid_0's rmse: 0.848613\n[124]\tvalid_0's rmse: 0.848589\n[125]\tvalid_0's rmse: 0.848562\n[126]\tvalid_0's rmse: 0.848548\n[127]\tvalid_0's rmse: 0.848482\n[128]\tvalid_0's rmse: 0.848494\n[129]\tvalid_0's rmse: 0.848482\n[130]\tvalid_0's rmse: 0.848484\n[131]\tvalid_0's rmse: 0.848475\n[132]\tvalid_0's rmse: 0.84847\n[133]\tvalid_0's rmse: 0.848469\n[134]\tvalid_0's rmse: 0.848428\n[135]\tvalid_0's rmse: 0.848405\n[136]\tvalid_0's rmse: 0.848369\n[137]\tvalid_0's rmse: 0.848335\n[138]\tvalid_0's rmse: 0.848357\n[139]\tvalid_0's rmse: 0.848355\n[140]\tvalid_0's rmse: 0.848353\n[141]\tvalid_0's rmse: 0.848346\n[142]\tvalid_0's rmse: 0.848335\n[143]\tvalid_0's rmse: 0.848327\n[144]\tvalid_0's rmse: 0.848304\n[145]\tvalid_0's rmse: 0.848308\n[146]\tvalid_0's rmse: 0.848311\n[147]\tvalid_0's rmse: 0.848276\n[148]\tvalid_0's rmse: 0.848246\n[149]\tvalid_0's rmse: 0.848225\n[150]\tvalid_0's rmse: 0.848229\n[151]\tvalid_0's rmse: 0.848206\n[152]\tvalid_0's rmse: 0.848192\n[153]\tvalid_0's rmse: 0.848158\n[154]\tvalid_0's rmse: 0.848148\n[155]\tvalid_0's rmse: 0.84815\n[156]\tvalid_0's rmse: 0.848133\n[157]\tvalid_0's rmse: 0.848135\n[158]\tvalid_0's rmse: 0.848107\n[159]\tvalid_0's rmse: 0.848097\n[160]\tvalid_0's rmse: 0.848092\n[161]\tvalid_0's rmse: 0.848078\n[162]\tvalid_0's rmse: 0.848063\n[163]\tvalid_0's rmse: 0.84802\n[164]\tvalid_0's rmse: 0.84801\n[165]\tvalid_0's rmse: 0.848002\n[166]\tvalid_0's rmse: 0.847972\n[167]\tvalid_0's rmse: 0.847968\n[168]\tvalid_0's rmse: 0.847989\n[169]\tvalid_0's rmse: 0.847987\n[170]\tvalid_0's rmse: 0.847971\n[171]\tvalid_0's rmse: 0.847976\n[172]\tvalid_0's rmse: 0.847967\n[173]\tvalid_0's rmse: 0.847946\n[174]\tvalid_0's rmse: 0.847934\n[175]\tvalid_0's rmse: 0.847929\n[176]\tvalid_0's rmse: 0.847912\n[177]\tvalid_0's rmse: 0.847862\n[178]\tvalid_0's rmse: 0.847849\n[179]\tvalid_0's rmse: 0.847832\n[180]\tvalid_0's rmse: 0.847846\n[181]\tvalid_0's rmse: 0.847812\n[182]\tvalid_0's rmse: 0.847801\n[183]\tvalid_0's rmse: 0.847804\n[184]\tvalid_0's rmse: 0.847808\n[185]\tvalid_0's rmse: 0.847791\n[186]\tvalid_0's rmse: 0.847798\n[187]\tvalid_0's rmse: 0.847786\n[188]\tvalid_0's rmse: 0.847759\n[189]\tvalid_0's rmse: 0.847716\n[190]\tvalid_0's rmse: 0.847719\n[191]\tvalid_0's rmse: 0.847727\n[192]\tvalid_0's rmse: 0.847722\n[193]\tvalid_0's rmse: 0.847713\n[194]\tvalid_0's rmse: 0.8477\n[195]\tvalid_0's rmse: 0.847705\n[196]\tvalid_0's rmse: 0.847703\n[197]\tvalid_0's rmse: 0.84771\n[198]\tvalid_0's rmse: 0.847705\n[199]\tvalid_0's rmse: 0.847721\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  15%|#5        | 3/20 [00:15<01:26,  5.09s/it]\u001b[32m[I 2021-02-05 22:54:48,933]\u001b[0m Trial 42 finished with value: 0.8477003354300913 and parameters: {'lambda_l1': 0.0027744871587540884, 'lambda_l2': 4.503869820586181e-07}. Best is trial 40 with value: 0.8474854744807965.\u001b[0m\nregularization_factors, val_score: 0.847465:  15%|#5        | 3/20 [00:15<01:26,  5.09s/it]","name":"stderr"},{"output_type":"stream","text":"[200]\tvalid_0's rmse: 0.84775\n[201]\tvalid_0's rmse: 0.847733\n[202]\tvalid_0's rmse: 0.847732\n[203]\tvalid_0's rmse: 0.847727\n[204]\tvalid_0's rmse: 0.847721\nEarly stopping, best iteration is:\n[194]\tvalid_0's rmse: 0.8477\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019357 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888339\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.8833\n[4]\tvalid_0's rmse: 0.881127\n[5]\tvalid_0's rmse: 0.879295\n[6]\tvalid_0's rmse: 0.877237\n[7]\tvalid_0's rmse: 0.875746\n[8]\tvalid_0's rmse: 0.874493\n[9]\tvalid_0's rmse: 0.87333\n[10]\tvalid_0's rmse: 0.872252\n[11]\tvalid_0's rmse: 0.870854\n[12]\tvalid_0's rmse: 0.869648\n[13]\tvalid_0's rmse: 0.868578\n[14]\tvalid_0's rmse: 0.867542\n[15]\tvalid_0's rmse: 0.866843\n[16]\tvalid_0's rmse: 0.866068\n[17]\tvalid_0's rmse: 0.865244\n[18]\tvalid_0's rmse: 0.864551\n[19]\tvalid_0's rmse: 0.863869\n[20]\tvalid_0's rmse: 0.863294\n[21]\tvalid_0's rmse: 0.862725\n[22]\tvalid_0's rmse: 0.862088\n[23]\tvalid_0's rmse: 0.861569\n[24]\tvalid_0's rmse: 0.861034\n[25]\tvalid_0's rmse: 0.860617\n[26]\tvalid_0's rmse: 0.860198\n[27]\tvalid_0's rmse: 0.859851\n[28]\tvalid_0's rmse: 0.859456\n[29]\tvalid_0's rmse: 0.85909\n[30]\tvalid_0's rmse: 0.858806\n[31]\tvalid_0's rmse: 0.858469\n[32]\tvalid_0's rmse: 0.858118\n[33]\tvalid_0's rmse: 0.857819\n[34]\tvalid_0's rmse: 0.857462\n[35]\tvalid_0's rmse: 0.85721\n[36]\tvalid_0's rmse: 0.856881\n[37]\tvalid_0's rmse: 0.856637\n[38]\tvalid_0's rmse: 0.856342\n[39]\tvalid_0's rmse: 0.856067\n[40]\tvalid_0's rmse: 0.855799\n[41]\tvalid_0's rmse: 0.855637\n[42]\tvalid_0's rmse: 0.855401\n[43]\tvalid_0's rmse: 0.855209\n[44]\tvalid_0's rmse: 0.854885\n[45]\tvalid_0's rmse: 0.854675\n[46]\tvalid_0's rmse: 0.854496\n[47]\tvalid_0's rmse: 0.854342\n[48]\tvalid_0's rmse: 0.854174\n[49]\tvalid_0's rmse: 0.853998\n[50]\tvalid_0's rmse: 0.853824\n[51]\tvalid_0's rmse: 0.853714\n[52]\tvalid_0's rmse: 0.853553\n[53]\tvalid_0's rmse: 0.853399\n[54]\tvalid_0's rmse: 0.853251\n[55]\tvalid_0's rmse: 0.853119\n[56]\tvalid_0's rmse: 0.852913\n[57]\tvalid_0's rmse: 0.852743\n[58]\tvalid_0's rmse: 0.852598\n[59]\tvalid_0's rmse: 0.852505\n[60]\tvalid_0's rmse: 0.852402\n[61]\tvalid_0's rmse: 0.8523\n[62]\tvalid_0's rmse: 0.852232\n[63]\tvalid_0's rmse: 0.852054\n[64]\tvalid_0's rmse: 0.851907\n[65]\tvalid_0's rmse: 0.851794\n[66]\tvalid_0's rmse: 0.851676\n[67]\tvalid_0's rmse: 0.85161\n[68]\tvalid_0's rmse: 0.851526\n[69]\tvalid_0's rmse: 0.851439\n[70]\tvalid_0's rmse: 0.851377\n[71]\tvalid_0's rmse: 0.851305\n[72]\tvalid_0's rmse: 0.851222\n[73]\tvalid_0's rmse: 0.851164\n[74]\tvalid_0's rmse: 0.851073\n[75]\tvalid_0's rmse: 0.850963\n[76]\tvalid_0's rmse: 0.850843\n[77]\tvalid_0's rmse: 0.850773\n[78]\tvalid_0's rmse: 0.85067\n[79]\tvalid_0's rmse: 0.850614\n[80]\tvalid_0's rmse: 0.850561\n[81]\tvalid_0's rmse: 0.850504\n[82]\tvalid_0's rmse: 0.850435\n[83]\tvalid_0's rmse: 0.85037\n[84]\tvalid_0's rmse: 0.850254\n[85]\tvalid_0's rmse: 0.850194\n[86]\tvalid_0's rmse: 0.850153\n[87]\tvalid_0's rmse: 0.850099\n[88]\tvalid_0's rmse: 0.850014\n[89]\tvalid_0's rmse: 0.849932\n[90]\tvalid_0's rmse: 0.849874\n[91]\tvalid_0's rmse: 0.849841\n[92]\tvalid_0's rmse: 0.849823\n[93]\tvalid_0's rmse: 0.849762\n[94]\tvalid_0's rmse: 0.849722\n[95]\tvalid_0's rmse: 0.849684\n[96]\tvalid_0's rmse: 0.849636\n[97]\tvalid_0's rmse: 0.849595\n[98]\tvalid_0's rmse: 0.849533\n[99]\tvalid_0's rmse: 0.849508\n[100]\tvalid_0's rmse: 0.849465\n[101]\tvalid_0's rmse: 0.849416\n[102]\tvalid_0's rmse: 0.849357\n[103]\tvalid_0's rmse: 0.849322\n[104]\tvalid_0's rmse: 0.849301\n[105]\tvalid_0's rmse: 0.849254\n[106]\tvalid_0's rmse: 0.849198\n[107]\tvalid_0's rmse: 0.849155\n[108]\tvalid_0's rmse: 0.849108\n[109]\tvalid_0's rmse: 0.849056\n[110]\tvalid_0's rmse: 0.849025\n[111]\tvalid_0's rmse: 0.848976\n[112]\tvalid_0's rmse: 0.848944\n[113]\tvalid_0's rmse: 0.848916\n[114]\tvalid_0's rmse: 0.84892\n[115]\tvalid_0's rmse: 0.848904\n[116]\tvalid_0's rmse: 0.848868\n[117]\tvalid_0's rmse: 0.848793\n[118]\tvalid_0's rmse: 0.848751\n[119]\tvalid_0's rmse: 0.848682\n[120]\tvalid_0's rmse: 0.848656\n[121]\tvalid_0's rmse: 0.848587\n[122]\tvalid_0's rmse: 0.848569\n[123]\tvalid_0's rmse: 0.848553\n[124]\tvalid_0's rmse: 0.848524\n[125]\tvalid_0's rmse: 0.848503\n[126]\tvalid_0's rmse: 0.848503\n[127]\tvalid_0's rmse: 0.848469\n[128]\tvalid_0's rmse: 0.848446\n[129]\tvalid_0's rmse: 0.84844\n[130]\tvalid_0's rmse: 0.848419\n[131]\tvalid_0's rmse: 0.848394\n[132]\tvalid_0's rmse: 0.848411\n[133]\tvalid_0's rmse: 0.848388\n[134]\tvalid_0's rmse: 0.848342\n[135]\tvalid_0's rmse: 0.848342\n[136]\tvalid_0's rmse: 0.848303\n[137]\tvalid_0's rmse: 0.848284\n[138]\tvalid_0's rmse: 0.848301\n[139]\tvalid_0's rmse: 0.84826\n[140]\tvalid_0's rmse: 0.848257\n[141]\tvalid_0's rmse: 0.848251\n[142]\tvalid_0's rmse: 0.848193\n[143]\tvalid_0's rmse: 0.848178\n[144]\tvalid_0's rmse: 0.848167\n[145]\tvalid_0's rmse: 0.848162\n[146]\tvalid_0's rmse: 0.848108\n[147]\tvalid_0's rmse: 0.848104\n[148]\tvalid_0's rmse: 0.848072\n[149]\tvalid_0's rmse: 0.848087\n[150]\tvalid_0's rmse: 0.84809\n[151]\tvalid_0's rmse: 0.848032\n[152]\tvalid_0's rmse: 0.848012\n[153]\tvalid_0's rmse: 0.848024\n[154]\tvalid_0's rmse: 0.848029\n[155]\tvalid_0's rmse: 0.848017\n[156]\tvalid_0's rmse: 0.84801\n[157]\tvalid_0's rmse: 0.847996\n[158]\tvalid_0's rmse: 0.847986\n[159]\tvalid_0's rmse: 0.847971\n[160]\tvalid_0's rmse: 0.847935\n[161]\tvalid_0's rmse: 0.847925\n[162]\tvalid_0's rmse: 0.847906\n[163]\tvalid_0's rmse: 0.84792\n[164]\tvalid_0's rmse: 0.847927\n[165]\tvalid_0's rmse: 0.847938\n[166]\tvalid_0's rmse: 0.847884\n[167]\tvalid_0's rmse: 0.847889\n[168]\tvalid_0's rmse: 0.847907\n[169]\tvalid_0's rmse: 0.84791\n[170]\tvalid_0's rmse: 0.847885\n[171]\tvalid_0's rmse: 0.84789\n[172]\tvalid_0's rmse: 0.84785\n[173]\tvalid_0's rmse: 0.847839\n[174]\tvalid_0's rmse: 0.847837\n[175]\tvalid_0's rmse: 0.847822\n[176]\tvalid_0's rmse: 0.847804\n[177]\tvalid_0's rmse: 0.847807\n[178]\tvalid_0's rmse: 0.847794\n[179]\tvalid_0's rmse: 0.847793\n[180]\tvalid_0's rmse: 0.847788\n[181]\tvalid_0's rmse: 0.847799\n[182]\tvalid_0's rmse: 0.847788\n[183]\tvalid_0's rmse: 0.847752\n[184]\tvalid_0's rmse: 0.84774\n[185]\tvalid_0's rmse: 0.847763\n[186]\tvalid_0's rmse: 0.847753\n[187]\tvalid_0's rmse: 0.847745\n[188]\tvalid_0's rmse: 0.84776\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  20%|##        | 4/20 [00:19<01:18,  4.91s/it]\u001b[32m[I 2021-02-05 22:54:53,570]\u001b[0m Trial 43 finished with value: 0.8477379277863034 and parameters: {'lambda_l1': 1.960078532267717e-07, 'lambda_l2': 1.0080549045867677}. Best is trial 40 with value: 0.8474854744807965.\u001b[0m\nregularization_factors, val_score: 0.847465:  20%|##        | 4/20 [00:19<01:18,  4.91s/it]","name":"stderr"},{"output_type":"stream","text":"[189]\tvalid_0's rmse: 0.847769\n[190]\tvalid_0's rmse: 0.847738\n[191]\tvalid_0's rmse: 0.847743\n[192]\tvalid_0's rmse: 0.847742\n[193]\tvalid_0's rmse: 0.847765\n[194]\tvalid_0's rmse: 0.847762\n[195]\tvalid_0's rmse: 0.847751\n[196]\tvalid_0's rmse: 0.84776\n[197]\tvalid_0's rmse: 0.847769\n[198]\tvalid_0's rmse: 0.847765\n[199]\tvalid_0's rmse: 0.847754\n[200]\tvalid_0's rmse: 0.847748\nEarly stopping, best iteration is:\n[190]\tvalid_0's rmse: 0.847738\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019404 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848116\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847947\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847566\n[230]\tvalid_0's rmse: 0.847548\n[231]\tvalid_0's rmse: 0.847554\n[232]\tvalid_0's rmse: 0.847539\n[233]\tvalid_0's rmse: 0.847515\n[234]\tvalid_0's rmse: 0.847501\n[235]\tvalid_0's rmse: 0.847502\n[236]\tvalid_0's rmse: 0.847501\n[237]\tvalid_0's rmse: 0.847512\n[238]\tvalid_0's rmse: 0.847495\n[239]\tvalid_0's rmse: 0.847494\n[240]\tvalid_0's rmse: 0.84749\n[241]\tvalid_0's rmse: 0.847502\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  25%|##5       | 5/20 [00:25<01:16,  5.12s/it]\u001b[32m[I 2021-02-05 22:54:59,072]\u001b[0m Trial 44 finished with value: 0.8474854360505399 and parameters: {'lambda_l1': 1.860709553211026e-07, 'lambda_l2': 0.0028931898199936294}. Best is trial 44 with value: 0.8474854360505399.\u001b[0m\nregularization_factors, val_score: 0.847465:  25%|##5       | 5/20 [00:25<01:16,  5.12s/it]","name":"stderr"},{"output_type":"stream","text":"[242]\tvalid_0's rmse: 0.847485\n[243]\tvalid_0's rmse: 0.847504\n[244]\tvalid_0's rmse: 0.847506\n[245]\tvalid_0's rmse: 0.847508\n[246]\tvalid_0's rmse: 0.847513\n[247]\tvalid_0's rmse: 0.847509\n[248]\tvalid_0's rmse: 0.847521\n[249]\tvalid_0's rmse: 0.847533\n[250]\tvalid_0's rmse: 0.847529\n[251]\tvalid_0's rmse: 0.847533\n[252]\tvalid_0's rmse: 0.847515\nEarly stopping, best iteration is:\n[242]\tvalid_0's rmse: 0.847485\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019057 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888382\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885598\n[3]\tvalid_0's rmse: 0.883369\n[4]\tvalid_0's rmse: 0.88121\n[5]\tvalid_0's rmse: 0.87937\n[6]\tvalid_0's rmse: 0.877327\n[7]\tvalid_0's rmse: 0.875857\n[8]\tvalid_0's rmse: 0.87462\n[9]\tvalid_0's rmse: 0.873456\n[10]\tvalid_0's rmse: 0.872395\n[11]\tvalid_0's rmse: 0.871023\n[12]\tvalid_0's rmse: 0.869841\n[13]\tvalid_0's rmse: 0.868807\n[14]\tvalid_0's rmse: 0.867779\n[15]\tvalid_0's rmse: 0.867068\n[16]\tvalid_0's rmse: 0.866292\n[17]\tvalid_0's rmse: 0.865485\n[18]\tvalid_0's rmse: 0.864838\n[19]\tvalid_0's rmse: 0.864153\n[20]\tvalid_0's rmse: 0.863618\n[21]\tvalid_0's rmse: 0.863076\n[22]\tvalid_0's rmse: 0.862436\n[23]\tvalid_0's rmse: 0.861938\n[24]\tvalid_0's rmse: 0.861397\n[25]\tvalid_0's rmse: 0.861063\n[26]\tvalid_0's rmse: 0.860619\n[27]\tvalid_0's rmse: 0.860281\n[28]\tvalid_0's rmse: 0.859873\n[29]\tvalid_0's rmse: 0.859504\n[30]\tvalid_0's rmse: 0.859127\n[31]\tvalid_0's rmse: 0.8588\n[32]\tvalid_0's rmse: 0.858438\n[33]\tvalid_0's rmse: 0.858132\n[34]\tvalid_0's rmse: 0.857687\n[35]\tvalid_0's rmse: 0.857461\n[36]\tvalid_0's rmse: 0.857163\n[37]\tvalid_0's rmse: 0.856884\n[38]\tvalid_0's rmse: 0.856587\n[39]\tvalid_0's rmse: 0.856315\n[40]\tvalid_0's rmse: 0.856062\n[41]\tvalid_0's rmse: 0.855874\n[42]\tvalid_0's rmse: 0.855646\n[43]\tvalid_0's rmse: 0.855465\n[44]\tvalid_0's rmse: 0.855255\n[45]\tvalid_0's rmse: 0.855028\n[46]\tvalid_0's rmse: 0.854856\n[47]\tvalid_0's rmse: 0.854709\n[48]\tvalid_0's rmse: 0.854552\n[49]\tvalid_0's rmse: 0.854413\n[50]\tvalid_0's rmse: 0.854256\n[51]\tvalid_0's rmse: 0.854159\n[52]\tvalid_0's rmse: 0.853875\n[53]\tvalid_0's rmse: 0.853722\n[54]\tvalid_0's rmse: 0.853604\n[55]\tvalid_0's rmse: 0.853482\n[56]\tvalid_0's rmse: 0.853258\n[57]\tvalid_0's rmse: 0.853114\n[58]\tvalid_0's rmse: 0.852881\n[59]\tvalid_0's rmse: 0.852788\n[60]\tvalid_0's rmse: 0.852648\n[61]\tvalid_0's rmse: 0.852541\n[62]\tvalid_0's rmse: 0.852404\n[63]\tvalid_0's rmse: 0.852298\n[64]\tvalid_0's rmse: 0.852137\n[65]\tvalid_0's rmse: 0.852031\n[66]\tvalid_0's rmse: 0.851931\n[67]\tvalid_0's rmse: 0.851871\n[68]\tvalid_0's rmse: 0.851796\n[69]\tvalid_0's rmse: 0.851683\n[70]\tvalid_0's rmse: 0.85159\n[71]\tvalid_0's rmse: 0.851515\n[72]\tvalid_0's rmse: 0.85144\n[73]\tvalid_0's rmse: 0.851367\n[74]\tvalid_0's rmse: 0.851282\n[75]\tvalid_0's rmse: 0.851185\n[76]\tvalid_0's rmse: 0.851021\n[77]\tvalid_0's rmse: 0.850929\n[78]\tvalid_0's rmse: 0.850826\n[79]\tvalid_0's rmse: 0.850725\n[80]\tvalid_0's rmse: 0.850659\n[81]\tvalid_0's rmse: 0.850578\n[82]\tvalid_0's rmse: 0.850515\n[83]\tvalid_0's rmse: 0.850448\n[84]\tvalid_0's rmse: 0.850376\n[85]\tvalid_0's rmse: 0.85032\n[86]\tvalid_0's rmse: 0.850276\n[87]\tvalid_0's rmse: 0.850221\n[88]\tvalid_0's rmse: 0.8501\n[89]\tvalid_0's rmse: 0.850019\n[90]\tvalid_0's rmse: 0.849982\n[91]\tvalid_0's rmse: 0.849918\n[92]\tvalid_0's rmse: 0.849887\n[93]\tvalid_0's rmse: 0.849808\n[94]\tvalid_0's rmse: 0.849757\n[95]\tvalid_0's rmse: 0.849682\n[96]\tvalid_0's rmse: 0.849668\n[97]\tvalid_0's rmse: 0.849636\n[98]\tvalid_0's rmse: 0.849565\n[99]\tvalid_0's rmse: 0.849526\n[100]\tvalid_0's rmse: 0.849483\n[101]\tvalid_0's rmse: 0.849428\n[102]\tvalid_0's rmse: 0.84936\n[103]\tvalid_0's rmse: 0.849343\n[104]\tvalid_0's rmse: 0.849306\n[105]\tvalid_0's rmse: 0.849258\n[106]\tvalid_0's rmse: 0.849229\n[107]\tvalid_0's rmse: 0.849168\n[108]\tvalid_0's rmse: 0.849116\n[109]\tvalid_0's rmse: 0.849039\n[110]\tvalid_0's rmse: 0.849003\n[111]\tvalid_0's rmse: 0.848942\n[112]\tvalid_0's rmse: 0.84891\n[113]\tvalid_0's rmse: 0.848839\n[114]\tvalid_0's rmse: 0.84881\n[115]\tvalid_0's rmse: 0.848761\n[116]\tvalid_0's rmse: 0.848764\n[117]\tvalid_0's rmse: 0.848712\n[118]\tvalid_0's rmse: 0.848674\n[119]\tvalid_0's rmse: 0.848605\n[120]\tvalid_0's rmse: 0.848582\n[121]\tvalid_0's rmse: 0.848534\n[122]\tvalid_0's rmse: 0.84848\n[123]\tvalid_0's rmse: 0.848455\n[124]\tvalid_0's rmse: 0.84843\n[125]\tvalid_0's rmse: 0.848402\n[126]\tvalid_0's rmse: 0.848375\n[127]\tvalid_0's rmse: 0.848375\n[128]\tvalid_0's rmse: 0.848344\n[129]\tvalid_0's rmse: 0.848306\n[130]\tvalid_0's rmse: 0.848296\n[131]\tvalid_0's rmse: 0.848272\n[132]\tvalid_0's rmse: 0.848254\n[133]\tvalid_0's rmse: 0.848242\n[134]\tvalid_0's rmse: 0.84822\n[135]\tvalid_0's rmse: 0.848203\n[136]\tvalid_0's rmse: 0.848174\n[137]\tvalid_0's rmse: 0.848167\n[138]\tvalid_0's rmse: 0.848158\n[139]\tvalid_0's rmse: 0.848137\n[140]\tvalid_0's rmse: 0.848141\n[141]\tvalid_0's rmse: 0.848122\n[142]\tvalid_0's rmse: 0.848073\n[143]\tvalid_0's rmse: 0.848063\n[144]\tvalid_0's rmse: 0.84805\n[145]\tvalid_0's rmse: 0.84803\n[146]\tvalid_0's rmse: 0.848014\n[147]\tvalid_0's rmse: 0.848015\n[148]\tvalid_0's rmse: 0.848004\n[149]\tvalid_0's rmse: 0.847991\n[150]\tvalid_0's rmse: 0.847958\n[151]\tvalid_0's rmse: 0.847952\n[152]\tvalid_0's rmse: 0.847936\n[153]\tvalid_0's rmse: 0.847911\n[154]\tvalid_0's rmse: 0.847874\n[155]\tvalid_0's rmse: 0.847869\n[156]\tvalid_0's rmse: 0.847864\n[157]\tvalid_0's rmse: 0.847864\n[158]\tvalid_0's rmse: 0.847852\n[159]\tvalid_0's rmse: 0.847835\n[160]\tvalid_0's rmse: 0.847804\n[161]\tvalid_0's rmse: 0.847786\n[162]\tvalid_0's rmse: 0.847768\n[163]\tvalid_0's rmse: 0.847768\n[164]\tvalid_0's rmse: 0.847725\n[165]\tvalid_0's rmse: 0.847734\n[166]\tvalid_0's rmse: 0.847738\n[167]\tvalid_0's rmse: 0.847724\n[168]\tvalid_0's rmse: 0.847741\n[169]\tvalid_0's rmse: 0.84774\n[170]\tvalid_0's rmse: 0.847719\n[171]\tvalid_0's rmse: 0.847725\n[172]\tvalid_0's rmse: 0.847735\n[173]\tvalid_0's rmse: 0.84772\n[174]\tvalid_0's rmse: 0.847697\n[175]\tvalid_0's rmse: 0.847691\n[176]\tvalid_0's rmse: 0.847663\n[177]\tvalid_0's rmse: 0.847652\n[178]\tvalid_0's rmse: 0.847651\n[179]\tvalid_0's rmse: 0.847637\n[180]\tvalid_0's rmse: 0.847636\n[181]\tvalid_0's rmse: 0.847627\n[182]\tvalid_0's rmse: 0.847635\n[183]\tvalid_0's rmse: 0.84763\n[184]\tvalid_0's rmse: 0.847639\n[185]\tvalid_0's rmse: 0.847639\n[186]\tvalid_0's rmse: 0.847642\n[187]\tvalid_0's rmse: 0.847642\n[188]\tvalid_0's rmse: 0.847642\n[189]\tvalid_0's rmse: 0.847631\n[190]\tvalid_0's rmse: 0.847612\n[191]\tvalid_0's rmse: 0.847613\n[192]\tvalid_0's rmse: 0.847642\n[193]\tvalid_0's rmse: 0.847632\n[194]\tvalid_0's rmse: 0.847595\n[195]\tvalid_0's rmse: 0.847591\n[196]\tvalid_0's rmse: 0.847598\n[197]\tvalid_0's rmse: 0.847606\n[198]\tvalid_0's rmse: 0.847603\n[199]\tvalid_0's rmse: 0.847602\n[200]\tvalid_0's rmse: 0.84761\n[201]\tvalid_0's rmse: 0.847619\n[202]\tvalid_0's rmse: 0.847612\n[203]\tvalid_0's rmse: 0.847624","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  30%|###       | 6/20 [00:30<01:11,  5.08s/it]\u001b[32m[I 2021-02-05 22:55:04,062]\u001b[0m Trial 45 finished with value: 0.8475909702124508 and parameters: {'lambda_l1': 6.691355809069201, 'lambda_l2': 1.5632299238769063}. Best is trial 44 with value: 0.8474854360505399.\u001b[0m\nregularization_factors, val_score: 0.847465:  30%|###       | 6/20 [00:30<01:11,  5.08s/it]","name":"stderr"},{"output_type":"stream","text":"\n[204]\tvalid_0's rmse: 0.847617\n[205]\tvalid_0's rmse: 0.847614\nEarly stopping, best iteration is:\n[195]\tvalid_0's rmse: 0.847591\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019373 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.872271\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858573\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852231\n[64]\tvalid_0's rmse: 0.852094\n[65]\tvalid_0's rmse: 0.851945\n[66]\tvalid_0's rmse: 0.851852\n[67]\tvalid_0's rmse: 0.851798\n[68]\tvalid_0's rmse: 0.851701\n[69]\tvalid_0's rmse: 0.851648\n[70]\tvalid_0's rmse: 0.85151\n[71]\tvalid_0's rmse: 0.851453\n[72]\tvalid_0's rmse: 0.851396\n[73]\tvalid_0's rmse: 0.851364\n[74]\tvalid_0's rmse: 0.851267\n[75]\tvalid_0's rmse: 0.851171\n[76]\tvalid_0's rmse: 0.851053\n[77]\tvalid_0's rmse: 0.85097\n[78]\tvalid_0's rmse: 0.850909\n[79]\tvalid_0's rmse: 0.850851\n[80]\tvalid_0's rmse: 0.85079\n[81]\tvalid_0's rmse: 0.85072\n[82]\tvalid_0's rmse: 0.850661\n[83]\tvalid_0's rmse: 0.850613\n[84]\tvalid_0's rmse: 0.850538\n[85]\tvalid_0's rmse: 0.850459\n[86]\tvalid_0's rmse: 0.850416\n[87]\tvalid_0's rmse: 0.850416\n[88]\tvalid_0's rmse: 0.850285\n[89]\tvalid_0's rmse: 0.850268\n[90]\tvalid_0's rmse: 0.850224\n[91]\tvalid_0's rmse: 0.850155\n[92]\tvalid_0's rmse: 0.85005\n[93]\tvalid_0's rmse: 0.849999\n[94]\tvalid_0's rmse: 0.849963\n[95]\tvalid_0's rmse: 0.849916\n[96]\tvalid_0's rmse: 0.849884\n[97]\tvalid_0's rmse: 0.849848\n[98]\tvalid_0's rmse: 0.849781\n[99]\tvalid_0's rmse: 0.849751\n[100]\tvalid_0's rmse: 0.84973\n[101]\tvalid_0's rmse: 0.849668\n[102]\tvalid_0's rmse: 0.849606\n[103]\tvalid_0's rmse: 0.849526\n[104]\tvalid_0's rmse: 0.849466\n[105]\tvalid_0's rmse: 0.849427\n[106]\tvalid_0's rmse: 0.849418\n[107]\tvalid_0's rmse: 0.849364\n[108]\tvalid_0's rmse: 0.849311\n[109]\tvalid_0's rmse: 0.849253\n[110]\tvalid_0's rmse: 0.849223\n[111]\tvalid_0's rmse: 0.849178\n[112]\tvalid_0's rmse: 0.849155\n[113]\tvalid_0's rmse: 0.849132\n[114]\tvalid_0's rmse: 0.849097\n[115]\tvalid_0's rmse: 0.849091\n[116]\tvalid_0's rmse: 0.849067\n[117]\tvalid_0's rmse: 0.849061\n[118]\tvalid_0's rmse: 0.849051\n[119]\tvalid_0's rmse: 0.849033\n[120]\tvalid_0's rmse: 0.849004\n[121]\tvalid_0's rmse: 0.848922\n[122]\tvalid_0's rmse: 0.848913\n[123]\tvalid_0's rmse: 0.848886\n[124]\tvalid_0's rmse: 0.848864\n[125]\tvalid_0's rmse: 0.848815\n[126]\tvalid_0's rmse: 0.848794\n[127]\tvalid_0's rmse: 0.848768\n[128]\tvalid_0's rmse: 0.848723\n[129]\tvalid_0's rmse: 0.848713\n[130]\tvalid_0's rmse: 0.848704\n[131]\tvalid_0's rmse: 0.848664\n[132]\tvalid_0's rmse: 0.848669\n[133]\tvalid_0's rmse: 0.848665\n[134]\tvalid_0's rmse: 0.848667\n[135]\tvalid_0's rmse: 0.84865\n[136]\tvalid_0's rmse: 0.848653\n[137]\tvalid_0's rmse: 0.848611\n[138]\tvalid_0's rmse: 0.848626\n[139]\tvalid_0's rmse: 0.848591\n[140]\tvalid_0's rmse: 0.848614\n[141]\tvalid_0's rmse: 0.848615\n[142]\tvalid_0's rmse: 0.848635\n[143]\tvalid_0's rmse: 0.848596\n[144]\tvalid_0's rmse: 0.848573\n[145]\tvalid_0's rmse: 0.848582\n[146]\tvalid_0's rmse: 0.848526\n[147]\tvalid_0's rmse: 0.848481\n[148]\tvalid_0's rmse: 0.848472\n[149]\tvalid_0's rmse: 0.848457\n[150]\tvalid_0's rmse: 0.848431\n[151]\tvalid_0's rmse: 0.848434\n[152]\tvalid_0's rmse: 0.848425\n[153]\tvalid_0's rmse: 0.848419\n[154]\tvalid_0's rmse: 0.848406\n[155]\tvalid_0's rmse: 0.848365\n[156]\tvalid_0's rmse: 0.848361\n[157]\tvalid_0's rmse: 0.848347\n[158]\tvalid_0's rmse: 0.848336\n[159]\tvalid_0's rmse: 0.84834\n[160]\tvalid_0's rmse: 0.848332\n[161]\tvalid_0's rmse: 0.848337\n[162]\tvalid_0's rmse: 0.848343\n[163]\tvalid_0's rmse: 0.848364\n[164]\tvalid_0's rmse: 0.848351\n[165]\tvalid_0's rmse: 0.848327\n[166]\tvalid_0's rmse: 0.848255\n[167]\tvalid_0's rmse: 0.848259\n[168]\tvalid_0's rmse: 0.848264\n[169]\tvalid_0's rmse: 0.848269\n[170]\tvalid_0's rmse: 0.848279\n[171]\tvalid_0's rmse: 0.848266\n[172]\tvalid_0's rmse: 0.848236\n[173]\tvalid_0's rmse: 0.848224\n[174]\tvalid_0's rmse: 0.848218\n[175]\tvalid_0's rmse: 0.848188\n[176]\tvalid_0's rmse: 0.848194\n[177]\tvalid_0's rmse: 0.848199\n[178]\tvalid_0's rmse: 0.848195\n[179]\tvalid_0's rmse: 0.848177\n[180]\tvalid_0's rmse: 0.848195\n[181]\tvalid_0's rmse: 0.848194\n[182]\tvalid_0's rmse: 0.848202\n[183]\tvalid_0's rmse: 0.848199\n[184]\tvalid_0's rmse: 0.848223\n[185]\tvalid_0's rmse: 0.848219\n[186]\tvalid_0's rmse: 0.848227\n[187]\tvalid_0's rmse: 0.848236\n[188]\tvalid_0's rmse: 0.84821\n[189]\tvalid_0's rmse: 0.848176\n[190]\tvalid_0's rmse: 0.848199\n[191]\tvalid_0's rmse: 0.848191\n[192]\tvalid_0's rmse: 0.848159\n[193]\tvalid_0's rmse: 0.848162\n[194]\tvalid_0's rmse: 0.848157\n[195]\tvalid_0's rmse: 0.848169\n[196]\tvalid_0's rmse: 0.848172\n[197]\tvalid_0's rmse: 0.848169\n[198]\tvalid_0's rmse: 0.848165\n[199]\tvalid_0's rmse: 0.84814\n[200]\tvalid_0's rmse: 0.848132\n[201]\tvalid_0's rmse: 0.848104\n[202]\tvalid_0's rmse: 0.848108\n[203]\tvalid_0's rmse: 0.8481\n[204]\tvalid_0's rmse: 0.848094\n[205]\tvalid_0's rmse: 0.8481\n[206]\tvalid_0's rmse: 0.848129\n[207]\tvalid_0's rmse: 0.848131\n[208]\tvalid_0's rmse: 0.848114\n[209]\tvalid_0's rmse: 0.84811\n[210]\tvalid_0's rmse: 0.848092\n[211]\tvalid_0's rmse: 0.848082\n[212]\tvalid_0's rmse: 0.848058\n[213]\tvalid_0's rmse: 0.848057\n[214]\tvalid_0's rmse: 0.848057\n[215]\tvalid_0's rmse: 0.848058\n[216]\tvalid_0's rmse: 0.84807\n[217]\tvalid_0's rmse: 0.848064\n[218]\tvalid_0's rmse: 0.848062\n[219]\tvalid_0's rmse: 0.848051\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  35%|###5      | 7/20 [00:35<01:07,  5.16s/it]\u001b[32m[I 2021-02-05 22:55:09,405]\u001b[0m Trial 46 finished with value: 0.848050215503766 and parameters: {'lambda_l1': 4.1640693748559604e-08, 'lambda_l2': 0.01781327833146105}. Best is trial 44 with value: 0.8474854360505399.\u001b[0m\nregularization_factors, val_score: 0.847465:  35%|###5      | 7/20 [00:35<01:07,  5.16s/it]","name":"stderr"},{"output_type":"stream","text":"[220]\tvalid_0's rmse: 0.84805\n[221]\tvalid_0's rmse: 0.848067\n[222]\tvalid_0's rmse: 0.848058\n[223]\tvalid_0's rmse: 0.848053\n[224]\tvalid_0's rmse: 0.848071\n[225]\tvalid_0's rmse: 0.848089\n[226]\tvalid_0's rmse: 0.848076\n[227]\tvalid_0's rmse: 0.848067\n[228]\tvalid_0's rmse: 0.848081\n[229]\tvalid_0's rmse: 0.84806\n[230]\tvalid_0's rmse: 0.848059\nEarly stopping, best iteration is:\n[220]\tvalid_0's rmse: 0.84805\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019255 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88834\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885549\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881131\n[5]\tvalid_0's rmse: 0.8793\n[6]\tvalid_0's rmse: 0.877241\n[7]\tvalid_0's rmse: 0.875749\n[8]\tvalid_0's rmse: 0.874496\n[9]\tvalid_0's rmse: 0.873333\n[10]\tvalid_0's rmse: 0.872265\n[11]\tvalid_0's rmse: 0.870881\n[12]\tvalid_0's rmse: 0.869674\n[13]\tvalid_0's rmse: 0.868602\n[14]\tvalid_0's rmse: 0.867547\n[15]\tvalid_0's rmse: 0.866848\n[16]\tvalid_0's rmse: 0.866071\n[17]\tvalid_0's rmse: 0.865254\n[18]\tvalid_0's rmse: 0.864617\n[19]\tvalid_0's rmse: 0.863912\n[20]\tvalid_0's rmse: 0.863337\n[21]\tvalid_0's rmse: 0.862794\n[22]\tvalid_0's rmse: 0.86216\n[23]\tvalid_0's rmse: 0.861631\n[24]\tvalid_0's rmse: 0.861098\n[25]\tvalid_0's rmse: 0.860758\n[26]\tvalid_0's rmse: 0.860353\n[27]\tvalid_0's rmse: 0.860022\n[28]\tvalid_0's rmse: 0.859654\n[29]\tvalid_0's rmse: 0.859282\n[30]\tvalid_0's rmse: 0.858913\n[31]\tvalid_0's rmse: 0.858589\n[32]\tvalid_0's rmse: 0.858228\n[33]\tvalid_0's rmse: 0.857916\n[34]\tvalid_0's rmse: 0.857592\n[35]\tvalid_0's rmse: 0.85734\n[36]\tvalid_0's rmse: 0.857004\n[37]\tvalid_0's rmse: 0.856739\n[38]\tvalid_0's rmse: 0.856455\n[39]\tvalid_0's rmse: 0.856209\n[40]\tvalid_0's rmse: 0.855947\n[41]\tvalid_0's rmse: 0.855788\n[42]\tvalid_0's rmse: 0.855571\n[43]\tvalid_0's rmse: 0.855379\n[44]\tvalid_0's rmse: 0.855043\n[45]\tvalid_0's rmse: 0.854829\n[46]\tvalid_0's rmse: 0.854668\n[47]\tvalid_0's rmse: 0.854495\n[48]\tvalid_0's rmse: 0.854331\n[49]\tvalid_0's rmse: 0.854174\n[50]\tvalid_0's rmse: 0.85402\n[51]\tvalid_0's rmse: 0.853916\n[52]\tvalid_0's rmse: 0.853758\n[53]\tvalid_0's rmse: 0.853587\n[54]\tvalid_0's rmse: 0.853436\n[55]\tvalid_0's rmse: 0.853328\n[56]\tvalid_0's rmse: 0.853156\n[57]\tvalid_0's rmse: 0.85305\n[58]\tvalid_0's rmse: 0.85287\n[59]\tvalid_0's rmse: 0.852759\n[60]\tvalid_0's rmse: 0.852623\n[61]\tvalid_0's rmse: 0.852529\n[62]\tvalid_0's rmse: 0.852429\n[63]\tvalid_0's rmse: 0.852261\n[64]\tvalid_0's rmse: 0.852099\n[65]\tvalid_0's rmse: 0.85196\n[66]\tvalid_0's rmse: 0.851864\n[67]\tvalid_0's rmse: 0.851799\n[68]\tvalid_0's rmse: 0.851681\n[69]\tvalid_0's rmse: 0.851559\n[70]\tvalid_0's rmse: 0.851469\n[71]\tvalid_0's rmse: 0.851416\n[72]\tvalid_0's rmse: 0.851372\n[73]\tvalid_0's rmse: 0.851345\n[74]\tvalid_0's rmse: 0.851248\n[75]\tvalid_0's rmse: 0.85116\n[76]\tvalid_0's rmse: 0.851062\n[77]\tvalid_0's rmse: 0.850965\n[78]\tvalid_0's rmse: 0.850894\n[79]\tvalid_0's rmse: 0.850831\n[80]\tvalid_0's rmse: 0.850776\n[81]\tvalid_0's rmse: 0.850712\n[82]\tvalid_0's rmse: 0.85065\n[83]\tvalid_0's rmse: 0.850575\n[84]\tvalid_0's rmse: 0.850472\n[85]\tvalid_0's rmse: 0.850432\n[86]\tvalid_0's rmse: 0.850396\n[87]\tvalid_0's rmse: 0.850382\n[88]\tvalid_0's rmse: 0.850279\n[89]\tvalid_0's rmse: 0.850212\n[90]\tvalid_0's rmse: 0.850179\n[91]\tvalid_0's rmse: 0.850134\n[92]\tvalid_0's rmse: 0.850073\n[93]\tvalid_0's rmse: 0.849989\n[94]\tvalid_0's rmse: 0.849939\n[95]\tvalid_0's rmse: 0.849882\n[96]\tvalid_0's rmse: 0.849816\n[97]\tvalid_0's rmse: 0.849771\n[98]\tvalid_0's rmse: 0.849659\n[99]\tvalid_0's rmse: 0.849641\n[100]\tvalid_0's rmse: 0.849619\n[101]\tvalid_0's rmse: 0.849563\n[102]\tvalid_0's rmse: 0.849473\n[103]\tvalid_0's rmse: 0.849445\n[104]\tvalid_0's rmse: 0.849415\n[105]\tvalid_0's rmse: 0.849319\n[106]\tvalid_0's rmse: 0.849305\n[107]\tvalid_0's rmse: 0.849253\n[108]\tvalid_0's rmse: 0.849215\n[109]\tvalid_0's rmse: 0.849183\n[110]\tvalid_0's rmse: 0.849174\n[111]\tvalid_0's rmse: 0.849162\n[112]\tvalid_0's rmse: 0.849123\n[113]\tvalid_0's rmse: 0.849088\n[114]\tvalid_0's rmse: 0.849063\n[115]\tvalid_0's rmse: 0.849038\n[116]\tvalid_0's rmse: 0.849012\n[117]\tvalid_0's rmse: 0.848991\n[118]\tvalid_0's rmse: 0.848985\n[119]\tvalid_0's rmse: 0.848949\n[120]\tvalid_0's rmse: 0.848917\n[121]\tvalid_0's rmse: 0.848841\n[122]\tvalid_0's rmse: 0.848822\n[123]\tvalid_0's rmse: 0.848814\n[124]\tvalid_0's rmse: 0.848783\n[125]\tvalid_0's rmse: 0.848763\n[126]\tvalid_0's rmse: 0.848735\n[127]\tvalid_0's rmse: 0.848713\n[128]\tvalid_0's rmse: 0.84871\n[129]\tvalid_0's rmse: 0.848687\n[130]\tvalid_0's rmse: 0.848694\n[131]\tvalid_0's rmse: 0.848681\n[132]\tvalid_0's rmse: 0.848687\n[133]\tvalid_0's rmse: 0.848665\n[134]\tvalid_0's rmse: 0.848667\n[135]\tvalid_0's rmse: 0.848624\n[136]\tvalid_0's rmse: 0.848614\n[137]\tvalid_0's rmse: 0.84857\n[138]\tvalid_0's rmse: 0.848549\n[139]\tvalid_0's rmse: 0.848517\n[140]\tvalid_0's rmse: 0.848474\n[141]\tvalid_0's rmse: 0.848463\n[142]\tvalid_0's rmse: 0.848443\n[143]\tvalid_0's rmse: 0.848438\n[144]\tvalid_0's rmse: 0.848434\n[145]\tvalid_0's rmse: 0.848426\n[146]\tvalid_0's rmse: 0.848407\n[147]\tvalid_0's rmse: 0.848371\n[148]\tvalid_0's rmse: 0.84834\n[149]\tvalid_0's rmse: 0.8483\n[150]\tvalid_0's rmse: 0.848312\n[151]\tvalid_0's rmse: 0.84831\n[152]\tvalid_0's rmse: 0.848316\n[153]\tvalid_0's rmse: 0.848298\n[154]\tvalid_0's rmse: 0.8483\n[155]\tvalid_0's rmse: 0.848262\n[156]\tvalid_0's rmse: 0.848262\n[157]\tvalid_0's rmse: 0.848237\n[158]\tvalid_0's rmse: 0.848233\n[159]\tvalid_0's rmse: 0.848229\n[160]\tvalid_0's rmse: 0.84823\n[161]\tvalid_0's rmse: 0.848229\n[162]\tvalid_0's rmse: 0.848241\n[163]\tvalid_0's rmse: 0.848237\n[164]\tvalid_0's rmse: 0.848247\n[165]\tvalid_0's rmse: 0.848257\n[166]\tvalid_0's rmse: 0.848243\n[167]\tvalid_0's rmse: 0.848236\n[168]\tvalid_0's rmse: 0.8482\n[169]\tvalid_0's rmse: 0.848209\n[170]\tvalid_0's rmse: 0.848168\n[171]\tvalid_0's rmse: 0.848175\n[172]\tvalid_0's rmse: 0.848165\n[173]\tvalid_0's rmse: 0.848174\n[174]\tvalid_0's rmse: 0.848175\n[175]\tvalid_0's rmse: 0.848154\n[176]\tvalid_0's rmse: 0.84815\n[177]\tvalid_0's rmse: 0.848158\n[178]\tvalid_0's rmse: 0.84815\n[179]\tvalid_0's rmse: 0.848157\n[180]\tvalid_0's rmse: 0.848155\n[181]\tvalid_0's rmse: 0.848155\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  40%|####      | 8/20 [00:40<00:59,  4.97s/it]\u001b[32m[I 2021-02-05 22:55:13,958]\u001b[0m Trial 47 finished with value: 0.8481495431820997 and parameters: {'lambda_l1': 0.24169707215278047, 'lambda_l2': 2.1265746620683292}. Best is trial 44 with value: 0.8474854360505399.\u001b[0m\nregularization_factors, val_score: 0.847465:  40%|####      | 8/20 [00:40<00:59,  4.97s/it]","name":"stderr"},{"output_type":"stream","text":"[182]\tvalid_0's rmse: 0.848161\n[183]\tvalid_0's rmse: 0.848167\n[184]\tvalid_0's rmse: 0.84817\n[185]\tvalid_0's rmse: 0.848163\n[186]\tvalid_0's rmse: 0.848166\nEarly stopping, best iteration is:\n[176]\tvalid_0's rmse: 0.84815\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019357 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888338\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885545\n[3]\tvalid_0's rmse: 0.883298\n[4]\tvalid_0's rmse: 0.881125\n[5]\tvalid_0's rmse: 0.879293\n[6]\tvalid_0's rmse: 0.877235\n[7]\tvalid_0's rmse: 0.875743\n[8]\tvalid_0's rmse: 0.87449\n[9]\tvalid_0's rmse: 0.873327\n[10]\tvalid_0's rmse: 0.872248\n[11]\tvalid_0's rmse: 0.870851\n[12]\tvalid_0's rmse: 0.869638\n[13]\tvalid_0's rmse: 0.868568\n[14]\tvalid_0's rmse: 0.867531\n[15]\tvalid_0's rmse: 0.866832\n[16]\tvalid_0's rmse: 0.866057\n[17]\tvalid_0's rmse: 0.865233\n[18]\tvalid_0's rmse: 0.86454\n[19]\tvalid_0's rmse: 0.863858\n[20]\tvalid_0's rmse: 0.863283\n[21]\tvalid_0's rmse: 0.862715\n[22]\tvalid_0's rmse: 0.862077\n[23]\tvalid_0's rmse: 0.861558\n[24]\tvalid_0's rmse: 0.861023\n[25]\tvalid_0's rmse: 0.860607\n[26]\tvalid_0's rmse: 0.860188\n[27]\tvalid_0's rmse: 0.859841\n[28]\tvalid_0's rmse: 0.859445\n[29]\tvalid_0's rmse: 0.859079\n[30]\tvalid_0's rmse: 0.858796\n[31]\tvalid_0's rmse: 0.858459\n[32]\tvalid_0's rmse: 0.858108\n[33]\tvalid_0's rmse: 0.85781\n[34]\tvalid_0's rmse: 0.857452\n[35]\tvalid_0's rmse: 0.8572\n[36]\tvalid_0's rmse: 0.856872\n[37]\tvalid_0's rmse: 0.856627\n[38]\tvalid_0's rmse: 0.856334\n[39]\tvalid_0's rmse: 0.856061\n[40]\tvalid_0's rmse: 0.855792\n[41]\tvalid_0's rmse: 0.855633\n[42]\tvalid_0's rmse: 0.855412\n[43]\tvalid_0's rmse: 0.855222\n[44]\tvalid_0's rmse: 0.854932\n[45]\tvalid_0's rmse: 0.854721\n[46]\tvalid_0's rmse: 0.854544\n[47]\tvalid_0's rmse: 0.854373\n[48]\tvalid_0's rmse: 0.854221\n[49]\tvalid_0's rmse: 0.854087\n[50]\tvalid_0's rmse: 0.853915\n[51]\tvalid_0's rmse: 0.853812\n[52]\tvalid_0's rmse: 0.853646\n[53]\tvalid_0's rmse: 0.853458\n[54]\tvalid_0's rmse: 0.853344\n[55]\tvalid_0's rmse: 0.853248\n[56]\tvalid_0's rmse: 0.853087\n[57]\tvalid_0's rmse: 0.852976\n[58]\tvalid_0's rmse: 0.852841\n[59]\tvalid_0's rmse: 0.852744\n[60]\tvalid_0's rmse: 0.852635\n[61]\tvalid_0's rmse: 0.852541\n[62]\tvalid_0's rmse: 0.852435\n[63]\tvalid_0's rmse: 0.852249\n[64]\tvalid_0's rmse: 0.852099\n[65]\tvalid_0's rmse: 0.851991\n[66]\tvalid_0's rmse: 0.851883\n[67]\tvalid_0's rmse: 0.851821\n[68]\tvalid_0's rmse: 0.851718\n[69]\tvalid_0's rmse: 0.851592\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.851433\n[72]\tvalid_0's rmse: 0.851392\n[73]\tvalid_0's rmse: 0.851324\n[74]\tvalid_0's rmse: 0.851273\n[75]\tvalid_0's rmse: 0.851168\n[76]\tvalid_0's rmse: 0.851071\n[77]\tvalid_0's rmse: 0.850978\n[78]\tvalid_0's rmse: 0.850873\n[79]\tvalid_0's rmse: 0.850781\n[80]\tvalid_0's rmse: 0.850692\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850571\n[83]\tvalid_0's rmse: 0.850495\n[84]\tvalid_0's rmse: 0.850379\n[85]\tvalid_0's rmse: 0.850339\n[86]\tvalid_0's rmse: 0.850285\n[87]\tvalid_0's rmse: 0.850229\n[88]\tvalid_0's rmse: 0.850148\n[89]\tvalid_0's rmse: 0.850111\n[90]\tvalid_0's rmse: 0.85007\n[91]\tvalid_0's rmse: 0.849993\n[92]\tvalid_0's rmse: 0.84991\n[93]\tvalid_0's rmse: 0.849836\n[94]\tvalid_0's rmse: 0.849814\n[95]\tvalid_0's rmse: 0.849735\n[96]\tvalid_0's rmse: 0.849716\n[97]\tvalid_0's rmse: 0.849673\n[98]\tvalid_0's rmse: 0.849578\n[99]\tvalid_0's rmse: 0.849548\n[100]\tvalid_0's rmse: 0.849516\n[101]\tvalid_0's rmse: 0.849418\n[102]\tvalid_0's rmse: 0.84937\n[103]\tvalid_0's rmse: 0.849302\n[104]\tvalid_0's rmse: 0.849277\n[105]\tvalid_0's rmse: 0.849201\n[106]\tvalid_0's rmse: 0.849202\n[107]\tvalid_0's rmse: 0.849107\n[108]\tvalid_0's rmse: 0.849043\n[109]\tvalid_0's rmse: 0.848994\n[110]\tvalid_0's rmse: 0.848964\n[111]\tvalid_0's rmse: 0.848945\n[112]\tvalid_0's rmse: 0.848923\n[113]\tvalid_0's rmse: 0.848906\n[114]\tvalid_0's rmse: 0.84889\n[115]\tvalid_0's rmse: 0.848853\n[116]\tvalid_0's rmse: 0.848864\n[117]\tvalid_0's rmse: 0.848846\n[118]\tvalid_0's rmse: 0.848836\n[119]\tvalid_0's rmse: 0.848772\n[120]\tvalid_0's rmse: 0.848747\n[121]\tvalid_0's rmse: 0.848675\n[122]\tvalid_0's rmse: 0.848681\n[123]\tvalid_0's rmse: 0.848666\n[124]\tvalid_0's rmse: 0.848643\n[125]\tvalid_0's rmse: 0.848656\n[126]\tvalid_0's rmse: 0.848605\n[127]\tvalid_0's rmse: 0.848595\n[128]\tvalid_0's rmse: 0.848605\n[129]\tvalid_0's rmse: 0.848588\n[130]\tvalid_0's rmse: 0.848552\n[131]\tvalid_0's rmse: 0.84856\n[132]\tvalid_0's rmse: 0.848533\n[133]\tvalid_0's rmse: 0.848501\n[134]\tvalid_0's rmse: 0.848466\n[135]\tvalid_0's rmse: 0.848447\n[136]\tvalid_0's rmse: 0.848461\n[137]\tvalid_0's rmse: 0.848471\n[138]\tvalid_0's rmse: 0.848474\n[139]\tvalid_0's rmse: 0.848452\n[140]\tvalid_0's rmse: 0.848459\n[141]\tvalid_0's rmse: 0.848472\n[142]\tvalid_0's rmse: 0.848463\n[143]\tvalid_0's rmse: 0.84846\n[144]\tvalid_0's rmse: 0.848453\n[145]\tvalid_0's rmse: 0.848444\n[146]\tvalid_0's rmse: 0.848387\n[147]\tvalid_0's rmse: 0.848375\n[148]\tvalid_0's rmse: 0.848352\n[149]\tvalid_0's rmse: 0.848375\n[150]\tvalid_0's rmse: 0.848385\n[151]\tvalid_0's rmse: 0.848373\n[152]\tvalid_0's rmse: 0.848349\n[153]\tvalid_0's rmse: 0.848346\n[154]\tvalid_0's rmse: 0.848357\n[155]\tvalid_0's rmse: 0.848324\n[156]\tvalid_0's rmse: 0.848316\n[157]\tvalid_0's rmse: 0.848322\n[158]\tvalid_0's rmse: 0.848298\n[159]\tvalid_0's rmse: 0.848287\n[160]\tvalid_0's rmse: 0.848249\n[161]\tvalid_0's rmse: 0.84823\n[162]\tvalid_0's rmse: 0.848236\n[163]\tvalid_0's rmse: 0.848223\n[164]\tvalid_0's rmse: 0.848221\n[165]\tvalid_0's rmse: 0.848198\n[166]\tvalid_0's rmse: 0.848184\n[167]\tvalid_0's rmse: 0.848198\n[168]\tvalid_0's rmse: 0.848197\n[169]\tvalid_0's rmse: 0.848177\n[170]\tvalid_0's rmse: 0.848147\n[171]\tvalid_0's rmse: 0.848156\n[172]\tvalid_0's rmse: 0.848137\n[173]\tvalid_0's rmse: 0.848103\n[174]\tvalid_0's rmse: 0.848084\n[175]\tvalid_0's rmse: 0.848064\n[176]\tvalid_0's rmse: 0.848059\n[177]\tvalid_0's rmse: 0.848039\n[178]\tvalid_0's rmse: 0.84805\n[179]\tvalid_0's rmse: 0.84806\n[180]\tvalid_0's rmse: 0.848064\n[181]\tvalid_0's rmse: 0.848038\n[182]\tvalid_0's rmse: 0.848033\n[183]\tvalid_0's rmse: 0.848053\n[184]\tvalid_0's rmse: 0.84804\n[185]\tvalid_0's rmse: 0.848035\n[186]\tvalid_0's rmse: 0.848028\n[187]\tvalid_0's rmse: 0.848034\n[188]\tvalid_0's rmse: 0.848023\n[189]\tvalid_0's rmse: 0.848002\n[190]\tvalid_0's rmse: 0.847995\n[191]\tvalid_0's rmse: 0.847984\n[192]\tvalid_0's rmse: 0.847972\n[193]\tvalid_0's rmse: 0.847973\n[194]\tvalid_0's rmse: 0.847973\n[195]\tvalid_0's rmse: 0.847971\n[196]\tvalid_0's rmse: 0.847974\n[197]\tvalid_0's rmse: 0.847989\n[198]\tvalid_0's rmse: 0.847955\n[199]\tvalid_0's rmse: 0.84793\n[200]\tvalid_0's rmse: 0.847929\n[201]\tvalid_0's rmse: 0.847909\n[202]\tvalid_0's rmse: 0.847898\n[203]\tvalid_0's rmse: 0.84788\n[204]\tvalid_0's rmse: 0.847869\n[205]\tvalid_0's rmse: 0.847849\n[206]\tvalid_0's rmse: 0.847845\n[207]\tvalid_0's rmse: 0.847858\n[208]\tvalid_0's rmse: 0.847847\n[209]\tvalid_0's rmse: 0.847839\n[210]\tvalid_0's rmse: 0.847849\n[211]\tvalid_0's rmse: 0.847855\n[212]\tvalid_0's rmse: 0.847869\n[213]\tvalid_0's rmse: 0.84787\n[214]\tvalid_0's rmse: 0.847876\n[215]\tvalid_0's rmse: 0.847872\n[216]\tvalid_0's rmse: 0.847874\n[217]\tvalid_0's rmse: 0.847859\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  45%|####5     | 9/20 [00:46<00:58,  5.30s/it]\u001b[32m[I 2021-02-05 22:55:19,988]\u001b[0m Trial 48 finished with value: 0.8478388869257277 and parameters: {'lambda_l1': 0.07277260904741113, 'lambda_l2': 1.7619423992183836e-07}. Best is trial 44 with value: 0.8474854360505399.\u001b[0m\nregularization_factors, val_score: 0.847465:  45%|####5     | 9/20 [00:46<00:58,  5.30s/it]","name":"stderr"},{"output_type":"stream","text":"[218]\tvalid_0's rmse: 0.84786\n[219]\tvalid_0's rmse: 0.847871\nEarly stopping, best iteration is:\n[209]\tvalid_0's rmse: 0.847839\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019910 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.88834\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885548\n[3]\tvalid_0's rmse: 0.883302\n[4]\tvalid_0's rmse: 0.881129\n[5]\tvalid_0's rmse: 0.879298\n[6]\tvalid_0's rmse: 0.877238\n[7]\tvalid_0's rmse: 0.875746\n[8]\tvalid_0's rmse: 0.874493\n[9]\tvalid_0's rmse: 0.87333\n[10]\tvalid_0's rmse: 0.872261\n[11]\tvalid_0's rmse: 0.870877\n[12]\tvalid_0's rmse: 0.86967\n[13]\tvalid_0's rmse: 0.868598\n[14]\tvalid_0's rmse: 0.867542\n[15]\tvalid_0's rmse: 0.866843\n[16]\tvalid_0's rmse: 0.866066\n[17]\tvalid_0's rmse: 0.86525\n[18]\tvalid_0's rmse: 0.864612\n[19]\tvalid_0's rmse: 0.863907\n[20]\tvalid_0's rmse: 0.863333\n[21]\tvalid_0's rmse: 0.862789\n[22]\tvalid_0's rmse: 0.862155\n[23]\tvalid_0's rmse: 0.861626\n[24]\tvalid_0's rmse: 0.861093\n[25]\tvalid_0's rmse: 0.860754\n[26]\tvalid_0's rmse: 0.860348\n[27]\tvalid_0's rmse: 0.860017\n[28]\tvalid_0's rmse: 0.859649\n[29]\tvalid_0's rmse: 0.859284\n[30]\tvalid_0's rmse: 0.858915\n[31]\tvalid_0's rmse: 0.858591\n[32]\tvalid_0's rmse: 0.85823\n[33]\tvalid_0's rmse: 0.857917\n[34]\tvalid_0's rmse: 0.857594\n[35]\tvalid_0's rmse: 0.857342\n[36]\tvalid_0's rmse: 0.857006\n[37]\tvalid_0's rmse: 0.856741\n[38]\tvalid_0's rmse: 0.856457\n[39]\tvalid_0's rmse: 0.856211\n[40]\tvalid_0's rmse: 0.855941\n[41]\tvalid_0's rmse: 0.855782\n[42]\tvalid_0's rmse: 0.855564\n[43]\tvalid_0's rmse: 0.855372\n[44]\tvalid_0's rmse: 0.855035\n[45]\tvalid_0's rmse: 0.854822\n[46]\tvalid_0's rmse: 0.854661\n[47]\tvalid_0's rmse: 0.854488\n[48]\tvalid_0's rmse: 0.854325\n[49]\tvalid_0's rmse: 0.854166\n[50]\tvalid_0's rmse: 0.854014\n[51]\tvalid_0's rmse: 0.853903\n[52]\tvalid_0's rmse: 0.853746\n[53]\tvalid_0's rmse: 0.853592\n[54]\tvalid_0's rmse: 0.853442\n[55]\tvalid_0's rmse: 0.853333\n[56]\tvalid_0's rmse: 0.853136\n[57]\tvalid_0's rmse: 0.853009\n[58]\tvalid_0's rmse: 0.852849\n[59]\tvalid_0's rmse: 0.852731\n[60]\tvalid_0's rmse: 0.852617\n[61]\tvalid_0's rmse: 0.85251\n[62]\tvalid_0's rmse: 0.852412\n[63]\tvalid_0's rmse: 0.852272\n[64]\tvalid_0's rmse: 0.852135\n[65]\tvalid_0's rmse: 0.851942\n[66]\tvalid_0's rmse: 0.851846\n[67]\tvalid_0's rmse: 0.851769\n[68]\tvalid_0's rmse: 0.85167\n[69]\tvalid_0's rmse: 0.851518\n[70]\tvalid_0's rmse: 0.851444\n[71]\tvalid_0's rmse: 0.851345\n[72]\tvalid_0's rmse: 0.851247\n[73]\tvalid_0's rmse: 0.851157\n[74]\tvalid_0's rmse: 0.851088\n[75]\tvalid_0's rmse: 0.850986\n[76]\tvalid_0's rmse: 0.850908\n[77]\tvalid_0's rmse: 0.850799\n[78]\tvalid_0's rmse: 0.850717\n[79]\tvalid_0's rmse: 0.850657\n[80]\tvalid_0's rmse: 0.850615\n[81]\tvalid_0's rmse: 0.850544\n[82]\tvalid_0's rmse: 0.850481\n[83]\tvalid_0's rmse: 0.850414\n[84]\tvalid_0's rmse: 0.850335\n[85]\tvalid_0's rmse: 0.850285\n[86]\tvalid_0's rmse: 0.850229\n[87]\tvalid_0's rmse: 0.850148\n[88]\tvalid_0's rmse: 0.850032\n[89]\tvalid_0's rmse: 0.850001\n[90]\tvalid_0's rmse: 0.849935\n[91]\tvalid_0's rmse: 0.849879\n[92]\tvalid_0's rmse: 0.849793\n[93]\tvalid_0's rmse: 0.849749\n[94]\tvalid_0's rmse: 0.849706\n[95]\tvalid_0's rmse: 0.849649\n[96]\tvalid_0's rmse: 0.849586\n[97]\tvalid_0's rmse: 0.849566\n[98]\tvalid_0's rmse: 0.849473\n[99]\tvalid_0's rmse: 0.849441\n[100]\tvalid_0's rmse: 0.849412\n[101]\tvalid_0's rmse: 0.849352\n[102]\tvalid_0's rmse: 0.84928\n[103]\tvalid_0's rmse: 0.849238\n[104]\tvalid_0's rmse: 0.849188\n[105]\tvalid_0's rmse: 0.849092\n[106]\tvalid_0's rmse: 0.849076\n[107]\tvalid_0's rmse: 0.849024\n[108]\tvalid_0's rmse: 0.848974\n[109]\tvalid_0's rmse: 0.848929\n[110]\tvalid_0's rmse: 0.848887\n[111]\tvalid_0's rmse: 0.848857\n[112]\tvalid_0's rmse: 0.848803\n[113]\tvalid_0's rmse: 0.848739\n[114]\tvalid_0's rmse: 0.848665\n[115]\tvalid_0's rmse: 0.848651\n[116]\tvalid_0's rmse: 0.848635\n[117]\tvalid_0's rmse: 0.84861\n[118]\tvalid_0's rmse: 0.848554\n[119]\tvalid_0's rmse: 0.848528\n[120]\tvalid_0's rmse: 0.848507\n[121]\tvalid_0's rmse: 0.848443\n[122]\tvalid_0's rmse: 0.848402\n[123]\tvalid_0's rmse: 0.848372\n[124]\tvalid_0's rmse: 0.848352\n[125]\tvalid_0's rmse: 0.84835\n[126]\tvalid_0's rmse: 0.848325\n[127]\tvalid_0's rmse: 0.84829\n[128]\tvalid_0's rmse: 0.848282\n[129]\tvalid_0's rmse: 0.84825\n[130]\tvalid_0's rmse: 0.848244\n[131]\tvalid_0's rmse: 0.848238\n[132]\tvalid_0's rmse: 0.848211\n[133]\tvalid_0's rmse: 0.848201\n[134]\tvalid_0's rmse: 0.848198\n[135]\tvalid_0's rmse: 0.848172\n[136]\tvalid_0's rmse: 0.848143\n[137]\tvalid_0's rmse: 0.848129\n[138]\tvalid_0's rmse: 0.848131\n[139]\tvalid_0's rmse: 0.848136\n[140]\tvalid_0's rmse: 0.848106\n[141]\tvalid_0's rmse: 0.848104\n[142]\tvalid_0's rmse: 0.84807\n[143]\tvalid_0's rmse: 0.848061\n[144]\tvalid_0's rmse: 0.848065\n[145]\tvalid_0's rmse: 0.848056\n[146]\tvalid_0's rmse: 0.84804\n[147]\tvalid_0's rmse: 0.848042\n[148]\tvalid_0's rmse: 0.848016\n[149]\tvalid_0's rmse: 0.848027\n[150]\tvalid_0's rmse: 0.848034\n[151]\tvalid_0's rmse: 0.848037\n[152]\tvalid_0's rmse: 0.848017\n[153]\tvalid_0's rmse: 0.847988\n[154]\tvalid_0's rmse: 0.847968\n[155]\tvalid_0's rmse: 0.847921\n[156]\tvalid_0's rmse: 0.847937\n[157]\tvalid_0's rmse: 0.847917\n[158]\tvalid_0's rmse: 0.847887\n[159]\tvalid_0's rmse: 0.847879\n[160]\tvalid_0's rmse: 0.84788\n[161]\tvalid_0's rmse: 0.847891\n[162]\tvalid_0's rmse: 0.847883\n[163]\tvalid_0's rmse: 0.847858\n[164]\tvalid_0's rmse: 0.847864\n[165]\tvalid_0's rmse: 0.847882\n[166]\tvalid_0's rmse: 0.847861\n[167]\tvalid_0's rmse: 0.84785\n[168]\tvalid_0's rmse: 0.847856\n[169]\tvalid_0's rmse: 0.847845\n[170]\tvalid_0's rmse: 0.847819\n[171]\tvalid_0's rmse: 0.84782\n[172]\tvalid_0's rmse: 0.847822\n[173]\tvalid_0's rmse: 0.847815\n[174]\tvalid_0's rmse: 0.847813\n[175]\tvalid_0's rmse: 0.847833\n[176]\tvalid_0's rmse: 0.847811\n[177]\tvalid_0's rmse: 0.847799\n[178]\tvalid_0's rmse: 0.847808\n[179]\tvalid_0's rmse: 0.847799\n[180]\tvalid_0's rmse: 0.847802\n[181]\tvalid_0's rmse: 0.84778\n[182]\tvalid_0's rmse: 0.847793\n[183]\tvalid_0's rmse: 0.84779\n[184]\tvalid_0's rmse: 0.847783\n[185]\tvalid_0's rmse: 0.847776\n[186]\tvalid_0's rmse: 0.847769\n[187]\tvalid_0's rmse: 0.847771\n[188]\tvalid_0's rmse: 0.847782\n[189]\tvalid_0's rmse: 0.847771\n[190]\tvalid_0's rmse: 0.847762\n[191]\tvalid_0's rmse: 0.847753\n[192]\tvalid_0's rmse: 0.847758\n[193]\tvalid_0's rmse: 0.847764\n[194]\tvalid_0's rmse: 0.847755\n[195]\tvalid_0's rmse: 0.847766\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  50%|#####     | 10/20 [00:51<00:51,  5.15s/it]\u001b[32m[I 2021-02-05 22:55:24,789]\u001b[0m Trial 49 finished with value: 0.8477534488191557 and parameters: {'lambda_l1': 7.188866662097751e-05, 'lambda_l2': 2.041519837740803}. Best is trial 44 with value: 0.8474854360505399.\u001b[0m\nregularization_factors, val_score: 0.847465:  50%|#####     | 10/20 [00:51<00:51,  5.15s/it]","name":"stderr"},{"output_type":"stream","text":"[196]\tvalid_0's rmse: 0.847765\n[197]\tvalid_0's rmse: 0.847761\n[198]\tvalid_0's rmse: 0.847755\n[199]\tvalid_0's rmse: 0.847762\n[200]\tvalid_0's rmse: 0.847765\n[201]\tvalid_0's rmse: 0.847777\nEarly stopping, best iteration is:\n[191]\tvalid_0's rmse: 0.847753\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019280 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848116\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847947\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n","name":"stdout"},{"output_type":"stream","text":"[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  55%|#####5    | 11/20 [00:56<00:47,  5.33s/it]\u001b[32m[I 2021-02-05 22:55:30,529]\u001b[0m Trial 50 finished with value: 0.8474653502483532 and parameters: {'lambda_l1': 6.587396048567404e-07, 'lambda_l2': 0.00020459769622405572}. Best is trial 50 with value: 0.8474653502483532.\u001b[0m\nregularization_factors, val_score: 0.847465:  55%|#####5    | 11/20 [00:56<00:47,  5.33s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019016 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848116\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847947\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  60%|######    | 12/20 [01:02<00:43,  5.45s/it]\u001b[32m[I 2021-02-05 22:55:36,264]\u001b[0m Trial 51 finished with value: 0.8474653498262191 and parameters: {'lambda_l1': 6.336525852016098e-07, 'lambda_l2': 0.00023017291551969142}. Best is trial 51 with value: 0.8474653498262191.\u001b[0m\nregularization_factors, val_score: 0.847465:  60%|######    | 12/20 [01:02<00:43,  5.45s/it]","name":"stderr"},{"output_type":"stream","text":"[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019606 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848117\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847948\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  65%|######5   | 13/20 [01:08<00:38,  5.56s/it]","name":"stderr"},{"output_type":"stream","text":"[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n","name":"stdout"},{"output_type":"stream","text":"\u001b[32m[I 2021-02-05 22:55:42,057]\u001b[0m Trial 52 finished with value: 0.847465352915566 and parameters: {'lambda_l1': 1.091591155313501e-06, 'lambda_l2': 4.289086540297058e-05}. Best is trial 51 with value: 0.8474653498262191.\u001b[0m\nregularization_factors, val_score: 0.847465:  65%|######5   | 13/20 [01:08<00:38,  5.56s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020498 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848116\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847947\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  70%|#######   | 14/20 [01:13<00:33,  5.58s/it]\u001b[32m[I 2021-02-05 22:55:47,689]\u001b[0m Trial 53 finished with value: 0.8474653495433168 and parameters: {'lambda_l1': 1.590176844141445e-08, 'lambda_l2': 0.00024850989454851854}. Best is trial 53 with value: 0.8474653495433168.\u001b[0m\nregularization_factors, val_score: 0.847465:  70%|#######   | 14/20 [01:13<00:33,  5.58s/it]","name":"stderr"},{"output_type":"stream","text":"[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019265 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848117\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847948\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n","name":"stdout"},{"output_type":"stream","text":"[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  75%|#######5  | 15/20 [01:20<00:28,  5.73s/it]\u001b[32m[I 2021-02-05 22:55:53,787]\u001b[0m Trial 54 finished with value: 0.8474653536235521 and parameters: {'lambda_l1': 1.2880096790219416e-08, 'lambda_l2': 2.3540195682993305e-06}. Best is trial 53 with value: 0.8474653495433168.\u001b[0m\nregularization_factors, val_score: 0.847465:  75%|#######5  | 15/20 [01:20<00:28,  5.73s/it]","name":"stderr"},{"output_type":"stream","text":"\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019032 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848116\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847947\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847566\n[230]\tvalid_0's rmse: 0.847548\n[231]\tvalid_0's rmse: 0.847554\n[232]\tvalid_0's rmse: 0.847539\n[233]\tvalid_0's rmse: 0.847515\n[234]\tvalid_0's rmse: 0.847501\n[235]\tvalid_0's rmse: 0.847502\n[236]\tvalid_0's rmse: 0.847501\n[237]\tvalid_0's rmse: 0.847512\n[238]\tvalid_0's rmse: 0.847495\n[239]\tvalid_0's rmse: 0.847494\n[240]\tvalid_0's rmse: 0.84749\n[241]\tvalid_0's rmse: 0.847502\n[242]\tvalid_0's rmse: 0.847485\n[243]\tvalid_0's rmse: 0.847504\n[244]\tvalid_0's rmse: 0.847506\n[245]\tvalid_0's rmse: 0.847508\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  80%|########  | 16/20 [01:25<00:22,  5.64s/it]\u001b[32m[I 2021-02-05 22:55:59,216]\u001b[0m Trial 55 finished with value: 0.8474854459952202 and parameters: {'lambda_l1': 1.390569708241963e-08, 'lambda_l2': 0.0021657752669030526}. Best is trial 53 with value: 0.8474653495433168.\u001b[0m\nregularization_factors, val_score: 0.847465:  80%|########  | 16/20 [01:25<00:22,  5.64s/it]","name":"stderr"},{"output_type":"stream","text":"[246]\tvalid_0's rmse: 0.847513\n[247]\tvalid_0's rmse: 0.847509\n[248]\tvalid_0's rmse: 0.847521\n[249]\tvalid_0's rmse: 0.847533\n[250]\tvalid_0's rmse: 0.847529\n[251]\tvalid_0's rmse: 0.847533\n[252]\tvalid_0's rmse: 0.847515\nEarly stopping, best iteration is:\n[242]\tvalid_0's rmse: 0.847485\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019010 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.872271\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849654\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848923\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.84842\n[131]\tvalid_0's rmse: 0.8484\n[132]\tvalid_0's rmse: 0.848391\n[133]\tvalid_0's rmse: 0.848405\n[134]\tvalid_0's rmse: 0.848373\n[135]\tvalid_0's rmse: 0.848362\n[136]\tvalid_0's rmse: 0.84835\n[137]\tvalid_0's rmse: 0.848345\n[138]\tvalid_0's rmse: 0.848327\n[139]\tvalid_0's rmse: 0.848322\n[140]\tvalid_0's rmse: 0.848289\n[141]\tvalid_0's rmse: 0.848277\n[142]\tvalid_0's rmse: 0.848274\n[143]\tvalid_0's rmse: 0.848266\n[144]\tvalid_0's rmse: 0.848271\n[145]\tvalid_0's rmse: 0.848249\n[146]\tvalid_0's rmse: 0.848228\n[147]\tvalid_0's rmse: 0.84821\n[148]\tvalid_0's rmse: 0.848209\n[149]\tvalid_0's rmse: 0.848226\n[150]\tvalid_0's rmse: 0.848217\n[151]\tvalid_0's rmse: 0.848196\n[152]\tvalid_0's rmse: 0.848183\n[153]\tvalid_0's rmse: 0.848168\n[154]\tvalid_0's rmse: 0.848154\n[155]\tvalid_0's rmse: 0.848139\n[156]\tvalid_0's rmse: 0.848137\n[157]\tvalid_0's rmse: 0.848137\n[158]\tvalid_0's rmse: 0.848118\n[159]\tvalid_0's rmse: 0.848125\n[160]\tvalid_0's rmse: 0.848092\n[161]\tvalid_0's rmse: 0.848068\n[162]\tvalid_0's rmse: 0.84803\n[163]\tvalid_0's rmse: 0.848032\n[164]\tvalid_0's rmse: 0.848036\n[165]\tvalid_0's rmse: 0.848048\n[166]\tvalid_0's rmse: 0.848061\n[167]\tvalid_0's rmse: 0.848046\n[168]\tvalid_0's rmse: 0.848035\n[169]\tvalid_0's rmse: 0.84805\n[170]\tvalid_0's rmse: 0.848032\n[171]\tvalid_0's rmse: 0.84801\n[172]\tvalid_0's rmse: 0.848007\n[173]\tvalid_0's rmse: 0.848012\n[174]\tvalid_0's rmse: 0.848005\n[175]\tvalid_0's rmse: 0.847996\n[176]\tvalid_0's rmse: 0.847989\n[177]\tvalid_0's rmse: 0.847973\n[178]\tvalid_0's rmse: 0.847972\n[179]\tvalid_0's rmse: 0.847962\n[180]\tvalid_0's rmse: 0.847919\n[181]\tvalid_0's rmse: 0.847924\n[182]\tvalid_0's rmse: 0.847906\n[183]\tvalid_0's rmse: 0.84789\n[184]\tvalid_0's rmse: 0.8479\n[185]\tvalid_0's rmse: 0.847886\n[186]\tvalid_0's rmse: 0.847877\n[187]\tvalid_0's rmse: 0.847864\n[188]\tvalid_0's rmse: 0.847836\n[189]\tvalid_0's rmse: 0.847808\n[190]\tvalid_0's rmse: 0.847805\n[191]\tvalid_0's rmse: 0.847803\n[192]\tvalid_0's rmse: 0.847804\n[193]\tvalid_0's rmse: 0.847796\n[194]\tvalid_0's rmse: 0.847774\n[195]\tvalid_0's rmse: 0.847774\n[196]\tvalid_0's rmse: 0.847776\n[197]\tvalid_0's rmse: 0.847783\n[198]\tvalid_0's rmse: 0.847773\n[199]\tvalid_0's rmse: 0.847755\n[200]\tvalid_0's rmse: 0.847748\n[201]\tvalid_0's rmse: 0.847706\n[202]\tvalid_0's rmse: 0.84767\n[203]\tvalid_0's rmse: 0.847662\n[204]\tvalid_0's rmse: 0.847665\n[205]\tvalid_0's rmse: 0.847666\n[206]\tvalid_0's rmse: 0.847682\n[207]\tvalid_0's rmse: 0.847684\n[208]\tvalid_0's rmse: 0.847655\n[209]\tvalid_0's rmse: 0.847644\n[210]\tvalid_0's rmse: 0.847642\n[211]\tvalid_0's rmse: 0.847634\n[212]\tvalid_0's rmse: 0.847648\n[213]\tvalid_0's rmse: 0.847625\n[214]\tvalid_0's rmse: 0.847623\n[215]\tvalid_0's rmse: 0.847627\n[216]\tvalid_0's rmse: 0.847625\n[217]\tvalid_0's rmse: 0.847592\n[218]\tvalid_0's rmse: 0.847584\n[219]\tvalid_0's rmse: 0.847541\n[220]\tvalid_0's rmse: 0.847548\n[221]\tvalid_0's rmse: 0.84755\n[222]\tvalid_0's rmse: 0.847553\n[223]\tvalid_0's rmse: 0.84755\n[224]\tvalid_0's rmse: 0.847518\n[225]\tvalid_0's rmse: 0.847548\n[226]\tvalid_0's rmse: 0.847546\n[227]\tvalid_0's rmse: 0.847527\n[228]\tvalid_0's rmse: 0.847532\n[229]\tvalid_0's rmse: 0.847535\n[230]\tvalid_0's rmse: 0.847515\n[231]\tvalid_0's rmse: 0.847524\n[232]\tvalid_0's rmse: 0.847524\n[233]\tvalid_0's rmse: 0.847522\n[234]\tvalid_0's rmse: 0.847504\n[235]\tvalid_0's rmse: 0.847512\n[236]\tvalid_0's rmse: 0.847489\n[237]\tvalid_0's rmse: 0.847494\n[238]\tvalid_0's rmse: 0.847489\n[239]\tvalid_0's rmse: 0.84747\n[240]\tvalid_0's rmse: 0.847478\n[241]\tvalid_0's rmse: 0.847493\n[242]\tvalid_0's rmse: 0.847496\n[243]\tvalid_0's rmse: 0.847499\n[244]\tvalid_0's rmse: 0.84748\n[245]\tvalid_0's rmse: 0.847491\n[246]\tvalid_0's rmse: 0.847482\n[247]\tvalid_0's rmse: 0.847488\n[248]\tvalid_0's rmse: 0.847471\n[249]\tvalid_0's rmse: 0.847478\nEarly stopping, best iteration is:\n[239]\tvalid_0's rmse: 0.84747\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  85%|########5 | 17/20 [01:31<00:16,  5.61s/it]\u001b[32m[I 2021-02-05 22:56:04,754]\u001b[0m Trial 56 finished with value: 0.8474702576619312 and parameters: {'lambda_l1': 0.0016015630786086067, 'lambda_l2': 9.153353261688587e-06}. Best is trial 53 with value: 0.8474653495433168.\u001b[0m\nregularization_factors, val_score: 0.847465:  85%|########5 | 17/20 [01:31<00:16,  5.61s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019305 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848116\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847947\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  90%|######### | 18/20 [01:36<00:11,  5.63s/it]\u001b[32m[I 2021-02-05 22:56:10,420]\u001b[0m Trial 57 finished with value: 0.8474653444627336 and parameters: {'lambda_l1': 3.091223000030874e-06, 'lambda_l2': 0.0005486056579747929}. Best is trial 57 with value: 0.8474653444627336.\u001b[0m\nregularization_factors, val_score: 0.847465:  90%|######### | 18/20 [01:36<00:11,  5.63s/it]","name":"stderr"},{"output_type":"stream","text":"[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021255 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848117\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847948\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n","name":"stdout"},{"output_type":"stream","text":"[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465:  95%|#########5| 19/20 [01:42<00:05,  5.68s/it]\u001b[32m[I 2021-02-05 22:56:16,205]\u001b[0m Trial 58 finished with value: 0.8474653533910321 and parameters: {'lambda_l1': 8.055382297079366e-06, 'lambda_l2': 1.252006806063039e-08}. Best is trial 57 with value: 0.8474653444627336.\u001b[0m\nregularization_factors, val_score: 0.847465:  95%|#########5| 19/20 [01:42<00:05,  5.68s/it]","name":"stderr"},{"output_type":"stream","text":"[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019458 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848233\n[156]\tvalid_0's rmse: 0.848222\n[157]\tvalid_0's rmse: 0.848199\n[158]\tvalid_0's rmse: 0.848192\n[159]\tvalid_0's rmse: 0.848172\n[160]\tvalid_0's rmse: 0.848172\n[161]\tvalid_0's rmse: 0.848163\n[162]\tvalid_0's rmse: 0.848141\n[163]\tvalid_0's rmse: 0.84815\n[164]\tvalid_0's rmse: 0.84814\n[165]\tvalid_0's rmse: 0.848125\n[166]\tvalid_0's rmse: 0.848126\n[167]\tvalid_0's rmse: 0.848128\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.84812\n[170]\tvalid_0's rmse: 0.848113\n[171]\tvalid_0's rmse: 0.848109\n[172]\tvalid_0's rmse: 0.848095\n[173]\tvalid_0's rmse: 0.848065\n[174]\tvalid_0's rmse: 0.848039\n[175]\tvalid_0's rmse: 0.848015\n[176]\tvalid_0's rmse: 0.847996\n[177]\tvalid_0's rmse: 0.848003\n[178]\tvalid_0's rmse: 0.847998\n[179]\tvalid_0's rmse: 0.847981\n[180]\tvalid_0's rmse: 0.847925\n[181]\tvalid_0's rmse: 0.847914\n[182]\tvalid_0's rmse: 0.847914\n[183]\tvalid_0's rmse: 0.847907\n[184]\tvalid_0's rmse: 0.847894\n[185]\tvalid_0's rmse: 0.847909\n[186]\tvalid_0's rmse: 0.847903\n[187]\tvalid_0's rmse: 0.847893\n[188]\tvalid_0's rmse: 0.84789\n[189]\tvalid_0's rmse: 0.847885\n[190]\tvalid_0's rmse: 0.847877\n[191]\tvalid_0's rmse: 0.847881\n[192]\tvalid_0's rmse: 0.847879\n[193]\tvalid_0's rmse: 0.847872\n[194]\tvalid_0's rmse: 0.847865\n[195]\tvalid_0's rmse: 0.847855\n[196]\tvalid_0's rmse: 0.847847\n[197]\tvalid_0's rmse: 0.84784\n[198]\tvalid_0's rmse: 0.847842\n[199]\tvalid_0's rmse: 0.847807\n[200]\tvalid_0's rmse: 0.847811\n[201]\tvalid_0's rmse: 0.847816\n[202]\tvalid_0's rmse: 0.847811\n[203]\tvalid_0's rmse: 0.847789\n[204]\tvalid_0's rmse: 0.847793\n[205]\tvalid_0's rmse: 0.847789\n[206]\tvalid_0's rmse: 0.847784\n[207]\tvalid_0's rmse: 0.84778\n[208]\tvalid_0's rmse: 0.847779\n[209]\tvalid_0's rmse: 0.847763\n[210]\tvalid_0's rmse: 0.847741\n[211]\tvalid_0's rmse: 0.847735\n[212]\tvalid_0's rmse: 0.847747\n[213]\tvalid_0's rmse: 0.847732\n[214]\tvalid_0's rmse: 0.847717\n","name":"stdout"},{"output_type":"stream","text":"regularization_factors, val_score: 0.847465: 100%|##########| 20/20 [01:48<00:00,  5.73s/it]\u001b[32m[I 2021-02-05 22:56:22,068]\u001b[0m Trial 59 finished with value: 0.8477166405584823 and parameters: {'lambda_l1': 0.00034942357796020565, 'lambda_l2': 0.003454160246977381}. Best is trial 57 with value: 0.8474653444627336.\u001b[0m\nregularization_factors, val_score: 0.847465: 100%|##########| 20/20 [01:48<00:00,  5.42s/it]\nmin_data_in_leaf, val_score: 0.847465:   0%|          | 0/5 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"[215]\tvalid_0's rmse: 0.847724\n[216]\tvalid_0's rmse: 0.847721\n[217]\tvalid_0's rmse: 0.847719\n[218]\tvalid_0's rmse: 0.847728\n[219]\tvalid_0's rmse: 0.84773\n[220]\tvalid_0's rmse: 0.847734\n[221]\tvalid_0's rmse: 0.847739\n[222]\tvalid_0's rmse: 0.847739\n[223]\tvalid_0's rmse: 0.84773\n[224]\tvalid_0's rmse: 0.847729\nEarly stopping, best iteration is:\n[214]\tvalid_0's rmse: 0.847717\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019624 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860393\n[27]\tvalid_0's rmse: 0.860019\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859251\n[30]\tvalid_0's rmse: 0.85889\n[31]\tvalid_0's rmse: 0.85857\n[32]\tvalid_0's rmse: 0.858224\n[33]\tvalid_0's rmse: 0.857905\n[34]\tvalid_0's rmse: 0.857553\n[35]\tvalid_0's rmse: 0.857333\n[36]\tvalid_0's rmse: 0.857009\n[37]\tvalid_0's rmse: 0.856747\n[38]\tvalid_0's rmse: 0.856448\n[39]\tvalid_0's rmse: 0.856191\n[40]\tvalid_0's rmse: 0.855911\n[41]\tvalid_0's rmse: 0.855757\n[42]\tvalid_0's rmse: 0.855529\n[43]\tvalid_0's rmse: 0.855352\n[44]\tvalid_0's rmse: 0.855134\n[45]\tvalid_0's rmse: 0.854924\n[46]\tvalid_0's rmse: 0.854762\n[47]\tvalid_0's rmse: 0.854634\n[48]\tvalid_0's rmse: 0.854463\n[49]\tvalid_0's rmse: 0.854266\n[50]\tvalid_0's rmse: 0.854104\n[51]\tvalid_0's rmse: 0.853997\n[52]\tvalid_0's rmse: 0.853771\n[53]\tvalid_0's rmse: 0.853614\n[54]\tvalid_0's rmse: 0.853477\n[55]\tvalid_0's rmse: 0.853386\n[56]\tvalid_0's rmse: 0.853224\n[57]\tvalid_0's rmse: 0.853096\n[58]\tvalid_0's rmse: 0.852961\n[59]\tvalid_0's rmse: 0.852872\n[60]\tvalid_0's rmse: 0.852772\n[61]\tvalid_0's rmse: 0.852672\n[62]\tvalid_0's rmse: 0.852521\n[63]\tvalid_0's rmse: 0.852434\n[64]\tvalid_0's rmse: 0.85231\n[65]\tvalid_0's rmse: 0.852244\n[66]\tvalid_0's rmse: 0.852151\n[67]\tvalid_0's rmse: 0.852088\n[68]\tvalid_0's rmse: 0.851964\n[69]\tvalid_0's rmse: 0.8518\n[70]\tvalid_0's rmse: 0.851737\n[71]\tvalid_0's rmse: 0.851661\n[72]\tvalid_0's rmse: 0.851577\n[73]\tvalid_0's rmse: 0.851509\n[74]\tvalid_0's rmse: 0.85145\n[75]\tvalid_0's rmse: 0.851357\n[76]\tvalid_0's rmse: 0.851272\n[77]\tvalid_0's rmse: 0.851162\n[78]\tvalid_0's rmse: 0.851064\n[79]\tvalid_0's rmse: 0.850975\n[80]\tvalid_0's rmse: 0.850926\n[81]\tvalid_0's rmse: 0.850858\n[82]\tvalid_0's rmse: 0.850787\n[83]\tvalid_0's rmse: 0.85072\n[84]\tvalid_0's rmse: 0.85069\n[85]\tvalid_0's rmse: 0.85066\n[86]\tvalid_0's rmse: 0.850622\n[87]\tvalid_0's rmse: 0.850567\n[88]\tvalid_0's rmse: 0.850474\n[89]\tvalid_0's rmse: 0.850382\n[90]\tvalid_0's rmse: 0.850334\n[91]\tvalid_0's rmse: 0.850281\n[92]\tvalid_0's rmse: 0.850246\n[93]\tvalid_0's rmse: 0.850172\n[94]\tvalid_0's rmse: 0.850125\n[95]\tvalid_0's rmse: 0.850078\n[96]\tvalid_0's rmse: 0.850013\n[97]\tvalid_0's rmse: 0.849967\n[98]\tvalid_0's rmse: 0.849842\n[99]\tvalid_0's rmse: 0.849816\n[100]\tvalid_0's rmse: 0.849794\n[101]\tvalid_0's rmse: 0.849698\n[102]\tvalid_0's rmse: 0.849612\n[103]\tvalid_0's rmse: 0.849569\n[104]\tvalid_0's rmse: 0.849498\n[105]\tvalid_0's rmse: 0.849473\n[106]\tvalid_0's rmse: 0.84942\n[107]\tvalid_0's rmse: 0.849368\n[108]\tvalid_0's rmse: 0.849315\n[109]\tvalid_0's rmse: 0.849275\n[110]\tvalid_0's rmse: 0.849239\n[111]\tvalid_0's rmse: 0.849207\n[112]\tvalid_0's rmse: 0.84916\n[113]\tvalid_0's rmse: 0.84913\n[114]\tvalid_0's rmse: 0.849101\n[115]\tvalid_0's rmse: 0.849073\n[116]\tvalid_0's rmse: 0.849058\n[117]\tvalid_0's rmse: 0.848957\n[118]\tvalid_0's rmse: 0.84892\n[119]\tvalid_0's rmse: 0.848881\n[120]\tvalid_0's rmse: 0.848863\n[121]\tvalid_0's rmse: 0.848807\n[122]\tvalid_0's rmse: 0.848775\n[123]\tvalid_0's rmse: 0.848766\n[124]\tvalid_0's rmse: 0.848727\n[125]\tvalid_0's rmse: 0.848727\n[126]\tvalid_0's rmse: 0.848712\n[127]\tvalid_0's rmse: 0.848698\n[128]\tvalid_0's rmse: 0.848692\n[129]\tvalid_0's rmse: 0.848679\n[130]\tvalid_0's rmse: 0.848686\n[131]\tvalid_0's rmse: 0.848685\n[132]\tvalid_0's rmse: 0.848664\n[133]\tvalid_0's rmse: 0.848657\n[134]\tvalid_0's rmse: 0.848608\n[135]\tvalid_0's rmse: 0.848595\n[136]\tvalid_0's rmse: 0.848567\n[137]\tvalid_0's rmse: 0.848571\n[138]\tvalid_0's rmse: 0.848529\n[139]\tvalid_0's rmse: 0.848481\n[140]\tvalid_0's rmse: 0.848453\n[141]\tvalid_0's rmse: 0.848472\n[142]\tvalid_0's rmse: 0.848455\n[143]\tvalid_0's rmse: 0.84845\n[144]\tvalid_0's rmse: 0.848438\n[145]\tvalid_0's rmse: 0.848462\n[146]\tvalid_0's rmse: 0.848389\n[147]\tvalid_0's rmse: 0.848364\n[148]\tvalid_0's rmse: 0.848354\n[149]\tvalid_0's rmse: 0.848358\n[150]\tvalid_0's rmse: 0.848385\n[151]\tvalid_0's rmse: 0.848375\n[152]\tvalid_0's rmse: 0.848365\n[153]\tvalid_0's rmse: 0.848354\n[154]\tvalid_0's rmse: 0.848359\n[155]\tvalid_0's rmse: 0.848346\n[156]\tvalid_0's rmse: 0.848342\n[157]\tvalid_0's rmse: 0.848316\n[158]\tvalid_0's rmse: 0.848318\n[159]\tvalid_0's rmse: 0.848314\n[160]\tvalid_0's rmse: 0.848316\n[161]\tvalid_0's rmse: 0.848303\n[162]\tvalid_0's rmse: 0.848311\n[163]\tvalid_0's rmse: 0.84832\n[164]\tvalid_0's rmse: 0.848313\n[165]\tvalid_0's rmse: 0.848303\n[166]\tvalid_0's rmse: 0.848282\n[167]\tvalid_0's rmse: 0.848262\n[168]\tvalid_0's rmse: 0.848236\n[169]\tvalid_0's rmse: 0.848227\n[170]\tvalid_0's rmse: 0.848223\n[171]\tvalid_0's rmse: 0.84822\n[172]\tvalid_0's rmse: 0.848206\n[173]\tvalid_0's rmse: 0.848157\n[174]\tvalid_0's rmse: 0.848165\n[175]\tvalid_0's rmse: 0.848159\n[176]\tvalid_0's rmse: 0.848168\n[177]\tvalid_0's rmse: 0.848159\n[178]\tvalid_0's rmse: 0.848151\n[179]\tvalid_0's rmse: 0.848117\n[180]\tvalid_0's rmse: 0.848105\n[181]\tvalid_0's rmse: 0.848082\n[182]\tvalid_0's rmse: 0.84807\n[183]\tvalid_0's rmse: 0.848058\n[184]\tvalid_0's rmse: 0.848057\n[185]\tvalid_0's rmse: 0.848038\n[186]\tvalid_0's rmse: 0.848053\n[187]\tvalid_0's rmse: 0.848012\n[188]\tvalid_0's rmse: 0.848014\n[189]\tvalid_0's rmse: 0.848027\n[190]\tvalid_0's rmse: 0.848024\n[191]\tvalid_0's rmse: 0.84804\n[192]\tvalid_0's rmse: 0.848055\n[193]\tvalid_0's rmse: 0.848022\n[194]\tvalid_0's rmse: 0.847991\n[195]\tvalid_0's rmse: 0.848003\n[196]\tvalid_0's rmse: 0.847982\n[197]\tvalid_0's rmse: 0.847972\n[198]\tvalid_0's rmse: 0.847983\n[199]\tvalid_0's rmse: 0.847988\n[200]\tvalid_0's rmse: 0.848\n[201]\tvalid_0's rmse: 0.848011\n[202]\tvalid_0's rmse: 0.848013\n[203]\tvalid_0's rmse: 0.848029\n[204]\tvalid_0's rmse: 0.848035\n[205]\tvalid_0's rmse: 0.848041\n[206]\tvalid_0's rmse: 0.848045\n[207]\tvalid_0's rmse: 0.848034\nEarly stopping, best iteration is:\n[197]\tvalid_0's rmse: 0.847972\n","name":"stdout"},{"output_type":"stream","text":"min_data_in_leaf, val_score: 0.847465:  20%|##        | 1/5 [00:04<00:19,  4.90s/it]\u001b[32m[I 2021-02-05 22:56:26,981]\u001b[0m Trial 60 finished with value: 0.8479716324666171 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.8479716324666171.\u001b[0m\nmin_data_in_leaf, val_score: 0.847465:  20%|##        | 1/5 [00:04<00:19,  4.90s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020088 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.857901\n[34]\tvalid_0's rmse: 0.857478\n[35]\tvalid_0's rmse: 0.857222\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855243\n[44]\tvalid_0's rmse: 0.854986\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854451\n[48]\tvalid_0's rmse: 0.854258\n[49]\tvalid_0's rmse: 0.854115\n[50]\tvalid_0's rmse: 0.853958\n[51]\tvalid_0's rmse: 0.85386\n[52]\tvalid_0's rmse: 0.853694\n[53]\tvalid_0's rmse: 0.853524\n[54]\tvalid_0's rmse: 0.85338\n[55]\tvalid_0's rmse: 0.853273\n[56]\tvalid_0's rmse: 0.85305\n[57]\tvalid_0's rmse: 0.852941\n[58]\tvalid_0's rmse: 0.852802\n[59]\tvalid_0's rmse: 0.852706\n[60]\tvalid_0's rmse: 0.852558\n[61]\tvalid_0's rmse: 0.852463\n[62]\tvalid_0's rmse: 0.852347\n[63]\tvalid_0's rmse: 0.852262\n[64]\tvalid_0's rmse: 0.852122\n[65]\tvalid_0's rmse: 0.852003\n[66]\tvalid_0's rmse: 0.851896\n[67]\tvalid_0's rmse: 0.851831\n[68]\tvalid_0's rmse: 0.851746\n[69]\tvalid_0's rmse: 0.85169\n[70]\tvalid_0's rmse: 0.851528\n[71]\tvalid_0's rmse: 0.851422\n[72]\tvalid_0's rmse: 0.851343\n[73]\tvalid_0's rmse: 0.851301\n[74]\tvalid_0's rmse: 0.851232\n[75]\tvalid_0's rmse: 0.851124\n[76]\tvalid_0's rmse: 0.85102\n[77]\tvalid_0's rmse: 0.85092\n[78]\tvalid_0's rmse: 0.850792\n[79]\tvalid_0's rmse: 0.850682\n[80]\tvalid_0's rmse: 0.850612\n[81]\tvalid_0's rmse: 0.850544\n[82]\tvalid_0's rmse: 0.850491\n[83]\tvalid_0's rmse: 0.850451\n[84]\tvalid_0's rmse: 0.850392\n[85]\tvalid_0's rmse: 0.850363\n[86]\tvalid_0's rmse: 0.850305\n[87]\tvalid_0's rmse: 0.850278\n[88]\tvalid_0's rmse: 0.850207\n[89]\tvalid_0's rmse: 0.850169\n[90]\tvalid_0's rmse: 0.850113\n[91]\tvalid_0's rmse: 0.850038\n[92]\tvalid_0's rmse: 0.849955\n[93]\tvalid_0's rmse: 0.849904\n[94]\tvalid_0's rmse: 0.849874\n[95]\tvalid_0's rmse: 0.849776\n[96]\tvalid_0's rmse: 0.849737\n[97]\tvalid_0's rmse: 0.849709\n[98]\tvalid_0's rmse: 0.84963\n[99]\tvalid_0's rmse: 0.849577\n[100]\tvalid_0's rmse: 0.849554\n[101]\tvalid_0's rmse: 0.849514\n[102]\tvalid_0's rmse: 0.84943\n[103]\tvalid_0's rmse: 0.849406\n[104]\tvalid_0's rmse: 0.849348\n[105]\tvalid_0's rmse: 0.849312\n[106]\tvalid_0's rmse: 0.849269\n[107]\tvalid_0's rmse: 0.849245\n[108]\tvalid_0's rmse: 0.849213\n[109]\tvalid_0's rmse: 0.849153\n[110]\tvalid_0's rmse: 0.849108\n[111]\tvalid_0's rmse: 0.849088\n[112]\tvalid_0's rmse: 0.849079\n[113]\tvalid_0's rmse: 0.849048\n[114]\tvalid_0's rmse: 0.849037\n[115]\tvalid_0's rmse: 0.849033\n[116]\tvalid_0's rmse: 0.849028\n[117]\tvalid_0's rmse: 0.849\n[118]\tvalid_0's rmse: 0.848988\n[119]\tvalid_0's rmse: 0.848983\n[120]\tvalid_0's rmse: 0.84896\n[121]\tvalid_0's rmse: 0.848954\n[122]\tvalid_0's rmse: 0.848939\n[123]\tvalid_0's rmse: 0.848892\n[124]\tvalid_0's rmse: 0.848866\n[125]\tvalid_0's rmse: 0.848853\n[126]\tvalid_0's rmse: 0.84884\n[127]\tvalid_0's rmse: 0.848831\n[128]\tvalid_0's rmse: 0.848777\n[129]\tvalid_0's rmse: 0.848754\n[130]\tvalid_0's rmse: 0.848708\n[131]\tvalid_0's rmse: 0.848656\n[132]\tvalid_0's rmse: 0.848654\n[133]\tvalid_0's rmse: 0.848638\n[134]\tvalid_0's rmse: 0.848641\n[135]\tvalid_0's rmse: 0.848645\n[136]\tvalid_0's rmse: 0.848618\n[137]\tvalid_0's rmse: 0.848612\n[138]\tvalid_0's rmse: 0.8486\n[139]\tvalid_0's rmse: 0.848559\n[140]\tvalid_0's rmse: 0.848557\n[141]\tvalid_0's rmse: 0.848553\n[142]\tvalid_0's rmse: 0.84855\n[143]\tvalid_0's rmse: 0.848536\n[144]\tvalid_0's rmse: 0.848537\n[145]\tvalid_0's rmse: 0.848536\n[146]\tvalid_0's rmse: 0.848521\n[147]\tvalid_0's rmse: 0.848518\n[148]\tvalid_0's rmse: 0.848507\n[149]\tvalid_0's rmse: 0.848515\n[150]\tvalid_0's rmse: 0.848493\n[151]\tvalid_0's rmse: 0.84845\n[152]\tvalid_0's rmse: 0.848446\n[153]\tvalid_0's rmse: 0.848457\n[154]\tvalid_0's rmse: 0.848447\n[155]\tvalid_0's rmse: 0.848446\n[156]\tvalid_0's rmse: 0.848447\n[157]\tvalid_0's rmse: 0.84843\n[158]\tvalid_0's rmse: 0.848412\n[159]\tvalid_0's rmse: 0.848398\n[160]\tvalid_0's rmse: 0.848338\n[161]\tvalid_0's rmse: 0.848326\n[162]\tvalid_0's rmse: 0.848327\n[163]\tvalid_0's rmse: 0.848315\n[164]\tvalid_0's rmse: 0.848303\n[165]\tvalid_0's rmse: 0.848315\n[166]\tvalid_0's rmse: 0.848288\n[167]\tvalid_0's rmse: 0.848274\n[168]\tvalid_0's rmse: 0.848255\n[169]\tvalid_0's rmse: 0.848248\n[170]\tvalid_0's rmse: 0.848217\n[171]\tvalid_0's rmse: 0.848217\n[172]\tvalid_0's rmse: 0.848186\n[173]\tvalid_0's rmse: 0.848178\n[174]\tvalid_0's rmse: 0.84818\n[175]\tvalid_0's rmse: 0.848185\n[176]\tvalid_0's rmse: 0.848163\n[177]\tvalid_0's rmse: 0.848159\n[178]\tvalid_0's rmse: 0.848181\n[179]\tvalid_0's rmse: 0.84817\n[180]\tvalid_0's rmse: 0.848156\n[181]\tvalid_0's rmse: 0.84814\n[182]\tvalid_0's rmse: 0.848141\n[183]\tvalid_0's rmse: 0.848123\n[184]\tvalid_0's rmse: 0.848128\n[185]\tvalid_0's rmse: 0.848149\n[186]\tvalid_0's rmse: 0.848142\n[187]\tvalid_0's rmse: 0.848108\n[188]\tvalid_0's rmse: 0.848106\n[189]\tvalid_0's rmse: 0.84806\n[190]\tvalid_0's rmse: 0.848041\n[191]\tvalid_0's rmse: 0.848046\n[192]\tvalid_0's rmse: 0.84806\n[193]\tvalid_0's rmse: 0.848079\n[194]\tvalid_0's rmse: 0.848067\n[195]\tvalid_0's rmse: 0.848049\n[196]\tvalid_0's rmse: 0.848052\n[197]\tvalid_0's rmse: 0.848053\n[198]\tvalid_0's rmse: 0.84805\n[199]\tvalid_0's rmse: 0.848014\n[200]\tvalid_0's rmse: 0.848014\n[201]\tvalid_0's rmse: 0.847987\n[202]\tvalid_0's rmse: 0.847981\n[203]\tvalid_0's rmse: 0.847979\n[204]\tvalid_0's rmse: 0.84796\n[205]\tvalid_0's rmse: 0.847951\n[206]\tvalid_0's rmse: 0.847964\n[207]\tvalid_0's rmse: 0.847966\n[208]\tvalid_0's rmse: 0.847979\n[209]\tvalid_0's rmse: 0.847977\n[210]\tvalid_0's rmse: 0.847975\n[211]\tvalid_0's rmse: 0.847978\n[212]\tvalid_0's rmse: 0.847943\n[213]\tvalid_0's rmse: 0.847928\n[214]\tvalid_0's rmse: 0.847918\n[215]\tvalid_0's rmse: 0.847913\n[216]\tvalid_0's rmse: 0.847915\n[217]\tvalid_0's rmse: 0.847896\n[218]\tvalid_0's rmse: 0.847881\n[219]\tvalid_0's rmse: 0.847878\n[220]\tvalid_0's rmse: 0.847878\n[221]\tvalid_0's rmse: 0.847871\n[222]\tvalid_0's rmse: 0.84786\n[223]\tvalid_0's rmse: 0.847872\n[224]\tvalid_0's rmse: 0.847869\n[225]\tvalid_0's rmse: 0.847865\n[226]\tvalid_0's rmse: 0.847869\n[227]\tvalid_0's rmse: 0.847865\n[228]\tvalid_0's rmse: 0.847831\n[229]\tvalid_0's rmse: 0.847818\n[230]\tvalid_0's rmse: 0.847817\n[231]\tvalid_0's rmse: 0.847806\n[232]\tvalid_0's rmse: 0.847823\n[233]\tvalid_0's rmse: 0.847831\n[234]\tvalid_0's rmse: 0.847816\n[235]\tvalid_0's rmse: 0.847826\n[236]\tvalid_0's rmse: 0.847825\n[237]\tvalid_0's rmse: 0.847803\n[238]\tvalid_0's rmse: 0.847777\n[239]\tvalid_0's rmse: 0.847757\n[240]\tvalid_0's rmse: 0.847741\n[241]\tvalid_0's rmse: 0.847741\n[242]\tvalid_0's rmse: 0.847749\n[243]\tvalid_0's rmse: 0.847746\n[244]\tvalid_0's rmse: 0.847751\n[245]\tvalid_0's rmse: 0.847742\n[246]\tvalid_0's rmse: 0.847738\n[247]\tvalid_0's rmse: 0.847729\n[248]\tvalid_0's rmse: 0.847733\n[249]\tvalid_0's rmse: 0.847749\n[250]\tvalid_0's rmse: 0.847748\n[251]\tvalid_0's rmse: 0.847749\n[252]\tvalid_0's rmse: 0.84774\n[253]\tvalid_0's rmse: 0.847768\n[254]\tvalid_0's rmse: 0.847753\n[255]\tvalid_0's rmse: 0.847757\n[256]\tvalid_0's rmse: 0.847752\n[257]\tvalid_0's rmse: 0.847764\nEarly stopping, best iteration is:\n[247]\tvalid_0's rmse: 0.847729\n","name":"stdout"},{"output_type":"stream","text":"min_data_in_leaf, val_score: 0.847465:  40%|####      | 2/5 [00:10<00:15,  5.29s/it]\u001b[32m[I 2021-02-05 22:56:32,543]\u001b[0m Trial 61 finished with value: 0.847729422670561 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.847729422670561.\u001b[0m\nmin_data_in_leaf, val_score: 0.847465:  40%|####      | 2/5 [00:10<00:15,  5.29s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018933 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875706\n[8]\tvalid_0's rmse: 0.874453\n[9]\tvalid_0's rmse: 0.873292\n[10]\tvalid_0's rmse: 0.872257\n[11]\tvalid_0's rmse: 0.870883\n[12]\tvalid_0's rmse: 0.869682\n[13]\tvalid_0's rmse: 0.868648\n[14]\tvalid_0's rmse: 0.867611\n[15]\tvalid_0's rmse: 0.866915\n[16]\tvalid_0's rmse: 0.866143\n[17]\tvalid_0's rmse: 0.865317\n[18]\tvalid_0's rmse: 0.864692\n[19]\tvalid_0's rmse: 0.863994\n[20]\tvalid_0's rmse: 0.86344\n[21]\tvalid_0's rmse: 0.862917\n[22]\tvalid_0's rmse: 0.862269\n[23]\tvalid_0's rmse: 0.861765\n[24]\tvalid_0's rmse: 0.861212\n[25]\tvalid_0's rmse: 0.860785\n[26]\tvalid_0's rmse: 0.860342\n[27]\tvalid_0's rmse: 0.859972\n[28]\tvalid_0's rmse: 0.859586\n[29]\tvalid_0's rmse: 0.859232\n[30]\tvalid_0's rmse: 0.858936\n[31]\tvalid_0's rmse: 0.858611\n[32]\tvalid_0's rmse: 0.858256\n[33]\tvalid_0's rmse: 0.857933\n[34]\tvalid_0's rmse: 0.857575\n[35]\tvalid_0's rmse: 0.857343\n[36]\tvalid_0's rmse: 0.857037\n[37]\tvalid_0's rmse: 0.856769\n[38]\tvalid_0's rmse: 0.856477\n[39]\tvalid_0's rmse: 0.856223\n[40]\tvalid_0's rmse: 0.855941\n[41]\tvalid_0's rmse: 0.85578\n[42]\tvalid_0's rmse: 0.855549\n[43]\tvalid_0's rmse: 0.855354\n[44]\tvalid_0's rmse: 0.855129\n[45]\tvalid_0's rmse: 0.854902\n[46]\tvalid_0's rmse: 0.854746\n[47]\tvalid_0's rmse: 0.854595\n[48]\tvalid_0's rmse: 0.854431\n[49]\tvalid_0's rmse: 0.854294\n[50]\tvalid_0's rmse: 0.854129\n[51]\tvalid_0's rmse: 0.85402\n[52]\tvalid_0's rmse: 0.853864\n[53]\tvalid_0's rmse: 0.853694\n[54]\tvalid_0's rmse: 0.85353\n[55]\tvalid_0's rmse: 0.853422\n[56]\tvalid_0's rmse: 0.853185\n[57]\tvalid_0's rmse: 0.853055\n[58]\tvalid_0's rmse: 0.852906\n[59]\tvalid_0's rmse: 0.852817\n[60]\tvalid_0's rmse: 0.852669\n[61]\tvalid_0's rmse: 0.852553\n[62]\tvalid_0's rmse: 0.852459\n[63]\tvalid_0's rmse: 0.85228\n[64]\tvalid_0's rmse: 0.852104\n[65]\tvalid_0's rmse: 0.851985\n[66]\tvalid_0's rmse: 0.851896\n[67]\tvalid_0's rmse: 0.851818\n[68]\tvalid_0's rmse: 0.85174\n[69]\tvalid_0's rmse: 0.851616\n[70]\tvalid_0's rmse: 0.851472\n[71]\tvalid_0's rmse: 0.851421\n[72]\tvalid_0's rmse: 0.851354\n[73]\tvalid_0's rmse: 0.851309\n[74]\tvalid_0's rmse: 0.851222\n[75]\tvalid_0's rmse: 0.851144\n[76]\tvalid_0's rmse: 0.850997\n[77]\tvalid_0's rmse: 0.850916\n[78]\tvalid_0's rmse: 0.850814\n[79]\tvalid_0's rmse: 0.850735\n[80]\tvalid_0's rmse: 0.850683\n[81]\tvalid_0's rmse: 0.850621\n[82]\tvalid_0's rmse: 0.85054\n[83]\tvalid_0's rmse: 0.850495\n[84]\tvalid_0's rmse: 0.850386\n[85]\tvalid_0's rmse: 0.850336\n[86]\tvalid_0's rmse: 0.850296\n[87]\tvalid_0's rmse: 0.850188\n[88]\tvalid_0's rmse: 0.850123\n[89]\tvalid_0's rmse: 0.850039\n[90]\tvalid_0's rmse: 0.849965\n[91]\tvalid_0's rmse: 0.849902\n[92]\tvalid_0's rmse: 0.849867\n[93]\tvalid_0's rmse: 0.849809\n[94]\tvalid_0's rmse: 0.849768\n[95]\tvalid_0's rmse: 0.849705\n[96]\tvalid_0's rmse: 0.849671\n[97]\tvalid_0's rmse: 0.849636\n[98]\tvalid_0's rmse: 0.849583\n[99]\tvalid_0's rmse: 0.849567\n[100]\tvalid_0's rmse: 0.849507\n[101]\tvalid_0's rmse: 0.849413\n[102]\tvalid_0's rmse: 0.849345\n[103]\tvalid_0's rmse: 0.849343\n[104]\tvalid_0's rmse: 0.849255\n[105]\tvalid_0's rmse: 0.849199\n[106]\tvalid_0's rmse: 0.849194\n[107]\tvalid_0's rmse: 0.849179\n[108]\tvalid_0's rmse: 0.849133\n[109]\tvalid_0's rmse: 0.849082\n[110]\tvalid_0's rmse: 0.849076\n[111]\tvalid_0's rmse: 0.848973\n[112]\tvalid_0's rmse: 0.848933\n[113]\tvalid_0's rmse: 0.848893\n[114]\tvalid_0's rmse: 0.848885\n[115]\tvalid_0's rmse: 0.848844\n[116]\tvalid_0's rmse: 0.848829\n[117]\tvalid_0's rmse: 0.848793\n[118]\tvalid_0's rmse: 0.848791\n[119]\tvalid_0's rmse: 0.848773\n[120]\tvalid_0's rmse: 0.848732\n[121]\tvalid_0's rmse: 0.848681\n[122]\tvalid_0's rmse: 0.848646\n[123]\tvalid_0's rmse: 0.84859\n[124]\tvalid_0's rmse: 0.848584\n[125]\tvalid_0's rmse: 0.848559\n[126]\tvalid_0's rmse: 0.848536\n[127]\tvalid_0's rmse: 0.848493\n[128]\tvalid_0's rmse: 0.848464\n[129]\tvalid_0's rmse: 0.848442\n[130]\tvalid_0's rmse: 0.84844\n[131]\tvalid_0's rmse: 0.848433\n[132]\tvalid_0's rmse: 0.848396\n[133]\tvalid_0's rmse: 0.848375\n[134]\tvalid_0's rmse: 0.848379\n[135]\tvalid_0's rmse: 0.848369\n[136]\tvalid_0's rmse: 0.848322\n[137]\tvalid_0's rmse: 0.848297\n[138]\tvalid_0's rmse: 0.848311\n[139]\tvalid_0's rmse: 0.848272\n[140]\tvalid_0's rmse: 0.848264\n[141]\tvalid_0's rmse: 0.848223\n[142]\tvalid_0's rmse: 0.848202\n[143]\tvalid_0's rmse: 0.848187\n[144]\tvalid_0's rmse: 0.848182\n[145]\tvalid_0's rmse: 0.848178\n[146]\tvalid_0's rmse: 0.848178\n[147]\tvalid_0's rmse: 0.848134\n[148]\tvalid_0's rmse: 0.848137\n[149]\tvalid_0's rmse: 0.848132\n[150]\tvalid_0's rmse: 0.848107\n[151]\tvalid_0's rmse: 0.848094\n[152]\tvalid_0's rmse: 0.84807\n[153]\tvalid_0's rmse: 0.848061\n[154]\tvalid_0's rmse: 0.848023\n[155]\tvalid_0's rmse: 0.84801\n[156]\tvalid_0's rmse: 0.847994\n[157]\tvalid_0's rmse: 0.847984\n[158]\tvalid_0's rmse: 0.847982\n[159]\tvalid_0's rmse: 0.847994\n[160]\tvalid_0's rmse: 0.847983\n[161]\tvalid_0's rmse: 0.847927\n[162]\tvalid_0's rmse: 0.84791\n[163]\tvalid_0's rmse: 0.847892\n[164]\tvalid_0's rmse: 0.847876\n[165]\tvalid_0's rmse: 0.847873\n[166]\tvalid_0's rmse: 0.847837\n[167]\tvalid_0's rmse: 0.847831\n[168]\tvalid_0's rmse: 0.847799\n[169]\tvalid_0's rmse: 0.847786\n[170]\tvalid_0's rmse: 0.847761\n[171]\tvalid_0's rmse: 0.847743\n[172]\tvalid_0's rmse: 0.847713\n[173]\tvalid_0's rmse: 0.847694\n[174]\tvalid_0's rmse: 0.847677\n[175]\tvalid_0's rmse: 0.847665\n[176]\tvalid_0's rmse: 0.84764\n[177]\tvalid_0's rmse: 0.847633","name":"stdout"},{"output_type":"stream","text":"min_data_in_leaf, val_score: 0.847465:  60%|######    | 3/5 [00:15<00:10,  5.04s/it]","name":"stderr"},{"output_type":"stream","text":"\n[178]\tvalid_0's rmse: 0.847625\n[179]\tvalid_0's rmse: 0.847616\n[180]\tvalid_0's rmse: 0.847634\n[181]\tvalid_0's rmse: 0.847638\n[182]\tvalid_0's rmse: 0.847633\n[183]\tvalid_0's rmse: 0.847647\n[184]\tvalid_0's rmse: 0.847649\n[185]\tvalid_0's rmse: 0.847656\n[186]\tvalid_0's rmse: 0.847642\n[187]\tvalid_0's rmse: 0.847637\n[188]\tvalid_0's rmse: 0.847628\n[189]\tvalid_0's rmse: 0.847637\nEarly stopping, best iteration is:\n[179]\tvalid_0's rmse: 0.847616\n","name":"stdout"},{"output_type":"stream","text":"\u001b[32m[I 2021-02-05 22:56:37,286]\u001b[0m Trial 62 finished with value: 0.8476158159230099 and parameters: {'min_child_samples': 50}. Best is trial 62 with value: 0.8476158159230099.\u001b[0m\nmin_data_in_leaf, val_score: 0.847465:  60%|######    | 3/5 [00:15<00:10,  5.04s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019213 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875706\n[8]\tvalid_0's rmse: 0.874453\n[9]\tvalid_0's rmse: 0.873293\n[10]\tvalid_0's rmse: 0.872246\n[11]\tvalid_0's rmse: 0.870861\n[12]\tvalid_0's rmse: 0.869661\n[13]\tvalid_0's rmse: 0.868628\n[14]\tvalid_0's rmse: 0.867592\n[15]\tvalid_0's rmse: 0.866896\n[16]\tvalid_0's rmse: 0.866123\n[17]\tvalid_0's rmse: 0.865299\n[18]\tvalid_0's rmse: 0.864677\n[19]\tvalid_0's rmse: 0.863981\n[20]\tvalid_0's rmse: 0.86343\n[21]\tvalid_0's rmse: 0.862902\n[22]\tvalid_0's rmse: 0.862261\n[23]\tvalid_0's rmse: 0.861759\n[24]\tvalid_0's rmse: 0.861212\n[25]\tvalid_0's rmse: 0.860741\n[26]\tvalid_0's rmse: 0.860336\n[27]\tvalid_0's rmse: 0.859967\n[28]\tvalid_0's rmse: 0.859592\n[29]\tvalid_0's rmse: 0.859221\n[30]\tvalid_0's rmse: 0.858924\n[31]\tvalid_0's rmse: 0.858605\n[32]\tvalid_0's rmse: 0.85823\n[33]\tvalid_0's rmse: 0.857949\n[34]\tvalid_0's rmse: 0.85764\n[35]\tvalid_0's rmse: 0.857428\n[36]\tvalid_0's rmse: 0.857112\n[37]\tvalid_0's rmse: 0.856847\n[38]\tvalid_0's rmse: 0.856527\n[39]\tvalid_0's rmse: 0.856268\n[40]\tvalid_0's rmse: 0.855991\n[41]\tvalid_0's rmse: 0.855821\n[42]\tvalid_0's rmse: 0.855599\n[43]\tvalid_0's rmse: 0.85541\n[44]\tvalid_0's rmse: 0.855197\n[45]\tvalid_0's rmse: 0.854986\n[46]\tvalid_0's rmse: 0.85482\n[47]\tvalid_0's rmse: 0.854677\n[48]\tvalid_0's rmse: 0.8545\n[49]\tvalid_0's rmse: 0.854314\n[50]\tvalid_0's rmse: 0.854156\n[51]\tvalid_0's rmse: 0.854045\n[52]\tvalid_0's rmse: 0.853854\n[53]\tvalid_0's rmse: 0.853695\n[54]\tvalid_0's rmse: 0.853535\n[55]\tvalid_0's rmse: 0.853418\n[56]\tvalid_0's rmse: 0.853247\n[57]\tvalid_0's rmse: 0.853075\n[58]\tvalid_0's rmse: 0.852948\n[59]\tvalid_0's rmse: 0.852864\n[60]\tvalid_0's rmse: 0.852759\n[61]\tvalid_0's rmse: 0.852658\n[62]\tvalid_0's rmse: 0.852524\n[63]\tvalid_0's rmse: 0.852315\n[64]\tvalid_0's rmse: 0.852168\n[65]\tvalid_0's rmse: 0.852053\n[66]\tvalid_0's rmse: 0.851991\n[67]\tvalid_0's rmse: 0.851931\n[68]\tvalid_0's rmse: 0.851836\n[69]\tvalid_0's rmse: 0.851722\n[70]\tvalid_0's rmse: 0.851633\n[71]\tvalid_0's rmse: 0.851554\n[72]\tvalid_0's rmse: 0.85148\n[73]\tvalid_0's rmse: 0.851415\n[74]\tvalid_0's rmse: 0.85137\n[75]\tvalid_0's rmse: 0.851281\n[76]\tvalid_0's rmse: 0.851175\n[77]\tvalid_0's rmse: 0.851095\n[78]\tvalid_0's rmse: 0.851003\n[79]\tvalid_0's rmse: 0.850903\n[80]\tvalid_0's rmse: 0.85084\n[81]\tvalid_0's rmse: 0.850762\n[82]\tvalid_0's rmse: 0.850721\n[83]\tvalid_0's rmse: 0.850665\n[84]\tvalid_0's rmse: 0.850599\n[85]\tvalid_0's rmse: 0.850572\n[86]\tvalid_0's rmse: 0.850544\n[87]\tvalid_0's rmse: 0.850494\n[88]\tvalid_0's rmse: 0.850367\n[89]\tvalid_0's rmse: 0.850279\n[90]\tvalid_0's rmse: 0.850249\n[91]\tvalid_0's rmse: 0.850179\n[92]\tvalid_0's rmse: 0.850121\n[93]\tvalid_0's rmse: 0.850029\n[94]\tvalid_0's rmse: 0.849982\n[95]\tvalid_0's rmse: 0.849888\n[96]\tvalid_0's rmse: 0.849844\n[97]\tvalid_0's rmse: 0.849827\n[98]\tvalid_0's rmse: 0.849744\n[99]\tvalid_0's rmse: 0.849722\n[100]\tvalid_0's rmse: 0.849679\n[101]\tvalid_0's rmse: 0.849627\n[102]\tvalid_0's rmse: 0.849603\n[103]\tvalid_0's rmse: 0.849547\n[104]\tvalid_0's rmse: 0.849518\n[105]\tvalid_0's rmse: 0.849475\n[106]\tvalid_0's rmse: 0.849456\n[107]\tvalid_0's rmse: 0.849406\n[108]\tvalid_0's rmse: 0.84937\n[109]\tvalid_0's rmse: 0.849328\n[110]\tvalid_0's rmse: 0.849285\n[111]\tvalid_0's rmse: 0.849243\n[112]\tvalid_0's rmse: 0.849213\n[113]\tvalid_0's rmse: 0.849175\n[114]\tvalid_0's rmse: 0.849157\n[115]\tvalid_0's rmse: 0.849133\n[116]\tvalid_0's rmse: 0.849072\n[117]\tvalid_0's rmse: 0.848982\n[118]\tvalid_0's rmse: 0.848921\n[119]\tvalid_0's rmse: 0.848858\n[120]\tvalid_0's rmse: 0.848847\n[121]\tvalid_0's rmse: 0.848811\n[122]\tvalid_0's rmse: 0.848799\n[123]\tvalid_0's rmse: 0.84878\n[124]\tvalid_0's rmse: 0.848732\n[125]\tvalid_0's rmse: 0.84872\n[126]\tvalid_0's rmse: 0.848676\n[127]\tvalid_0's rmse: 0.848652\n[128]\tvalid_0's rmse: 0.848628\n[129]\tvalid_0's rmse: 0.848606\n[130]\tvalid_0's rmse: 0.848571\n[131]\tvalid_0's rmse: 0.848567\n[132]\tvalid_0's rmse: 0.848554\n[133]\tvalid_0's rmse: 0.848536\n[134]\tvalid_0's rmse: 0.848536\n[135]\tvalid_0's rmse: 0.848519\n[136]\tvalid_0's rmse: 0.848486\n[137]\tvalid_0's rmse: 0.848475\n[138]\tvalid_0's rmse: 0.848456\n[139]\tvalid_0's rmse: 0.848408\n[140]\tvalid_0's rmse: 0.848377\n[141]\tvalid_0's rmse: 0.848374\n[142]\tvalid_0's rmse: 0.848366\n[143]\tvalid_0's rmse: 0.848375\n[144]\tvalid_0's rmse: 0.848368\n[145]\tvalid_0's rmse: 0.848371\n[146]\tvalid_0's rmse: 0.848372\n[147]\tvalid_0's rmse: 0.848376\n[148]\tvalid_0's rmse: 0.848378\n[149]\tvalid_0's rmse: 0.848367\n[150]\tvalid_0's rmse: 0.848349\n[151]\tvalid_0's rmse: 0.848332\n[152]\tvalid_0's rmse: 0.848327\n[153]\tvalid_0's rmse: 0.848306\n[154]\tvalid_0's rmse: 0.848301\n[155]\tvalid_0's rmse: 0.848277\n[156]\tvalid_0's rmse: 0.848256\n[157]\tvalid_0's rmse: 0.848253\n[158]\tvalid_0's rmse: 0.848255\n[159]\tvalid_0's rmse: 0.848245\n[160]\tvalid_0's rmse: 0.848182\n[161]\tvalid_0's rmse: 0.848157\n[162]\tvalid_0's rmse: 0.848162\n[163]\tvalid_0's rmse: 0.848147\n[164]\tvalid_0's rmse: 0.848132\n[165]\tvalid_0's rmse: 0.848121\n[166]\tvalid_0's rmse: 0.848096\n[167]\tvalid_0's rmse: 0.848098\n[168]\tvalid_0's rmse: 0.848112\n[169]\tvalid_0's rmse: 0.848093\n[170]\tvalid_0's rmse: 0.848085\n[171]\tvalid_0's rmse: 0.848094\n[172]\tvalid_0's rmse: 0.848101\n[173]\tvalid_0's rmse: 0.848081\n[174]\tvalid_0's rmse: 0.848069\n[175]\tvalid_0's rmse: 0.848031\n[176]\tvalid_0's rmse: 0.848027\n[177]\tvalid_0's rmse: 0.848003\n[178]\tvalid_0's rmse: 0.847998\n[179]\tvalid_0's rmse: 0.847959\n[180]\tvalid_0's rmse: 0.847943\n[181]\tvalid_0's rmse: 0.847927\n[182]\tvalid_0's rmse: 0.847941\n[183]\tvalid_0's rmse: 0.84791\n[184]\tvalid_0's rmse: 0.84791\n[185]\tvalid_0's rmse: 0.847902\n[186]\tvalid_0's rmse: 0.847899\n[187]\tvalid_0's rmse: 0.847893\n[188]\tvalid_0's rmse: 0.847878\n[189]\tvalid_0's rmse: 0.847839\n[190]\tvalid_0's rmse: 0.847832\n[191]\tvalid_0's rmse: 0.847839\n[192]\tvalid_0's rmse: 0.84782\n[193]\tvalid_0's rmse: 0.847841\n[194]\tvalid_0's rmse: 0.847816\n[195]\tvalid_0's rmse: 0.847798\n[196]\tvalid_0's rmse: 0.847813\n[197]\tvalid_0's rmse: 0.847818\n[198]\tvalid_0's rmse: 0.847814\n[199]\tvalid_0's rmse: 0.847798\n[200]\tvalid_0's rmse: 0.847789\n[201]\tvalid_0's rmse: 0.847792\n[202]\tvalid_0's rmse: 0.847806\n[203]\tvalid_0's rmse: 0.847799\n[204]\tvalid_0's rmse: 0.847794\n[205]\tvalid_0's rmse: 0.847785\n[206]\tvalid_0's rmse: 0.847775\n[207]\tvalid_0's rmse: 0.847774\n[208]\tvalid_0's rmse: 0.847771\n[209]\tvalid_0's rmse: 0.847771\n[210]\tvalid_0's rmse: 0.84776\n[211]\tvalid_0's rmse: 0.847739\n[212]\tvalid_0's rmse: 0.847735\n[213]\tvalid_0's rmse: 0.847721\n[214]\tvalid_0's rmse: 0.847717\n[215]\tvalid_0's rmse: 0.847716\n[216]\tvalid_0's rmse: 0.847728\n[217]\tvalid_0's rmse: 0.847695\n[218]\tvalid_0's rmse: 0.847702\n[219]\tvalid_0's rmse: 0.847672\n[220]\tvalid_0's rmse: 0.847633\n[221]\tvalid_0's rmse: 0.847626\n[222]\tvalid_0's rmse: 0.847626\n[223]\tvalid_0's rmse: 0.847647\n[224]\tvalid_0's rmse: 0.847641\n[225]\tvalid_0's rmse: 0.847621\n[226]\tvalid_0's rmse: 0.847582\n[227]\tvalid_0's rmse: 0.847589\n[228]\tvalid_0's rmse: 0.847618\n[229]\tvalid_0's rmse: 0.847602\n[230]\tvalid_0's rmse: 0.847592\n[231]\tvalid_0's rmse: 0.847579\n[232]\tvalid_0's rmse: 0.847615\n[233]\tvalid_0's rmse: 0.847602\n[234]\tvalid_0's rmse: 0.847622\n[235]\tvalid_0's rmse: 0.847612\n[236]\tvalid_0's rmse: 0.847622\n[237]\tvalid_0's rmse: 0.847617\n[238]\tvalid_0's rmse: 0.847624\n[239]\tvalid_0's rmse: 0.847614\n[240]\tvalid_0's rmse: 0.84761\n[241]\tvalid_0's rmse: 0.847596\nEarly stopping, best iteration is:\n[231]\tvalid_0's rmse: 0.847579\n","name":"stdout"},{"output_type":"stream","text":"min_data_in_leaf, val_score: 0.847465:  80%|########  | 4/5 [00:20<00:05,  5.17s/it]\u001b[32m[I 2021-02-05 22:56:42,645]\u001b[0m Trial 63 finished with value: 0.8475794107209788 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.8475794107209788.\u001b[0m\nmin_data_in_leaf, val_score: 0.847465:  80%|########  | 4/5 [00:20<00:05,  5.17s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018957 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860393\n[27]\tvalid_0's rmse: 0.860019\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859251\n[30]\tvalid_0's rmse: 0.85889\n[31]\tvalid_0's rmse: 0.85857\n[32]\tvalid_0's rmse: 0.858224\n[33]\tvalid_0's rmse: 0.857909\n[34]\tvalid_0's rmse: 0.857558\n[35]\tvalid_0's rmse: 0.857338\n[36]\tvalid_0's rmse: 0.857014\n[37]\tvalid_0's rmse: 0.856751\n[38]\tvalid_0's rmse: 0.856452\n[39]\tvalid_0's rmse: 0.856196\n[40]\tvalid_0's rmse: 0.855916\n[41]\tvalid_0's rmse: 0.855757\n[42]\tvalid_0's rmse: 0.855529\n[43]\tvalid_0's rmse: 0.855342\n[44]\tvalid_0's rmse: 0.855119\n[45]\tvalid_0's rmse: 0.854909\n[46]\tvalid_0's rmse: 0.854748\n[47]\tvalid_0's rmse: 0.854617\n[48]\tvalid_0's rmse: 0.854446\n[49]\tvalid_0's rmse: 0.854248\n[50]\tvalid_0's rmse: 0.854102\n[51]\tvalid_0's rmse: 0.853989\n[52]\tvalid_0's rmse: 0.85385\n[53]\tvalid_0's rmse: 0.853687\n[54]\tvalid_0's rmse: 0.853554\n[55]\tvalid_0's rmse: 0.853458\n[56]\tvalid_0's rmse: 0.853226\n[57]\tvalid_0's rmse: 0.853097\n[58]\tvalid_0's rmse: 0.852953\n[59]\tvalid_0's rmse: 0.852885\n[60]\tvalid_0's rmse: 0.852769\n[61]\tvalid_0's rmse: 0.852669\n[62]\tvalid_0's rmse: 0.852507\n[63]\tvalid_0's rmse: 0.85236\n[64]\tvalid_0's rmse: 0.852206\n[65]\tvalid_0's rmse: 0.852084\n[66]\tvalid_0's rmse: 0.851987\n[67]\tvalid_0's rmse: 0.851924\n[68]\tvalid_0's rmse: 0.85183\n[69]\tvalid_0's rmse: 0.851727\n[70]\tvalid_0's rmse: 0.851645\n[71]\tvalid_0's rmse: 0.851596\n[72]\tvalid_0's rmse: 0.851521\n[73]\tvalid_0's rmse: 0.851445\n[74]\tvalid_0's rmse: 0.851423\n[75]\tvalid_0's rmse: 0.851324\n[76]\tvalid_0's rmse: 0.851135\n[77]\tvalid_0's rmse: 0.851069\n[78]\tvalid_0's rmse: 0.850974\n[79]\tvalid_0's rmse: 0.850896\n[80]\tvalid_0's rmse: 0.850842\n[81]\tvalid_0's rmse: 0.850768\n[82]\tvalid_0's rmse: 0.850721\n[83]\tvalid_0's rmse: 0.85067\n[84]\tvalid_0's rmse: 0.850624\n[85]\tvalid_0's rmse: 0.850562\n[86]\tvalid_0's rmse: 0.850521\n[87]\tvalid_0's rmse: 0.850433\n[88]\tvalid_0's rmse: 0.850312\n[89]\tvalid_0's rmse: 0.850302\n[90]\tvalid_0's rmse: 0.850271\n[91]\tvalid_0's rmse: 0.850215\n[92]\tvalid_0's rmse: 0.850129\n[93]\tvalid_0's rmse: 0.850057\n[94]\tvalid_0's rmse: 0.850008\n[95]\tvalid_0's rmse: 0.849923\n[96]\tvalid_0's rmse: 0.849868\n[97]\tvalid_0's rmse: 0.849823\n[98]\tvalid_0's rmse: 0.849705\n[99]\tvalid_0's rmse: 0.849664\n[100]\tvalid_0's rmse: 0.849626\n[101]\tvalid_0's rmse: 0.849604\n[102]\tvalid_0's rmse: 0.849561\n[103]\tvalid_0's rmse: 0.849513\n[104]\tvalid_0's rmse: 0.84947\n[105]\tvalid_0's rmse: 0.849429\n[106]\tvalid_0's rmse: 0.849397\n[107]\tvalid_0's rmse: 0.849361\n[108]\tvalid_0's rmse: 0.849277\n[109]\tvalid_0's rmse: 0.849203\n[110]\tvalid_0's rmse: 0.849191\n[111]\tvalid_0's rmse: 0.84916\n[112]\tvalid_0's rmse: 0.849121\n[113]\tvalid_0's rmse: 0.849057\n[114]\tvalid_0's rmse: 0.849047\n[115]\tvalid_0's rmse: 0.849033\n[116]\tvalid_0's rmse: 0.849011\n[117]\tvalid_0's rmse: 0.848926\n[118]\tvalid_0's rmse: 0.848934\n[119]\tvalid_0's rmse: 0.84888\n[120]\tvalid_0's rmse: 0.848844\n[121]\tvalid_0's rmse: 0.848826\n[122]\tvalid_0's rmse: 0.848814\n[123]\tvalid_0's rmse: 0.848795\n[124]\tvalid_0's rmse: 0.848783\n[125]\tvalid_0's rmse: 0.848748\n[126]\tvalid_0's rmse: 0.848724\n[127]\tvalid_0's rmse: 0.848708\n[128]\tvalid_0's rmse: 0.848705\n[129]\tvalid_0's rmse: 0.848707\n[130]\tvalid_0's rmse: 0.848681\n[131]\tvalid_0's rmse: 0.848635\n[132]\tvalid_0's rmse: 0.848624\n[133]\tvalid_0's rmse: 0.848606\n[134]\tvalid_0's rmse: 0.848582\n[135]\tvalid_0's rmse: 0.848533\n[136]\tvalid_0's rmse: 0.8485\n[137]\tvalid_0's rmse: 0.848461\n[138]\tvalid_0's rmse: 0.848464\n[139]\tvalid_0's rmse: 0.84842\n[140]\tvalid_0's rmse: 0.848422\n[141]\tvalid_0's rmse: 0.848392\n[142]\tvalid_0's rmse: 0.848383\n[143]\tvalid_0's rmse: 0.848365\n[144]\tvalid_0's rmse: 0.848345\n[145]\tvalid_0's rmse: 0.84835\n[146]\tvalid_0's rmse: 0.848304\n[147]\tvalid_0's rmse: 0.84828\n[148]\tvalid_0's rmse: 0.848262\n[149]\tvalid_0's rmse: 0.848265\n[150]\tvalid_0's rmse: 0.848267\n[151]\tvalid_0's rmse: 0.848268\n[152]\tvalid_0's rmse: 0.848244\n[153]\tvalid_0's rmse: 0.848243\n[154]\tvalid_0's rmse: 0.848235\n[155]\tvalid_0's rmse: 0.848224\n[156]\tvalid_0's rmse: 0.848226\n[157]\tvalid_0's rmse: 0.848241\n[158]\tvalid_0's rmse: 0.848239\n[159]\tvalid_0's rmse: 0.848241\n[160]\tvalid_0's rmse: 0.848195\n[161]\tvalid_0's rmse: 0.848179\n[162]\tvalid_0's rmse: 0.848171\n[163]\tvalid_0's rmse: 0.848151\n[164]\tvalid_0's rmse: 0.848143\n[165]\tvalid_0's rmse: 0.848133\n[166]\tvalid_0's rmse: 0.848112\n[167]\tvalid_0's rmse: 0.848098\n[168]\tvalid_0's rmse: 0.848084\n[169]\tvalid_0's rmse: 0.848035\n[170]\tvalid_0's rmse: 0.848016\n[171]\tvalid_0's rmse: 0.84801\n[172]\tvalid_0's rmse: 0.848013\n[173]\tvalid_0's rmse: 0.848003\n[174]\tvalid_0's rmse: 0.847995\n[175]\tvalid_0's rmse: 0.847983\n[176]\tvalid_0's rmse: 0.847964\n[177]\tvalid_0's rmse: 0.847962\n[178]\tvalid_0's rmse: 0.847949\n[179]\tvalid_0's rmse: 0.847916\n[180]\tvalid_0's rmse: 0.847942\n[181]\tvalid_0's rmse: 0.847929\n[182]\tvalid_0's rmse: 0.847911\n","name":"stdout"},{"output_type":"stream","text":"min_data_in_leaf, val_score: 0.847465: 100%|##########| 5/5 [00:25<00:00,  5.00s/it]","name":"stderr"},{"output_type":"stream","text":"[183]\tvalid_0's rmse: 0.847919\n[184]\tvalid_0's rmse: 0.847928\n[185]\tvalid_0's rmse: 0.84791\n[186]\tvalid_0's rmse: 0.847892\n[187]\tvalid_0's rmse: 0.8479\n[188]\tvalid_0's rmse: 0.847902\n[189]\tvalid_0's rmse: 0.847921\n[190]\tvalid_0's rmse: 0.847918\n[191]\tvalid_0's rmse: 0.847944\n[192]\tvalid_0's rmse: 0.847934\n[193]\tvalid_0's rmse: 0.847914\n[194]\tvalid_0's rmse: 0.847924\n[195]\tvalid_0's rmse: 0.847929\n[196]\tvalid_0's rmse: 0.847943\nEarly stopping, best iteration is:\n[186]\tvalid_0's rmse: 0.847892\n","name":"stdout"},{"output_type":"stream","text":"\u001b[32m[I 2021-02-05 22:56:47,365]\u001b[0m Trial 64 finished with value: 0.8478917517714692 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.8475794107209788.\u001b[0m\nmin_data_in_leaf, val_score: 0.847465: 100%|##########| 5/5 [00:25<00:00,  5.06s/it]\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019157 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3662\n[LightGBM] [Info] Number of data points in the train set: 239999, number of used features: 60\n[LightGBM] [Info] Start training from score 7.457212\n[1]\tvalid_0's rmse: 0.888331\nTraining until validation scores don't improve for 10 rounds\n[2]\tvalid_0's rmse: 0.885546\n[3]\tvalid_0's rmse: 0.883304\n[4]\tvalid_0's rmse: 0.881132\n[5]\tvalid_0's rmse: 0.879271\n[6]\tvalid_0's rmse: 0.877206\n[7]\tvalid_0's rmse: 0.875721\n[8]\tvalid_0's rmse: 0.874468\n[9]\tvalid_0's rmse: 0.873307\n[10]\tvalid_0's rmse: 0.87227\n[11]\tvalid_0's rmse: 0.870894\n[12]\tvalid_0's rmse: 0.869691\n[13]\tvalid_0's rmse: 0.868656\n[14]\tvalid_0's rmse: 0.867618\n[15]\tvalid_0's rmse: 0.866922\n[16]\tvalid_0's rmse: 0.866149\n[17]\tvalid_0's rmse: 0.865324\n[18]\tvalid_0's rmse: 0.8647\n[19]\tvalid_0's rmse: 0.864002\n[20]\tvalid_0's rmse: 0.86345\n[21]\tvalid_0's rmse: 0.86292\n[22]\tvalid_0's rmse: 0.862274\n[23]\tvalid_0's rmse: 0.861772\n[24]\tvalid_0's rmse: 0.861232\n[25]\tvalid_0's rmse: 0.860808\n[26]\tvalid_0's rmse: 0.860394\n[27]\tvalid_0's rmse: 0.86002\n[28]\tvalid_0's rmse: 0.859615\n[29]\tvalid_0's rmse: 0.859253\n[30]\tvalid_0's rmse: 0.858893\n[31]\tvalid_0's rmse: 0.858572\n[32]\tvalid_0's rmse: 0.858226\n[33]\tvalid_0's rmse: 0.8579\n[34]\tvalid_0's rmse: 0.857477\n[35]\tvalid_0's rmse: 0.857221\n[36]\tvalid_0's rmse: 0.856903\n[37]\tvalid_0's rmse: 0.856634\n[38]\tvalid_0's rmse: 0.856331\n[39]\tvalid_0's rmse: 0.856086\n[40]\tvalid_0's rmse: 0.855812\n[41]\tvalid_0's rmse: 0.855645\n[42]\tvalid_0's rmse: 0.855417\n[43]\tvalid_0's rmse: 0.855242\n[44]\tvalid_0's rmse: 0.854985\n[45]\tvalid_0's rmse: 0.854787\n[46]\tvalid_0's rmse: 0.854636\n[47]\tvalid_0's rmse: 0.854461\n[48]\tvalid_0's rmse: 0.854269\n[49]\tvalid_0's rmse: 0.854125\n[50]\tvalid_0's rmse: 0.853964\n[51]\tvalid_0's rmse: 0.853865\n[52]\tvalid_0's rmse: 0.8537\n[53]\tvalid_0's rmse: 0.853529\n[54]\tvalid_0's rmse: 0.853385\n[55]\tvalid_0's rmse: 0.853278\n[56]\tvalid_0's rmse: 0.853055\n[57]\tvalid_0's rmse: 0.852945\n[58]\tvalid_0's rmse: 0.852806\n[59]\tvalid_0's rmse: 0.852713\n[60]\tvalid_0's rmse: 0.852564\n[61]\tvalid_0's rmse: 0.852466\n[62]\tvalid_0's rmse: 0.852324\n[63]\tvalid_0's rmse: 0.852227\n[64]\tvalid_0's rmse: 0.852092\n[65]\tvalid_0's rmse: 0.851937\n[66]\tvalid_0's rmse: 0.851845\n[67]\tvalid_0's rmse: 0.851791\n[68]\tvalid_0's rmse: 0.851695\n[69]\tvalid_0's rmse: 0.851639\n[70]\tvalid_0's rmse: 0.851507\n[71]\tvalid_0's rmse: 0.85144\n[72]\tvalid_0's rmse: 0.851368\n[73]\tvalid_0's rmse: 0.851328\n[74]\tvalid_0's rmse: 0.851291\n[75]\tvalid_0's rmse: 0.85119\n[76]\tvalid_0's rmse: 0.851081\n[77]\tvalid_0's rmse: 0.851017\n[78]\tvalid_0's rmse: 0.850939\n[79]\tvalid_0's rmse: 0.850837\n[80]\tvalid_0's rmse: 0.850725\n[81]\tvalid_0's rmse: 0.850637\n[82]\tvalid_0's rmse: 0.850558\n[83]\tvalid_0's rmse: 0.85052\n[84]\tvalid_0's rmse: 0.850455\n[85]\tvalid_0's rmse: 0.850384\n[86]\tvalid_0's rmse: 0.850377\n[87]\tvalid_0's rmse: 0.85028\n[88]\tvalid_0's rmse: 0.850185\n[89]\tvalid_0's rmse: 0.850116\n[90]\tvalid_0's rmse: 0.850084\n[91]\tvalid_0's rmse: 0.85002\n[92]\tvalid_0's rmse: 0.849916\n[93]\tvalid_0's rmse: 0.849875\n[94]\tvalid_0's rmse: 0.849811\n[95]\tvalid_0's rmse: 0.849732\n[96]\tvalid_0's rmse: 0.849699\n[97]\tvalid_0's rmse: 0.849653\n[98]\tvalid_0's rmse: 0.849627\n[99]\tvalid_0's rmse: 0.849594\n[100]\tvalid_0's rmse: 0.849572\n[101]\tvalid_0's rmse: 0.849509\n[102]\tvalid_0's rmse: 0.849416\n[103]\tvalid_0's rmse: 0.84937\n[104]\tvalid_0's rmse: 0.849337\n[105]\tvalid_0's rmse: 0.849295\n[106]\tvalid_0's rmse: 0.849237\n[107]\tvalid_0's rmse: 0.849193\n[108]\tvalid_0's rmse: 0.849152\n[109]\tvalid_0's rmse: 0.849084\n[110]\tvalid_0's rmse: 0.849078\n[111]\tvalid_0's rmse: 0.849039\n[112]\tvalid_0's rmse: 0.849015\n[113]\tvalid_0's rmse: 0.848988\n[114]\tvalid_0's rmse: 0.848957\n[115]\tvalid_0's rmse: 0.848962\n[116]\tvalid_0's rmse: 0.848922\n[117]\tvalid_0's rmse: 0.848876\n[118]\tvalid_0's rmse: 0.848854\n[119]\tvalid_0's rmse: 0.848794\n[120]\tvalid_0's rmse: 0.848739\n[121]\tvalid_0's rmse: 0.848651\n[122]\tvalid_0's rmse: 0.848624\n[123]\tvalid_0's rmse: 0.848621\n[124]\tvalid_0's rmse: 0.848599\n[125]\tvalid_0's rmse: 0.84856\n[126]\tvalid_0's rmse: 0.848531\n[127]\tvalid_0's rmse: 0.848479\n[128]\tvalid_0's rmse: 0.848454\n[129]\tvalid_0's rmse: 0.848416\n[130]\tvalid_0's rmse: 0.848418\n[131]\tvalid_0's rmse: 0.848398\n[132]\tvalid_0's rmse: 0.848388\n[133]\tvalid_0's rmse: 0.848403\n[134]\tvalid_0's rmse: 0.84837\n[135]\tvalid_0's rmse: 0.84836\n[136]\tvalid_0's rmse: 0.848347\n[137]\tvalid_0's rmse: 0.848343\n[138]\tvalid_0's rmse: 0.848324\n[139]\tvalid_0's rmse: 0.848312\n[140]\tvalid_0's rmse: 0.848303\n[141]\tvalid_0's rmse: 0.848296\n[142]\tvalid_0's rmse: 0.848294\n[143]\tvalid_0's rmse: 0.848251\n[144]\tvalid_0's rmse: 0.84826\n[145]\tvalid_0's rmse: 0.848238\n[146]\tvalid_0's rmse: 0.848251\n[147]\tvalid_0's rmse: 0.848233\n[148]\tvalid_0's rmse: 0.848215\n[149]\tvalid_0's rmse: 0.848232\n[150]\tvalid_0's rmse: 0.848235\n[151]\tvalid_0's rmse: 0.848245\n[152]\tvalid_0's rmse: 0.84824\n[153]\tvalid_0's rmse: 0.848255\n[154]\tvalid_0's rmse: 0.848242\n[155]\tvalid_0's rmse: 0.848243\n[156]\tvalid_0's rmse: 0.848232\n[157]\tvalid_0's rmse: 0.84821\n[158]\tvalid_0's rmse: 0.848221\n[159]\tvalid_0's rmse: 0.848224\n[160]\tvalid_0's rmse: 0.848216\n[161]\tvalid_0's rmse: 0.848207\n[162]\tvalid_0's rmse: 0.848207\n[163]\tvalid_0's rmse: 0.848198\n[164]\tvalid_0's rmse: 0.848182\n[165]\tvalid_0's rmse: 0.848161\n[166]\tvalid_0's rmse: 0.848115\n[167]\tvalid_0's rmse: 0.848121\n[168]\tvalid_0's rmse: 0.848103\n[169]\tvalid_0's rmse: 0.848116\n[170]\tvalid_0's rmse: 0.848117\n[171]\tvalid_0's rmse: 0.848121\n[172]\tvalid_0's rmse: 0.848123\n[173]\tvalid_0's rmse: 0.848093\n[174]\tvalid_0's rmse: 0.848097\n[175]\tvalid_0's rmse: 0.848073\n[176]\tvalid_0's rmse: 0.848057\n[177]\tvalid_0's rmse: 0.848054\n[178]\tvalid_0's rmse: 0.848034\n[179]\tvalid_0's rmse: 0.84804\n[180]\tvalid_0's rmse: 0.847989\n[181]\tvalid_0's rmse: 0.847994\n[182]\tvalid_0's rmse: 0.847976\n[183]\tvalid_0's rmse: 0.847969\n[184]\tvalid_0's rmse: 0.847974\n[185]\tvalid_0's rmse: 0.847947\n[186]\tvalid_0's rmse: 0.847958\n[187]\tvalid_0's rmse: 0.847959\n[188]\tvalid_0's rmse: 0.847942\n[189]\tvalid_0's rmse: 0.847952\n[190]\tvalid_0's rmse: 0.847913\n[191]\tvalid_0's rmse: 0.847883\n[192]\tvalid_0's rmse: 0.847885\n[193]\tvalid_0's rmse: 0.84787\n[194]\tvalid_0's rmse: 0.847813\n[195]\tvalid_0's rmse: 0.847808\n[196]\tvalid_0's rmse: 0.847808\n[197]\tvalid_0's rmse: 0.847795\n[198]\tvalid_0's rmse: 0.8478\n[199]\tvalid_0's rmse: 0.847784\n[200]\tvalid_0's rmse: 0.847785\n[201]\tvalid_0's rmse: 0.847782\n[202]\tvalid_0's rmse: 0.847756\n[203]\tvalid_0's rmse: 0.847708\n[204]\tvalid_0's rmse: 0.847715\n[205]\tvalid_0's rmse: 0.847706\n[206]\tvalid_0's rmse: 0.847701\n[207]\tvalid_0's rmse: 0.8477\n[208]\tvalid_0's rmse: 0.847704\n[209]\tvalid_0's rmse: 0.847687\n[210]\tvalid_0's rmse: 0.847682\n[211]\tvalid_0's rmse: 0.847663\n[212]\tvalid_0's rmse: 0.847636\n[213]\tvalid_0's rmse: 0.847636\n[214]\tvalid_0's rmse: 0.847642\n[215]\tvalid_0's rmse: 0.847637\n[216]\tvalid_0's rmse: 0.847633\n[217]\tvalid_0's rmse: 0.847628\n[218]\tvalid_0's rmse: 0.847616\n[219]\tvalid_0's rmse: 0.84759\n[220]\tvalid_0's rmse: 0.847593\n[221]\tvalid_0's rmse: 0.84759\n[222]\tvalid_0's rmse: 0.847597\n[223]\tvalid_0's rmse: 0.847572\n[224]\tvalid_0's rmse: 0.847559\n[225]\tvalid_0's rmse: 0.847589\n[226]\tvalid_0's rmse: 0.847599\n[227]\tvalid_0's rmse: 0.847572\n[228]\tvalid_0's rmse: 0.847573\n[229]\tvalid_0's rmse: 0.847568\n[230]\tvalid_0's rmse: 0.84755\n[231]\tvalid_0's rmse: 0.847556\n[232]\tvalid_0's rmse: 0.84755\n[233]\tvalid_0's rmse: 0.847525\n[234]\tvalid_0's rmse: 0.847511\n[235]\tvalid_0's rmse: 0.847513\n[236]\tvalid_0's rmse: 0.847511\n[237]\tvalid_0's rmse: 0.847522\n[238]\tvalid_0's rmse: 0.847505\n[239]\tvalid_0's rmse: 0.847503\n[240]\tvalid_0's rmse: 0.8475\n[241]\tvalid_0's rmse: 0.847512\n[242]\tvalid_0's rmse: 0.847511\n[243]\tvalid_0's rmse: 0.847496\n[244]\tvalid_0's rmse: 0.847499\n[245]\tvalid_0's rmse: 0.847501\n[246]\tvalid_0's rmse: 0.847497\n[247]\tvalid_0's rmse: 0.847495\n[248]\tvalid_0's rmse: 0.847483\n[249]\tvalid_0's rmse: 0.847475\n[250]\tvalid_0's rmse: 0.84747\n[251]\tvalid_0's rmse: 0.847476\n[252]\tvalid_0's rmse: 0.847478\n[253]\tvalid_0's rmse: 0.847477\n[254]\tvalid_0's rmse: 0.847475\n[255]\tvalid_0's rmse: 0.847465\n","name":"stdout"},{"output_type":"stream","text":"[256]\tvalid_0's rmse: 0.847466\n[257]\tvalid_0's rmse: 0.847479\n[258]\tvalid_0's rmse: 0.847489\n[259]\tvalid_0's rmse: 0.847487\n[260]\tvalid_0's rmse: 0.84747\n[261]\tvalid_0's rmse: 0.847473\n[262]\tvalid_0's rmse: 0.847469\n[263]\tvalid_0's rmse: 0.8475\n[264]\tvalid_0's rmse: 0.847498\n[265]\tvalid_0's rmse: 0.847511\nEarly stopping, best iteration is:\n[255]\tvalid_0's rmse: 0.847465\n0.7181975070303817\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport lightgbm as lgb\n\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nrmse=[]  # list contains rmse for each fold\nn=0\npreds=0\n\n# kf.splitはindexを返すことに注意。データ自体じゃないよ!\nfor train, test in kf.split(X, y):\n    model = lgb.LGBMRegressor(**best_params)\n    x_tr = X.iloc[train, :].values\n    x_te = X.iloc[test,  :].values\n    y_tr = y.iloc[train].values\n    y_te = y.iloc[test].values\n    \n    model.fit(x_tr,y_tr,eval_set=[(x_te,y_te)],early_stopping_rounds=100,verbose=False)\n    rmse.append(mean_squared_error(y_te, model.predict(x_te), squared=False))\n    preds+=model.predict(X_prediction)\n    print(n+1,rmse[n])\n    n+=1\n\ny_pred = preds/kf.n_splits\nimport statistics as stat\nprint(f'RMSE mean = {stat.mean(rmse)}')\nprint(f'RMSE = {rmse}')","execution_count":4,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] lambda_l1 is set=3.091223000030874e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.091223000030874e-06\n[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n[LightGBM] [Warning] lambda_l2 is set=0.0005486056579747929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005486056579747929\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n1 0.8423521171301173\n[LightGBM] [Warning] lambda_l1 is set=3.091223000030874e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.091223000030874e-06\n[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n[LightGBM] [Warning] lambda_l2 is set=0.0005486056579747929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005486056579747929\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"2 0.8463045408944343\n[LightGBM] [Warning] lambda_l1 is set=3.091223000030874e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.091223000030874e-06\n[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n[LightGBM] [Warning] lambda_l2 is set=0.0005486056579747929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005486056579747929\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"3 0.8466526687737727\n[LightGBM] [Warning] lambda_l1 is set=3.091223000030874e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.091223000030874e-06\n[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n[LightGBM] [Warning] lambda_l2 is set=0.0005486056579747929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005486056579747929\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"4 0.8434694053761003\n[LightGBM] [Warning] lambda_l1 is set=3.091223000030874e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.091223000030874e-06\n[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n[LightGBM] [Warning] lambda_l2 is set=0.0005486056579747929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005486056579747929\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"5 0.8432270968880907\nRMSE mean = 0.844401165812503\nRMSE = [0.8423521171301173, 0.8463045408944343, 0.8466526687737727, 0.8434694053761003, 0.8432270968880907]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## CatBoost Optuna\nfrom catboost import CatBoostRegressor\nfrom catboost import Pool\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport optuna\n\ncat_train = Pool(X_train, y_train, cat_features=category)\ncat_test = Pool(X_test, y_test, cat_features=category)\n\ndef objective(trial):\n    params = {\n        'iterations': trial.suggest_int('iterations', 50, 500),\n        'depth': trial.suggest_int('depth', 4, 10),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n        'l2_leaf_reg': trial.suggest_int('l2_leaf', 1,10),\n        'eval_metric': trial.suggest_categorical('eval_metric', ['RMSE']),\n        'random_strength': trial.suggest_int('random_strength', 0, 100),\n        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n        'od_wait': trial.suggest_int('od_wait', 10, 50),\n        'use_best_model': True,\n        'cat_features': category\n    }  \n    \n    model = CatBoostRegressor(**params)\n    model.fit(cat_train, eval_set = cat_test)\n    y_pred = model.predict(cat_test)\n    \n    return np.sqrt(mean_squared_error(y_test, y_pred))\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=20, n_jobs=-1)\ncat_best = study.best_params\nprint(cat_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n    \n    def fit(self, X, y, X_test, y_test):\n        self.models_ = [clone(x) for x in self.models]\n\n        for model in self.models_:\n            # CatBoostに関しては、eval_setが必須のためここでエラーが発生する。\n            # その場合はexceptでfit処理を行う\n            print(f'************ RUNNING : {model} ************')\n            try:\n                model.fit(X, y)\n            except:\n                model.fit(X, y, eval_set=(X_test, y_test))\n                \n            y_pred = model.predict(X_test)\n            print(f'{model} RMSE: {mean_squared_error(y_test, y_pred)}')\n            \n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack(\n            [model.predict(X) for model in self.models_]\n            )\n        return np.mean(predictions, axis=1)\n\n    \naveraged_models = AveragingModels(models = (cat, lasso, lgb_tuned))\naveraged_models.fit(X_train, y_train, X_test, y_test)\n\n# 予想してみる\nfrom sklearn.metrics import mean_squared_error\ny_pred = averaged_models.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\ndef rmse(y_true, y_pred):\n    return tf.sqrt(tf.losses.mean_squared_error(y_true, y_pred))\n\n### ***********************************************************###\nmodel = tf.keras.Sequential()\n\n#model.add(tf.keras.layers.Dense(1024, activation='relu', input_shape=(X.shape[1],)))\n#model.add(tf.keras.layers.LeakyReLU())\n#model.add(tf.keras.layers.BatchNormalization())\n#model.add(tf.keras.layers.Dropout(0.5))\n\n#model.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu',input_shape=(X.shape[1],)))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.4))\n\n#model.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.4))\n\n#model.add(tf.keras.layers.Dense(units=256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#model.add(tf.keras.layers.Dense(units=256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#model.add(tf.keras.layers.Dense(units=128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\nmodel.add(tf.keras.layers.LeakyReLU())\n\nmodel.add(tf.keras.layers.Dense(units=1, activation='linear'))\n### ***********************************************************###\n\noptimizer = tf.keras.optimizers.Adam(lr=0.005, decay=5e-4)\nmodel.compile(optimizer = optimizer, loss = 'mae', metrics = ['mse', 'mae'])\n\n#checkpoint_name = 'Model/{epoch:03d}-{val_loss:.5f}.hdf5'\ncheckpoint_name = 'DNN_BestModel.hdf5'\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\ncallback_list = [checkpoint]\n\nhistory = model.fit(X_train, y_train, validation_split=0.2, epochs = 500, batch_size = 1024,\n                    validation_data=(X_test, y_test), callbacks=callback_list)\ny_pred = model.predict(X_test).reshape(-1)\nRMSE = rmse(y_test, y_pred)\nprint(f'RMSE = {RMSE}')\n\nfig = plt.figure(figsize=(8,5))\nax = fig.add_subplot(111)\nax.set_ylim(0.6, 0.75)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.savefig(fname='1024 neurons enable LearningRate.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# CatBoosting\n'''\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfrom sklearn.model_selection import GridSearchCV\nparam_cat = {'depth':[6,8,10],\n            'learning_rate':[0.005, 0.001],\n            'l2_leaf_reg':[1,4,9],\n            'iterations':[100],\n            'cat_features':[feature_cat],\n            'eval_metric':['RMSE']\n            }\n\ngrid_result = GridSearchCV(estimator=CatBoostRegressor(),param_grid=param_cat, cv=kfold, scoring='neg_mean_squared_error', n_jobs = -1, verbose=2)\ngrid_result.fit(X_train, y_train)\ngrid_param = grid_result.best_params_\nprint(grid_param)\n\n\ncat = CatBoostRegressor(task_type='GPU', iterations=8000, use_best_model=True, depth=10, eval_metric='RMSE', l2_leaf_reg=1, learning_rate=0.001, early_stopping_rounds=10)\ncat.fit(X_train, y_train, cat_features=feature_cat, eval_set = (X_test, y_test))\ny_pred = cat.predict(X_test)\nprint(f'RMSE: {mean_squared_error(y_test, y_pred)}')\n\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred=regressor.predict(X_prediction)\noutput = pd.DataFrame({'id': prediction_id, 'target': y_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}